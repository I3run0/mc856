{"0.0.1":{"info":{"author":null,"author_email":"Nathan Tam <nathan1295@gmail.com>","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":"MIT","maintainer":null,"maintainer_email":null,"name":"mlx-textgen","package_url":"https://pypi.org/project/mlx-textgen/","platform":null,"project_url":"https://pypi.org/project/mlx-textgen/","project_urls":{"Homepage":"https://github.com/nath1295/MLX-Textgen"},"provides_extra":null,"release_url":"https://pypi.org/project/mlx-textgen/0.0.1/","requires_dist":["mlx-lm>=0.18.2","orjson","fastapi","uvicorn"],"requires_python":">=3.9","summary":"A python package for serving LLM on OpenAI-compatible API endpoints with prompt caching using MLX.","version":"0.0.1","yanked":false,"yanked_reason":null},"last_serial":25696038,"urls":[{"comment_text":"","digests":{"blake2b_256":"5aa2daebb9fd5cba667f67c0da3bb206616e1470055c02b403e2c991f079065a","md5":"a0260c43694c8cc749b693103ff94c8a","sha256":"d3b40758c78e77bb6add3acbf76d863c9da633dd457eb55877623efa66534632"},"downloads":-1,"filename":"mlx_textgen-0.0.1.tar.gz","has_sig":false,"md5_digest":"a0260c43694c8cc749b693103ff94c8a","packagetype":"sdist","python_version":"source","requires_python":">=3.9","size":21309,"upload_time":"2024-09-30T18:16:30","upload_time_iso_8601":"2024-09-30T18:16:30.988237Z","url":"https://files.pythonhosted.org/packages/5a/a2/daebb9fd5cba667f67c0da3bb206616e1470055c02b403e2c991f079065a/mlx_textgen-0.0.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.2":{"info":{"author":null,"author_email":"Nathan Tam <nathan1295@gmail.com>","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":"MIT","maintainer":null,"maintainer_email":null,"name":"mlx-textgen","package_url":"https://pypi.org/project/mlx-textgen/","platform":null,"project_url":"https://pypi.org/project/mlx-textgen/","project_urls":{"Homepage":"https://github.com/nath1295/MLX-Textgen"},"provides_extra":null,"release_url":"https://pypi.org/project/mlx-textgen/0.0.2/","requires_dist":["mlx-lm>=0.18.2","orjson","fastapi","uvicorn"],"requires_python":">=3.9","summary":"A python package for serving LLM on OpenAI-compatible API endpoints with prompt caching using MLX.","version":"0.0.2","yanked":false,"yanked_reason":null},"last_serial":25696038,"urls":[{"comment_text":"","digests":{"blake2b_256":"8345b56c2b0587c61006f3396fe260f8c098819ed31d650ed882d10f34a4d9ac","md5":"ca5a9253777333f438a18d588686164f","sha256":"b630dc4071ddab7b24b1612de006da452aa4154f4552a638e8a4ea787a353a65"},"downloads":-1,"filename":"mlx_textgen-0.0.2.tar.gz","has_sig":false,"md5_digest":"ca5a9253777333f438a18d588686164f","packagetype":"sdist","python_version":"source","requires_python":">=3.9","size":17772,"upload_time":"2024-09-30T21:34:43","upload_time_iso_8601":"2024-09-30T21:34:43.508194Z","url":"https://files.pythonhosted.org/packages/83/45/b56c2b0587c61006f3396fe260f8c098819ed31d650ed882d10f34a4d9ac/mlx_textgen-0.0.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.3":{"info":{"author":null,"author_email":"Nathan Tam <nathan1295@gmail.com>","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":"MIT","maintainer":null,"maintainer_email":null,"name":"mlx-textgen","package_url":"https://pypi.org/project/mlx-textgen/","platform":null,"project_url":"https://pypi.org/project/mlx-textgen/","project_urls":{"Homepage":"https://github.com/nath1295/MLX-Textgen"},"provides_extra":null,"release_url":"https://pypi.org/project/mlx-textgen/0.0.3/","requires_dist":["mlx-lm>=0.18.2","orjson","fastapi","uvicorn"],"requires_python":">=3.9","summary":"A python package for serving LLM on OpenAI-compatible API endpoints with prompt caching using MLX.","version":"0.0.3","yanked":false,"yanked_reason":null},"last_serial":25696038,"urls":[{"comment_text":"","digests":{"blake2b_256":"d56c89da72d596246c214b307bc54b1aeb22e96d58b3d005f9aff834f7bfdc40","md5":"83c87b51f0f74a99c36367eba5713118","sha256":"a776b240ac8f4eacb98c77bc358f2907cea7c99231ca7a1c1b99386a61c0114c"},"downloads":-1,"filename":"mlx_textgen-0.0.3.tar.gz","has_sig":false,"md5_digest":"83c87b51f0f74a99c36367eba5713118","packagetype":"sdist","python_version":"source","requires_python":">=3.9","size":18102,"upload_time":"2024-10-01T22:11:54","upload_time_iso_8601":"2024-10-01T22:11:54.466222Z","url":"https://files.pythonhosted.org/packages/d5/6c/89da72d596246c214b307bc54b1aeb22e96d58b3d005f9aff834f7bfdc40/mlx_textgen-0.0.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.4":{"info":{"author":null,"author_email":"Nathan Tam <nathan1295@gmail.com>","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":"MIT","maintainer":null,"maintainer_email":null,"name":"mlx-textgen","package_url":"https://pypi.org/project/mlx-textgen/","platform":null,"project_url":"https://pypi.org/project/mlx-textgen/","project_urls":{"Homepage":"https://github.com/nath1295/MLX-Textgen"},"provides_extra":null,"release_url":"https://pypi.org/project/mlx-textgen/0.0.4/","requires_dist":["mlx-lm>=0.18.2","orjson","fastapi","uvicorn"],"requires_python":">=3.9","summary":"A python package for serving LLM on OpenAI-compatible API endpoints with prompt caching using MLX.","version":"0.0.4","yanked":false,"yanked_reason":null},"last_serial":25696038,"urls":[{"comment_text":"","digests":{"blake2b_256":"ffed01f9a1d003aa01bd97b5e678580e7215fbef0267af7ab7ba010fe36f8571","md5":"21dac5b034842e17154479fc37099f35","sha256":"6db1769a38a0c6cde88af6d5942e0f1dafcc123d88305fc45428eb4dbbe742bc"},"downloads":-1,"filename":"mlx_textgen-0.0.4.tar.gz","has_sig":false,"md5_digest":"21dac5b034842e17154479fc37099f35","packagetype":"sdist","python_version":"source","requires_python":">=3.9","size":18201,"upload_time":"2024-10-05T12:24:10","upload_time_iso_8601":"2024-10-05T12:24:10.439827Z","url":"https://files.pythonhosted.org/packages/ff/ed/01f9a1d003aa01bd97b5e678580e7215fbef0267af7ab7ba010fe36f8571/mlx_textgen-0.0.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.5":{"info":{"author":null,"author_email":"Nathan Tam <nathan1295@gmail.com>","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":"MIT","maintainer":null,"maintainer_email":null,"name":"mlx-textgen","package_url":"https://pypi.org/project/mlx-textgen/","platform":null,"project_url":"https://pypi.org/project/mlx-textgen/","project_urls":{"Homepage":"https://github.com/nath1295/MLX-Textgen"},"provides_extra":null,"release_url":"https://pypi.org/project/mlx-textgen/0.0.5/","requires_dist":["mlx-lm>=0.18.2","orjson","fastapi","uvicorn"],"requires_python":">=3.9","summary":"A python package for serving LLM on OpenAI-compatible API endpoints with prompt caching using MLX.","version":"0.0.5","yanked":false,"yanked_reason":null},"last_serial":25696038,"urls":[{"comment_text":"","digests":{"blake2b_256":"0619099d23f4188af036ae2a658d0b67e31d4d3877c143ab4bea81421c8197ce","md5":"af59bad1cef0caa68fe6df78b3118055","sha256":"e63767c6e5344707bd239c8411217a1d8cc5b2652c44368900d2adad4104f428"},"downloads":-1,"filename":"mlx_textgen-0.0.5.tar.gz","has_sig":false,"md5_digest":"af59bad1cef0caa68fe6df78b3118055","packagetype":"sdist","python_version":"source","requires_python":">=3.9","size":18147,"upload_time":"2024-10-05T15:39:32","upload_time_iso_8601":"2024-10-05T15:39:32.628172Z","url":"https://files.pythonhosted.org/packages/06/19/099d23f4188af036ae2a658d0b67e31d4d3877c143ab4bea81421c8197ce/mlx_textgen-0.0.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.6":{"info":{"author":null,"author_email":"Nathan Tam <nathan1295@gmail.com>","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":"MIT","maintainer":null,"maintainer_email":null,"name":"mlx-textgen","package_url":"https://pypi.org/project/mlx-textgen/","platform":null,"project_url":"https://pypi.org/project/mlx-textgen/","project_urls":{"Homepage":"https://github.com/nath1295/MLX-Textgen"},"provides_extra":null,"release_url":"https://pypi.org/project/mlx-textgen/0.0.6/","requires_dist":["mlx-lm>=0.18.2","orjson","fastapi","uvicorn"],"requires_python":">=3.9","summary":"A python package for serving LLM on OpenAI-compatible API endpoints with prompt caching using MLX.","version":"0.0.6","yanked":false,"yanked_reason":null},"last_serial":25696038,"urls":[{"comment_text":"","digests":{"blake2b_256":"8668c886a3fe49780b5b476f73fe63a70375869d1056842139b5c1886e086527","md5":"8b399aea80ba1bd4e60815a723b5c8ce","sha256":"d4ad6cf4ad9441d3d4c0dd684fffd979ff74514a82dc8832b1a724d05b427f72"},"downloads":-1,"filename":"mlx_textgen-0.0.6.tar.gz","has_sig":false,"md5_digest":"8b399aea80ba1bd4e60815a723b5c8ce","packagetype":"sdist","python_version":"source","requires_python":">=3.9","size":22132,"upload_time":"2024-10-07T20:45:57","upload_time_iso_8601":"2024-10-07T20:45:57.689846Z","url":"https://files.pythonhosted.org/packages/86/68/c886a3fe49780b5b476f73fe63a70375869d1056842139b5c1886e086527/mlx_textgen-0.0.6.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.0":{"info":{"author":null,"author_email":"Nathan Tam <nathan1295@gmail.com>","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":"MIT","maintainer":null,"maintainer_email":null,"name":"mlx-textgen","package_url":"https://pypi.org/project/mlx-textgen/","platform":null,"project_url":"https://pypi.org/project/mlx-textgen/","project_urls":{"Homepage":"https://github.com/nath1295/MLX-Textgen"},"provides_extra":null,"release_url":"https://pypi.org/project/mlx-textgen/0.1.0/","requires_dist":["mlx-lm>=0.19.1","outlines>=0.1.1","fastapi","uvicorn"],"requires_python":">=3.9","summary":"A python package for serving LLM on OpenAI-compatible API endpoints with prompt caching using MLX.","version":"0.1.0","yanked":false,"yanked_reason":null},"last_serial":25696038,"urls":[{"comment_text":"","digests":{"blake2b_256":"8cba0f36466a8570076435b12aaf1615c96a0100e98bfe26da31f394b8019dbd","md5":"e95e71ce9e5bf78107947a840cf8ca63","sha256":"3c72ef58e3548263cd1741c0ac9a6a5b6e7eee853bad4340ced5c1afc29d0ba2"},"downloads":-1,"filename":"mlx_textgen-0.1.0.tar.gz","has_sig":false,"md5_digest":"e95e71ce9e5bf78107947a840cf8ca63","packagetype":"sdist","python_version":"source","requires_python":">=3.9","size":29454,"upload_time":"2024-10-20T22:35:46","upload_time_iso_8601":"2024-10-20T22:35:46.617136Z","url":"https://files.pythonhosted.org/packages/8c/ba/0f36466a8570076435b12aaf1615c96a0100e98bfe26da31f394b8019dbd/mlx_textgen-0.1.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.1":{"info":{"author":null,"author_email":"Nathan Tam <nathan1295@gmail.com>","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":"MIT","maintainer":null,"maintainer_email":null,"name":"mlx-textgen","package_url":"https://pypi.org/project/mlx-textgen/","platform":null,"project_url":"https://pypi.org/project/mlx-textgen/","project_urls":{"Homepage":"https://github.com/nath1295/MLX-Textgen"},"provides_extra":null,"release_url":"https://pypi.org/project/mlx-textgen/0.1.1/","requires_dist":["mlx-lm>=0.19.1","outlines>=0.1.1","fastapi","uvicorn"],"requires_python":">=3.9","summary":"A python package for serving LLM on OpenAI-compatible API endpoints with prompt caching using MLX.","version":"0.1.1","yanked":false,"yanked_reason":null},"last_serial":25696038,"urls":[{"comment_text":"","digests":{"blake2b_256":"7816e4bc3d4bf4bc0a7c4bae01a6af6683fe52b7485318f3499de624f05cda40","md5":"5b0258e6956a40d4680b9cd54b2b577d","sha256":"d54e21a871ea21f757abe286b1ec1a573bba507564e0602404e97751d9261f96"},"downloads":-1,"filename":"mlx_textgen-0.1.1.tar.gz","has_sig":false,"md5_digest":"5b0258e6956a40d4680b9cd54b2b577d","packagetype":"sdist","python_version":"source","requires_python":">=3.9","size":30355,"upload_time":"2024-10-21T16:19:47","upload_time_iso_8601":"2024-10-21T16:19:47.924927Z","url":"https://files.pythonhosted.org/packages/78/16/e4bc3d4bf4bc0a7c4bae01a6af6683fe52b7485318f3499de624f05cda40/mlx_textgen-0.1.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.2":{"info":{"author":null,"author_email":"Nathan Tam <nathan1295@gmail.com>","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":"MIT","maintainer":null,"maintainer_email":null,"name":"mlx-textgen","package_url":"https://pypi.org/project/mlx-textgen/","platform":null,"project_url":"https://pypi.org/project/mlx-textgen/","project_urls":{"Homepage":"https://github.com/nath1295/MLX-Textgen"},"provides_extra":null,"release_url":"https://pypi.org/project/mlx-textgen/0.1.2/","requires_dist":["mlx-lm>=0.19.1","outlines>=0.1.1","fastapi","uvicorn"],"requires_python":">=3.9","summary":"A python package for serving LLM on OpenAI-compatible API endpoints with prompt caching using MLX.","version":"0.1.2","yanked":false,"yanked_reason":null},"last_serial":25696038,"urls":[{"comment_text":"","digests":{"blake2b_256":"9a955e48160f6091332aa6b6e3d14e7a5c713b8d6f6e7926062e7f7a01d1b924","md5":"560bdcc91cdfa43b82e6f8b51388efea","sha256":"ef462a0e21861bff8a45f0578acc920b7937156d14e4a8d204def5688aaaee0e"},"downloads":-1,"filename":"mlx_textgen-0.1.2.tar.gz","has_sig":false,"md5_digest":"560bdcc91cdfa43b82e6f8b51388efea","packagetype":"sdist","python_version":"source","requires_python":">=3.9","size":30647,"upload_time":"2024-10-25T11:44:31","upload_time_iso_8601":"2024-10-25T11:44:31.481245Z","url":"https://files.pythonhosted.org/packages/9a/95/5e48160f6091332aa6b6e3d14e7a5c713b8d6f6e7926062e7f7a01d1b924/mlx_textgen-0.1.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.3":{"info":{"author":null,"author_email":"Nathan Tam <nathan1295@gmail.com>","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":"MIT","maintainer":null,"maintainer_email":null,"name":"mlx-textgen","package_url":"https://pypi.org/project/mlx-textgen/","platform":null,"project_url":"https://pypi.org/project/mlx-textgen/","project_urls":{"Homepage":"https://github.com/nath1295/MLX-Textgen"},"provides_extra":null,"release_url":"https://pypi.org/project/mlx-textgen/0.1.3/","requires_dist":["mlx-lm>=0.19.1","outlines>=0.1.1","fastapi","uvicorn"],"requires_python":">=3.9","summary":"A python package for serving LLM on OpenAI-compatible API endpoints with prompt caching using MLX.","version":"0.1.3","yanked":false,"yanked_reason":null},"last_serial":25696038,"urls":[{"comment_text":"","digests":{"blake2b_256":"5467f7991bffee98294ad3ab8cfebe1ce3da8bd2617874fd4f95dad5a016e882","md5":"32605e8d5ed046dbfe54333400c5ef09","sha256":"f2259c06d358a15889697eb7b209cc08b08e3e6846a3b4a333e066f550e5ca50"},"downloads":-1,"filename":"mlx_textgen-0.1.3.tar.gz","has_sig":false,"md5_digest":"32605e8d5ed046dbfe54333400c5ef09","packagetype":"sdist","python_version":"source","requires_python":">=3.9","size":33483,"upload_time":"2024-10-26T18:43:29","upload_time_iso_8601":"2024-10-26T18:43:29.238253Z","url":"https://files.pythonhosted.org/packages/54/67/f7991bffee98294ad3ab8cfebe1ce3da8bd2617874fd4f95dad5a016e882/mlx_textgen-0.1.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.4":{"info":{"author":null,"author_email":"Nathan Tam <nathan1295@gmail.com>","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":"MIT","maintainer":null,"maintainer_email":null,"name":"mlx-textgen","package_url":"https://pypi.org/project/mlx-textgen/","platform":null,"project_url":"https://pypi.org/project/mlx-textgen/","project_urls":{"Homepage":"https://github.com/nath1295/MLX-Textgen"},"provides_extra":null,"release_url":"https://pypi.org/project/mlx-textgen/0.1.4/","requires_dist":["mlx-lm>=0.19.1","outlines>=0.1.1","fastapi","uvicorn"],"requires_python":">=3.9","summary":"A python package for serving LLM on OpenAI-compatible API endpoints with prompt caching using MLX.","version":"0.1.4","yanked":false,"yanked_reason":null},"last_serial":25696038,"urls":[{"comment_text":"","digests":{"blake2b_256":"3fbf73bd20efc0e25909bcfd5e30eebadf5b10015cffdf685a2f1cc9f9ab416f","md5":"18d95f06183fc667a9f90e96a98e857b","sha256":"d60731dad8f149dbca31f38148644a98085de77e9affc6f114bc1412797b959a"},"downloads":-1,"filename":"mlx_textgen-0.1.4.tar.gz","has_sig":false,"md5_digest":"18d95f06183fc667a9f90e96a98e857b","packagetype":"sdist","python_version":"source","requires_python":">=3.9","size":33464,"upload_time":"2024-10-27T19:12:38","upload_time_iso_8601":"2024-10-27T19:12:38.984243Z","url":"https://files.pythonhosted.org/packages/3f/bf/73bd20efc0e25909bcfd5e30eebadf5b10015cffdf685a2f1cc9f9ab416f/mlx_textgen-0.1.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.5":{"info":{"author":null,"author_email":"Nathan Tam <nathan1295@gmail.com>","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: MacOS :: MacOS X","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":"MIT","maintainer":null,"maintainer_email":null,"name":"mlx-textgen","package_url":"https://pypi.org/project/mlx-textgen/","platform":null,"project_url":"https://pypi.org/project/mlx-textgen/","project_urls":{"Homepage":"https://github.com/nath1295/MLX-Textgen"},"provides_extra":null,"release_url":"https://pypi.org/project/mlx-textgen/0.1.5/","requires_dist":["mlx-lm>=0.19.1","outlines>=0.1.1","fastapi","uvicorn"],"requires_python":">=3.9","summary":"An OpenAI-compatible API LLM engine with smart prompt caching, batch processing, structured output with guided decoding, and function calling for all models using MLX.","version":"0.1.5","yanked":false,"yanked_reason":null},"last_serial":25696038,"urls":[{"comment_text":"","digests":{"blake2b_256":"ff58653761d18658477a4009841746ce08828f2ba0535b357303f82f8c4d8d03","md5":"4ae67bd3b37eda1f3dba1cd7b68d00e9","sha256":"21be8ccb559b179656bfe2fcd4c5529a7a5b17401c41d872253ca54bb3818640"},"downloads":-1,"filename":"mlx_textgen-0.1.5.tar.gz","has_sig":false,"md5_digest":"4ae67bd3b37eda1f3dba1cd7b68d00e9","packagetype":"sdist","python_version":"source","requires_python":">=3.9","size":33407,"upload_time":"2024-10-27T19:25:29","upload_time_iso_8601":"2024-10-27T19:25:29.818689Z","url":"https://files.pythonhosted.org/packages/ff/58/653761d18658477a4009841746ce08828f2ba0535b357303f82f8c4d8d03/mlx_textgen-0.1.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}