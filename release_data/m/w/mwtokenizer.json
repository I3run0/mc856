{"0.0.2":{"info":{"author":"Appledora & Isaac Johnson & Martin Gerlach","author_email":"<isaac@wikimedia.org>","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","License :: OSI Approved :: MIT License","Natural Language :: English","Operating System :: MacOS :: MacOS X","Operating System :: Microsoft :: Windows","Operating System :: Unix","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://gitlab.wikimedia.org/repos/research/wiki-nlp-tools/","keywords":"python,wikipedia,nlp,tokenizer","license":"MIT License","maintainer":"","maintainer_email":"","name":"mwtokenizer","package_url":"https://pypi.org/project/mwtokenizer/","platform":null,"project_url":"https://pypi.org/project/mwtokenizer/","project_urls":{"Homepage":"https://gitlab.wikimedia.org/repos/research/wiki-nlp-tools/"},"provides_extra":null,"release_url":"https://pypi.org/project/mwtokenizer/0.0.2/","requires_dist":["regex","requests","sentencepiece","pandas ; extra == 'benchmarking'","pytest (>=6.2.5) ; extra == 'dev'","pre-commit ; extra == 'dev'","mypy (>=0.961) ; extra == 'dev'","pandas ; extra == 'dev'","pre-commit ; extra == 'pre-commit'","pytest (>=6.2.5) ; extra == 'tests'","mypy (>=0.961) ; extra == 'typing'"],"requires_python":"","summary":"Wikipedia Tokenizer Utility","version":"0.0.2","yanked":false,"yanked_reason":null},"last_serial":21175097,"urls":[{"comment_text":"","digests":{"blake2b_256":"f5b9b045767ee5b08f8d9678aa179970c5c24812f63034125b736a64390d48e7","md5":"c0f8dfaf991b652785a64debbb19f227","sha256":"31c5a39e680cf78331eed06305b6dc5c42c16f9f8edc291f4b9abc42f455f020"},"downloads":-1,"filename":"mwtokenizer-0.0.2-py3-none-any.whl","has_sig":false,"md5_digest":"c0f8dfaf991b652785a64debbb19f227","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":7097725,"upload_time":"2023-06-26T19:12:07","upload_time_iso_8601":"2023-06-26T19:12:07.699724Z","url":"https://files.pythonhosted.org/packages/f5/b9/b045767ee5b08f8d9678aa179970c5c24812f63034125b736a64390d48e7/mwtokenizer-0.0.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7b06cfa57d330b102458eaf4c78e0629bc465160989f4231fdc843abf58caf29","md5":"87c27cd333c72782c9e6e4fe7e737ebe","sha256":"c8080477a7917d8cdd9ae7d193616cd42858e13b08cad5a32ad34dae75428902"},"downloads":-1,"filename":"mwtokenizer-0.0.2.tar.gz","has_sig":false,"md5_digest":"87c27cd333c72782c9e6e4fe7e737ebe","packagetype":"sdist","python_version":"source","requires_python":null,"size":7083495,"upload_time":"2023-06-26T19:12:12","upload_time_iso_8601":"2023-06-26T19:12:12.420428Z","url":"https://files.pythonhosted.org/packages/7b/06/cfa57d330b102458eaf4c78e0629bc465160989f4231fdc843abf58caf29/mwtokenizer-0.0.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.0":{"info":{"author":"Aisha Khatun & Appledora & Isaac Johnson & Martin Gerlach","author_email":"<isaac@wikimedia.org>","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","License :: OSI Approved :: MIT License","Natural Language :: English","Operating System :: MacOS :: MacOS X","Operating System :: Microsoft :: Windows","Operating System :: Unix","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://gitlab.wikimedia.org/repos/research/wiki-nlp-tools/","keywords":"python,wikipedia,nlp,tokenizer","license":"MIT License","maintainer":"","maintainer_email":"","name":"mwtokenizer","package_url":"https://pypi.org/project/mwtokenizer/","platform":null,"project_url":"https://pypi.org/project/mwtokenizer/","project_urls":{"Homepage":"https://gitlab.wikimedia.org/repos/research/wiki-nlp-tools/"},"provides_extra":null,"release_url":"https://pypi.org/project/mwtokenizer/0.1.0/","requires_dist":["regex","sentencepiece","pandas ; extra == 'benchmarking'","pytest >=6.2.5 ; extra == 'dev'","pre-commit ; extra == 'dev'","pandas ; extra == 'dev'","pre-commit ; extra == 'pre-commit'","pytest >=6.2.5 ; extra == 'tests'"],"requires_python":"","summary":"Wikipedia Tokenizer Utility","version":"0.1.0","yanked":false,"yanked_reason":null},"last_serial":21175097,"urls":[{"comment_text":"","digests":{"blake2b_256":"aa2f45f9fabb51e8698f61e9a3b38e816cf496a002ff7f2e1fcd68df9024b9d2","md5":"3979ff2ac6f3600aa70ed76fdaddc31c","sha256":"77dc8db6fdec6537093c862cd07bdcbeb03991dd530bd8b9d21f1c90ff03418c"},"downloads":-1,"filename":"mwtokenizer-0.1.0-py3-none-any.whl","has_sig":false,"md5_digest":"3979ff2ac6f3600aa70ed76fdaddc31c","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6890907,"upload_time":"2023-12-05T15:50:23","upload_time_iso_8601":"2023-12-05T15:50:23.346887Z","url":"https://files.pythonhosted.org/packages/aa/2f/45f9fabb51e8698f61e9a3b38e816cf496a002ff7f2e1fcd68df9024b9d2/mwtokenizer-0.1.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"32a612e4310ae10550db556ef4c7dde0748311201d6b749d0448f8ebb591ebc7","md5":"8c3a0a466c456c16451a1df2750c0fb0","sha256":"e4226e915c4888a058b1ed3ba158aabc7f0d3019ae900d3e1fcdfb66a3b01449"},"downloads":-1,"filename":"mwtokenizer-0.1.0.tar.gz","has_sig":false,"md5_digest":"8c3a0a466c456c16451a1df2750c0fb0","packagetype":"sdist","python_version":"source","requires_python":null,"size":6875922,"upload_time":"2023-12-05T15:50:25","upload_time_iso_8601":"2023-12-05T15:50:25.634458Z","url":"https://files.pythonhosted.org/packages/32/a6/12e4310ae10550db556ef4c7dde0748311201d6b749d0448f8ebb591ebc7/mwtokenizer-0.1.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.0":{"info":{"author":"Aisha Khatun & Appledora & Isaac Johnson & Martin Gerlach","author_email":"<isaac@wikimedia.org>","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","License :: OSI Approved :: MIT License","Natural Language :: English","Operating System :: MacOS :: MacOS X","Operating System :: Microsoft :: Windows","Operating System :: Unix","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://gitlab.wikimedia.org/repos/research/wiki-nlp-tools/","keywords":"python,wikipedia,nlp,tokenizer","license":"MIT License","maintainer":"","maintainer_email":"","name":"mwtokenizer","package_url":"https://pypi.org/project/mwtokenizer/","platform":null,"project_url":"https://pypi.org/project/mwtokenizer/","project_urls":{"Homepage":"https://gitlab.wikimedia.org/repos/research/wiki-nlp-tools/"},"provides_extra":null,"release_url":"https://pypi.org/project/mwtokenizer/0.2.0/","requires_dist":["regex","sentencepiece","pandas ; extra == 'benchmarking'","pytest >=6.2.5 ; extra == 'dev'","pre-commit ; extra == 'dev'","pandas ; extra == 'dev'","pre-commit ; extra == 'pre-commit'","pytest >=6.2.5 ; extra == 'tests'"],"requires_python":"","summary":"Wikipedia Tokenizer Utility","version":"0.2.0","yanked":false,"yanked_reason":null},"last_serial":21175097,"urls":[{"comment_text":"","digests":{"blake2b_256":"25292aad1f38a7b70d7291c716e17958e43ab17416cd041910a1dbfa15a82773","md5":"02a3beba69e796719d424cbf313b4722","sha256":"84c87ea1968761fa7ad2d774d87bdbf440abba9a56c5e972710b4b504ad1f1b9"},"downloads":-1,"filename":"mwtokenizer-0.2.0-py3-none-any.whl","has_sig":false,"md5_digest":"02a3beba69e796719d424cbf313b4722","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6891060,"upload_time":"2023-12-22T16:24:42","upload_time_iso_8601":"2023-12-22T16:24:42.775472Z","url":"https://files.pythonhosted.org/packages/25/29/2aad1f38a7b70d7291c716e17958e43ab17416cd041910a1dbfa15a82773/mwtokenizer-0.2.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"0d713097b66d99807c97babcaf2db08abbcee3157c00e7f76337565431c48e5c","md5":"781a3a64665b5c360ac588736c2feeae","sha256":"95c496172e6915814edbed261bc64829b8661622fcae2947e530b63aad7bc4ec"},"downloads":-1,"filename":"mwtokenizer-0.2.0.tar.gz","has_sig":false,"md5_digest":"781a3a64665b5c360ac588736c2feeae","packagetype":"sdist","python_version":"source","requires_python":null,"size":6876048,"upload_time":"2023-12-22T16:24:45","upload_time_iso_8601":"2023-12-22T16:24:45.606168Z","url":"https://files.pythonhosted.org/packages/0d/71/3097b66d99807c97babcaf2db08abbcee3157c00e7f76337565431c48e5c/mwtokenizer-0.2.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}