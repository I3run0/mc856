{"1.3.1":{"info":{"author":"Benjamin Elizalde and Soham Deshmukh and Huaming Wang","author_email":"","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"MIT","maintainer":"","maintainer_email":"","name":"msclap","package_url":"https://pypi.org/project/msclap/","platform":null,"project_url":"https://pypi.org/project/msclap/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/msclap/1.3.1/","requires_dist":["librosa (>=0.10.1,<0.11.0)","numpy (>=1.25.0,<1.26.0)","numba (>=0.58.0,<0.59.0)","pandas (>=2.0.0,<2.1.0)","torch (>=2.1.0,<3.0.0)","torchaudio (>=2.1.0,<3.0.0)","torchlibrosa (>=0.1.0,<0.2.0)","torchvision (>=0.16.0,<0.17.0)","tqdm (>=4.66.1,<5.0.0)","transformers (>=4.34.0,<5.0.0)","pyyaml (>=6.0.1,<7.0.0)","scikit-learn (>=1.3.1,<2.0.0)"],"requires_python":">=3.8,<4.0","summary":"CLAP (Contrastive Language-Audio Pretraining) is a model that learns acoustic concepts from natural language supervision and enables “Zero-Shot” inference. The model has been extensively evaluated in 26 audio downstream tasks achieving SoTA in several of them including classification, retrieval, and captioning.","version":"1.3.1","yanked":false,"yanked_reason":null},"last_serial":20266798,"urls":[{"comment_text":"","digests":{"blake2b_256":"cb263eec15d58fbb12e64ba2e9dda58302155f7594ddd97c58d0d5529c2dda9c","md5":"05639b0c9db4780153c00996050ca870","sha256":"2919bbddfde1a4701f78bbd38d11ccde2d3dd7625bb22fa2d73b33dfc7b06567"},"downloads":-1,"filename":"msclap-1.3.1-py3-none-any.whl","has_sig":false,"md5_digest":"05639b0c9db4780153c00996050ca870","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8,<4.0","size":31574,"upload_time":"2023-10-12T00:05:00","upload_time_iso_8601":"2023-10-12T00:05:00.512503Z","url":"https://files.pythonhosted.org/packages/cb/26/3eec15d58fbb12e64ba2e9dda58302155f7594ddd97c58d0d5529c2dda9c/msclap-1.3.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"678cabe113e35868d3e1d0e5e0159f2bbea05200764b74670edad4420e86d678","md5":"f997e3a7081c7e50141ee048e2ebc65b","sha256":"89935cfc8d39ead9a1afcf85d9fec791fbe4828df825f7724edf5c44ddb7e497"},"downloads":-1,"filename":"msclap-1.3.1.tar.gz","has_sig":false,"md5_digest":"f997e3a7081c7e50141ee048e2ebc65b","packagetype":"sdist","python_version":"source","requires_python":">=3.8,<4.0","size":29405,"upload_time":"2023-10-12T00:05:02","upload_time_iso_8601":"2023-10-12T00:05:02.097596Z","url":"https://files.pythonhosted.org/packages/67/8c/abe113e35868d3e1d0e5e0159f2bbea05200764b74670edad4420e86d678/msclap-1.3.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.3.2":{"info":{"author":"Benjamin Elizalde and Soham Deshmukh and Huaming Wang","author_email":"","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"MIT","maintainer":"","maintainer_email":"","name":"msclap","package_url":"https://pypi.org/project/msclap/","platform":null,"project_url":"https://pypi.org/project/msclap/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/msclap/1.3.2/","requires_dist":["librosa (>=0.10.1,<0.11.0)","numpy (>=1.25.0,<1.26.0)","numba (>=0.58.0,<0.59.0)","pandas (>=2.0.0,<2.1.0)","torch (>=2.1.0,<3.0.0)","torchaudio (>=2.1.0,<3.0.0)","torchlibrosa (>=0.1.0,<0.2.0)","torchvision (>=0.16.0,<0.17.0)","tqdm (>=4.66.1,<5.0.0)","transformers (>=4.34.0,<5.0.0)","pyyaml (>=6.0.1,<7.0.0)","scikit-learn (>=1.3.1,<2.0.0)"],"requires_python":">=3.8,<4.0","summary":"CLAP (Contrastive Language-Audio Pretraining) is a model that learns acoustic concepts from natural language supervision and enables “Zero-Shot” inference. The model has been extensively evaluated in 26 audio downstream tasks achieving SoTA in several of them including classification, retrieval, and captioning.","version":"1.3.2","yanked":false,"yanked_reason":null},"last_serial":20266798,"urls":[{"comment_text":"","digests":{"blake2b_256":"36eec38ff55ada1d6fa880642387fb1259624822231ec967d58191cac4fa6e32","md5":"ab9672086eeadf3afd13bdade6c0a252","sha256":"0504b1e26a53fb1920595cdd0bb8248f562ca0d13b80e2ae3e1007ed21fa95a4"},"downloads":-1,"filename":"msclap-1.3.2-py3-none-any.whl","has_sig":false,"md5_digest":"ab9672086eeadf3afd13bdade6c0a252","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8,<4.0","size":31252,"upload_time":"2023-10-12T00:07:02","upload_time_iso_8601":"2023-10-12T00:07:02.878551Z","url":"https://files.pythonhosted.org/packages/36/ee/c38ff55ada1d6fa880642387fb1259624822231ec967d58191cac4fa6e32/msclap-1.3.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7365bdcbe3b362cd303e5e1febb00c0140d3faee2d2d6ccd9017c964ae817d13","md5":"8777f2a05d117b0117f2ea47b3987b57","sha256":"76d84e2c22ef4c5206e03c84db8a0c1d62064cb84befdea73a28355d46533284"},"downloads":-1,"filename":"msclap-1.3.2.tar.gz","has_sig":false,"md5_digest":"8777f2a05d117b0117f2ea47b3987b57","packagetype":"sdist","python_version":"source","requires_python":">=3.8,<4.0","size":29286,"upload_time":"2023-10-12T00:07:04","upload_time_iso_8601":"2023-10-12T00:07:04.565970Z","url":"https://files.pythonhosted.org/packages/73/65/bdcbe3b362cd303e5e1febb00c0140d3faee2d2d6ccd9017c964ae817d13/msclap-1.3.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.3.2.post1":{"info":{"author":"Benjamin Elizalde and Soham Deshmukh and Huaming Wang","author_email":"","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"MIT","maintainer":"","maintainer_email":"","name":"msclap","package_url":"https://pypi.org/project/msclap/","platform":null,"project_url":"https://pypi.org/project/msclap/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/msclap/1.3.2.post1/","requires_dist":["librosa (>=0.10.1,<0.11.0)","numpy (>=1.23.0,<2.0.0)","numba (>=0.58.0,<0.59.0)","pandas (>=2.0.0,<3.0.0)","torch (>=2.1.0,<3.0.0)","torchaudio (>=2.1.0,<3.0.0)","torchlibrosa (>=0.1.0,<0.2.0)","torchvision (>=0.16.0,<0.17.0)","tqdm (>=4.66.1,<5.0.0)","transformers (>=4.34.0,<5.0.0)","pyyaml (>=6.0.1,<7.0.0)","scikit-learn (>=1.3.1,<2.0.0)"],"requires_python":">=3.8,<4.0","summary":"CLAP (Contrastive Language-Audio Pretraining) is a model that learns acoustic concepts from natural language supervision and enables “Zero-Shot” inference. The model has been extensively evaluated in 26 audio downstream tasks achieving SoTA in several of them including classification, retrieval, and captioning.","version":"1.3.2.post1","yanked":false,"yanked_reason":null},"last_serial":20266798,"urls":[{"comment_text":"","digests":{"blake2b_256":"34be2dd322041102a30bf5daa51d53e737f151631f85047545655143d17e94c1","md5":"65f4ef0e14ee214d4e5b2e6991e882f9","sha256":"a587028e102b5b2bd3fec7b91f8291f31b5bdb9e357d764c69050b8c7dddbcd5"},"downloads":-1,"filename":"msclap-1.3.2.post1-py3-none-any.whl","has_sig":false,"md5_digest":"65f4ef0e14ee214d4e5b2e6991e882f9","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8,<4.0","size":31306,"upload_time":"2023-10-12T04:25:35","upload_time_iso_8601":"2023-10-12T04:25:35.240326Z","url":"https://files.pythonhosted.org/packages/34/be/2dd322041102a30bf5daa51d53e737f151631f85047545655143d17e94c1/msclap-1.3.2.post1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b74d8dfe09d6757bd7cb1c7e551c516aa6de539232eac661461e315ee2804754","md5":"41e0c324b886eae216037bee7abf5245","sha256":"89a52d24f06081e3ef8c0dc87a2de3ec21c6ed36df10aa672ff143db0cccb627"},"downloads":-1,"filename":"msclap-1.3.2.post1.tar.gz","has_sig":false,"md5_digest":"41e0c324b886eae216037bee7abf5245","packagetype":"sdist","python_version":"source","requires_python":">=3.8,<4.0","size":29300,"upload_time":"2023-10-12T04:25:37","upload_time_iso_8601":"2023-10-12T04:25:37.070345Z","url":"https://files.pythonhosted.org/packages/b7/4d/8dfe09d6757bd7cb1c7e551c516aa6de539232eac661461e315ee2804754/msclap-1.3.2.post1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.3.3":{"info":{"author":"Benjamin Elizalde","author_email":"","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"MIT","maintainer":"","maintainer_email":"","name":"msclap","package_url":"https://pypi.org/project/msclap/","platform":null,"project_url":"https://pypi.org/project/msclap/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/msclap/1.3.3/","requires_dist":["librosa (>=0.10.1,<0.11.0)","numpy (>=1.23.0,<2.0.0)","numba (>=0.58.0,<0.59.0)","pandas (>=2.0.0,<3.0.0)","torch (>=2.1.0,<3.0.0)","torchaudio (>=2.1.0,<3.0.0)","torchlibrosa (>=0.1.0,<0.2.0)","torchvision (>=0.16.0,<0.17.0)","tqdm (>=4.66.1,<5.0.0)","transformers (>=4.34.0,<5.0.0)","pyyaml (>=6.0.1,<7.0.0)","scikit-learn (>=1.3.1,<2.0.0)"],"requires_python":">=3.8,<4.0","summary":"CLAP (Contrastive Language-Audio Pretraining) is a model that learns acoustic concepts from natural language supervision and enables “Zero-Shot” inference. The model has been extensively evaluated in 26 audio downstream tasks achieving SoTA in several of them including classification, retrieval, and captioning.","version":"1.3.3","yanked":false,"yanked_reason":null},"last_serial":20266798,"urls":[{"comment_text":"","digests":{"blake2b_256":"28aec22b7e05ec7864637d39acede8bdc5e36a481b9701ad47ed7e754ad5155d","md5":"cfc7ea4b1c54bfeb29ec179bf6afc1d1","sha256":"ee9f36ecbb19d8cc4dee42c54a1b48d9fae2b01c9b4532ef35be18533b1ea8c3"},"downloads":-1,"filename":"msclap-1.3.3-py3-none-any.whl","has_sig":false,"md5_digest":"cfc7ea4b1c54bfeb29ec179bf6afc1d1","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8,<4.0","size":31350,"upload_time":"2023-10-20T21:18:50","upload_time_iso_8601":"2023-10-20T21:18:50.215697Z","url":"https://files.pythonhosted.org/packages/28/ae/c22b7e05ec7864637d39acede8bdc5e36a481b9701ad47ed7e754ad5155d/msclap-1.3.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b01b6605192e5f4ccf9eef13aaea46443e0658db61f11abb8910373b13089926","md5":"9258a4c87ee49acf0783e187b3976882","sha256":"ded253972b745d4e06026dda408dc80f625717e6887837ce4e6ec3e633052269"},"downloads":-1,"filename":"msclap-1.3.3.tar.gz","has_sig":false,"md5_digest":"9258a4c87ee49acf0783e187b3976882","packagetype":"sdist","python_version":"source","requires_python":">=3.8,<4.0","size":27498,"upload_time":"2023-10-20T21:18:51","upload_time_iso_8601":"2023-10-20T21:18:51.541597Z","url":"https://files.pythonhosted.org/packages/b0/1b/6605192e5f4ccf9eef13aaea46443e0658db61f11abb8910373b13089926/msclap-1.3.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}