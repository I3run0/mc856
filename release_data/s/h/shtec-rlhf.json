{"1.0.5":{"info":{"author":"PKU-Alignment Team","author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Software Development :: Libraries :: Python Modules"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"Reinforcement Learning, Safe Reinforcement Learning, Reinforcement Learning from Human Feedback, Safe Reinforcement Learning from Human Feedback, Large Language Model, Language Model, RLHF, Safe RLHF, LLM","license":"Apache License, Version 2.0","maintainer":null,"maintainer_email":null,"name":"shtec-rlhf","package_url":"https://pypi.org/project/shtec-rlhf/","platform":null,"project_url":"https://pypi.org/project/shtec-rlhf/","project_urls":{"Bug Report":"https://github.com/PKU-Alignment/shtec-rlhf","Documentation":"https://shtec-rlhf.readthedocs.io","Homepage":"https://github.com/PKU-Alignment/shtec-rlhf","Repository":"https://github.com/PKU-Alignment/shtec-rlhf"},"provides_extra":null,"release_url":"https://pypi.org/project/shtec-rlhf/1.0.5/","requires_dist":["torch>=1.13","transformers>=4.37","datasets","tokenizers>=0.13.3","accelerate","deepspeed","numpy","scipy","sentencepiece","wandb","tensorboard","optree","matplotlib","tqdm","rich","isort>=5.11.0; extra == \"lint\"","black>=23.1.0; extra == \"lint\"","pylint[spelling]>=2.15.0; extra == \"lint\"","mypy>=1.0; extra == \"lint\"","flake8; extra == \"lint\"","flake8-bugbear; extra == \"lint\"","flake8-comprehensions; extra == \"lint\"","flake8-docstrings; extra == \"lint\"","flake8-pyi; extra == \"lint\"","flake8-simplify; extra == \"lint\"","ruff; extra == \"lint\"","doc8; extra == \"lint\"","pydocstyle[toml]; extra == \"lint\"","pyenchant; extra == \"lint\"","pre-commit; extra == \"lint\""],"requires_python":">=3.8","summary":"shtec-rlhf: Safe Reinforcement Learning from Human Feedback","version":"1.0.5","yanked":false,"yanked_reason":null},"last_serial":23815920,"urls":[{"comment_text":"","digests":{"blake2b_256":"07a1d2019172152e594a869e4ff673c7eb652e56012c8b344e8c54ec6bcf6d37","md5":"6f8043a3f8a2fa8eb796e9a4b6dddea4","sha256":"2c211da6704b7d4f922b943f6ddcc8ae8739e59fecf7d861c3b4c5b825989eaf"},"downloads":-1,"filename":"shtec_rlhf-1.0.5-py3-none-any.whl","has_sig":false,"md5_digest":"6f8043a3f8a2fa8eb796e9a4b6dddea4","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":301429,"upload_time":"2024-06-24T05:55:05","upload_time_iso_8601":"2024-06-24T05:55:05.527087Z","url":"https://files.pythonhosted.org/packages/07/a1/d2019172152e594a869e4ff673c7eb652e56012c8b344e8c54ec6bcf6d37/shtec_rlhf-1.0.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"fe5e1c6a5d1254fe36eb10d266f37eb840e47fdab985fedc3b871cd249fb551a","md5":"eef5a35730a5bc7ccff0da40c819edd9","sha256":"56e9504ab77b25322431decba6edd0d258a6ce788fd50db2bd67c7add3c6f37f"},"downloads":-1,"filename":"shtec-rlhf-1.0.5.tar.gz","has_sig":false,"md5_digest":"eef5a35730a5bc7ccff0da40c819edd9","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":76951,"upload_time":"2024-06-24T05:55:07","upload_time_iso_8601":"2024-06-24T05:55:07.324345Z","url":"https://files.pythonhosted.org/packages/fe/5e/1c6a5d1254fe36eb10d266f37eb840e47fdab985fedc3b871cd249fb551a/shtec-rlhf-1.0.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}