{"0.0.1":{"info":{"author":"Erfan Zare Chavoshi","author_email":"erfanzare810@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 3 - Alpha","Intended Audience :: Developers","License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.13","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/erfanzar/jax-flash-attn2","keywords":"JAX, Deep Learning, Machine Learning, XLA","license":"Apache-2.0","maintainer":null,"maintainer_email":null,"name":"jax-flash-attn2","package_url":"https://pypi.org/project/jax-flash-attn2/","platform":null,"project_url":"https://pypi.org/project/jax-flash-attn2/","project_urls":{"Documentation":"https://erfanzar.github.io/jax-flash-attn2","Homepage":"https://github.com/erfanzar/jax-flash-attn2","Repository":"https://github.com/erfanzar/jax-flash-attn2"},"provides_extra":null,"release_url":"https://pypi.org/project/jax-flash-attn2/0.0.1/","requires_dist":["jax>=0.4.33","jaxlib>=0.4.33","triton<3.1.0,>=3.0.0","scipy==1.13.1","einops","chex"],"requires_python":">=3.10","summary":"Flash Attention Implementation with Multiple Backend Support and Sharding This module provides a flexible implementation of Flash Attention with support for different backends (GPU, TPU, CPU) and platforms (Triton, Pallas, JAX).","version":"0.0.1","yanked":false,"yanked_reason":null},"last_serial":25640394,"urls":[{"comment_text":"","digests":{"blake2b_256":"33bf6f165b9632be5dd07aee61201c2e2a29bb857eab8e0ecbb94b5d04de2c98","md5":"8d7ca7e9095345343bca1488389d2743","sha256":"161f2baf1bc3a11e80fa30717521769267c5840cabb39af2b5b012f9e1e0ebdb"},"downloads":-1,"filename":"jax_flash_attn2-0.0.1-py3-none-any.whl","has_sig":false,"md5_digest":"8d7ca7e9095345343bca1488389d2743","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":42759,"upload_time":"2024-10-23T22:37:12","upload_time_iso_8601":"2024-10-23T22:37:12.917018Z","url":"https://files.pythonhosted.org/packages/33/bf/6f165b9632be5dd07aee61201c2e2a29bb857eab8e0ecbb94b5d04de2c98/jax_flash_attn2-0.0.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"39be7edd549bc129222063dc504a50943db32024d37d72f0987ff469f79c7418","md5":"78211d0cf9ed7c68ca72e7e2279bd22a","sha256":"c76947468451f41d4c9d2fe59c868c13bffdb7e96d05354491567a542f48c815"},"downloads":-1,"filename":"jax_flash_attn2-0.0.1.tar.gz","has_sig":false,"md5_digest":"78211d0cf9ed7c68ca72e7e2279bd22a","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":35406,"upload_time":"2024-10-23T22:37:19","upload_time_iso_8601":"2024-10-23T22:37:19.469703Z","url":"https://files.pythonhosted.org/packages/39/be/7edd549bc129222063dc504a50943db32024d37d72f0987ff469f79c7418/jax_flash_attn2-0.0.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}