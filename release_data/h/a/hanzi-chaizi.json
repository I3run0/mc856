{"0.2":{"info":{"author":"Xiaoquan Kong","author_email":"u1mail2me@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":null,"docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/howl-anderson/hanzi_chaizi","keywords":null,"license":null,"maintainer":null,"maintainer_email":null,"name":"hanzi-chaizi","package_url":"https://pypi.org/project/hanzi-chaizi/","platform":null,"project_url":"https://pypi.org/project/hanzi-chaizi/","project_urls":{"Homepage":"https://github.com/howl-anderson/hanzi_chaizi"},"provides_extra":null,"release_url":"https://pypi.org/project/hanzi-chaizi/0.2/","requires_dist":null,"requires_python":null,"summary":"The hanzi_chaizi package provides tools for breaking down Chinese characters into basic structural units, such as strokes and components. This decomposition reveals structural similarities between characters with similar shapes. These features can be used in deep learning models to capture character-based attributes, particularly shape-related ones, for applications like natural language processing or character recognition.","version":"0.2","yanked":false,"yanked_reason":null},"last_serial":25520335,"urls":[{"comment_text":"","digests":{"blake2b_256":"b05d66c45180412679cd680ee950c63cb9e85a2da921da4dfc80aa6d3291172f","md5":"e3f6a3780c7322e2d55ef1c00feae3f7","sha256":"5554ae1f6576147a69717a2ab9335888dff553e87924aacf5fd501cf49906d44"},"downloads":-1,"filename":"hanzi_chaizi-0.2-py3-none-any.whl","has_sig":false,"md5_digest":"e3f6a3780c7322e2d55ef1c00feae3f7","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":477764,"upload_time":"2024-10-17T03:40:47","upload_time_iso_8601":"2024-10-17T03:40:47.147092Z","url":"https://files.pythonhosted.org/packages/b0/5d/66c45180412679cd680ee950c63cb9e85a2da921da4dfc80aa6d3291172f/hanzi_chaizi-0.2-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}