{"0.1.0":{"info":{"author":"Sebastian Sosa","author_email":"ssosarippe@gmail.com","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"MIT","maintainer":"","maintainer_email":"","name":"adversarial-examples","package_url":"https://pypi.org/project/adversarial-examples/","platform":null,"project_url":"https://pypi.org/project/adversarial-examples/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/adversarial-examples/0.1.0/","requires_dist":["ipython (>=8.22.2,<9.0.0)","pillow (>=10.2.0,<11.0.0)","torch (>=2.2.1,<3.0.0)","torchvision (>=0.17.1,<0.18.0)"],"requires_python":">=3.10,<4.0","summary":"Create adversarial images that make a neural network misclassify them.","version":"0.1.0","yanked":false,"yanked_reason":null},"last_serial":22216138,"urls":[{"comment_text":"","digests":{"blake2b_256":"cc006db8341a8b16ce9431184f4541385139a59eb72e635ef257c1c2d69983bf","md5":"a0f26df9f4b5b04c06a94ebdea0b420d","sha256":"c5a90c6f26328dbb3d8aa7986a101886fdde39865f4117e5880dad9aae2d3e8a"},"downloads":-1,"filename":"adversarial_examples-0.1.0-py3-none-any.whl","has_sig":false,"md5_digest":"a0f26df9f4b5b04c06a94ebdea0b420d","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10,<4.0","size":4311,"upload_time":"2024-03-07T15:50:11","upload_time_iso_8601":"2024-03-07T15:50:11.558988Z","url":"https://files.pythonhosted.org/packages/cc/00/6db8341a8b16ce9431184f4541385139a59eb72e635ef257c1c2d69983bf/adversarial_examples-0.1.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"f6b991583504beba2e07c11f82db3d3f94c0499871759d1987a37cb2f447bae9","md5":"60f8c9049c7c992cbcc9ea55191d824d","sha256":"37ec127f0a430a7e27fc7467cb77225758e70bc74ae9304074e275eeb6515dd5"},"downloads":-1,"filename":"adversarial_examples-0.1.0.tar.gz","has_sig":false,"md5_digest":"60f8c9049c7c992cbcc9ea55191d824d","packagetype":"sdist","python_version":"source","requires_python":">=3.10,<4.0","size":3365,"upload_time":"2024-03-07T15:50:12","upload_time_iso_8601":"2024-03-07T15:50:12.823574Z","url":"https://files.pythonhosted.org/packages/f6/b9/91583504beba2e07c11f82db3d3f94c0499871759d1987a37cb2f447bae9/adversarial_examples-0.1.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.1":{"info":{"author":"Sebastian Sosa","author_email":"ssosarippe@gmail.com","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"MIT","maintainer":"","maintainer_email":"","name":"adversarial-examples","package_url":"https://pypi.org/project/adversarial-examples/","platform":null,"project_url":"https://pypi.org/project/adversarial-examples/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/adversarial-examples/0.1.1/","requires_dist":["pillow (>=10.2.0,<11.0.0)","torch (>=2.2.1,<3.0.0)","torchvision (>=0.17.1,<0.18.0)"],"requires_python":">=3.10,<4.0","summary":"Create adversarial images that make a neural network misclassify them.","version":"0.1.1","yanked":false,"yanked_reason":null},"last_serial":22216138,"urls":[{"comment_text":"","digests":{"blake2b_256":"65c80baa244602bad626c6741f1f637c3998a8ec31f45511eb4700e9cbdda025","md5":"a845700031a1f72aabbcc69e6ac42bd9","sha256":"fc0fd365b667281a28e6ce2d7fdd44779479c9376cb63ab2720627fbd5054818"},"downloads":-1,"filename":"adversarial_examples-0.1.1-py3-none-any.whl","has_sig":false,"md5_digest":"a845700031a1f72aabbcc69e6ac42bd9","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10,<4.0","size":4299,"upload_time":"2024-03-07T15:57:32","upload_time_iso_8601":"2024-03-07T15:57:32.228507Z","url":"https://files.pythonhosted.org/packages/65/c8/0baa244602bad626c6741f1f637c3998a8ec31f45511eb4700e9cbdda025/adversarial_examples-0.1.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"71dfac2b362111510a2cffb4e822382b0772c17308f8150641bd7fd27154b7b3","md5":"fde27345d49d2d9fc207efec4959d36a","sha256":"3865e5fdc9de015a7c6d2b6b00c9eb0a9b1f5f5a5639774bb14c4805b8d26aab"},"downloads":-1,"filename":"adversarial_examples-0.1.1.tar.gz","has_sig":false,"md5_digest":"fde27345d49d2d9fc207efec4959d36a","packagetype":"sdist","python_version":"source","requires_python":">=3.10,<4.0","size":3354,"upload_time":"2024-03-07T15:57:34","upload_time_iso_8601":"2024-03-07T15:57:34.161735Z","url":"https://files.pythonhosted.org/packages/71/df/ac2b362111510a2cffb4e822382b0772c17308f8150641bd7fd27154b7b3/adversarial_examples-0.1.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}