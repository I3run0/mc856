{"2.0.0a1":{"info":{"author":"AI Verify","author_email":null,"bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":null,"maintainer":null,"maintainer_email":null,"name":"aiverify-fairness-metrics-toolbox-for-classification","package_url":"https://pypi.org/project/aiverify-fairness-metrics-toolbox-for-classification/","platform":null,"project_url":"https://pypi.org/project/aiverify-fairness-metrics-toolbox-for-classification/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/aiverify-fairness-metrics-toolbox-for-classification/2.0.0a1/","requires_dist":["aiverify-test-engine==2.0.0a1","joblib==1.4.2","numpy==1.26.4","scikit-learn==1.5.2","scipy==1.14.1"],"requires_python":"<3.12,>=3.10","summary":"AI Verify Fairness Metrics Toolbox (FMT) for Classification contains a list of fairness metrics to measure how resources (e.g. opportunities, food, loan, medical help) are allocated among the demographic groups (e.g. married male, married female) given a set of sensitive feature(s) (e.g. gender, marital status). This plugin is developed for classification models.","version":"2.0.0a1","yanked":false,"yanked_reason":null},"last_serial":25854367,"urls":[{"comment_text":null,"digests":{"blake2b_256":"0acfef9fe0b07f6fc5820e097fcc0017eb0404c786c68d64d554af55791ec1e0","md5":"f85d5cd14cceb4fb9eaf071443c33dea","sha256":"73024554df852a5b39f814e58bdbfc8cdb790bd52ad26e008df6bc303b1d338b"},"downloads":-1,"filename":"aiverify_fairness_metrics_toolbox_for_classification-2.0.0a1-py3-none-any.whl","has_sig":false,"md5_digest":"f85d5cd14cceb4fb9eaf071443c33dea","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<3.12,>=3.10","size":25372,"upload_time":"2024-11-06T13:11:10","upload_time_iso_8601":"2024-11-06T13:11:10.607362Z","url":"https://files.pythonhosted.org/packages/0a/cf/ef9fe0b07f6fc5820e097fcc0017eb0404c786c68d64d554af55791ec1e0/aiverify_fairness_metrics_toolbox_for_classification-2.0.0a1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":null,"digests":{"blake2b_256":"b87a9ea1a4613f11ad3e097934a66e6faa650c31b0ffb13a4d1ba4115905f21b","md5":"a3b70c534ec9a1f3d61873d98bdc6850","sha256":"4aa6236a92101d7547bd0166ba40ce9a22b9ca9288e3da12de80278705f41e13"},"downloads":-1,"filename":"aiverify_fairness_metrics_toolbox_for_classification-2.0.0a1.tar.gz","has_sig":false,"md5_digest":"a3b70c534ec9a1f3d61873d98bdc6850","packagetype":"sdist","python_version":"source","requires_python":"<3.12,>=3.10","size":23783,"upload_time":"2024-11-06T13:11:12","upload_time_iso_8601":"2024-11-06T13:11:12.639974Z","url":"https://files.pythonhosted.org/packages/b8/7a/9ea1a4613f11ad3e097934a66e6faa650c31b0ffb13a4d1ba4115905f21b/aiverify_fairness_metrics_toolbox_for_classification-2.0.0a1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}