{"0.9.1":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/0.9.1/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"0.9.1","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"b507de7f718a2832f3a63bad0383be0b123e7f4c1ffc16d08b7d3198274be6eb","md5":"43edf88b24034721b4fb5056b6ca4e50","sha256":"ae86a92a598a60ece31ffec8db81d323d068da71aaeb6b4d6b307818469a347a"},"downloads":-1,"filename":"airllm-0.9.1-py3-none-any.whl","has_sig":false,"md5_digest":"43edf88b24034721b4fb5056b6ca4e50","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":16356,"upload_time":"2023-11-17T20:45:43","upload_time_iso_8601":"2023-11-17T20:45:43.966282Z","url":"https://files.pythonhosted.org/packages/b5/07/de7f718a2832f3a63bad0383be0b123e7f4c1ffc16d08b7d3198274be6eb/airllm-0.9.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"1dc255c148ef09890ef6f88f4bcf8124632aaff431241a9fea6f508724bcb70f","md5":"dfeda0fc2e4e877c3e208e91c69e7eb6","sha256":"4c43d37ba57e92b83ef76c0cf6fe120e7b5b09d17e5dc312d2604f61cb11b99d"},"downloads":-1,"filename":"airllm-0.9.1.tar.gz","has_sig":false,"md5_digest":"dfeda0fc2e4e877c3e208e91c69e7eb6","packagetype":"sdist","python_version":"source","requires_python":null,"size":10564,"upload_time":"2023-11-17T20:45:46","upload_time_iso_8601":"2023-11-17T20:45:46.376176Z","url":"https://files.pythonhosted.org/packages/1d/c2/55c148ef09890ef6f88f4bcf8124632aaff431241a9fea6f508724bcb70f/airllm-0.9.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.9.2":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/0.9.2/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"0.9.2","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"551522dbb464d7a74d475a25d252d6588cf77348eb8c827f3dca9ce41f8ed6fe","md5":"b917b9114f0dd5afc6ab83ca1bfa5c05","sha256":"01ae5cac4489c7e0144bb05faaf6dbcd8fcb32ee7920236fd2d878759aed1a54"},"downloads":-1,"filename":"airllm-0.9.2-py3-none-any.whl","has_sig":false,"md5_digest":"b917b9114f0dd5afc6ab83ca1bfa5c05","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":16443,"upload_time":"2023-11-17T20:52:23","upload_time_iso_8601":"2023-11-17T20:52:23.600651Z","url":"https://files.pythonhosted.org/packages/55/15/22dbb464d7a74d475a25d252d6588cf77348eb8c827f3dca9ce41f8ed6fe/airllm-0.9.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"1b90e6b04ba6cb7b3d01bb6211460b58c4d056fa8e3004038a1e5f80af057db0","md5":"a6fcf60d902875dc7dbdf12a47620215","sha256":"b937d9a2f5f1a19f273ce2791ad5a1dd66b4c1382bdce059bf1d18560107af06"},"downloads":-1,"filename":"airllm-0.9.2.tar.gz","has_sig":false,"md5_digest":"a6fcf60d902875dc7dbdf12a47620215","packagetype":"sdist","python_version":"source","requires_python":null,"size":10666,"upload_time":"2023-11-17T20:52:25","upload_time_iso_8601":"2023-11-17T20:52:25.413595Z","url":"https://files.pythonhosted.org/packages/1b/90/e6b04ba6cb7b3d01bb6211460b58c4d056fa8e3004038a1e5f80af057db0/airllm-0.9.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.9.3":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/0.9.3/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"0.9.3","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"ccf765ff007e351ea8b80f1c10f9dd8f014592d0ad11cdb7e480b75434661e42","md5":"313eeaba1b310789c2b1f660b6336267","sha256":"17149e5bbc95f39c6a32ae6c2c9910debd81df3ca0003116ca3b6028c1592d0f"},"downloads":-1,"filename":"airllm-0.9.3-py3-none-any.whl","has_sig":false,"md5_digest":"313eeaba1b310789c2b1f660b6336267","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":16428,"upload_time":"2023-11-17T20:54:42","upload_time_iso_8601":"2023-11-17T20:54:42.779487Z","url":"https://files.pythonhosted.org/packages/cc/f7/65ff007e351ea8b80f1c10f9dd8f014592d0ad11cdb7e480b75434661e42/airllm-0.9.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a54885690e7dcc9c35900307dc9d48f01d8f592f67f4d49ad61531d0071fd109","md5":"a048b98185ae134266c59f22e8638fbd","sha256":"e95510870ea8946a144b0d7661fc763ef734db6c9ec7380790d870196162f160"},"downloads":-1,"filename":"airllm-0.9.3.tar.gz","has_sig":false,"md5_digest":"a048b98185ae134266c59f22e8638fbd","packagetype":"sdist","python_version":"source","requires_python":null,"size":10655,"upload_time":"2023-11-17T20:54:44","upload_time_iso_8601":"2023-11-17T20:54:44.135627Z","url":"https://files.pythonhosted.org/packages/a5/48/85690e7dcc9c35900307dc9d48f01d8f592f67f4d49ad61531d0071fd109/airllm-0.9.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.9.4":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/0.9.4/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"0.9.4","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"a850077a209904f935721f6ad0f0087b274cda6a722345cd1a5257df42cfddd5","md5":"49e923dc4b641a201afd93aa7d089a5e","sha256":"47ec961ccc53652b9c3f411384987d034951c0c844620a057ce8fdf2926b83bd"},"downloads":-1,"filename":"airllm-0.9.4-py3-none-any.whl","has_sig":false,"md5_digest":"49e923dc4b641a201afd93aa7d089a5e","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":16761,"upload_time":"2023-11-18T14:05:28","upload_time_iso_8601":"2023-11-18T14:05:28.591559Z","url":"https://files.pythonhosted.org/packages/a8/50/077a209904f935721f6ad0f0087b274cda6a722345cd1a5257df42cfddd5/airllm-0.9.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8303ca2b8b53529c4068f8b8329218a9659c691409b2b7f6cac3d18e59e01140","md5":"831f06cd14accf343914a09b317b293c","sha256":"c583285b4763c08261c5b5fa79f365b7c4b6fcc7117f8940981ce74cfe008599"},"downloads":-1,"filename":"airllm-0.9.4.tar.gz","has_sig":false,"md5_digest":"831f06cd14accf343914a09b317b293c","packagetype":"sdist","python_version":"source","requires_python":null,"size":11042,"upload_time":"2023-11-18T14:05:30","upload_time_iso_8601":"2023-11-18T14:05:30.063753Z","url":"https://files.pythonhosted.org/packages/83/03/ca2b8b53529c4068f8b8329218a9659c691409b2b7f6cac3d18e59e01140/airllm-0.9.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.9.5":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/0.9.5/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"0.9.5","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"f578fa4e45905c7afecf20c0d2321882d9c8d6207b123456c4111d8c1bde77f8","md5":"41b3b77151e86d545cff2cb7e3b0669b","sha256":"05404331f6db6e8897973edc9960ea8a669485c324d47725c3032162754e1510"},"downloads":-1,"filename":"airllm-0.9.5-py3-none-any.whl","has_sig":false,"md5_digest":"41b3b77151e86d545cff2cb7e3b0669b","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":17334,"upload_time":"2023-11-21T02:40:03","upload_time_iso_8601":"2023-11-21T02:40:03.375072Z","url":"https://files.pythonhosted.org/packages/f5/78/fa4e45905c7afecf20c0d2321882d9c8d6207b123456c4111d8c1bde77f8/airllm-0.9.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"c6f409805c5004d5219df07335f3e24bf64ec9fc84b0d0a8a4f85dd6e5ff9e01","md5":"87eddc2a7cca2085d5d9960830f523cc","sha256":"ef0f1ab8b1c52c6fb5e20bc15d694fe9a18e89e3b50a733f625210b470de34d6"},"downloads":-1,"filename":"airllm-0.9.5.tar.gz","has_sig":false,"md5_digest":"87eddc2a7cca2085d5d9960830f523cc","packagetype":"sdist","python_version":"source","requires_python":null,"size":11527,"upload_time":"2023-11-21T02:40:05","upload_time_iso_8601":"2023-11-21T02:40:05.664180Z","url":"https://files.pythonhosted.org/packages/c6/f4/09805c5004d5219df07335f3e24bf64ec9fc84b0d0a8a4f85dd6e5ff9e01/airllm-0.9.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.0.0":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.0.0/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hubscipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.0.0","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"d14e41ee3350c96b2bc375d2f1aad3fe9ab9e289075aa3cd93a81c048f08792c","md5":"5140de18727eca5bae15ae181c6c6ed3","sha256":"e82b7895f15d6f027f64667814e8650cbdf42b36bafb3cfada418867926ff60e"},"downloads":-1,"filename":"airllm-2.0.0-py3-none-any.whl","has_sig":false,"md5_digest":"5140de18727eca5bae15ae181c6c6ed3","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":19670,"upload_time":"2023-12-02T03:12:11","upload_time_iso_8601":"2023-12-02T03:12:11.156241Z","url":"https://files.pythonhosted.org/packages/d1/4e/41ee3350c96b2bc375d2f1aad3fe9ab9e289075aa3cd93a81c048f08792c/airllm-2.0.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"21ac136231c59d5b66473926bfd760bd3fcc6f13cf58814db6bd0ab074abfda9","md5":"9c5dca1412d9493c9e8ea5787728f4a8","sha256":"6188524510767f45a3270aca94561089a936ee24463fa729029aac139fe489ec"},"downloads":-1,"filename":"airllm-2.0.0.tar.gz","has_sig":false,"md5_digest":"9c5dca1412d9493c9e8ea5787728f4a8","packagetype":"sdist","python_version":"source","requires_python":null,"size":16781,"upload_time":"2023-12-02T03:12:12","upload_time_iso_8601":"2023-12-02T03:12:12.956021Z","url":"https://files.pythonhosted.org/packages/21/ac/136231c59d5b66473926bfd760bd3fcc6f13cf58814db6bd0ab074abfda9/airllm-2.0.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.1.0":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.1.0/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hubscipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.1.0","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"ec85da103a0293fa01d8c35d535688cb6ca86f32820e9fd6a4a1c396b6310b1e","md5":"83a9c78b866891f49226d9b840121738","sha256":"2cf38b2b989cabd1bab0a1da6a3cd242215d20ecad348d84818152edc29150b1"},"downloads":-1,"filename":"airllm-2.1.0-py3-none-any.whl","has_sig":false,"md5_digest":"83a9c78b866891f49226d9b840121738","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":25654,"upload_time":"2023-12-03T00:12:29","upload_time_iso_8601":"2023-12-03T00:12:29.568946Z","url":"https://files.pythonhosted.org/packages/ec/85/da103a0293fa01d8c35d535688cb6ca86f32820e9fd6a4a1c396b6310b1e/airllm-2.1.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"ef367ab9b11675ff1f1beb71733321bf1499f83cdab1d8afcc4bfa2059828005","md5":"86aff40c200013a5a1506ec5ef6cb0c2","sha256":"97385141c7a828f0aa91f2e2fb4a59f45170bff4119a79a327585393577ca99c"},"downloads":-1,"filename":"airllm-2.1.0.tar.gz","has_sig":false,"md5_digest":"86aff40c200013a5a1506ec5ef6cb0c2","packagetype":"sdist","python_version":"source","requires_python":null,"size":18896,"upload_time":"2023-12-03T00:12:31","upload_time_iso_8601":"2023-12-03T00:12:31.242375Z","url":"https://files.pythonhosted.org/packages/ef/36/7ab9b11675ff1f1beb71733321bf1499f83cdab1d8afcc4bfa2059828005/airllm-2.1.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.1.1":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.1.1/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.1.1","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"9dcca0d4d700fd51f681d931c82664104bcc514b3384bedc79dfcac1cf930494","md5":"3799648080e9aadc00da1dd4c1addc3c","sha256":"356a09f82156c6a590465927a8fd6cab2615704c11ec96910fd1289ac0ffa9ba"},"downloads":-1,"filename":"airllm-2.1.1-py3-none-any.whl","has_sig":false,"md5_digest":"3799648080e9aadc00da1dd4c1addc3c","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":25658,"upload_time":"2023-12-03T00:17:15","upload_time_iso_8601":"2023-12-03T00:17:15.321133Z","url":"https://files.pythonhosted.org/packages/9d/cc/a0d4d700fd51f681d931c82664104bcc514b3384bedc79dfcac1cf930494/airllm-2.1.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"3079abed0eab7efb40355b549d3154406763ea9cfcdc6b61c32a2afe0f5cc991","md5":"a1674282ca38b5339d2c1251e1393649","sha256":"9020b96ee58a5a387c2decb3f009461449769fd6beb946d7362f2aeffd18dca6"},"downloads":-1,"filename":"airllm-2.1.1.tar.gz","has_sig":false,"md5_digest":"a1674282ca38b5339d2c1251e1393649","packagetype":"sdist","python_version":"source","requires_python":null,"size":18868,"upload_time":"2023-12-03T00:17:16","upload_time_iso_8601":"2023-12-03T00:17:16.893824Z","url":"https://files.pythonhosted.org/packages/30/79/abed0eab7efb40355b549d3154406763ea9cfcdc6b61c32a2afe0f5cc991/airllm-2.1.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.10.1":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/airllm","keywords":null,"license":null,"maintainer":null,"maintainer_email":null,"name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/airllm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.10.1/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":null,"summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning. 8GB vmem to run 405B Llama3.1.","version":"2.10.1","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"e18c46c536648ec0dd36d2d9156ed02f6bd3742c5e5644cbbcae3ab2c5c14385","md5":"f3f509940fdaf83144c81d98b90b43e3","sha256":"acc6c3e971a9a0655f64e32b55ec4ca716ff67ba19dd4fbd1eafb92453a5f94b"},"downloads":-1,"filename":"airllm-2.10.1-py3-none-any.whl","has_sig":false,"md5_digest":"f3f509940fdaf83144c81d98b90b43e3","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":36620,"upload_time":"2024-08-18T16:47:58","upload_time_iso_8601":"2024-08-18T16:47:58.536192Z","url":"https://files.pythonhosted.org/packages/e1/8c/46c536648ec0dd36d2d9156ed02f6bd3742c5e5644cbbcae3ab2c5c14385/airllm-2.10.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"503864d1145ab78ebd133a757ba800d59e90d5389f5ba1db2b8d172f8d58b9d5","md5":"60cf418627613ac6eb7fbc0efeba068a","sha256":"a63f5acad4860295f90143d0c1e3d13c932bc9fa10996b608eb41ca9985a6faf"},"downloads":-1,"filename":"airllm-2.10.1.tar.gz","has_sig":false,"md5_digest":"60cf418627613ac6eb7fbc0efeba068a","packagetype":"sdist","python_version":"source","requires_python":null,"size":35114,"upload_time":"2024-08-18T16:48:00","upload_time_iso_8601":"2024-08-18T16:48:00.136761Z","url":"https://files.pythonhosted.org/packages/50/38/64d1145ab78ebd133a757ba800d59e90d5389f5ba1db2b8d172f8d58b9d5/airllm-2.10.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.10.2":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/airllm","keywords":null,"license":null,"maintainer":null,"maintainer_email":null,"name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/airllm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.10.2/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":null,"summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning. 8GB vmem to run 405B Llama3.1.","version":"2.10.2","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"c4af2ca6c0eb673dd5f5d16414e1ee2693757a8f966e9eb3b4614a3bae8804de","md5":"83cdf5c53c78f84ba97745c54af44cc4","sha256":"003332fd1dd59d41e62f6e5ec0d3f547cb4461efb62b8e0cdb3c4bd55fff579a"},"downloads":-1,"filename":"airllm-2.10.2-py3-none-any.whl","has_sig":false,"md5_digest":"83cdf5c53c78f84ba97745c54af44cc4","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":36622,"upload_time":"2024-08-23T14:38:21","upload_time_iso_8601":"2024-08-23T14:38:21.346553Z","url":"https://files.pythonhosted.org/packages/c4/af/2ca6c0eb673dd5f5d16414e1ee2693757a8f966e9eb3b4614a3bae8804de/airllm-2.10.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"3aaaef78649b37202cdd8d5279cdde8d09fa5c742799cfcb721184d9c1ae4eb3","md5":"0cfc2a36f8fad0d0f3f607ec3e7c7ba3","sha256":"b49cf4eb76acf700ec882dfe3d7fd49a6f3b071a2b62a1a727e864220c46ab9c"},"downloads":-1,"filename":"airllm-2.10.2.tar.gz","has_sig":false,"md5_digest":"0cfc2a36f8fad0d0f3f607ec3e7c7ba3","packagetype":"sdist","python_version":"source","requires_python":null,"size":35132,"upload_time":"2024-08-23T14:38:22","upload_time_iso_8601":"2024-08-23T14:38:22.879524Z","url":"https://files.pythonhosted.org/packages/3a/aa/ef78649b37202cdd8d5279cdde8d09fa5c742799cfcb721184d9c1ae4eb3/airllm-2.10.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.11.0":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/airllm","keywords":null,"license":null,"maintainer":null,"maintainer_email":null,"name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/airllm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.11.0/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":null,"summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning. 8GB vmem to run 405B Llama3.1.","version":"2.11.0","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"645f5e7209493a02c7230d970b7fada8a1b12673022792ac956da7d189527f58","md5":"a25d0e81d8b4a56840b1c751bebb901e","sha256":"668c8424c8f72151cfbecc0892a9cd3c8bd792dceb977683c93a318240a248a2"},"downloads":-1,"filename":"airllm-2.11.0-py3-none-any.whl","has_sig":false,"md5_digest":"a25d0e81d8b4a56840b1c751bebb901e","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":36963,"upload_time":"2024-09-21T02:52:22","upload_time_iso_8601":"2024-09-21T02:52:22.091498Z","url":"https://files.pythonhosted.org/packages/64/5f/5e7209493a02c7230d970b7fada8a1b12673022792ac956da7d189527f58/airllm-2.11.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"2ad07ce495f2b834bcd210f8b62bf180148c769d7e2b1dcec5eb9fc78e72c0b1","md5":"85e709a334f5cd3c002b60a7790d4c5b","sha256":"62fbd17de01d64ce667e72291fa8642bf5ce20c68ff1ca835b9d1d2ed371856d"},"downloads":-1,"filename":"airllm-2.11.0.tar.gz","has_sig":false,"md5_digest":"85e709a334f5cd3c002b60a7790d4c5b","packagetype":"sdist","python_version":"source","requires_python":null,"size":35301,"upload_time":"2024-09-21T02:52:23","upload_time_iso_8601":"2024-09-21T02:52:23.572843Z","url":"https://files.pythonhosted.org/packages/2a/d0/7ce495f2b834bcd210f8b62bf180148c769d7e2b1dcec5eb9fc78e72c0b1/airllm-2.11.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.2.0":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.2.0/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.2.0","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"996868ef08c789ae7e85614d86a567902b69ec16236a7c9076ab86f8fa78c19c","md5":"dce2e542a88e191cfe9e1ec5894861c0","sha256":"f1da97a7861a95448a080f2fdc3176537ec9fef21ebe5853ad28f036e70bc358"},"downloads":-1,"filename":"airllm-2.2.0-py3-none-any.whl","has_sig":false,"md5_digest":"dce2e542a88e191cfe9e1ec5894861c0","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":31034,"upload_time":"2023-12-03T17:53:45","upload_time_iso_8601":"2023-12-03T17:53:45.346022Z","url":"https://files.pythonhosted.org/packages/99/68/68ef08c789ae7e85614d86a567902b69ec16236a7c9076ab86f8fa78c19c/airllm-2.2.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"de54e1e422b9846cba7041903b2bc7449d46e4964d1f0cd484c44146a0ed8b76","md5":"6e2388fa9bb9bea3e44f3545927753f6","sha256":"b9ba5f3bb1e0e5faf00495317a4540f74292daa8da685a7db63d3098b2d33ca6"},"downloads":-1,"filename":"airllm-2.2.0.tar.gz","has_sig":false,"md5_digest":"6e2388fa9bb9bea3e44f3545927753f6","packagetype":"sdist","python_version":"source","requires_python":null,"size":20346,"upload_time":"2023-12-03T17:53:47","upload_time_iso_8601":"2023-12-03T17:53:47.103656Z","url":"https://files.pythonhosted.org/packages/de/54/e1e422b9846cba7041903b2bc7449d46e4964d1f0cd484c44146a0ed8b76/airllm-2.2.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.3.0":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.3.0/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.3.0","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"ce74a3beb7eff1b161605fa6022fbefafd291f6da951ed1a4db685804d46ef59","md5":"c74a4e13060d4b16536ee635924584eb","sha256":"e21064cdd8d20f2c8e140304b6d3f2d14b53a0904e8baf25d35dca6e976c2371"},"downloads":-1,"filename":"airllm-2.3.0-py3-none-any.whl","has_sig":false,"md5_digest":"c74a4e13060d4b16536ee635924584eb","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":31270,"upload_time":"2023-12-04T00:19:22","upload_time_iso_8601":"2023-12-04T00:19:22.489686Z","url":"https://files.pythonhosted.org/packages/ce/74/a3beb7eff1b161605fa6022fbefafd291f6da951ed1a4db685804d46ef59/airllm-2.3.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"478ce4a5b9b5bbfe2eda1111a73fac876baed56cde9366981eadea202d6f4462","md5":"eb31c521d1e097fda74588c9c89ebcdf","sha256":"da8fc6dc928d24acd0ef281aa122a1481cbe8246602cf343b2b7c6afc9848881"},"downloads":-1,"filename":"airllm-2.3.0.tar.gz","has_sig":false,"md5_digest":"eb31c521d1e097fda74588c9c89ebcdf","packagetype":"sdist","python_version":"source","requires_python":null,"size":20848,"upload_time":"2023-12-04T00:19:24","upload_time_iso_8601":"2023-12-04T00:19:24.179005Z","url":"https://files.pythonhosted.org/packages/47/8c/e4a5b9b5bbfe2eda1111a73fac876baed56cde9366981eadea202d6f4462/airllm-2.3.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.3.1":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.3.1/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.3.1","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"26d505f7faaf31230e48817803925d031e4b68532bd8281b2952301f9d9a4611","md5":"d9480840e5c20d9f18fc5e1dcab45729","sha256":"235070922e713a5d3eac486fb298ba4cfc3731ae53b9e87f7cb01e2f4aa0814e"},"downloads":-1,"filename":"airllm-2.3.1-py3-none-any.whl","has_sig":false,"md5_digest":"d9480840e5c20d9f18fc5e1dcab45729","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":31273,"upload_time":"2023-12-04T00:21:42","upload_time_iso_8601":"2023-12-04T00:21:42.817797Z","url":"https://files.pythonhosted.org/packages/26/d5/05f7faaf31230e48817803925d031e4b68532bd8281b2952301f9d9a4611/airllm-2.3.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"dd8bc95f7afa0d628acb14304b05bb25130623706f4e3696b209a11dc57bc43a","md5":"2794da960e4b85b6c0e9ee5af5d3a740","sha256":"f5ff592d49036188a5cf96d1de20be6fbbbe867849f57e7c6ad848ae98b17a0e"},"downloads":-1,"filename":"airllm-2.3.1.tar.gz","has_sig":false,"md5_digest":"2794da960e4b85b6c0e9ee5af5d3a740","packagetype":"sdist","python_version":"source","requires_python":null,"size":20857,"upload_time":"2023-12-04T00:21:44","upload_time_iso_8601":"2023-12-04T00:21:44.499857Z","url":"https://files.pythonhosted.org/packages/dd/8b/c95f7afa0d628acb14304b05bb25130623706f4e3696b209a11dc57bc43a/airllm-2.3.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.4.0":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.4.0/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.4.0","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"1435862cef30b14ff18094ecf39564056e27be6774ec768c36f65233c490a0c9","md5":"3061000a7e2cd347902a256be83ea473","sha256":"bc9ed8a676ab30f97d12160922e307fb1ffd2eeb155001da9a8f7a444b5abec8"},"downloads":-1,"filename":"airllm-2.4.0-py3-none-any.whl","has_sig":false,"md5_digest":"3061000a7e2cd347902a256be83ea473","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":48600,"upload_time":"2023-12-04T05:47:25","upload_time_iso_8601":"2023-12-04T05:47:25.601325Z","url":"https://files.pythonhosted.org/packages/14/35/862cef30b14ff18094ecf39564056e27be6774ec768c36f65233c490a0c9/airllm-2.4.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e4798aa50258cd51eb466fd87eef556200d3a469f9facbc05e01b13883b268d1","md5":"ab5fdc8969764d3e8b7804fa8d448af1","sha256":"490cffb02c06d9e131bd08a83a954ed28b7d75700f591ece11389e9927a79ded"},"downloads":-1,"filename":"airllm-2.4.0.tar.gz","has_sig":false,"md5_digest":"ab5fdc8969764d3e8b7804fa8d448af1","packagetype":"sdist","python_version":"source","requires_python":null,"size":26300,"upload_time":"2023-12-04T05:47:26","upload_time_iso_8601":"2023-12-04T05:47:26.775162Z","url":"https://files.pythonhosted.org/packages/e4/79/8aa50258cd51eb466fd87eef556200d3a469f9facbc05e01b13883b268d1/airllm-2.4.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.4.1":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.4.1/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.4.1","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"5d827dc775ef1afd10521d85c5f5080af02fb42972aa34483d3a95b244fe97e3","md5":"6aacd89fbdcd888d6a03dcc2a9042e27","sha256":"937ae562993355072c063dc38572b5d7fa3a7ad45eef28d31a590b1ac655d7c3"},"downloads":-1,"filename":"airllm-2.4.1-py3-none-any.whl","has_sig":false,"md5_digest":"6aacd89fbdcd888d6a03dcc2a9042e27","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":49144,"upload_time":"2023-12-05T18:53:23","upload_time_iso_8601":"2023-12-05T18:53:23.865554Z","url":"https://files.pythonhosted.org/packages/5d/82/7dc775ef1afd10521d85c5f5080af02fb42972aa34483d3a95b244fe97e3/airllm-2.4.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"c54c52d58099c235d070c7384d9deaca242da235b27e7da1dfbbe0b40ba72595","md5":"8dc801243fe59598b96f0d9b5ea37b27","sha256":"ee3adc0e3b67873df084d220448eab30a46d25b5cd13bc967d5a7f9c6838811d"},"downloads":-1,"filename":"airllm-2.4.1.tar.gz","has_sig":false,"md5_digest":"8dc801243fe59598b96f0d9b5ea37b27","packagetype":"sdist","python_version":"source","requires_python":null,"size":26982,"upload_time":"2023-12-05T18:53:26","upload_time_iso_8601":"2023-12-05T18:53:26.351927Z","url":"https://files.pythonhosted.org/packages/c5/4c/52d58099c235d070c7384d9deaca242da235b27e7da1dfbbe0b40ba72595/airllm-2.4.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.4.2":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.4.2/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.4.2","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"1b0c35ecdc1c7da1801f0b23ec58e93f6fa7f701746962c89ba7a7dbcb8b06a8","md5":"75cfa1a826e4ee46166073c953be63f6","sha256":"5bd50f8c2005a83044189a772af1c59f91e34c47100d5ff4e335d07b7f71494c"},"downloads":-1,"filename":"airllm-2.4.2-py3-none-any.whl","has_sig":false,"md5_digest":"75cfa1a826e4ee46166073c953be63f6","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":49329,"upload_time":"2023-12-08T00:17:53","upload_time_iso_8601":"2023-12-08T00:17:53.464574Z","url":"https://files.pythonhosted.org/packages/1b/0c/35ecdc1c7da1801f0b23ec58e93f6fa7f701746962c89ba7a7dbcb8b06a8/airllm-2.4.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"dad8b5bc504867dc3ab92e027b2bc560087340af69b90a7b1205eb2c469ea7a9","md5":"992c49759bf54aa06302c886010a8132","sha256":"9088654efefb9f0f6f6a7ccb0fea3ca9581a0e744c584d8c7ca30c326e91e740"},"downloads":-1,"filename":"airllm-2.4.2.tar.gz","has_sig":false,"md5_digest":"992c49759bf54aa06302c886010a8132","packagetype":"sdist","python_version":"source","requires_python":null,"size":27209,"upload_time":"2023-12-08T00:17:55","upload_time_iso_8601":"2023-12-08T00:17:55.351459Z","url":"https://files.pythonhosted.org/packages/da/d8/b5bc504867dc3ab92e027b2bc560087340af69b90a7b1205eb2c469ea7a9/airllm-2.4.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.4.3":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.4.3/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.4.3","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"135a0e292a97f7288045a58a27c2ecb071dd5776e26825e2fa6a526a286e6779","md5":"30b41a891eea10299d873d7e37e7c954","sha256":"be33e1b9d1acbd048223939f8658a24728d72dbe111676c297c5bc70da7f126d"},"downloads":-1,"filename":"airllm-2.4.3-py3-none-any.whl","has_sig":false,"md5_digest":"30b41a891eea10299d873d7e37e7c954","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":49673,"upload_time":"2023-12-17T17:06:04","upload_time_iso_8601":"2023-12-17T17:06:04.593765Z","url":"https://files.pythonhosted.org/packages/13/5a/0e292a97f7288045a58a27c2ecb071dd5776e26825e2fa6a526a286e6779/airllm-2.4.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"ef87dcb6cdaacf7a56676d35fc153cbed8155d8b68b33796a72c775d74f508f7","md5":"f80c877f77cb1164005728ca034c0d27","sha256":"fc6c8e820776ccc171843a0e7395b7d4bc919e4dc7d2e1addaa4b002f47c258e"},"downloads":-1,"filename":"airllm-2.4.3.tar.gz","has_sig":false,"md5_digest":"f80c877f77cb1164005728ca034c0d27","packagetype":"sdist","python_version":"source","requires_python":null,"size":27812,"upload_time":"2023-12-17T17:06:07","upload_time_iso_8601":"2023-12-17T17:06:07.577268Z","url":"https://files.pythonhosted.org/packages/ef/87/dcb6cdaacf7a56676d35fc153cbed8155d8b68b33796a72c775d74f508f7/airllm-2.4.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.4.4":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.4.4/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.4.4","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"ef9de5ed779a4b3ed5aaad85e10aace9c239ef6a716d0371d3959230e55519ea","md5":"7f621e597c7a29b76ba0414fa1805f5d","sha256":"b9470569db9267fd5b33fd31e99addde4b59e0d245232fb83de60c165dbc2128"},"downloads":-1,"filename":"airllm-2.4.4-py3-none-any.whl","has_sig":false,"md5_digest":"7f621e597c7a29b76ba0414fa1805f5d","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":49712,"upload_time":"2023-12-17T17:23:05","upload_time_iso_8601":"2023-12-17T17:23:05.741147Z","url":"https://files.pythonhosted.org/packages/ef/9d/e5ed779a4b3ed5aaad85e10aace9c239ef6a716d0371d3959230e55519ea/airllm-2.4.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"5c4da24e3aa1f0def6afcf9a342edadd772f83f81ec1ed1f03b82ed8fc5026eb","md5":"886f60fe6d138bae2653dfa8900c3006","sha256":"b7a2ba6afe36655f4f60fc8a2df1bbf74646bf9489de90b55a64cf6dd5ee69c8"},"downloads":-1,"filename":"airllm-2.4.4.tar.gz","has_sig":false,"md5_digest":"886f60fe6d138bae2653dfa8900c3006","packagetype":"sdist","python_version":"source","requires_python":null,"size":27875,"upload_time":"2023-12-17T17:23:08","upload_time_iso_8601":"2023-12-17T17:23:08.320986Z","url":"https://files.pythonhosted.org/packages/5c/4d/a24e3aa1f0def6afcf9a342edadd772f83f81ec1ed1f03b82ed8fc5026eb/airllm-2.4.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.4.5":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.4.5/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.4.5","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"29a91e7619eef2d437b665a4b6e2da755fcd224ed4771cb31b1ac9083f7a1a2c","md5":"bf0d0f5d8ad03b22123a6512a434d4f9","sha256":"bb68a9e3714319c96057c6f293db33eb1e9773e31cc66de5999a8a8c06ab5f8c"},"downloads":-1,"filename":"airllm-2.4.5-py3-none-any.whl","has_sig":false,"md5_digest":"bf0d0f5d8ad03b22123a6512a434d4f9","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":49816,"upload_time":"2023-12-17T23:12:40","upload_time_iso_8601":"2023-12-17T23:12:40.237473Z","url":"https://files.pythonhosted.org/packages/29/a9/1e7619eef2d437b665a4b6e2da755fcd224ed4771cb31b1ac9083f7a1a2c/airllm-2.4.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"c0c1b0d4659663ae44df464d65e0fe95d3701f88084fed3d5d34d06eb77a25ef","md5":"cc49adbc6c9800aa2001b9eb2572530d","sha256":"66ec9ef49144472970c40de0d6d2f10d37bbc346dbcc9d6a708358c69ca8d364"},"downloads":-1,"filename":"airllm-2.4.5.tar.gz","has_sig":false,"md5_digest":"cc49adbc6c9800aa2001b9eb2572530d","packagetype":"sdist","python_version":"source","requires_python":null,"size":28028,"upload_time":"2023-12-17T23:12:42","upload_time_iso_8601":"2023-12-17T23:12:42.138780Z","url":"https://files.pythonhosted.org/packages/c0/c1/b0d4659663ae44df464d65e0fe95d3701f88084fed3d5d34d06eb77a25ef/airllm-2.4.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.5":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.5/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.5","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"a943d50ba39bad0c94b4538d84873206ddd80b51e9a729b67fac2c94d9eadfb6","md5":"d38009899f4095597510224cb7bbb344","sha256":"f271f41a90b36c251d9a8f50f73d471d06ae17bbe40561c67d54884cce26cf6e"},"downloads":-1,"filename":"airllm-2.5-py3-none-any.whl","has_sig":false,"md5_digest":"d38009899f4095597510224cb7bbb344","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":50649,"upload_time":"2023-12-19T05:06:44","upload_time_iso_8601":"2023-12-19T05:06:44.540416Z","url":"https://files.pythonhosted.org/packages/a9/43/d50ba39bad0c94b4538d84873206ddd80b51e9a729b67fac2c94d9eadfb6/airllm-2.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"ee91fcc766dfb2ee37b5adcf8e71168dc17f1db0900b1ba13e84d7995c537e86","md5":"532deb2ac0e075a6e37f531236998ecf","sha256":"be561f3501437403b3ad4bb98e45bda64914008e40e20534244cb67ca75e2377"},"downloads":-1,"filename":"airllm-2.5.tar.gz","has_sig":false,"md5_digest":"532deb2ac0e075a6e37f531236998ecf","packagetype":"sdist","python_version":"source","requires_python":null,"size":29132,"upload_time":"2023-12-19T05:06:45","upload_time_iso_8601":"2023-12-19T05:06:45.898441Z","url":"https://files.pythonhosted.org/packages/ee/91/fcc766dfb2ee37b5adcf8e71168dc17f1db0900b1ba13e84d7995c537e86/airllm-2.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.6":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.6/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.6","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"b536d1cefb0725097e7ddf907783f31e9e17b191009978839a3d06598e72c41d","md5":"5bb3c10cb0425a808c1939f7893e6558","sha256":"e5d49b1a4101de1ef526022ace9153a3eae5e55c577de31f8dc7bd58504b1a34"},"downloads":-1,"filename":"airllm-2.6-py3-none-any.whl","has_sig":false,"md5_digest":"5bb3c10cb0425a808c1939f7893e6558","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":33405,"upload_time":"2023-12-20T14:55:02","upload_time_iso_8601":"2023-12-20T14:55:02.283920Z","url":"https://files.pythonhosted.org/packages/b5/36/d1cefb0725097e7ddf907783f31e9e17b191009978839a3d06598e72c41d/airllm-2.6-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"2c9fd4cc78574e06fe86738a1ce2a290ca5847fb1476cada0883f0ad24295c84","md5":"c35409f76287a14dbdcf6fa443b17e98","sha256":"32ad6946d9946050d4cb3527281206d912ce4ff2ab2bd44b20fb1847d69e6441"},"downloads":-1,"filename":"airllm-2.6.tar.gz","has_sig":false,"md5_digest":"c35409f76287a14dbdcf6fa443b17e98","packagetype":"sdist","python_version":"source","requires_python":null,"size":28288,"upload_time":"2023-12-20T14:55:04","upload_time_iso_8601":"2023-12-20T14:55:04.281567Z","url":"https://files.pythonhosted.org/packages/2c/9f/d4cc78574e06fe86738a1ce2a290ca5847fb1476cada0883f0ad24295c84/airllm-2.6.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.6.1":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.6.1/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.6.1","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"1813166d43c7274069aaca71ad054270175950a6f62bd18a7c78d29d6fc12c2d","md5":"503545f56985ec79754c703222236e16","sha256":"4ec55f3fbc81f7aa7dda8dc25365db2c758b5d76c4680e6e8a5cedce219927ce"},"downloads":-1,"filename":"airllm-2.6.1-py3-none-any.whl","has_sig":false,"md5_digest":"503545f56985ec79754c703222236e16","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":33635,"upload_time":"2023-12-20T16:57:11","upload_time_iso_8601":"2023-12-20T16:57:11.188000Z","url":"https://files.pythonhosted.org/packages/18/13/166d43c7274069aaca71ad054270175950a6f62bd18a7c78d29d6fc12c2d/airllm-2.6.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a0af2c40a21bd257686748860a6ce75ec2ca6152a71e9752e5b3a554651004f6","md5":"8f1e8e4e7b209dc59b178a2fef6e5a1f","sha256":"1d561c5627a28d2e30ad9895edd064d104b7a04741cfa7b11ac97637701d46df"},"downloads":-1,"filename":"airllm-2.6.1.tar.gz","has_sig":false,"md5_digest":"8f1e8e4e7b209dc59b178a2fef6e5a1f","packagetype":"sdist","python_version":"source","requires_python":null,"size":28665,"upload_time":"2023-12-20T16:57:12","upload_time_iso_8601":"2023-12-20T16:57:12.438200Z","url":"https://files.pythonhosted.org/packages/a0/af/2c40a21bd257686748860a6ce75ec2ca6152a71e9752e5b3a554651004f6/airllm-2.6.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.6.2":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.6.2/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.6.2","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"253fc94605c7d69ca2da62d5cbf84646738635c610bf27013c4a44b62271cf1c","md5":"f375744870bb075d5165d88a0594ca36","sha256":"737469b379b6ccfdb5179e7110e33c99d532c3621b82ccb63bb4e8f1962883b5"},"downloads":-1,"filename":"airllm-2.6.2-py3-none-any.whl","has_sig":false,"md5_digest":"f375744870bb075d5165d88a0594ca36","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":33676,"upload_time":"2023-12-20T17:51:01","upload_time_iso_8601":"2023-12-20T17:51:01.832958Z","url":"https://files.pythonhosted.org/packages/25/3f/c94605c7d69ca2da62d5cbf84646738635c610bf27013c4a44b62271cf1c/airllm-2.6.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a386a533170081adb64e9d796a298f4c0b7f20011c56d4786b9ee10c602ece26","md5":"21a00373780080b0ce94ce0cb24fec11","sha256":"887855dd7cac53bb07ba4014ca325303f0180cb7c0a4cc2357b4ff550ccacfaa"},"downloads":-1,"filename":"airllm-2.6.2.tar.gz","has_sig":false,"md5_digest":"21a00373780080b0ce94ce0cb24fec11","packagetype":"sdist","python_version":"source","requires_python":null,"size":28690,"upload_time":"2023-12-20T17:51:03","upload_time_iso_8601":"2023-12-20T17:51:03.159887Z","url":"https://files.pythonhosted.org/packages/a3/86/a533170081adb64e9d796a298f4c0b7f20011c56d4786b9ee10c602ece26/airllm-2.6.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.7":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.7/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.7","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"5446524a254541ecb8f2f3551f7707c37e91a54a3057c2b8121601fa8fbf12ff","md5":"8b7434d6224ed1ac6be1014842eafbad","sha256":"58f040883048298d581bc041e4c814698d4f566cd7c9bd15eb133062e5059d71"},"downloads":-1,"filename":"airllm-2.7-py3-none-any.whl","has_sig":false,"md5_digest":"8b7434d6224ed1ac6be1014842eafbad","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":34004,"upload_time":"2023-12-21T04:36:03","upload_time_iso_8601":"2023-12-21T04:36:03.317257Z","url":"https://files.pythonhosted.org/packages/54/46/524a254541ecb8f2f3551f7707c37e91a54a3057c2b8121601fa8fbf12ff/airllm-2.7-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"022a9e63fc6305e6aaf3ef328a2b28075cdd94be41322bba61a0a2ebc0141a56","md5":"2d29d1ffdd8df3c05ba7fc7a4d365542","sha256":"96852892edd47d27a2efaf0c30d0f687052e134bc95a492c3a31ea2f60a72ba1"},"downloads":-1,"filename":"airllm-2.7.tar.gz","has_sig":false,"md5_digest":"2d29d1ffdd8df3c05ba7fc7a4d365542","packagetype":"sdist","python_version":"source","requires_python":null,"size":28778,"upload_time":"2023-12-21T04:36:04","upload_time_iso_8601":"2023-12-21T04:36:04.711104Z","url":"https://files.pythonhosted.org/packages/02/2a/9e63fc6305e6aaf3ef328a2b28075cdd94be41322bba61a0a2ebc0141a56/airllm-2.7.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.8":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.8/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.8","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"1444a0372f4f7aac8860a7d0e417d5a62ab073e406c70bd5fc2cf47f3bd2a681","md5":"25dd1e0be88901f5f4ee58c830ebe128","sha256":"e825f2662cc58e53e64ba67fcd1e2b1ff3b84ba093091749c48add648a15229e"},"downloads":-1,"filename":"airllm-2.8-py3-none-any.whl","has_sig":false,"md5_digest":"25dd1e0be88901f5f4ee58c830ebe128","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":41143,"upload_time":"2023-12-25T22:18:18","upload_time_iso_8601":"2023-12-25T22:18:18.641562Z","url":"https://files.pythonhosted.org/packages/14/44/a0372f4f7aac8860a7d0e417d5a62ab073e406c70bd5fc2cf47f3bd2a681/airllm-2.8-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b82af65d4e6e6e2c32f9ba2d5979d255e6734441073380b870ae2ac43910dd9e","md5":"2b79685b923148aaa7bf3ae07b07919e","sha256":"4cc96f19f62841bf63ffea3f0bd69d036791b7b1b5e9e8bd27dc1729db13e541"},"downloads":-1,"filename":"airllm-2.8.tar.gz","has_sig":false,"md5_digest":"2b79685b923148aaa7bf3ae07b07919e","packagetype":"sdist","python_version":"source","requires_python":null,"size":34335,"upload_time":"2023-12-25T22:18:20","upload_time_iso_8601":"2023-12-25T22:18:20.982571Z","url":"https://files.pythonhosted.org/packages/b8/2a/f65d4e6e6e2c32f9ba2d5979d255e6734441073380b870ae2ac43910dd9e/airllm-2.8.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.8.1":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.8.1/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.8.1","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"5a2774a33f70c0d557661fec34726288eb98fa14fb2972a6089dc7198e8a6620","md5":"596da1a4c2737fd1db2f570b11b4bff7","sha256":"2d9a5c00f08c4a659dd79c7a80eee14f9fd2e4ede75bd262350dcc17b8343b56"},"downloads":-1,"filename":"airllm-2.8.1-py3-none-any.whl","has_sig":false,"md5_digest":"596da1a4c2737fd1db2f570b11b4bff7","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":41165,"upload_time":"2023-12-25T22:20:23","upload_time_iso_8601":"2023-12-25T22:20:23.312278Z","url":"https://files.pythonhosted.org/packages/5a/27/74a33f70c0d557661fec34726288eb98fa14fb2972a6089dc7198e8a6620/airllm-2.8.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"23c1db8ab4347f9e11dae40c71df8afad9348beb6acef4a732f7b394356f1053","md5":"6155ef93bad208f9de459ddc61679adf","sha256":"784d7174ee09c3483de0ff5ce2a039fc33d2248d660a72d7b2691b84a4008e16"},"downloads":-1,"filename":"airllm-2.8.1.tar.gz","has_sig":false,"md5_digest":"6155ef93bad208f9de459ddc61679adf","packagetype":"sdist","python_version":"source","requires_python":null,"size":34351,"upload_time":"2023-12-25T22:20:25","upload_time_iso_8601":"2023-12-25T22:20:25.143464Z","url":"https://files.pythonhosted.org/packages/23/c1/db8ab4347f9e11dae40c71df8afad9348beb6acef4a732f7b394356f1053/airllm-2.8.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.8.2":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.8.2/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.8.2","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"bc02e8879e59774e4597fd40798104f83167eea48818d18f11f1e321302c149c","md5":"18971774279dc0b8d0c139c1d5f48d8e","sha256":"813aba11a2a8b82be518fc20b707e74205cbcae9fe9a3a24da025d9b6fe6c64a"},"downloads":-1,"filename":"airllm-2.8.2-py3-none-any.whl","has_sig":false,"md5_digest":"18971774279dc0b8d0c139c1d5f48d8e","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":41249,"upload_time":"2023-12-25T22:29:10","upload_time_iso_8601":"2023-12-25T22:29:10.250979Z","url":"https://files.pythonhosted.org/packages/bc/02/e8879e59774e4597fd40798104f83167eea48818d18f11f1e321302c149c/airllm-2.8.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"16c945b033b7c19993e04d75c9f52aa252bf4274e58ee515c493f480d53b4111","md5":"4cf61aa68bac4860f8522bd9e9266b00","sha256":"71d671a1dcd323017a8a605616f23f508e58043e0707342eebddfcda6e178a4a"},"downloads":-1,"filename":"airllm-2.8.2.tar.gz","has_sig":false,"md5_digest":"4cf61aa68bac4860f8522bd9e9266b00","packagetype":"sdist","python_version":"source","requires_python":null,"size":34395,"upload_time":"2023-12-25T22:29:12","upload_time_iso_8601":"2023-12-25T22:29:12.023810Z","url":"https://files.pythonhosted.org/packages/16/c9/45b033b7c19993e04d75c9f52aa252bf4274e58ee515c493f480d53b4111/airllm-2.8.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.8.3":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/Anima/tree/main/air_llm","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/Anima/tree/main/air_llm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.8.3/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":"","summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.8.3","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"e79bc004e44bd4f0e4aacda99eeec68ba3e5f5424c47325d9a890853455dd412","md5":"3d59a76de6ad8aff906bb910e6811bc4","sha256":"7a2cfb1133393fd4dfa232550c4becfab2a5b001bdda20c9e856303079facf99"},"downloads":-1,"filename":"airllm-2.8.3-py3-none-any.whl","has_sig":false,"md5_digest":"3d59a76de6ad8aff906bb910e6811bc4","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":41929,"upload_time":"2023-12-27T14:54:45","upload_time_iso_8601":"2023-12-27T14:54:45.791893Z","url":"https://files.pythonhosted.org/packages/e7/9b/c004e44bd4f0e4aacda99eeec68ba3e5f5424c47325d9a890853455dd412/airllm-2.8.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8577111bf6a467937f73d301088134cf03b181ce7076786f3cf74ab2e08dce6c","md5":"7e106ba3c02516c38a5a52c18f4dceb8","sha256":"8fae0b48163d854f33807658e04ea94ccf720b9cc6b38a02e6206508f365574a"},"downloads":-1,"filename":"airllm-2.8.3.tar.gz","has_sig":false,"md5_digest":"7e106ba3c02516c38a5a52c18f4dceb8","packagetype":"sdist","python_version":"source","requires_python":null,"size":35276,"upload_time":"2023-12-27T14:54:47","upload_time_iso_8601":"2023-12-27T14:54:47.076659Z","url":"https://files.pythonhosted.org/packages/85/77/111bf6a467937f73d301088134cf03b181ce7076786f3cf74ab2e08dce6c/airllm-2.8.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.8.4":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/airllm","keywords":null,"license":null,"maintainer":null,"maintainer_email":null,"name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/airllm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.8.4/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":null,"summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.8.4","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"0032fc784dda6917ea0b7f411d7f5d4ac91f2debae983af4760109b3ee99f642","md5":"67f6c75581decea21c824bdb1317835c","sha256":"d0ed841ee5b32930c7af04b07b4830e144eacd6f06202573f60c43c32450297c"},"downloads":-1,"filename":"airllm-2.8.4-py3-none-any.whl","has_sig":false,"md5_digest":"67f6c75581decea21c824bdb1317835c","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":37439,"upload_time":"2024-07-29T20:22:53","upload_time_iso_8601":"2024-07-29T20:22:53.207039Z","url":"https://files.pythonhosted.org/packages/00/32/fc784dda6917ea0b7f411d7f5d4ac91f2debae983af4760109b3ee99f642/airllm-2.8.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a67fe72e111701ad63248ce3650889dd83d02afb6efb9c759b9c0bc715742bd7","md5":"9375db053f393126ff0fed72360c6c52","sha256":"292ca7b8e300c84546e9af923b82ae9c48a3fc87d182775bd97de6e24663a5e1"},"downloads":-1,"filename":"airllm-2.8.4.tar.gz","has_sig":false,"md5_digest":"9375db053f393126ff0fed72360c6c52","packagetype":"sdist","python_version":"source","requires_python":null,"size":37532,"upload_time":"2024-07-29T20:22:54","upload_time_iso_8601":"2024-07-29T20:22:54.841612Z","url":"https://files.pythonhosted.org/packages/a6/7f/e72e111701ad63248ce3650889dd83d02afb6efb9c759b9c0bc715742bd7/airllm-2.8.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.8.6":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/airllm","keywords":null,"license":null,"maintainer":null,"maintainer_email":null,"name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/airllm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.8.6/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":null,"summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning.","version":"2.8.6","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"97746f28bce8daedb1c5f5b749ba2c270cda594380c16b4a0e2c06d28ee53402","md5":"e392285a1e6403839bc780ccea37be68","sha256":"144d5a620a0a08eaf982ed3b6f099e3c96ef1bd980d8cfecfcdd615a4f6dbc3e"},"downloads":-1,"filename":"airllm-2.8.6-py3-none-any.whl","has_sig":false,"md5_digest":"e392285a1e6403839bc780ccea37be68","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":35820,"upload_time":"2024-07-29T20:48:50","upload_time_iso_8601":"2024-07-29T20:48:50.263035Z","url":"https://files.pythonhosted.org/packages/97/74/6f28bce8daedb1c5f5b749ba2c270cda594380c16b4a0e2c06d28ee53402/airllm-2.8.6-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"2f7371403ff9f083d7f2562a3669ed73ee0061fec6117b501c1460143b0db0b3","md5":"a900b57b20c0b2ce41bd101ffed4de7f","sha256":"115f08e49f9dc15d1ff3b0d08b4ddbc3b11ce4334830f5a3863bfffe2c0d2871"},"downloads":-1,"filename":"airllm-2.8.6.tar.gz","has_sig":false,"md5_digest":"a900b57b20c0b2ce41bd101ffed4de7f","packagetype":"sdist","python_version":"source","requires_python":null,"size":34110,"upload_time":"2024-07-29T20:48:51","upload_time_iso_8601":"2024-07-29T20:48:51.996879Z","url":"https://files.pythonhosted.org/packages/2f/73/71403ff9f083d7f2562a3669ed73ee0061fec6117b501c1460143b0db0b3/airllm-2.8.6.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.9":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/airllm","keywords":null,"license":null,"maintainer":null,"maintainer_email":null,"name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/airllm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.9/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":null,"summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning. 8GB vmem to run 405B Llama3.1.","version":"2.9","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"ef8a00f90cf2f6c8d420e786e949aa39ca61c08d998c332556af366d4cf4ea37","md5":"e4adfce24f820fb5ae0e283bdd2bd079","sha256":"0a8e5a0d9c07c29c08731430ce0575ff0fa66ddea684cc966c15c9b70ca1a3dd"},"downloads":-1,"filename":"airllm-2.9-py3-none-any.whl","has_sig":false,"md5_digest":"e4adfce24f820fb5ae0e283bdd2bd079","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":36194,"upload_time":"2024-07-31T03:46:31","upload_time_iso_8601":"2024-07-31T03:46:31.681255Z","url":"https://files.pythonhosted.org/packages/ef/8a/00f90cf2f6c8d420e786e949aa39ca61c08d998c332556af366d4cf4ea37/airllm-2.9-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8c3ea84ac52d148acb0b265405d10c27761cb308c5ac8b64830ab40c5ac240ca","md5":"41ace476b41e8b6692211c821570147f","sha256":"c794ee4e54f4a02883e28abdcd701b869d67dea40f7fc718e91ec6cb2106205e"},"downloads":-1,"filename":"airllm-2.9.tar.gz","has_sig":false,"md5_digest":"41ace476b41e8b6692211c821570147f","packagetype":"sdist","python_version":"source","requires_python":null,"size":34544,"upload_time":"2024-07-31T03:46:33","upload_time_iso_8601":"2024-07-31T03:46:33.404159Z","url":"https://files.pythonhosted.org/packages/8c/3e/a84ac52d148acb0b265405d10c27761cb308c5ac8b64830ab40c5ac240ca/airllm-2.9.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"2.9.1":{"info":{"author":"Gavin Li","author_email":"gavinli@animaai.cloud","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lyogavin/airllm","keywords":null,"license":null,"maintainer":null,"maintainer_email":null,"name":"airllm","package_url":"https://pypi.org/project/airllm/","platform":null,"project_url":"https://pypi.org/project/airllm/","project_urls":{"Homepage":"https://github.com/lyogavin/airllm"},"provides_extra":null,"release_url":"https://pypi.org/project/airllm/2.9.1/","requires_dist":["tqdm","torch","transformers","accelerate","safetensors","optimum","huggingface-hub","scipy"],"requires_python":null,"summary":"AirLLM allows single 4GB GPU card to run 70B large language models without quantization, distillation or pruning. 8GB vmem to run 405B Llama3.1.","version":"2.9.1","yanked":false,"yanked_reason":null},"last_serial":25125557,"urls":[{"comment_text":"","digests":{"blake2b_256":"45ef49ba8c3f0769ec3c92109b8878fab99e21a252b1a668b55d701c2e45b379","md5":"ac7aa281a113c9aa8a7aab8cdc61fc1e","sha256":"ff61c8d198406fe33c424dee3d8b055db2e719cdaf5eab8318fcb5a008e5e8d3"},"downloads":-1,"filename":"airllm-2.9.1-py3-none-any.whl","has_sig":false,"md5_digest":"ac7aa281a113c9aa8a7aab8cdc61fc1e","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":36218,"upload_time":"2024-08-03T14:22:41","upload_time_iso_8601":"2024-08-03T14:22:41.536349Z","url":"https://files.pythonhosted.org/packages/45/ef/49ba8c3f0769ec3c92109b8878fab99e21a252b1a668b55d701c2e45b379/airllm-2.9.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"83df0e854f884aabeb66856bc9b2bb8feebaffcc226ae70547a16c82ebaa4c8d","md5":"f8274bb9458923fd3527f2457a18ecbb","sha256":"c3f3de9d23fca19f1b20c1befe0cfca61ec124ab2de25d88dff1e85f9cb50224"},"downloads":-1,"filename":"airllm-2.9.1.tar.gz","has_sig":false,"md5_digest":"f8274bb9458923fd3527f2457a18ecbb","packagetype":"sdist","python_version":"source","requires_python":null,"size":34530,"upload_time":"2024-08-03T14:22:43","upload_time_iso_8601":"2024-08-03T14:22:43.530786Z","url":"https://files.pythonhosted.org/packages/83/df/0e854f884aabeb66856bc9b2bb8feebaffcc226ae70547a16c82ebaa4c8d/airllm-2.9.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}