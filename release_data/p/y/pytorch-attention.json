{"1.0.0":{"info":{"author":"changzy00","author_email":"changzy@pku.org.cn","bugtrack_url":null,"classifiers":["Intended Audience :: Developers","Intended Audience :: Education","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/changzy00/pytorch-attention","keywords":"AttentionCNNsMLPsViTs","license":"Apache","maintainer":"","maintainer_email":"","name":"pytorch-attention","package_url":"https://pypi.org/project/pytorch-attention/","platform":null,"project_url":"https://pypi.org/project/pytorch-attention/","project_urls":{"Homepage":"https://github.com/changzy00/pytorch-attention"},"provides_extra":null,"release_url":"https://pypi.org/project/pytorch-attention/1.0.0/","requires_dist":null,"requires_python":">=3.7.0","summary":"Pytorch implementation of popular Attention Mechanisms, Vision Transformers, MLP-Like models and CNNs.","version":"1.0.0","yanked":false,"yanked_reason":null},"last_serial":18541865,"urls":[{"comment_text":"","digests":{"blake2b_256":"5bc7a20d2f16a97925a1951571bda607ac5fb9cd4fbbed01a47a8a498629e803","md5":"2d8bde10ae5f63017bae85e2a40543bb","sha256":"cf74e56fbe57c0e93f84a61819c670395cb4f7f025fb4142b9ef9ba765417d86"},"downloads":-1,"filename":"pytorch-attention-1.0.0.tar.gz","has_sig":false,"md5_digest":"2d8bde10ae5f63017bae85e2a40543bb","packagetype":"sdist","python_version":"source","requires_python":">=3.7.0","size":3340,"upload_time":"2023-06-17T08:49:02","upload_time_iso_8601":"2023-06-17T08:49:02.330894Z","url":"https://files.pythonhosted.org/packages/5b/c7/a20d2f16a97925a1951571bda607ac5fb9cd4fbbed01a47a8a498629e803/pytorch-attention-1.0.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}