{"0.0.10":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.10/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","daily-python~=0.7.4; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.10","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"38f70eb4f7ba21ded0686e85200aad95ab5fe238cd091d6413f48a62bf4e211d","md5":"9a73e4f20102b4db31f72b4571aad88a","sha256":"653cc1e425c9b2a5eb1c9ef79541256b4236c213b5e39eb1e7da4d594f626668"},"downloads":-1,"filename":"pipecat_ai-0.0.10-py3-none-any.whl","has_sig":false,"md5_digest":"9a73e4f20102b4db31f72b4571aad88a","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":62925,"upload_time":"2024-05-14T01:17:44","upload_time_iso_8601":"2024-05-14T01:17:44.588014Z","url":"https://files.pythonhosted.org/packages/38/f7/0eb4f7ba21ded0686e85200aad95ab5fe238cd091d6413f48a62bf4e211d/pipecat_ai-0.0.10-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"1ee6b29ac2ccd2c98cf88623729ff53583dec36f89cffdb63741ae4575bc9fb9","md5":"add9f294b726dd99036b8c3f3f91c29f","sha256":"2e59020d19e9380132a00e155c54d53541a25ceb397e0203684bbac4e706d612"},"downloads":-1,"filename":"pipecat_ai-0.0.10.tar.gz","has_sig":false,"md5_digest":"add9f294b726dd99036b8c3f3f91c29f","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":63266887,"upload_time":"2024-05-14T01:17:48","upload_time_iso_8601":"2024-05-14T01:17:48.749045Z","url":"https://files.pythonhosted.org/packages/1e/e6/b29ac2ccd2c98cf88623729ff53583dec36f89cffdb63741ae4575bc9fb9/pipecat_ai-0.0.10.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.11":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.11/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","daily-python~=0.7.4; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.11","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"ee63ef65a02471e5c9cec73728ff411a39dbd8efa1fcb740d3f30c6a132ba8c4","md5":"6b7d26f256e7439db03a4c76df563cfa","sha256":"ee9015990300f333c5f16f9275cb01bd79a6a8a969cb3391bcb334cf01c115bf"},"downloads":-1,"filename":"pipecat_ai-0.0.11-py3-none-any.whl","has_sig":false,"md5_digest":"6b7d26f256e7439db03a4c76df563cfa","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":62426,"upload_time":"2024-05-14T07:43:53","upload_time_iso_8601":"2024-05-14T07:43:53.512525Z","url":"https://files.pythonhosted.org/packages/ee/63/ef65a02471e5c9cec73728ff411a39dbd8efa1fcb740d3f30c6a132ba8c4/pipecat_ai-0.0.11-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"fb76882112b8792d85df4e6a2b144f7f811942792e2ecd2fd88644b4714901bb","md5":"c002b8f8c1d6df4cdea33855ff75aada","sha256":"6f7f95bfd6d43df0ec4d1387d604f1985405263a45858ae2cef876bdae147ad2"},"downloads":-1,"filename":"pipecat_ai-0.0.11.tar.gz","has_sig":false,"md5_digest":"c002b8f8c1d6df4cdea33855ff75aada","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":63266193,"upload_time":"2024-05-14T07:43:55","upload_time_iso_8601":"2024-05-14T07:43:55.633334Z","url":"https://files.pythonhosted.org/packages/fb/76/882112b8792d85df4e6a2b144f7f811942792e2ecd2fd88644b4714901bb/pipecat_ai-0.0.11.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.12":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.12/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","daily-python~=0.7.4; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.12","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"c2926b1b9468db52fe9399356afbd7dabe8f77c0a47fea4d5ca6069d4f1f2390","md5":"bf507ecdf8e6690be4d0b5cf6cc3cc8f","sha256":"f53e34dbb3b2e38c0de30845cabd59dc41876d7646205c9a1183083ca1c4f963"},"downloads":-1,"filename":"pipecat_ai-0.0.12-py3-none-any.whl","has_sig":false,"md5_digest":"bf507ecdf8e6690be4d0b5cf6cc3cc8f","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":62449,"upload_time":"2024-05-14T21:56:40","upload_time_iso_8601":"2024-05-14T21:56:40.069628Z","url":"https://files.pythonhosted.org/packages/c2/92/6b1b9468db52fe9399356afbd7dabe8f77c0a47fea4d5ca6069d4f1f2390/pipecat_ai-0.0.12-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"40efe92c16066f2d509da2ab7992d9322291e9eb91002a52b211eb5133b196e6","md5":"6a5ce3b80cc7c384180caab8a3e5aa60","sha256":"544f0371e7452597d6fbd1465b943b0d3a8dd7154c7bd8e5e371b38c7782d31f"},"downloads":-1,"filename":"pipecat_ai-0.0.12.tar.gz","has_sig":false,"md5_digest":"6a5ce3b80cc7c384180caab8a3e5aa60","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":63267970,"upload_time":"2024-05-14T21:56:43","upload_time_iso_8601":"2024-05-14T21:56:43.990065Z","url":"https://files.pythonhosted.org/packages/40/ef/e92c16066f2d509da2ab7992d9322291e9eb91002a52b211eb5133b196e6/pipecat_ai-0.0.12.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.13":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.13/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","daily-python~=0.7.4; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.13","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"7b488dc6b1db641a588e85cb6cf8878917be53dcf55af70bcfa744051a01fb3d","md5":"90af99c253a995bcbff529f970be266f","sha256":"b4e660ee5501a379a98115fb2fc048b9ceadc50270fe7f603767a718265587e9"},"downloads":-1,"filename":"pipecat_ai-0.0.13-py3-none-any.whl","has_sig":false,"md5_digest":"90af99c253a995bcbff529f970be266f","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":62903,"upload_time":"2024-05-15T02:11:09","upload_time_iso_8601":"2024-05-15T02:11:09.925173Z","url":"https://files.pythonhosted.org/packages/7b/48/8dc6b1db641a588e85cb6cf8878917be53dcf55af70bcfa744051a01fb3d/pipecat_ai-0.0.13-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"5214d73a397f87a539737c36d4216829509a42f174e4d50b51855e1346e40569","md5":"e0753a50191f900bfb5e29cf685f9037","sha256":"0b6702da4b8ee57c32ad955ff7db95bde0554a9f74618b124bb52dcca7c73167"},"downloads":-1,"filename":"pipecat_ai-0.0.13.tar.gz","has_sig":false,"md5_digest":"e0753a50191f900bfb5e29cf685f9037","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":63268324,"upload_time":"2024-05-15T02:11:12","upload_time_iso_8601":"2024-05-15T02:11:12.199648Z","url":"https://files.pythonhosted.org/packages/52/14/d73a397f87a539737c36d4216829509a42f174e4d50b51855e1346e40569/pipecat_ai-0.0.13.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.14":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.14/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","daily-python~=0.7.4; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.14","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"8841c8d82113a842ace51668a06555513f2bf9cebd21fb2994fab0ad1ba221c6","md5":"9720324fdd8d89fc548f3ec93d217db5","sha256":"b0c8cbf166ee39e04799e4fe9f7c82a2d3e2da8ab217679e6b6497e4db939c4b"},"downloads":-1,"filename":"pipecat_ai-0.0.14-py3-none-any.whl","has_sig":false,"md5_digest":"9720324fdd8d89fc548f3ec93d217db5","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":63325,"upload_time":"2024-05-15T23:02:42","upload_time_iso_8601":"2024-05-15T23:02:42.615213Z","url":"https://files.pythonhosted.org/packages/88/41/c8d82113a842ace51668a06555513f2bf9cebd21fb2994fab0ad1ba221c6/pipecat_ai-0.0.14-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"1b27dc0ebbbad7fa397e7b1e6acc65379ee9c4cb387b9ea333ae72cca3ff2810","md5":"acec5b49e65333f156f1c52301f28283","sha256":"bd86433353cc8539fbfe16f12bccf70352b855888e0452ef19ec9bd89b6546e3"},"downloads":-1,"filename":"pipecat_ai-0.0.14.tar.gz","has_sig":false,"md5_digest":"acec5b49e65333f156f1c52301f28283","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":63268809,"upload_time":"2024-05-15T23:02:46","upload_time_iso_8601":"2024-05-15T23:02:46.611753Z","url":"https://files.pythonhosted.org/packages/1b/27/dc0ebbbad7fa397e7b1e6acc65379ee9c4cb387b9ea333ae72cca3ff2810/pipecat_ai-0.0.14.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.15":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.15/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","daily-python~=0.7.4; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.15","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"5742b3c2dfff5f515892085ae6fe2ba7217654cb0316e9f083184ca500452c12","md5":"2d9509d5a07a20668d6f7699033fb5ef","sha256":"364eb339911bbb55f0b3ea32b49d6bbf20cf9c32e4b275ee2093c26d4c76c7c4"},"downloads":-1,"filename":"pipecat_ai-0.0.15-py3-none-any.whl","has_sig":false,"md5_digest":"2d9509d5a07a20668d6f7699033fb5ef","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":63308,"upload_time":"2024-05-16T00:10:15","upload_time_iso_8601":"2024-05-16T00:10:15.929683Z","url":"https://files.pythonhosted.org/packages/57/42/b3c2dfff5f515892085ae6fe2ba7217654cb0316e9f083184ca500452c12/pipecat_ai-0.0.15-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e405f3d7c75f226b372b9b09ff0dd9f30f3d5194687e2eeff27b54f2d53a838d","md5":"0dcd4464ee19013bbabfb3b53714f423","sha256":"6d826284f2f55b9b021d6007f9cc3035518741b481c6d6cf4ac7f956bb053f20"},"downloads":-1,"filename":"pipecat_ai-0.0.15.tar.gz","has_sig":false,"md5_digest":"0dcd4464ee19013bbabfb3b53714f423","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":63268834,"upload_time":"2024-05-16T00:10:17","upload_time_iso_8601":"2024-05-16T00:10:17.968180Z","url":"https://files.pythonhosted.org/packages/e4/05/f3d7c75f226b372b9b09ff0dd9f30f3d5194687e2eeff27b54f2d53a838d/pipecat_ai-0.0.15.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.16":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.16/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","daily-python~=0.7.4; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.16","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"100f51f83747feeddce2e69aabe49160585f428caa7db3b1fbfb8f0dca78fcc9","md5":"a33186704d5f3815a89e1f27d6ac0152","sha256":"5b1e9230946ae2c58bced1f613888e132a5eca2303f847d9abdff006b6345c68"},"downloads":-1,"filename":"pipecat_ai-0.0.16-py3-none-any.whl","has_sig":false,"md5_digest":"a33186704d5f3815a89e1f27d6ac0152","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":63486,"upload_time":"2024-05-17T01:17:52","upload_time_iso_8601":"2024-05-17T01:17:52.601164Z","url":"https://files.pythonhosted.org/packages/10/0f/51f83747feeddce2e69aabe49160585f428caa7db3b1fbfb8f0dca78fcc9/pipecat_ai-0.0.16-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"539cff98069633519e0bb24b69926a5d227bcc9c6d289de6b3f75d3df24e5914","md5":"b28522c7b9ab309afcedbdac468aae03","sha256":"bcf40a4219eed9dbd5a8602a88b43957cc2469df138ee808f317085e3b8c9d40"},"downloads":-1,"filename":"pipecat_ai-0.0.16.tar.gz","has_sig":false,"md5_digest":"b28522c7b9ab309afcedbdac468aae03","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":63269217,"upload_time":"2024-05-17T01:17:56","upload_time_iso_8601":"2024-05-17T01:17:56.027696Z","url":"https://files.pythonhosted.org/packages/53/9c/ff98069633519e0bb24b69926a5d227bcc9c6d289de6b3f75d3df24e5914/pipecat_ai-0.0.16.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.17":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.17/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","daily-python~=0.7.4; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.17","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"91b0b116c9d4e7e62e63b5988d8763537971dd7ec89203dfb05d8debbba3a0ab","md5":"89b624fb1c129e1e86448e619cb73197","sha256":"8d4612f0d5ff3c9a3119feabb343cdf37bd8008fbf0871c5ff82d39fde543847"},"downloads":-1,"filename":"pipecat_ai-0.0.17-py3-none-any.whl","has_sig":false,"md5_digest":"89b624fb1c129e1e86448e619cb73197","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":67753,"upload_time":"2024-05-20T02:31:22","upload_time_iso_8601":"2024-05-20T02:31:22.647015Z","url":"https://files.pythonhosted.org/packages/91/b0/b116c9d4e7e62e63b5988d8763537971dd7ec89203dfb05d8debbba3a0ab/pipecat_ai-0.0.17-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"6cc28a9c73d56c39c9c7fd5414bc00afe7f80ba9662d9f723f63064178a64486","md5":"9f7e4487a10c5bac292b7eec40bd25a6","sha256":"5729c9acf2aa486a74fc29f7935b0360d79a7a4611c9d001394f120f14fc3b06"},"downloads":-1,"filename":"pipecat_ai-0.0.17.tar.gz","has_sig":false,"md5_digest":"9f7e4487a10c5bac292b7eec40bd25a6","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":63273673,"upload_time":"2024-05-20T02:31:25","upload_time_iso_8601":"2024-05-20T02:31:25.572990Z","url":"https://files.pythonhosted.org/packages/6c/c2/8a9c73d56c39c9c7fd5414bc00afe7f80ba9662d9f723f63064178a64486/pipecat_ai-0.0.17.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.18":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.18/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","daily-python~=0.7.4; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.18","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"72890b3df6afd03c28ee70c4201342911f3001a9ea05eacc1d2fcabfedf361ef","md5":"1a8be4faf0a1edf52a7194e0b7d1dc41","sha256":"1bd70df2e23727bc86637d10773d9b1295b815b3ec0fb0a193107241ba072378"},"downloads":-1,"filename":"pipecat_ai-0.0.18-py3-none-any.whl","has_sig":false,"md5_digest":"1a8be4faf0a1edf52a7194e0b7d1dc41","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":67761,"upload_time":"2024-05-20T17:35:35","upload_time_iso_8601":"2024-05-20T17:35:35.510538Z","url":"https://files.pythonhosted.org/packages/72/89/0b3df6afd03c28ee70c4201342911f3001a9ea05eacc1d2fcabfedf361ef/pipecat_ai-0.0.18-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"aa837e66db44d119a9bcc5813a557d0f797c1d391dfd64a59331902f87aaa6d5","md5":"47c378341e697f0d29d40b3ffb74c3d4","sha256":"ccd3631577b9b901d807a110eaacf19be3d7f2ab5f2952f47f9650c4fcf852c3"},"downloads":-1,"filename":"pipecat_ai-0.0.18.tar.gz","has_sig":false,"md5_digest":"47c378341e697f0d29d40b3ffb74c3d4","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":63273623,"upload_time":"2024-05-20T17:35:40","upload_time_iso_8601":"2024-05-20T17:35:40.511486Z","url":"https://files.pythonhosted.org/packages/aa/83/7e66db44d119a9bcc5813a557d0f797c1d391dfd64a59331902f87aaa6d5/pipecat_ai-0.0.18.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.19":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.19/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","daily-python~=0.7.4; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.19","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"fe8bd3eb793cec74844e007f3a8f48f93467ef9cddf8177a39afd8afa20c9172","md5":"2803f6f6de44c6ac0948e7c0a7a7f23d","sha256":"106351aa945e37374675117dc0821d043372f9af2a63b9ec5d8cdc01626eb579"},"downloads":-1,"filename":"pipecat_ai-0.0.19-py3-none-any.whl","has_sig":false,"md5_digest":"2803f6f6de44c6ac0948e7c0a7a7f23d","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":67809,"upload_time":"2024-05-21T04:39:52","upload_time_iso_8601":"2024-05-21T04:39:52.062982Z","url":"https://files.pythonhosted.org/packages/fe/8b/d3eb793cec74844e007f3a8f48f93467ef9cddf8177a39afd8afa20c9172/pipecat_ai-0.0.19-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"1cc731e1f71d87deec900b40ef064caf24eb1f80eab8125574a1d9d7ada3022c","md5":"376b48735cde604a9b92e65234dbd84b","sha256":"63e0ff0e10f12cd299f0ce14b07519df7a760c765c7a19db8d8277727d9a53e0"},"downloads":-1,"filename":"pipecat_ai-0.0.19.tar.gz","has_sig":false,"md5_digest":"376b48735cde604a9b92e65234dbd84b","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":63273693,"upload_time":"2024-05-21T04:39:55","upload_time_iso_8601":"2024-05-21T04:39:55.425539Z","url":"https://files.pythonhosted.org/packages/1c/c7/31e1f71d87deec900b40ef064caf24eb1f80eab8125574a1d9d7ada3022c/pipecat_ai-0.0.19.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.20":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.20/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","pyloudnorm~=0.1.1","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","daily-python~=0.7.4; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.20","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"c9d5fcc9b270d3b5b9596658041ddedb65bb72db9a8a113a8eca85b89a69eca6","md5":"f96beeff169998c988d9ae470b64ea59","sha256":"8731f588c8bfe7429be6d27b546f86747f46898f390f54f2cc515d90ed1f2f40"},"downloads":-1,"filename":"pipecat_ai-0.0.20-py3-none-any.whl","has_sig":false,"md5_digest":"f96beeff169998c988d9ae470b64ea59","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":68346,"upload_time":"2024-05-22T21:29:26","upload_time_iso_8601":"2024-05-22T21:29:26.712440Z","url":"https://files.pythonhosted.org/packages/c9/d5/fcc9b270d3b5b9596658041ddedb65bb72db9a8a113a8eca85b89a69eca6/pipecat_ai-0.0.20-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"1b985c5337f762d3c9f63f5a54f89384b52ce922bf33744408b2426ccc7ec660","md5":"0a3d54d7b76733d22b242e7e15a7fba8","sha256":"643acb74599097b0e314e9c66347b3e1c6096b44b6c94cca4ccf92a49a50e6da"},"downloads":-1,"filename":"pipecat_ai-0.0.20.tar.gz","has_sig":false,"md5_digest":"0a3d54d7b76733d22b242e7e15a7fba8","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":63274383,"upload_time":"2024-05-22T21:29:29","upload_time_iso_8601":"2024-05-22T21:29:29.874462Z","url":"https://files.pythonhosted.org/packages/1b/98/5c5337f762d3c9f63f5a54f89384b52ce922bf33744408b2426ccc7ec660/pipecat_ai-0.0.20.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.21":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.21/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","pyloudnorm~=0.1.1","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","daily-python~=0.7.4; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.21","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"8e6c3a33ccff09e242678ac2d471719f13c3031af76826cbdbbd32a1c07be409","md5":"d1e4e4874bc8db3e9d465d3b6a64954e","sha256":"76596d427a736e99ba8a257f2bcc711be4fd65d2137ab48e1ad3194965bf10a3"},"downloads":-1,"filename":"pipecat_ai-0.0.21-py3-none-any.whl","has_sig":false,"md5_digest":"d1e4e4874bc8db3e9d465d3b6a64954e","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":70207,"upload_time":"2024-05-23T04:46:57","upload_time_iso_8601":"2024-05-23T04:46:57.308315Z","url":"https://files.pythonhosted.org/packages/8e/6c/3a33ccff09e242678ac2d471719f13c3031af76826cbdbbd32a1c07be409/pipecat_ai-0.0.21-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"1db88a65d4303aff4b67a8a69d9a6ed14f118f427e6365bb180dc5f035be3926","md5":"da81734ad9349638bfb207b116707401","sha256":"5d48710692600338ec1ff3e8a07019ab8314ae85b2730922e4b62aee3a092b7c"},"downloads":-1,"filename":"pipecat_ai-0.0.21.tar.gz","has_sig":false,"md5_digest":"da81734ad9349638bfb207b116707401","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":63276675,"upload_time":"2024-05-23T04:46:59","upload_time_iso_8601":"2024-05-23T04:46:59.459135Z","url":"https://files.pythonhosted.org/packages/1d/b8/8a65d4303aff4b67a8a69d9a6ed14f118f427e6365bb180dc5f035be3926/pipecat_ai-0.0.21.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.22":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.22/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","pyloudnorm~=0.1.1","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","daily-python~=0.8.0; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.22","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"cd0653567207704f6b2466853c2b5b816e5fdd69345b8807f109210268f1d9bd","md5":"aaac84d1387b914c65f2269977a03d96","sha256":"85b81374787ddcc01b0c93a33c112b11f58a480c15fdf0b5a73346cd73f48685"},"downloads":-1,"filename":"pipecat_ai-0.0.22-py3-none-any.whl","has_sig":false,"md5_digest":"aaac84d1387b914c65f2269977a03d96","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":70777,"upload_time":"2024-05-23T21:05:19","upload_time_iso_8601":"2024-05-23T21:05:19.843528Z","url":"https://files.pythonhosted.org/packages/cd/06/53567207704f6b2466853c2b5b816e5fdd69345b8807f109210268f1d9bd/pipecat_ai-0.0.22-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"58f3f5c4ef8fbc0b02fc5bb636442cc3fd022fa4cb64fd89e1771e50bdf9f1a6","md5":"b46bd8c5b1433fa8a84d5bbc70d55913","sha256":"11bc8c67567d1efd22cf34f9cbf19e24d9469950fcbecf5ac5685980b5f1576d"},"downloads":-1,"filename":"pipecat_ai-0.0.22.tar.gz","has_sig":false,"md5_digest":"b46bd8c5b1433fa8a84d5bbc70d55913","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":63277313,"upload_time":"2024-05-23T21:05:27","upload_time_iso_8601":"2024-05-23T21:05:27.459961Z","url":"https://files.pythonhosted.org/packages/58/f3/f5c4ef8fbc0b02fc5bb636442cc3fd022fa4cb64fd89e1771e50bdf9f1a6/pipecat_ai-0.0.22.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.23":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.23/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","pyloudnorm~=0.1.1","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","daily-python~=0.8.0; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.23","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"b79e75132ac3544fa9e1bcb0600589e8249913fb8f6afa0eb0fe89a586a37fec","md5":"cda694e4c30d6ed3cab6891a7474f742","sha256":"e6691a6002b0ca53cece318ea1de7de1ce36db5378fc60d2140de53e1c7571e1"},"downloads":-1,"filename":"pipecat_ai-0.0.23-py3-none-any.whl","has_sig":false,"md5_digest":"cda694e4c30d6ed3cab6891a7474f742","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":70788,"upload_time":"2024-05-23T21:44:41","upload_time_iso_8601":"2024-05-23T21:44:41.502302Z","url":"https://files.pythonhosted.org/packages/b7/9e/75132ac3544fa9e1bcb0600589e8249913fb8f6afa0eb0fe89a586a37fec/pipecat_ai-0.0.23-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"522a201751c95f5da516190dd245eddb90d98de67135516690bee56836b42d70","md5":"95ed02b572a1aa0580cd65f80cf644e7","sha256":"98f245774f09c1e345238812cf85c0c74330f33ae25e129af9ef8705e22ac603"},"downloads":-1,"filename":"pipecat_ai-0.0.23.tar.gz","has_sig":false,"md5_digest":"95ed02b572a1aa0580cd65f80cf644e7","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":63277331,"upload_time":"2024-05-23T21:44:44","upload_time_iso_8601":"2024-05-23T21:44:44.456992Z","url":"https://files.pythonhosted.org/packages/52/2a/201751c95f5da516190dd245eddb90d98de67135516690bee56836b42d70/pipecat_ai-0.0.23.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.24":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.24/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","pyloudnorm~=0.1.1","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","daily-python~=0.9.0; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.24","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"1281a07ae3eeddee1711c05e403a401d2b80cd7660047975030e32564af193dd","md5":"bf1a51e0032b9d63a5e8f013819c732a","sha256":"111d398679b6d8dd67426569549b38bcb70f7a4eba05f394095e954dd2fbe68b"},"downloads":-1,"filename":"pipecat_ai-0.0.24-py3-none-any.whl","has_sig":false,"md5_digest":"bf1a51e0032b9d63a5e8f013819c732a","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":71237,"upload_time":"2024-05-29T15:26:31","upload_time_iso_8601":"2024-05-29T15:26:31.221262Z","url":"https://files.pythonhosted.org/packages/12/81/a07ae3eeddee1711c05e403a401d2b80cd7660047975030e32564af193dd/pipecat_ai-0.0.24-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"648096f2b0334b9c3538556af89f6f123386710d11e5d54820a2bb82446d85ec","md5":"51734f52a631f96653fe61fabb5c1ab6","sha256":"8208efc1cd9ff1e13ee23e15fd58302024555b9ce94a7beef0af4f540fc70dd2"},"downloads":-1,"filename":"pipecat_ai-0.0.24.tar.gz","has_sig":false,"md5_digest":"51734f52a631f96653fe61fabb5c1ab6","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":63278550,"upload_time":"2024-05-29T15:26:34","upload_time_iso_8601":"2024-05-29T15:26:34.812787Z","url":"https://files.pythonhosted.org/packages/64/80/96f2b0334b9c3538556af89f6f123386710d11e5d54820a2bb82446d85ec/pipecat_ai-0.0.24.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.25":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.25/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","protobuf~=4.25.3","pyloudnorm~=0.1.1","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","numpy~=1.26.0; extra == \"cartesia\"","sounddevice; extra == \"cartesia\"","cartesia; extra == \"cartesia\"","daily-python~=0.9.0; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","langchain~=0.2.1; extra == \"langchain\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.25","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"fe568199cd00ce5dfa523b6121483efd99667947553274f5c8f7f7f1e43160fc","md5":"94c2e2597ef7b944214a7c73ef1526e1","sha256":"83551d314576c21fa60bba128f33eb90b7a8c0a35dc97215bac1a4a90c5f12f8"},"downloads":-1,"filename":"pipecat_ai-0.0.25-py3-none-any.whl","has_sig":false,"md5_digest":"94c2e2597ef7b944214a7c73ef1526e1","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":77046,"upload_time":"2024-05-31T23:53:23","upload_time_iso_8601":"2024-05-31T23:53:23.792328Z","url":"https://files.pythonhosted.org/packages/fe/56/8199cd00ce5dfa523b6121483efd99667947553274f5c8f7f7f1e43160fc/pipecat_ai-0.0.25-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"0790f4570cb74c4badae1ad66d88c38fb37c0e9ca743dfcc5a8c3e20ae5fda70","md5":"a158793bb6180119d6a7b3b077f18c27","sha256":"3bed38628e40a3941dc360eb78785e4ed1a860dc37ea000515e36cfc08382eba"},"downloads":-1,"filename":"pipecat_ai-0.0.25.tar.gz","has_sig":false,"md5_digest":"a158793bb6180119d6a7b3b077f18c27","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":64309931,"upload_time":"2024-05-31T23:53:27","upload_time_iso_8601":"2024-05-31T23:53:27.094694Z","url":"https://files.pythonhosted.org/packages/07/90/f4570cb74c4badae1ad66d88c38fb37c0e9ca743dfcc5a8c3e20ae5fda70/pipecat_ai-0.0.25.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.26":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.26/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","protobuf~=4.25.3","pyloudnorm~=0.1.1","typing-extensions~=4.12.1","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","numpy~=1.26.0; extra == \"cartesia\"","sounddevice; extra == \"cartesia\"","cartesia; extra == \"cartesia\"","daily-python~=0.9.0; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","langchain~=0.2.1; extra == \"langchain\"","langchain-community~=0.2.1; extra == \"langchain\"","langchain-openai~=0.1.8; extra == \"langchain\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.26","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"c42204c04ef361395e20907dceb3462e9bde0dec32d4df9ef82e190a0d6e42a4","md5":"d35660d9f6e3992c5d430832203d19ec","sha256":"de931dad3a975be49628b181ec895f883b8d61d399870c103821478bc49297db"},"downloads":-1,"filename":"pipecat_ai-0.0.26-py3-none-any.whl","has_sig":false,"md5_digest":"d35660d9f6e3992c5d430832203d19ec","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":79402,"upload_time":"2024-06-05T17:13:31","upload_time_iso_8601":"2024-06-05T17:13:31.106238Z","url":"https://files.pythonhosted.org/packages/c4/22/04c04ef361395e20907dceb3462e9bde0dec32d4df9ef82e190a0d6e42a4/pipecat_ai-0.0.26-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7879b27ea81d35fe372c60e4c1471e98ba2dd65bb8fe062b0a29b7054d8fd888","md5":"63aed42eb60837b66168a02437ab4feb","sha256":"a75c1850195e1b67f82e4aa96e2b17cc6d7ff74da840e7b1125015daa7622192"},"downloads":-1,"filename":"pipecat_ai-0.0.26.tar.gz","has_sig":false,"md5_digest":"63aed42eb60837b66168a02437ab4feb","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":64313151,"upload_time":"2024-06-05T17:14:14","upload_time_iso_8601":"2024-06-05T17:14:14.699555Z","url":"https://files.pythonhosted.org/packages/78/79/b27ea81d35fe372c60e4c1471e98ba2dd65bb8fe062b0a29b7054d8fd888/pipecat_ai-0.0.26.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.27":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.27/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","protobuf~=4.25.3","pyloudnorm~=0.1.1","typing-extensions~=4.12.1","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","numpy~=1.26.0; extra == \"cartesia\"","sounddevice; extra == \"cartesia\"","cartesia; extra == \"cartesia\"","daily-python~=0.9.0; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","langchain~=0.2.1; extra == \"langchain\"","langchain-community~=0.2.1; extra == \"langchain\"","langchain-openai~=0.1.8; extra == \"langchain\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.27","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"3135f71d7b2b9eda41fa3e4c0fa38f7b62b652fbf649f14120c4c1ed84f9c1ae","md5":"cf4124359e4ad8c368a37f608d4de6e2","sha256":"8fd13b5d032430b03d6def319e90d6d355acc4c5712bb76e84ba6825c727837c"},"downloads":-1,"filename":"pipecat_ai-0.0.27-py3-none-any.whl","has_sig":false,"md5_digest":"cf4124359e4ad8c368a37f608d4de6e2","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":79431,"upload_time":"2024-06-05T19:18:57","upload_time_iso_8601":"2024-06-05T19:18:57.737448Z","url":"https://files.pythonhosted.org/packages/31/35/f71d7b2b9eda41fa3e4c0fa38f7b62b652fbf649f14120c4c1ed84f9c1ae/pipecat_ai-0.0.27-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7ad4a25916e02bd188bce979ad2c919e93cb76f7adeacd4c3ec88ba1282b8561","md5":"d84128ed01eff6a637e5f29d4ac16d11","sha256":"179e118856ff99968258ef2c011700420f8babe4e6f49e96f244b1ba415a0ff8"},"downloads":-1,"filename":"pipecat_ai-0.0.27.tar.gz","has_sig":false,"md5_digest":"d84128ed01eff6a637e5f29d4ac16d11","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":64313257,"upload_time":"2024-06-05T19:19:02","upload_time_iso_8601":"2024-06-05T19:19:02.107464Z","url":"https://files.pythonhosted.org/packages/7a/d4/a25916e02bd188bce979ad2c919e93cb76f7adeacd4c3ec88ba1282b8561/pipecat_ai-0.0.27.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.28":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.28/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","protobuf~=4.25.3","pyloudnorm~=0.1.1","typing-extensions~=4.12.1","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","numpy~=1.26.0; extra == \"cartesia\"","sounddevice; extra == \"cartesia\"","cartesia; extra == \"cartesia\"","daily-python~=0.9.0; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","langchain~=0.2.1; extra == \"langchain\"","langchain-community~=0.2.1; extra == \"langchain\"","langchain-openai~=0.1.8; extra == \"langchain\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.28","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"8c5bdce3b3cebdd01dfa9fc2ac29378f912a2a554c9f59fac09c7266fe85eb3e","md5":"0e5bd49a8f4b81f4256823f2969d47d3","sha256":"642c782f8be6fd04fbb87ef66344f2eccea597548d55a33d8ebda35fab483463"},"downloads":-1,"filename":"pipecat_ai-0.0.28-py3-none-any.whl","has_sig":false,"md5_digest":"0e5bd49a8f4b81f4256823f2969d47d3","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":79628,"upload_time":"2024-06-05T21:53:28","upload_time_iso_8601":"2024-06-05T21:53:28.872336Z","url":"https://files.pythonhosted.org/packages/8c/5b/dce3b3cebdd01dfa9fc2ac29378f912a2a554c9f59fac09c7266fe85eb3e/pipecat_ai-0.0.28-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"4ec3f6503938ca100ecf9083317644714c976620c229c029040a402754900407","md5":"ab18e425bc7f871127fad6bce72b9eaa","sha256":"1c2add73b067371e6e05091355c9fecae0cf9a96d02a657f9a02c64bb51f3fce"},"downloads":-1,"filename":"pipecat_ai-0.0.28.tar.gz","has_sig":false,"md5_digest":"ab18e425bc7f871127fad6bce72b9eaa","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":64313502,"upload_time":"2024-06-05T21:53:31","upload_time_iso_8601":"2024-06-05T21:53:31.572081Z","url":"https://files.pythonhosted.org/packages/4e/c3/f6503938ca100ecf9083317644714c976620c229c029040a402754900407/pipecat_ai-0.0.28.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.29":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.29/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","protobuf~=4.25.3","pyloudnorm~=0.1.1","typing-extensions~=4.12.1","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","numpy~=1.26.0; extra == \"cartesia\"","sounddevice; extra == \"cartesia\"","cartesia; extra == \"cartesia\"","daily-python~=0.9.0; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","langchain~=0.2.1; extra == \"langchain\"","langchain-community~=0.2.1; extra == \"langchain\"","langchain-openai~=0.1.8; extra == \"langchain\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.29","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"0ecb5f3a7530be5b9be254b54164d41775cc7e0e9d4bf2b57a9e1484dd4a8e17","md5":"4f7b15fdda2908e2351a48ea9e260816","sha256":"f0040c47d2f1a9dffb76b7b75c0b927d9a0adc9d35faca7680f4ca44e2464655"},"downloads":-1,"filename":"pipecat_ai-0.0.29-py3-none-any.whl","has_sig":false,"md5_digest":"4f7b15fdda2908e2351a48ea9e260816","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":81803,"upload_time":"2024-06-07T20:49:57","upload_time_iso_8601":"2024-06-07T20:49:57.599738Z","url":"https://files.pythonhosted.org/packages/0e/cb/5f3a7530be5b9be254b54164d41775cc7e0e9d4bf2b57a9e1484dd4a8e17/pipecat_ai-0.0.29-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"bf58838fe3743bfd7772fa70099f206476e04dbbae0100ed406ba75ece063364","md5":"039f2de0ff729b0ed3cbe6fe37e025b8","sha256":"ad4206229bf361c8acd05a35ef081b3e7ee46e2569fd7c327720b5e7b62ff429"},"downloads":-1,"filename":"pipecat_ai-0.0.29.tar.gz","has_sig":false,"md5_digest":"039f2de0ff729b0ed3cbe6fe37e025b8","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":64316412,"upload_time":"2024-06-07T20:50:00","upload_time_iso_8601":"2024-06-07T20:50:00.973465Z","url":"https://files.pythonhosted.org/packages/bf/58/838fe3743bfd7772fa70099f206476e04dbbae0100ed406ba75ece063364/pipecat_ai-0.0.29.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.30":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.30/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","protobuf~=4.25.3","pyloudnorm~=0.1.1","typing-extensions~=4.12.1","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","numpy~=1.26.0; extra == \"cartesia\"","sounddevice; extra == \"cartesia\"","cartesia; extra == \"cartesia\"","daily-python~=0.9.0; extra == \"daily\"","deepgram-sdk~=3.2.7; extra == \"deepgram\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","langchain~=0.2.1; extra == \"langchain\"","langchain-community~=0.2.1; extra == \"langchain\"","langchain-openai~=0.1.8; extra == \"langchain\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","openpipe~=4.14.0; extra == \"openpipe\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.30","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"99f506d6344644f33ff03a000934d801bae7e1131e57e9ae0b17fbf7c0d7aee8","md5":"a21da58bf7b5032a167543fdb13cf115","sha256":"995ad557946a942b9fc5782b3ef5c726393710ad6be4cb7cf4fa05316405d6e1"},"downloads":-1,"filename":"pipecat_ai-0.0.30-py3-none-any.whl","has_sig":false,"md5_digest":"a21da58bf7b5032a167543fdb13cf115","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":84414,"upload_time":"2024-06-13T21:32:31","upload_time_iso_8601":"2024-06-13T21:32:31.728142Z","url":"https://files.pythonhosted.org/packages/99/f5/06d6344644f33ff03a000934d801bae7e1131e57e9ae0b17fbf7c0d7aee8/pipecat_ai-0.0.30-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"3604a6c157bba42c139aed2d3d88c646cef912c24d76de66487d15986016340a","md5":"f289ba59a576fc93f680faa80db21784","sha256":"6b418bd2ec3096e0c2ffdd2817e916e8ae4b0fdbd63c7d57a873023fdb90b1a0"},"downloads":-1,"filename":"pipecat_ai-0.0.30.tar.gz","has_sig":false,"md5_digest":"f289ba59a576fc93f680faa80db21784","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":64346319,"upload_time":"2024-06-13T21:32:33","upload_time_iso_8601":"2024-06-13T21:32:33.981299Z","url":"https://files.pythonhosted.org/packages/36/04/a6c157bba42c139aed2d3d88c646cef912c24d76de66487d15986016340a/pipecat_ai-0.0.30.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.31":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.31/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","protobuf~=4.25.3","pyloudnorm~=0.1.1","typing-extensions~=4.12.1","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","numpy~=1.26.0; extra == \"cartesia\"","sounddevice; extra == \"cartesia\"","cartesia; extra == \"cartesia\"","daily-python~=0.9.0; extra == \"daily\"","deepgram-sdk~=3.2.7; extra == \"deepgram\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","langchain~=0.2.1; extra == \"langchain\"","langchain-community~=0.2.1; extra == \"langchain\"","langchain-openai~=0.1.8; extra == \"langchain\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","openpipe~=4.14.0; extra == \"openpipe\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.31","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"43346f0cdc6b08b2c24c13060faadd6bf354ba41071acd04e9ff91aa4566831b","md5":"795acecb857220df5a91c36db3f8197c","sha256":"759ffe0840cb94301a2b361956b2d7e0d3184e967169e76c782f26392f3515f0"},"downloads":-1,"filename":"pipecat_ai-0.0.31-py3-none-any.whl","has_sig":false,"md5_digest":"795acecb857220df5a91c36db3f8197c","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":84399,"upload_time":"2024-06-13T22:35:23","upload_time_iso_8601":"2024-06-13T22:35:23.706243Z","url":"https://files.pythonhosted.org/packages/43/34/6f0cdc6b08b2c24c13060faadd6bf354ba41071acd04e9ff91aa4566831b/pipecat_ai-0.0.31-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"0994e29cf5ad2133c1813af5f1ce59d3f507950bc55fa32cce7bbc645fd7a36a","md5":"75bb6920d208767213298a5e8d8242b7","sha256":"c530f1ef0ab072cd9bb35e4c37a05b44a3e8a0c94c473523be1a064fe44e8762"},"downloads":-1,"filename":"pipecat_ai-0.0.31.tar.gz","has_sig":false,"md5_digest":"75bb6920d208767213298a5e8d8242b7","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":64346289,"upload_time":"2024-06-13T22:35:26","upload_time_iso_8601":"2024-06-13T22:35:26.519603Z","url":"https://files.pythonhosted.org/packages/09/94/e29cf5ad2133c1813af5f1ce59d3f507950bc55fa32cce7bbc645fd7a36a/pipecat_ai-0.0.31.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.32":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","azure","cartesia","daily","deepgram","examples","fal","fireworks","google","langchain","local","moondream","openai","openpipe","playht","silero","websocket","whisper"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.32/","requires_dist":["sounddevice; extra == \"cartesia\"","cartesia; extra == \"cartesia\"","daily-python~=0.10.0; extra == \"daily\"","deepgram-sdk~=3.2.7; extra == \"deepgram\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","langchain~=0.2.1; extra == \"langchain\"","langchain-community~=0.2.1; extra == \"langchain\"","langchain-openai~=0.1.8; extra == \"langchain\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","openpipe~=4.14.0; extra == \"openpipe\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","fastapi~=0.111.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\"","aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","protobuf~=4.25.3","pyloudnorm~=0.1.1","typing-extensions~=4.12.1","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","numpy~=1.26.0; extra == \"cartesia\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.32","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"6e3bbd33e911d7132ac155e62cec970e3ca9339d32b8675c7fffffa094f5e0dd","md5":"56cdbaf4ce0489c0d3b7374b7e6f742b","sha256":"953cb5efe76f895b035367f43040519844859f24c4b0ee746a23a1dd83d1a0cc"},"downloads":-1,"filename":"pipecat_ai-0.0.32-py3-none-any.whl","has_sig":false,"md5_digest":"56cdbaf4ce0489c0d3b7374b7e6f742b","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":87951,"upload_time":"2024-06-22T16:24:33","upload_time_iso_8601":"2024-06-22T16:24:33.023354Z","url":"https://files.pythonhosted.org/packages/6e/3b/bd33e911d7132ac155e62cec970e3ca9339d32b8675c7fffffa094f5e0dd/pipecat_ai-0.0.32-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8be5b32b84673e58bd889b3c6ff957030acf9be3ff05f60e21e8848e7c6b8ff9","md5":"dd6643502e7debe38645387810871489","sha256":"566851c256024e81f3def1b540cd53d9306bd0342b4e9720e63fc1232ccd780f"},"downloads":-1,"filename":"pipecat_ai-0.0.32.tar.gz","has_sig":false,"md5_digest":"dd6643502e7debe38645387810871489","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":64352044,"upload_time":"2024-06-22T16:24:37","upload_time_iso_8601":"2024-06-22T16:24:37.181979Z","url":"https://files.pythonhosted.org/packages/8b/e5/b32b84673e58bd889b3c6ff957030acf9be3ff05f60e21e8848e7c6b8ff9/pipecat_ai-0.0.32.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.33":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","azure","cartesia","daily","deepgram","examples","fal","fireworks","google","langchain","local","moondream","openai","openpipe","playht","silero","websocket","whisper"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.33/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","protobuf~=4.25.3","pyloudnorm~=0.1.1","typing-extensions~=4.12.1","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","cartesia~=1.0.0; extra == \"cartesia\"","daily-python~=0.10.1; extra == \"daily\"","deepgram-sdk~=3.2.7; extra == \"deepgram\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","langchain~=0.2.1; extra == \"langchain\"","langchain-community~=0.2.1; extra == \"langchain\"","langchain-openai~=0.1.8; extra == \"langchain\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","openpipe~=4.14.0; extra == \"openpipe\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","fastapi~=0.111.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.33","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"690be35afd60c41c2f0b260150d09a58d50e6a858bfacf3e5000264cc6f60f9f","md5":"8455c183783a90ef3707e4f8ddfef12f","sha256":"50b8c047e99eece5fa1bda748e1a899d7fdf40f7f87554c2721f497446833094"},"downloads":-1,"filename":"pipecat_ai-0.0.33-py3-none-any.whl","has_sig":false,"md5_digest":"8455c183783a90ef3707e4f8ddfef12f","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":88888,"upload_time":"2024-06-25T19:08:05","upload_time_iso_8601":"2024-06-25T19:08:05.331213Z","url":"https://files.pythonhosted.org/packages/69/0b/e35afd60c41c2f0b260150d09a58d50e6a858bfacf3e5000264cc6f60f9f/pipecat_ai-0.0.33-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"69b7d780aa0fe773c7f3ad4e8edd397b0d204be1bdfa3617364473d69e59e01f","md5":"c60708c1967e0906bb10e34b06f9aae8","sha256":"dd4d05f61eee7494493baf0b8e6ff303c99d661d1863babd9102bafafb3a63c9"},"downloads":-1,"filename":"pipecat_ai-0.0.33.tar.gz","has_sig":false,"md5_digest":"c60708c1967e0906bb10e34b06f9aae8","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":64352567,"upload_time":"2024-06-25T19:08:07","upload_time_iso_8601":"2024-06-25T19:08:07.752023Z","url":"https://files.pythonhosted.org/packages/69/b7/d780aa0fe773c7f3ad4e8edd397b0d204be1bdfa3617364473d69e59e01f/pipecat_ai-0.0.33.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.34":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","azure","cartesia","daily","deepgram","examples","fal","fireworks","google","langchain","local","moondream","openai","openpipe","playht","silero","websocket","whisper"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.34/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","protobuf~=4.25.3","pyloudnorm~=0.1.1","typing-extensions~=4.12.1","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","cartesia~=1.0.0; extra == \"cartesia\"","daily-python~=0.10.1; extra == \"daily\"","deepgram-sdk~=3.2.7; extra == \"deepgram\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","langchain~=0.2.1; extra == \"langchain\"","langchain-community~=0.2.1; extra == \"langchain\"","langchain-openai~=0.1.8; extra == \"langchain\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","openpipe~=4.14.0; extra == \"openpipe\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","fastapi~=0.111.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.34","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"59118e3034dd30c07891359ebf330867b74fc120d9b7040ef185ec026d1a5a84","md5":"d9c4f193c89c5206514f93b193821d51","sha256":"e26a4340a2e438dcb2076cdf319554b9fa03662a893fb37b72bffc91fa2e3ee0"},"downloads":-1,"filename":"pipecat_ai-0.0.34-py3-none-any.whl","has_sig":false,"md5_digest":"d9c4f193c89c5206514f93b193821d51","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":88600,"upload_time":"2024-06-26T04:54:50","upload_time_iso_8601":"2024-06-26T04:54:50.418553Z","url":"https://files.pythonhosted.org/packages/59/11/8e3034dd30c07891359ebf330867b74fc120d9b7040ef185ec026d1a5a84/pipecat_ai-0.0.34-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d81a381f206401155c90fd4d03dc0537741992e0d5ccd06ae4295a7b89e1896b","md5":"f9cb9e1102f8d9eb9fbabfa4cdb09753","sha256":"860664e731c22515b5aae58ce9803aa76b4efebcbeacb88ba2ac788fc4eee651"},"downloads":-1,"filename":"pipecat_ai-0.0.34.tar.gz","has_sig":false,"md5_digest":"f9cb9e1102f8d9eb9fbabfa4cdb09753","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":64352571,"upload_time":"2024-06-26T04:54:53","upload_time_iso_8601":"2024-06-26T04:54:53.161668Z","url":"https://files.pythonhosted.org/packages/d8/1a/381f206401155c90fd4d03dc0537741992e0d5ccd06ae4295a7b89e1896b/pipecat_ai-0.0.34.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.35":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","azure","cartesia","daily","deepgram","examples","fal","fireworks","google","langchain","local","moondream","openai","openpipe","playht","silero","websocket","whisper"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.35/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","protobuf~=4.25.3","pyloudnorm~=0.1.1","typing-extensions~=4.12.1","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","cartesia~=1.0.0; extra == \"cartesia\"","daily-python~=0.10.1; extra == \"daily\"","deepgram-sdk~=3.2.7; extra == \"deepgram\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","google-generativeai~=0.5.3; extra == \"google\"","langchain~=0.2.1; extra == \"langchain\"","langchain-community~=0.2.1; extra == \"langchain\"","langchain-openai~=0.1.8; extra == \"langchain\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","openpipe~=4.14.0; extra == \"openpipe\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","fastapi~=0.111.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.35","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"71e2da4475d8e5cc330779951f38d9739555da57642a1f5089a9dcfac5bd0fde","md5":"9e7afbd805e8565a3836f539fd1f339d","sha256":"2038b299e1beda1886103ae3c2844d066428d8e6f59de85341146cfe60c9ab94"},"downloads":-1,"filename":"pipecat_ai-0.0.35-py3-none-any.whl","has_sig":false,"md5_digest":"9e7afbd805e8565a3836f539fd1f339d","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":88607,"upload_time":"2024-06-28T18:30:47","upload_time_iso_8601":"2024-06-28T18:30:47.076945Z","url":"https://files.pythonhosted.org/packages/71/e2/da4475d8e5cc330779951f38d9739555da57642a1f5089a9dcfac5bd0fde/pipecat_ai-0.0.35-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"2425b164ea6c1bf491122c79f043c55789b9d3eee92a29030379fb0f00dbff32","md5":"eb6daf654f281e012374c8cc6d81f4e2","sha256":"eb9bc85d1c08af4f2fca5f74018f628b7ab0fc4b237fc7f421acbb1cffabf8cc"},"downloads":-1,"filename":"pipecat_ai-0.0.35.tar.gz","has_sig":false,"md5_digest":"eb6daf654f281e012374c8cc6d81f4e2","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":64353028,"upload_time":"2024-06-28T18:30:51","upload_time_iso_8601":"2024-06-28T18:30:51.214552Z","url":"https://files.pythonhosted.org/packages/24/25/b164ea6c1bf491122c79f043c55789b9d3eee92a29030379fb0f00dbff32/pipecat_ai-0.0.35.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.36":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","azure","cartesia","daily","deepgram","examples","fal","fireworks","gladia","google","langchain","local","moondream","openai","openpipe","playht","silero","websocket","whisper","xtts"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.36/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","protobuf~=4.25.3","pyloudnorm~=0.1.1","typing-extensions~=4.12.1","anthropic~=0.28.1; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.38.0; extra == \"azure\"","cartesia~=1.0.3; extra == \"cartesia\"","daily-python~=0.10.1; extra == \"daily\"","deepgram-sdk~=3.2.7; extra == \"deepgram\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.1; extra == \"fal\"","openai~=1.27.0; extra == \"fireworks\"","websockets~=12.0; extra == \"gladia\"","google-generativeai~=0.7.1; extra == \"google\"","langchain~=0.2.6; extra == \"langchain\"","langchain-community~=0.2.6; extra == \"langchain\"","langchain-openai~=0.1.10; extra == \"langchain\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.27.0; extra == \"openai\"","openpipe~=4.16.0; extra == \"openpipe\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.1; extra == \"silero\"","torchaudio~=2.3.1; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","fastapi~=0.111.0; extra == \"websocket\"","faster-whisper~=1.0.3; extra == \"whisper\"","resampy~=0.4.3; extra == \"xtts\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.36","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"ef75190e54c16fcc3d95e81970c16c0a0e8551ace66e2e0f5305e25dd7b6d146","md5":"e6fc4ca5f6847393f81ce4b5793102de","sha256":"d3d088b9c08aff153ad80bfcd88dd7c4d36183f861622ef68d31948a5119c873"},"downloads":-1,"filename":"pipecat_ai-0.0.36-py3-none-any.whl","has_sig":false,"md5_digest":"e6fc4ca5f6847393f81ce4b5793102de","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":94818,"upload_time":"2024-07-02T17:19:25","upload_time_iso_8601":"2024-07-02T17:19:25.153705Z","url":"https://files.pythonhosted.org/packages/ef/75/190e54c16fcc3d95e81970c16c0a0e8551ace66e2e0f5305e25dd7b6d146/pipecat_ai-0.0.36-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a194b0fb3cd31ae91081b406620ada6b8d1a88660cb29a2d92ae0daf4a431d9f","md5":"64a3fed700de3f10b0669d8a811d6b06","sha256":"319fe5c25d258d435b5952d5adf1599fc633d273faacb29728288e5e65a3ebb4"},"downloads":-1,"filename":"pipecat_ai-0.0.36.tar.gz","has_sig":false,"md5_digest":"64a3fed700de3f10b0669d8a811d6b06","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":64362717,"upload_time":"2024-07-02T17:19:27","upload_time_iso_8601":"2024-07-02T17:19:27.884232Z","url":"https://files.pythonhosted.org/packages/a1/94/b0fb3cd31ae91081b406620ada6b8d1a88660cb29a2d92ae0daf4a431d9f/pipecat_ai-0.0.36.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.37":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","azure","cartesia","daily","deepgram","examples","fal","fireworks","gladia","google","langchain","local","moondream","openai","openpipe","playht","silero","websocket","whisper","xtts"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.37/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","protobuf~=4.25.3","pyloudnorm~=0.1.1","typing-extensions~=4.12.1","anthropic~=0.28.1; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.38.0; extra == \"azure\"","websockets~=12.0; extra == \"cartesia\"","daily-python~=0.10.1; extra == \"daily\"","deepgram-sdk~=3.2.7; extra == \"deepgram\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.1; extra == \"fal\"","openai~=1.27.0; extra == \"fireworks\"","websockets~=12.0; extra == \"gladia\"","google-generativeai~=0.7.1; extra == \"google\"","langchain~=0.2.6; extra == \"langchain\"","langchain-community~=0.2.6; extra == \"langchain\"","langchain-openai~=0.1.10; extra == \"langchain\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.27.0; extra == \"openai\"","openpipe~=4.16.0; extra == \"openpipe\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.1; extra == \"silero\"","torchaudio~=2.3.1; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","fastapi~=0.111.0; extra == \"websocket\"","faster-whisper~=1.0.3; extra == \"whisper\"","resampy~=0.4.3; extra == \"xtts\""],"requires_python":">=3.10","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.37","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"48d15040515164ee23926eef9d944d3b1bcf964af2f6b633c9d3d2156a11c4e1","md5":"534a2210633a39b24ecf26a93fe2e144","sha256":"e16e0e6f6d5e053209eab69fe8b6aff305b0a644ead4677472faee33e8b494c4"},"downloads":-1,"filename":"pipecat_ai-0.0.37-py3-none-any.whl","has_sig":false,"md5_digest":"534a2210633a39b24ecf26a93fe2e144","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":101986,"upload_time":"2024-07-23T00:03:27","upload_time_iso_8601":"2024-07-23T00:03:27.726272Z","url":"https://files.pythonhosted.org/packages/48/d1/5040515164ee23926eef9d944d3b1bcf964af2f6b633c9d3d2156a11c4e1/pipecat_ai-0.0.37-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e428921b325b18403a18f17b97da60fffdf2a3ba9003c654bead40398e3d478a","md5":"1f6d97acfe1f79f4762e135ed6e38604","sha256":"c90345038041ab62fafd6d03cf39534f53300f124144f271d54a01e43d0d2b38"},"downloads":-1,"filename":"pipecat_ai-0.0.37.tar.gz","has_sig":false,"md5_digest":"1f6d97acfe1f79f4762e135ed6e38604","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":64370590,"upload_time":"2024-07-23T00:03:30","upload_time_iso_8601":"2024-07-23T00:03:30.324508Z","url":"https://files.pythonhosted.org/packages/e4/28/921b325b18403a18f17b97da60fffdf2a3ba9003c654bead40398e3d478a/pipecat_ai-0.0.37.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.38":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","azure","cartesia","daily","deepgram","examples","fal","fireworks","gladia","google","langchain","local","moondream","openai","openpipe","playht","silero","websocket","whisper","xtts"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.38/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","protobuf~=4.25.3","pyloudnorm~=0.1.1","typing-extensions~=4.12.1","anthropic~=0.28.1; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.38.0; extra == \"azure\"","websockets~=12.0; extra == \"cartesia\"","daily-python~=0.10.1; extra == \"daily\"","deepgram-sdk~=3.2.7; extra == \"deepgram\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.1; extra == \"fal\"","openai~=1.27.0; extra == \"fireworks\"","websockets~=12.0; extra == \"gladia\"","google-generativeai~=0.7.1; extra == \"google\"","langchain~=0.2.6; extra == \"langchain\"","langchain-community~=0.2.6; extra == \"langchain\"","langchain-openai~=0.1.10; extra == \"langchain\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.27.0; extra == \"openai\"","openpipe~=4.16.0; extra == \"openpipe\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.1; extra == \"silero\"","torchaudio~=2.3.1; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","fastapi~=0.111.0; extra == \"websocket\"","faster-whisper~=1.0.3; extra == \"whisper\"","resampy~=0.4.3; extra == \"xtts\""],"requires_python":">=3.10","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.38","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"3431cd2ac0842206d45bde868485e15c8da73113533b1b1053505c65e5919461","md5":"fbfd07a11e2d73f55717d042c6dfd973","sha256":"6a243ddd1634913065fdcbb59dc3473eec593710ec049ffa4dfe15dfd27ffa6d"},"downloads":-1,"filename":"pipecat_ai-0.0.38-py3-none-any.whl","has_sig":false,"md5_digest":"fbfd07a11e2d73f55717d042c6dfd973","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":102624,"upload_time":"2024-07-23T21:29:40","upload_time_iso_8601":"2024-07-23T21:29:40.405165Z","url":"https://files.pythonhosted.org/packages/34/31/cd2ac0842206d45bde868485e15c8da73113533b1b1053505c65e5919461/pipecat_ai-0.0.38-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8ed9ec5e941544d2236f9b4ff35ffbc7321aa88fd4de69dc8b86a3efd8758666","md5":"5fcac373e3183721851b9af023726865","sha256":"08fbd823e487adc39e255e75f50fc031e58daa5ccd98d535770f0a503d87555c"},"downloads":-1,"filename":"pipecat_ai-0.0.38.tar.gz","has_sig":false,"md5_digest":"5fcac373e3183721851b9af023726865","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":64370739,"upload_time":"2024-07-23T21:29:42","upload_time_iso_8601":"2024-07-23T21:29:42.540893Z","url":"https://files.pythonhosted.org/packages/8e/d9/ec5e941544d2236f9b4ff35ffbc7321aa88fd4de69dc8b86a3efd8758666/pipecat_ai-0.0.38.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.39":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","azure","cartesia","daily","deepgram","examples","fal","fireworks","gladia","google","langchain","local","moondream","openai","openpipe","playht","silero","websocket","whisper","xtts"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.39/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","protobuf~=4.25.3","pyloudnorm~=0.1.1","typing-extensions~=4.12.1","anthropic~=0.28.1; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.38.0; extra == \"azure\"","websockets~=12.0; extra == \"cartesia\"","daily-python~=0.10.1; extra == \"daily\"","deepgram-sdk~=3.2.7; extra == \"deepgram\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.1; extra == \"fal\"","openai~=1.27.0; extra == \"fireworks\"","websockets~=12.0; extra == \"gladia\"","google-generativeai~=0.7.1; extra == \"google\"","langchain~=0.2.6; extra == \"langchain\"","langchain-community~=0.2.6; extra == \"langchain\"","langchain-openai~=0.1.10; extra == \"langchain\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.27.0; extra == \"openai\"","openpipe~=4.16.0; extra == \"openpipe\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.1; extra == \"silero\"","torchaudio~=2.3.1; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","fastapi~=0.111.0; extra == \"websocket\"","faster-whisper~=1.0.3; extra == \"whisper\"","resampy~=0.4.3; extra == \"xtts\""],"requires_python":">=3.10","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.39","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"b1825b97b1e02582b8354f5e6e751de38565798d2c3022c8d04c9f7ec4a4eae3","md5":"5eafb73638612580eaff8c16f6343593","sha256":"6e615e77172185e34d771b077254741c6abe10eeafc37d2d01ccf45f815c3b2d"},"downloads":-1,"filename":"pipecat_ai-0.0.39-py3-none-any.whl","has_sig":false,"md5_digest":"5eafb73638612580eaff8c16f6343593","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":102577,"upload_time":"2024-07-23T22:29:55","upload_time_iso_8601":"2024-07-23T22:29:55.164679Z","url":"https://files.pythonhosted.org/packages/b1/82/5b97b1e02582b8354f5e6e751de38565798d2c3022c8d04c9f7ec4a4eae3/pipecat_ai-0.0.39-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"68b4e36a3ba16d6bff236090225eeff7ab71e4b1fecbad24527112644a98cb4e","md5":"fc3c026e0abd4260836541443c8b01ea","sha256":"b4b6aee43ca01556881a0af4ded91b85414958ac12bc46df7e220f68f108109e"},"downloads":-1,"filename":"pipecat_ai-0.0.39.tar.gz","has_sig":false,"md5_digest":"fc3c026e0abd4260836541443c8b01ea","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":64370804,"upload_time":"2024-07-23T22:29:57","upload_time_iso_8601":"2024-07-23T22:29:57.667986Z","url":"https://files.pythonhosted.org/packages/68/b4/e36a3ba16d6bff236090225eeff7ab71e4b1fecbad24527112644a98cb4e/pipecat_ai-0.0.39.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.40":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","azure","cartesia","daily","deepgram","examples","fal","fireworks","gladia","google","gstreamer","langchain","local","moondream","openai","openpipe","playht","silero","together","websocket","whisper","xtts"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.40/","requires_dist":["aiohttp~=3.10.3","numpy~=1.26.4","loguru~=0.7.2","Pillow~=10.4.0","protobuf~=4.25.4","pydantic~=2.8.2","pyloudnorm~=0.1.1","anthropic~=0.34.0; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.40.0; extra == \"azure\"","websockets~=12.0; extra == \"cartesia\"","daily-python~=0.10.1; extra == \"daily\"","deepgram-sdk~=3.5.0; extra == \"deepgram\"","python-dotenv~=1.0.1; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.1; extra == \"fal\"","openai~=1.37.2; extra == \"fireworks\"","websockets~=12.0; extra == \"gladia\"","google-generativeai~=0.7.2; extra == \"google\"","pygobject~=3.48.2; extra == \"gstreamer\"","langchain~=0.2.14; extra == \"langchain\"","langchain-community~=0.2.12; extra == \"langchain\"","langchain-openai~=0.1.20; extra == \"langchain\"","pyaudio~=0.2.14; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=1.0.8; extra == \"moondream\"","transformers~=4.44.0; extra == \"moondream\"","openai~=1.37.2; extra == \"openai\"","openpipe~=4.24.0; extra == \"openpipe\"","pyht~=0.0.28; extra == \"playht\"","silero-vad~=5.1; extra == \"silero\"","together~=1.2.7; extra == \"together\"","websockets~=12.0; extra == \"websocket\"","fastapi~=0.112.1; extra == \"websocket\"","faster-whisper~=1.0.3; extra == \"whisper\"","resampy~=0.4.3; extra == \"xtts\""],"requires_python":">=3.10","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.40","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"66e05081001b2515b9dafa2437222478eae1e3206f20580a2df0467505131228","md5":"09dfe7221baf10317a52aab387c1dd61","sha256":"a5f376cca4d2293db069cc95bc88180d1dec94f315eacd8f74c3c0a8fd92c239"},"downloads":-1,"filename":"pipecat_ai-0.0.40-py3-none-any.whl","has_sig":false,"md5_digest":"09dfe7221baf10317a52aab387c1dd61","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":116853,"upload_time":"2024-08-20T18:54:13","upload_time_iso_8601":"2024-08-20T18:54:13.956526Z","url":"https://files.pythonhosted.org/packages/66/e0/5081001b2515b9dafa2437222478eae1e3206f20580a2df0467505131228/pipecat_ai-0.0.40-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"5893017760b18ab1d1e62cc1f9df9aa7630175fc40e724ea6e930f6dffabd2d4","md5":"a28488970419783fad614ff91acdeec5","sha256":"8cd6df6f6a931ad88ffb9f99cd4bb73b58fe5983a696e2ada072caf1049c0a6e"},"downloads":-1,"filename":"pipecat_ai-0.0.40.tar.gz","has_sig":false,"md5_digest":"a28488970419783fad614ff91acdeec5","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":64418456,"upload_time":"2024-08-20T18:54:16","upload_time_iso_8601":"2024-08-20T18:54:16.330665Z","url":"https://files.pythonhosted.org/packages/58/93/017760b18ab1d1e62cc1f9df9aa7630175fc40e724ea6e930f6dffabd2d4/pipecat_ai-0.0.40.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.41":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","azure","cartesia","daily","deepgram","examples","fal","fireworks","gladia","google","gstreamer","langchain","livekit","local","moondream","openai","openpipe","playht","silero","together","websocket","whisper","xtts"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.41/","requires_dist":["aiohttp~=3.10.3","numpy~=1.26.4","loguru~=0.7.2","Pillow~=10.4.0","protobuf~=4.25.4","pydantic~=2.8.2","pyloudnorm~=0.1.1","anthropic~=0.34.0; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.40.0; extra == \"azure\"","websockets~=12.0; extra == \"cartesia\"","daily-python~=0.10.1; extra == \"daily\"","deepgram-sdk~=3.5.0; extra == \"deepgram\"","python-dotenv~=1.0.1; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.1; extra == \"fal\"","openai~=1.37.2; extra == \"fireworks\"","websockets~=12.0; extra == \"gladia\"","google-generativeai~=0.7.2; extra == \"google\"","pygobject~=3.48.2; extra == \"gstreamer\"","langchain~=0.2.14; extra == \"langchain\"","langchain-community~=0.2.12; extra == \"langchain\"","langchain-openai~=0.1.20; extra == \"langchain\"","livekit~=0.13.1; extra == \"livekit\"","pyaudio~=0.2.14; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=1.0.8; extra == \"moondream\"","transformers~=4.44.0; extra == \"moondream\"","openai~=1.37.2; extra == \"openai\"","openpipe~=4.24.0; extra == \"openpipe\"","pyht~=0.0.28; extra == \"playht\"","silero-vad~=5.1; extra == \"silero\"","together~=1.2.7; extra == \"together\"","websockets~=12.0; extra == \"websocket\"","fastapi~=0.112.1; extra == \"websocket\"","faster-whisper~=1.0.3; extra == \"whisper\"","resampy~=0.4.3; extra == \"xtts\""],"requires_python":">=3.10","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.41","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"7f01ab0323a6e699b8f8b011bb31163b572752ad2b30cd49d14ef69a049d88f0","md5":"11777ff456be0b94da92161440fb7ab2","sha256":"4cce7e8ecd63cf6c0adab84d53a6cecd07802ff64897ba0476ea529604623407"},"downloads":-1,"filename":"pipecat_ai-0.0.41-py3-none-any.whl","has_sig":false,"md5_digest":"11777ff456be0b94da92161440fb7ab2","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":117770,"upload_time":"2024-08-23T00:04:28","upload_time_iso_8601":"2024-08-23T00:04:28.747310Z","url":"https://files.pythonhosted.org/packages/7f/01/ab0323a6e699b8f8b011bb31163b572752ad2b30cd49d14ef69a049d88f0/pipecat_ai-0.0.41-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8c0a038250e881fda17cc9bcb3cc9b8b30ab7e5d825f5c5f220c872f40e5f68c","md5":"38777780ac774c03950404efbf6e3028","sha256":"56303085809f65649ba8e652a0b7fec53f2e2369ea619668c3cef3f6d8f96316"},"downloads":-1,"filename":"pipecat_ai-0.0.41.tar.gz","has_sig":false,"md5_digest":"38777780ac774c03950404efbf6e3028","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":64418941,"upload_time":"2024-08-23T00:04:31","upload_time_iso_8601":"2024-08-23T00:04:31.416549Z","url":"https://files.pythonhosted.org/packages/8c/0a/038250e881fda17cc9bcb3cc9b8b30ab7e5d825f5c5f220c872f40e5f68c/pipecat_ai-0.0.41.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.42":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","aws","azure","cartesia","daily","deepgram","elevenlabs","examples","fal","fireworks","gladia","google","gstreamer","langchain","livekit","lmnt","local","moondream","openai","openpipe","playht","silero","together","websocket","whisper","xtts"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.42/","requires_dist":["aiohttp~=3.10.3","numpy~=1.26.4","loguru~=0.7.2","Pillow~=10.4.0","protobuf~=4.25.4","pydantic~=2.8.2","pyloudnorm~=0.1.1","anthropic~=0.34.0; extra == \"anthropic\"","boto3~=1.35.27; extra == \"aws\"","azure-cognitiveservices-speech~=1.40.0; extra == \"azure\"","cartesia~=1.0.13; extra == \"cartesia\"","websockets~=12.0; extra == \"cartesia\"","daily-python~=0.11.0; extra == \"daily\"","deepgram-sdk~=3.5.0; extra == \"deepgram\"","websockets~=12.0; extra == \"elevenlabs\"","python-dotenv~=1.0.1; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.1; extra == \"fal\"","openai~=1.37.2; extra == \"fireworks\"","websockets~=12.0; extra == \"gladia\"","google-generativeai~=0.7.2; extra == \"google\"","google-cloud-texttospeech~=2.17.2; extra == \"google\"","pygobject~=3.48.2; extra == \"gstreamer\"","langchain~=0.2.14; extra == \"langchain\"","langchain-community~=0.2.12; extra == \"langchain\"","langchain-openai~=0.1.20; extra == \"langchain\"","livekit~=0.13.1; extra == \"livekit\"","tenacity~=9.0.0; extra == \"livekit\"","lmnt~=1.1.4; extra == \"lmnt\"","pyaudio~=0.2.14; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=1.0.8; extra == \"moondream\"","transformers~=4.44.0; extra == \"moondream\"","openai~=1.37.2; extra == \"openai\"","openpipe~=4.24.0; extra == \"openpipe\"","pyht~=0.0.28; extra == \"playht\"","onnxruntime>=1.16.1; extra == \"silero\"","together~=1.2.7; extra == \"together\"","websockets~=12.0; extra == \"websocket\"","fastapi~=0.115.0; extra == \"websocket\"","faster-whisper~=1.0.3; extra == \"whisper\"","resampy~=0.4.3; extra == \"xtts\""],"requires_python":">=3.10","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.42","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"4e14093553842b4d5c061f3fed963f66f70015da2f9a0c475a9673213a75c9be","md5":"3cde0e697130aa59f28d6974a126de13","sha256":"a0ed397afda28d25153e1a0042306c8bc3d095db0bcef304f1cd010b32cea83b"},"downloads":-1,"filename":"pipecat_ai-0.0.42-py3-none-any.whl","has_sig":false,"md5_digest":"3cde0e697130aa59f28d6974a126de13","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":2088140,"upload_time":"2024-10-02T20:52:31","upload_time_iso_8601":"2024-10-02T20:52:31.173386Z","url":"https://files.pythonhosted.org/packages/4e/14/093553842b4d5c061f3fed963f66f70015da2f9a0c475a9673213a75c9be/pipecat_ai-0.0.42-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"25fc30a95670ac960b58d79d25ad3d5bd92609c64f4165222928e8b8d7d3fcd7","md5":"09e42b768cc27ec0e03602e040704bf9","sha256":"c8206dfab91f38bde6edcca72d399308527357ddaa08cdbc2c8ba034b1a0355d"},"downloads":-1,"filename":"pipecat_ai-0.0.42.tar.gz","has_sig":false,"md5_digest":"09e42b768cc27ec0e03602e040704bf9","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":66342924,"upload_time":"2024-10-02T20:52:33","upload_time_iso_8601":"2024-10-02T20:52:33.743083Z","url":"https://files.pythonhosted.org/packages/25/fc/30a95670ac960b58d79d25ad3d5bd92609c64f4165222928e8b8d7d3fcd7/pipecat_ai-0.0.42.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.43":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","aws","azure","cartesia","daily","deepgram","elevenlabs","examples","fal","fireworks","gladia","google","gstreamer","langchain","livekit","lmnt","local","moondream","openai","openpipe","playht","silero","together","websocket","whisper","xtts"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.43/","requires_dist":["aiohttp~=3.10.3","Markdown~=3.7","numpy~=1.26.4","loguru~=0.7.2","Pillow~=10.4.0","protobuf~=4.25.4","pydantic~=2.8.2","pyloudnorm~=0.1.1","anthropic~=0.34.0; extra == \"anthropic\"","boto3~=1.35.27; extra == \"aws\"","azure-cognitiveservices-speech~=1.40.0; extra == \"azure\"","cartesia~=1.0.13; extra == \"cartesia\"","websockets~=12.0; extra == \"cartesia\"","daily-python~=0.11.0; extra == \"daily\"","deepgram-sdk~=3.7.3; extra == \"deepgram\"","websockets~=12.0; extra == \"elevenlabs\"","python-dotenv~=1.0.1; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.1; extra == \"fal\"","openai~=1.37.2; extra == \"fireworks\"","websockets~=12.0; extra == \"gladia\"","google-generativeai~=0.7.2; extra == \"google\"","google-cloud-texttospeech~=2.17.2; extra == \"google\"","pygobject~=3.48.2; extra == \"gstreamer\"","langchain~=0.2.14; extra == \"langchain\"","langchain-community~=0.2.12; extra == \"langchain\"","langchain-openai~=0.1.20; extra == \"langchain\"","livekit~=0.13.1; extra == \"livekit\"","tenacity~=9.0.0; extra == \"livekit\"","lmnt~=1.1.4; extra == \"lmnt\"","pyaudio~=0.2.14; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=1.0.8; extra == \"moondream\"","transformers~=4.44.0; extra == \"moondream\"","openai~=1.37.2; extra == \"openai\"","openpipe~=4.24.0; extra == \"openpipe\"","pyht~=0.0.28; extra == \"playht\"","onnxruntime>=1.16.1; extra == \"silero\"","together~=1.2.7; extra == \"together\"","websockets~=12.0; extra == \"websocket\"","fastapi~=0.115.0; extra == \"websocket\"","faster-whisper~=1.0.3; extra == \"whisper\"","resampy~=0.4.3; extra == \"xtts\""],"requires_python":">=3.10","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.43","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"a1ae5c17eed1b12b003ebd248e13d23ba1979548ece5b2393e6fda04cb69a5fd","md5":"035e75a779a929ea73e3d463d46e99f8","sha256":"35439a4f5bef7b31efa71aff52d4dc9fecf23241ef4f14d187773cc1346a4c75"},"downloads":-1,"filename":"pipecat_ai-0.0.43-py3-none-any.whl","has_sig":false,"md5_digest":"035e75a779a929ea73e3d463d46e99f8","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":2090633,"upload_time":"2024-10-10T21:12:11","upload_time_iso_8601":"2024-10-10T21:12:11.296189Z","url":"https://files.pythonhosted.org/packages/a1/ae/5c17eed1b12b003ebd248e13d23ba1979548ece5b2393e6fda04cb69a5fd/pipecat_ai-0.0.43-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"394451e07682350f03bc8dde4d8ad54ac307a176d890b36f890de91d43402a35","md5":"3fe7e753b4846c614e61346f4942e137","sha256":"7bd488265123cebb110f830224a9426e29e5441ea5d0d8222237be8e6b0d08cc"},"downloads":-1,"filename":"pipecat_ai-0.0.43.tar.gz","has_sig":false,"md5_digest":"3fe7e753b4846c614e61346f4942e137","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":66344917,"upload_time":"2024-10-10T21:12:14","upload_time_iso_8601":"2024-10-10T21:12:14.329046Z","url":"https://files.pythonhosted.org/packages/39/44/51e07682350f03bc8dde4d8ad54ac307a176d890b36f890de91d43402a35/pipecat_ai-0.0.43.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.44":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","aws","azure","canonical","cartesia","daily","deepgram","elevenlabs","examples","fal","fireworks","gladia","google","gstreamer","langchain","livekit","lmnt","local","moondream","openai","openpipe","playht","silero","together","websocket","whisper","xtts"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.44/","requires_dist":["aiohttp~=3.10.3","Markdown~=3.7","numpy~=1.26.4","loguru~=0.7.2","Pillow~=10.4.0","protobuf~=4.25.4","pydantic~=2.8.2","pyloudnorm~=0.1.1","anthropic~=0.34.0; extra == \"anthropic\"","boto3~=1.35.27; extra == \"aws\"","azure-cognitiveservices-speech~=1.40.0; extra == \"azure\"","aiofiles~=24.1.0; extra == \"canonical\"","cartesia~=1.0.13; extra == \"cartesia\"","websockets~=12.0; extra == \"cartesia\"","daily-python~=0.11.0; extra == \"daily\"","deepgram-sdk~=3.7.3; extra == \"deepgram\"","websockets~=12.0; extra == \"elevenlabs\"","python-dotenv~=1.0.1; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.1; extra == \"fal\"","openai~=1.37.2; extra == \"fireworks\"","websockets~=12.0; extra == \"gladia\"","google-generativeai~=0.7.2; extra == \"google\"","google-cloud-texttospeech~=2.17.2; extra == \"google\"","pygobject~=3.48.2; extra == \"gstreamer\"","langchain~=0.2.14; extra == \"langchain\"","langchain-community~=0.2.12; extra == \"langchain\"","langchain-openai~=0.1.20; extra == \"langchain\"","livekit~=0.13.1; extra == \"livekit\"","tenacity~=9.0.0; extra == \"livekit\"","lmnt~=1.1.4; extra == \"lmnt\"","pyaudio~=0.2.14; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=1.0.8; extra == \"moondream\"","transformers~=4.44.0; extra == \"moondream\"","openai~=1.50.2; extra == \"openai\"","websockets~=12.0; extra == \"openai\"","python-deepcompare~=1.0.1; extra == \"openai\"","openpipe~=4.24.0; extra == \"openpipe\"","pyht~=0.0.28; extra == \"playht\"","onnxruntime>=1.16.1; extra == \"silero\"","openai~=1.50.2; extra == \"together\"","websockets~=12.0; extra == \"websocket\"","fastapi~=0.115.0; extra == \"websocket\"","faster-whisper~=1.0.3; extra == \"whisper\"","resampy~=0.4.3; extra == \"xtts\""],"requires_python":">=3.10","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.44","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"6adde675d5f59002269080017886d5722750caf3f81e9c1bd11ac7fd97a749d1","md5":"b7451957ac39802426b1a51d8dae8240","sha256":"162d3f74da49ece8c4c72a314365775b3e274d1770c62112214bad211bf0638a"},"downloads":-1,"filename":"pipecat_ai-0.0.44-py3-none-any.whl","has_sig":false,"md5_digest":"b7451957ac39802426b1a51d8dae8240","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":2108038,"upload_time":"2024-10-16T01:15:31","upload_time_iso_8601":"2024-10-16T01:15:31.111771Z","url":"https://files.pythonhosted.org/packages/6a/dd/e675d5f59002269080017886d5722750caf3f81e9c1bd11ac7fd97a749d1/pipecat_ai-0.0.44-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"4553865f9ef2a9ed5647ee07d58afbf7af9c76d229d91526180c56ff8bcbd7a6","md5":"567bcc3ddb26c56c1c1fa41dbf09033b","sha256":"351ad99ae89b14e65142dc0ff5ac3ce781193c7de64f63cea058903d7ff9be4f"},"downloads":-1,"filename":"pipecat_ai-0.0.44.tar.gz","has_sig":false,"md5_digest":"567bcc3ddb26c56c1c1fa41dbf09033b","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":66370840,"upload_time":"2024-10-16T01:15:34","upload_time_iso_8601":"2024-10-16T01:15:34.055925Z","url":"https://files.pythonhosted.org/packages/45/53/865f9ef2a9ed5647ee07d58afbf7af9c76d229d91526180c56ff8bcbd7a6/pipecat_ai-0.0.44.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.45":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","aws","azure","canonical","cartesia","daily","deepgram","elevenlabs","examples","fal","fireworks","gladia","google","gstreamer","langchain","livekit","lmnt","local","moondream","openai","openpipe","playht","silero","together","websocket","whisper","xtts"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.45/","requires_dist":["aiohttp~=3.10.3","Markdown~=3.7","numpy~=1.26.4","loguru~=0.7.2","Pillow~=10.4.0","protobuf~=4.25.4","pydantic~=2.8.2","pyloudnorm~=0.1.1","anthropic~=0.34.0; extra == \"anthropic\"","boto3~=1.35.27; extra == \"aws\"","azure-cognitiveservices-speech~=1.40.0; extra == \"azure\"","aiofiles~=24.1.0; extra == \"canonical\"","cartesia~=1.0.13; extra == \"cartesia\"","websockets~=12.0; extra == \"cartesia\"","daily-python~=0.11.0; extra == \"daily\"","deepgram-sdk~=3.7.3; extra == \"deepgram\"","websockets~=12.0; extra == \"elevenlabs\"","python-dotenv~=1.0.1; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.1; extra == \"fal\"","openai~=1.37.2; extra == \"fireworks\"","websockets~=12.0; extra == \"gladia\"","google-generativeai~=0.7.2; extra == \"google\"","google-cloud-texttospeech~=2.17.2; extra == \"google\"","pygobject~=3.48.2; extra == \"gstreamer\"","langchain~=0.2.14; extra == \"langchain\"","langchain-community~=0.2.12; extra == \"langchain\"","langchain-openai~=0.1.20; extra == \"langchain\"","livekit~=0.13.1; extra == \"livekit\"","tenacity~=9.0.0; extra == \"livekit\"","lmnt~=1.1.4; extra == \"lmnt\"","pyaudio~=0.2.14; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=1.0.8; extra == \"moondream\"","transformers~=4.44.0; extra == \"moondream\"","openai~=1.50.2; extra == \"openai\"","websockets~=12.0; extra == \"openai\"","python-deepcompare~=1.0.1; extra == \"openai\"","openpipe~=4.24.0; extra == \"openpipe\"","pyht~=0.0.28; extra == \"playht\"","onnxruntime>=1.16.1; extra == \"silero\"","openai~=1.50.2; extra == \"together\"","websockets~=12.0; extra == \"websocket\"","fastapi~=0.115.0; extra == \"websocket\"","faster-whisper~=1.0.3; extra == \"whisper\"","resampy~=0.4.3; extra == \"xtts\""],"requires_python":">=3.10","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.45","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"28656bd2d44067ff5e7381d1c2d6c35061c9a7ad4ad07fd1f0d51cd92920bf27","md5":"0758055f0767b0274052afd9b75364cf","sha256":"f2c043470121d9ed2c01025c150cc92b42897bd1e7dc8956d9c368afbeb04b0e"},"downloads":-1,"filename":"pipecat_ai-0.0.45-py3-none-any.whl","has_sig":false,"md5_digest":"0758055f0767b0274052afd9b75364cf","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":2107755,"upload_time":"2024-10-16T16:20:32","upload_time_iso_8601":"2024-10-16T16:20:32.656887Z","url":"https://files.pythonhosted.org/packages/28/65/6bd2d44067ff5e7381d1c2d6c35061c9a7ad4ad07fd1f0d51cd92920bf27/pipecat_ai-0.0.45-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"61692b22b3de75783b570fb675fd5849675395ae52eb43cfd2a133dcc17e40c1","md5":"53b746e0ae82537682f02967fb821c46","sha256":"b20c6a81a4f068b8913f6adc8ce6b63a8dd91a12442980730d5634e3bd26b45f"},"downloads":-1,"filename":"pipecat_ai-0.0.45.tar.gz","has_sig":false,"md5_digest":"53b746e0ae82537682f02967fb821c46","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":66370759,"upload_time":"2024-10-16T16:20:35","upload_time_iso_8601":"2024-10-16T16:20:35.206021Z","url":"https://files.pythonhosted.org/packages/61/69/2b22b3de75783b570fb675fd5849675395ae52eb43cfd2a133dcc17e40c1/pipecat_ai-0.0.45.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.46":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","aws","azure","canonical","cartesia","daily","deepgram","elevenlabs","examples","fal","fireworks","gladia","google","gstreamer","langchain","livekit","lmnt","local","moondream","openai","openpipe","playht","silero","together","websocket","whisper"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.46/","requires_dist":["aiohttp~=3.10.3","Markdown~=3.7","numpy~=1.26.4","loguru~=0.7.2","Pillow~=10.4.0","protobuf~=4.25.4","pydantic~=2.8.2","pyloudnorm~=0.1.1","scipy~=1.14.1","anthropic~=0.34.0; extra == \"anthropic\"","boto3~=1.35.27; extra == \"aws\"","azure-cognitiveservices-speech~=1.40.0; extra == \"azure\"","aiofiles~=24.1.0; extra == \"canonical\"","cartesia~=1.0.13; extra == \"cartesia\"","websockets~=13.1; extra == \"cartesia\"","daily-python~=0.11.0; extra == \"daily\"","deepgram-sdk~=3.7.3; extra == \"deepgram\"","websockets~=13.1; extra == \"elevenlabs\"","python-dotenv~=1.0.1; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.1; extra == \"fal\"","openai~=1.37.2; extra == \"fireworks\"","websockets~=13.1; extra == \"gladia\"","google-generativeai~=0.7.2; extra == \"google\"","google-cloud-texttospeech~=2.17.2; extra == \"google\"","pygobject~=3.48.2; extra == \"gstreamer\"","langchain~=0.2.14; extra == \"langchain\"","langchain-community~=0.2.12; extra == \"langchain\"","langchain-openai~=0.1.20; extra == \"langchain\"","livekit~=0.17.5; extra == \"livekit\"","livekit-api~=0.7.1; extra == \"livekit\"","tenacity~=8.5.0; extra == \"livekit\"","lmnt~=1.1.4; extra == \"lmnt\"","pyaudio~=0.2.14; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=1.0.8; extra == \"moondream\"","transformers~=4.44.0; extra == \"moondream\"","openai~=1.50.2; extra == \"openai\"","websockets~=13.1; extra == \"openai\"","python-deepcompare~=1.0.1; extra == \"openai\"","openpipe~=4.24.0; extra == \"openpipe\"","pyht~=0.1.4; extra == \"playht\"","websockets~=13.1; extra == \"playht\"","onnxruntime~=1.19.2; extra == \"silero\"","openai~=1.50.2; extra == \"together\"","websockets~=13.1; extra == \"websocket\"","fastapi~=0.115.0; extra == \"websocket\"","faster-whisper~=1.0.3; extra == \"whisper\""],"requires_python":">=3.10","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.46","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"611885a79793e1ccfb9833281415e3c69339bd5248ea8638ff4f4ef652001374","md5":"26f50038153511396ed9b626bddc6f51","sha256":"3e4d918196793de7944b71f5957799cec509d3eb6389f9e31d29c738fc74a008"},"downloads":-1,"filename":"pipecat_ai-0.0.46-py3-none-any.whl","has_sig":false,"md5_digest":"26f50038153511396ed9b626bddc6f51","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":2112407,"upload_time":"2024-10-20T01:28:26","upload_time_iso_8601":"2024-10-20T01:28:26.900437Z","url":"https://files.pythonhosted.org/packages/61/18/85a79793e1ccfb9833281415e3c69339bd5248ea8638ff4f4ef652001374/pipecat_ai-0.0.46-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"9d2600c220dc92e8921d609a458359f6276283ddf065e82446b9fef395837a43","md5":"7684789797ef05648d9b9e5c05c3ecf1","sha256":"06ba8512fb816bcd4f3482b810bf1629daad0338a9d219113c18d42f67dcf6fb"},"downloads":-1,"filename":"pipecat_ai-0.0.46.tar.gz","has_sig":false,"md5_digest":"7684789797ef05648d9b9e5c05c3ecf1","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":66373178,"upload_time":"2024-10-20T01:28:30","upload_time_iso_8601":"2024-10-20T01:28:30.915732Z","url":"https://files.pythonhosted.org/packages/9d/26/00c220dc92e8921d609a458359f6276283ddf065e82446b9fef395837a43/pipecat_ai-0.0.46.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.47":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","assemblyai","aws","azure","canonical","cartesia","daily","deepgram","elevenlabs","examples","fal","fireworks","gladia","google","gstreamer","langchain","livekit","lmnt","local","moondream","openai","openpipe","playht","silero","together","websocket","whisper"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.47/","requires_dist":["aiohttp~=3.10.3","loguru~=0.7.2","Markdown~=3.7","numpy~=1.26.4","Pillow~=10.4.0","protobuf~=4.25.4","pydantic~=2.8.2","pyloudnorm~=0.1.1","scipy~=1.14.1","anthropic~=0.34.0; extra == \"anthropic\"","assemblyai~=0.34.0; extra == \"assemblyai\"","boto3~=1.35.27; extra == \"aws\"","azure-cognitiveservices-speech~=1.40.0; extra == \"azure\"","aiofiles~=24.1.0; extra == \"canonical\"","cartesia~=1.0.13; extra == \"cartesia\"","websockets~=13.1; extra == \"cartesia\"","daily-python~=0.11.0; extra == \"daily\"","deepgram-sdk~=3.7.3; extra == \"deepgram\"","websockets~=13.1; extra == \"elevenlabs\"","python-dotenv~=1.0.1; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.1; extra == \"fal\"","openai~=1.37.2; extra == \"fireworks\"","websockets~=13.1; extra == \"gladia\"","google-generativeai~=0.7.2; extra == \"google\"","google-cloud-texttospeech~=2.17.2; extra == \"google\"","pygobject~=3.48.2; extra == \"gstreamer\"","langchain~=0.2.14; extra == \"langchain\"","langchain-community~=0.2.12; extra == \"langchain\"","langchain-openai~=0.1.20; extra == \"langchain\"","livekit~=0.17.5; extra == \"livekit\"","livekit-api~=0.7.1; extra == \"livekit\"","tenacity~=8.5.0; extra == \"livekit\"","lmnt~=1.1.4; extra == \"lmnt\"","pyaudio~=0.2.14; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=1.0.8; extra == \"moondream\"","transformers~=4.44.0; extra == \"moondream\"","openai~=1.50.2; extra == \"openai\"","websockets~=13.1; extra == \"openai\"","python-deepcompare~=1.0.1; extra == \"openai\"","openpipe~=4.24.0; extra == \"openpipe\"","pyht~=0.1.4; extra == \"playht\"","websockets~=13.1; extra == \"playht\"","onnxruntime~=1.19.2; extra == \"silero\"","openai~=1.50.2; extra == \"together\"","websockets~=13.1; extra == \"websocket\"","fastapi~=0.115.0; extra == \"websocket\"","faster-whisper~=1.0.3; extra == \"whisper\""],"requires_python":">=3.10","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.47","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"5230f53661e8ee99a4940b08276d870df87c482882de212b2d14f457aecf9c41","md5":"fdae90f7611ae9dac841e96b30b5719b","sha256":"4065af99f2023fec859aa05afbf5744d9bac70c35bf42274e2189a1ca2224a65"},"downloads":-1,"filename":"pipecat_ai-0.0.47-py3-none-any.whl","has_sig":false,"md5_digest":"fdae90f7611ae9dac841e96b30b5719b","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":2114621,"upload_time":"2024-10-22T17:32:47","upload_time_iso_8601":"2024-10-22T17:32:47.757027Z","url":"https://files.pythonhosted.org/packages/52/30/f53661e8ee99a4940b08276d870df87c482882de212b2d14f457aecf9c41/pipecat_ai-0.0.47-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"08c2314c8f5454a4787c1b87827a5e4beb682ac2b92c4ab46306ff346e9bc2a5","md5":"fb1b6530f83034e6dbf35ae4126d1e94","sha256":"bb768d5003975b1d4092ee78e5a111c2f839729ae6d9354c846343440b95ba08"},"downloads":-1,"filename":"pipecat_ai-0.0.47.tar.gz","has_sig":false,"md5_digest":"fb1b6530f83034e6dbf35ae4126d1e94","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":66378088,"upload_time":"2024-10-22T17:32:49","upload_time_iso_8601":"2024-10-22T17:32:49.979971Z","url":"https://files.pythonhosted.org/packages/08/c2/314c8f5454a4787c1b87827a5e4beb682ac2b92c4ab46306ff346e9bc2a5/pipecat_ai-0.0.47.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.48":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":["anthropic","assemblyai","aws","azure","canonical","cartesia","daily","deepgram","elevenlabs","examples","fal","fireworks","gladia","google","gstreamer","krisp","langchain","livekit","lmnt","local","moondream","noisereduce","openai","openpipe","playht","silero","soundfile","together","websocket","whisper"],"release_url":"https://pypi.org/project/pipecat-ai/0.0.48/","requires_dist":["aiohttp~=3.10.3","loguru~=0.7.2","Markdown~=3.7","numpy~=1.26.4","Pillow~=10.4.0","protobuf~=4.25.4","pydantic~=2.8.2","pyloudnorm~=0.1.1","resampy~=0.4.3","anthropic~=0.34.0; extra == \"anthropic\"","assemblyai~=0.34.0; extra == \"assemblyai\"","boto3~=1.35.27; extra == \"aws\"","azure-cognitiveservices-speech~=1.40.0; extra == \"azure\"","aiofiles~=24.1.0; extra == \"canonical\"","cartesia~=1.0.13; extra == \"cartesia\"","websockets~=13.1; extra == \"cartesia\"","daily-python~=0.12.0; extra == \"daily\"","deepgram-sdk~=3.7.3; extra == \"deepgram\"","websockets~=13.1; extra == \"elevenlabs\"","python-dotenv~=1.0.1; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.1; extra == \"fal\"","openai~=1.37.2; extra == \"fireworks\"","websockets~=13.1; extra == \"gladia\"","google-generativeai~=0.8.3; extra == \"google\"","google-cloud-texttospeech~=2.17.2; extra == \"google\"","pygobject~=3.48.2; extra == \"gstreamer\"","pipecat-ai-krisp~=0.2.0; extra == \"krisp\"","langchain~=0.2.14; extra == \"langchain\"","langchain-community~=0.2.12; extra == \"langchain\"","langchain-openai~=0.1.20; extra == \"langchain\"","livekit~=0.17.5; extra == \"livekit\"","livekit-api~=0.7.1; extra == \"livekit\"","tenacity~=8.5.0; extra == \"livekit\"","lmnt~=1.1.4; extra == \"lmnt\"","pyaudio~=0.2.14; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=1.0.8; extra == \"moondream\"","transformers~=4.44.0; extra == \"moondream\"","noisereduce~=3.0.3; extra == \"noisereduce\"","openai~=1.50.2; extra == \"openai\"","websockets~=13.1; extra == \"openai\"","python-deepcompare~=1.0.1; extra == \"openai\"","openpipe~=4.24.0; extra == \"openpipe\"","pyht~=0.1.4; extra == \"playht\"","websockets~=13.1; extra == \"playht\"","onnxruntime~=1.19.2; extra == \"silero\"","soundfile~=0.12.1; extra == \"soundfile\"","openai~=1.50.2; extra == \"together\"","websockets~=13.1; extra == \"websocket\"","fastapi~=0.115.0; extra == \"websocket\"","faster-whisper~=1.0.3; extra == \"whisper\""],"requires_python":">=3.10","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.48","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"564216cd7c30a101115e95c75ef2bdf7f42d4eeeb1eed3ca00208318b32f6d8c","md5":"56a90bbb84bdbf70edee356b9535475c","sha256":"9ee427289c95dce7d53c6040a8d9f1dcb4e69adc488f683c40b0b27f32e3a433"},"downloads":-1,"filename":"pipecat_ai-0.0.48-py3-none-any.whl","has_sig":false,"md5_digest":"56a90bbb84bdbf70edee356b9535475c","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":2131276,"upload_time":"2024-11-10T22:11:10","upload_time_iso_8601":"2024-11-10T22:11:10.462968Z","url":"https://files.pythonhosted.org/packages/56/42/16cd7c30a101115e95c75ef2bdf7f42d4eeeb1eed3ca00208318b32f6d8c/pipecat_ai-0.0.48-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8fb95da91b2e97cf0175786108977ba4121b76abbe27a24ff2f4fca54868a31c","md5":"01dcf57d1c397c5df82c4a16af782a89","sha256":"96b4a4f78f7b1b7b0ee649cdc9b61f4912b094ca6c3dce71617a90ad83984e79"},"downloads":-1,"filename":"pipecat_ai-0.0.48.tar.gz","has_sig":false,"md5_digest":"01dcf57d1c397c5df82c4a16af782a89","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":66395332,"upload_time":"2024-11-10T22:11:13","upload_time_iso_8601":"2024-11-10T22:11:13.559624Z","url":"https://files.pythonhosted.org/packages/8f/b9/5da91b2e97cf0175786108977ba4121b76abbe27a24ff2f4fca54868a31c/pipecat_ai-0.0.48.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.9":{"info":{"author":null,"author_email":null,"bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","License :: OSI Approved :: BSD License","Topic :: Communications :: Conferencing","Topic :: Multimedia :: Sound/Audio","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"webrtc, audio, video, ai","license":"BSD 2-Clause License","maintainer":null,"maintainer_email":null,"name":"pipecat-ai","package_url":"https://pypi.org/project/pipecat-ai/","platform":null,"project_url":"https://pypi.org/project/pipecat-ai/","project_urls":{"Source":"https://github.com/pipecat-ai/pipecat","Website":"https://pipecat.ai"},"provides_extra":null,"release_url":"https://pypi.org/project/pipecat-ai/0.0.9/","requires_dist":["aiohttp~=3.9.5","numpy~=1.26.4","loguru~=0.7.0","Pillow~=10.3.0","typing-extensions~=4.11.0","anthropic~=0.25.7; extra == \"anthropic\"","azure-cognitiveservices-speech~=1.37.0; extra == \"azure\"","daily-python~=0.7.4; extra == \"daily\"","python-dotenv~=1.0.0; extra == \"examples\"","flask~=3.0.3; extra == \"examples\"","flask-cors~=4.0.1; extra == \"examples\"","fal-client~=0.4.0; extra == \"fal\"","openai~=1.26.0; extra == \"fireworks\"","pyaudio~=0.2.0; extra == \"local\"","einops~=0.8.0; extra == \"moondream\"","timm~=0.9.16; extra == \"moondream\"","transformers~=4.40.2; extra == \"moondream\"","openai~=1.26.0; extra == \"openai\"","pyht~=0.0.28; extra == \"playht\"","torch~=2.3.0; extra == \"silero\"","torchaudio~=2.3.0; extra == \"silero\"","websockets~=12.0; extra == \"websocket\"","faster-whisper~=1.0.2; extra == \"whisper\""],"requires_python":">=3.7","summary":"An open source framework for voice (and multimodal) assistants","version":"0.0.9","yanked":false,"yanked_reason":null},"last_serial":25926547,"urls":[{"comment_text":"","digests":{"blake2b_256":"06130e5d21a4bf3e00921d71497a3f98f72270f584d7ac1ceae8739f22b12c91","md5":"7a4a709246dac2aec25275ec911e3b23","sha256":"fc3efd8f77e488e37a5e438d05b78a5d2b658a25aad9f4f05c027bfdc85188f4"},"downloads":-1,"filename":"pipecat_ai-0.0.9-py3-none-any.whl","has_sig":false,"md5_digest":"7a4a709246dac2aec25275ec911e3b23","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":62177,"upload_time":"2024-05-13T05:38:21","upload_time_iso_8601":"2024-05-13T05:38:21.625055Z","url":"https://files.pythonhosted.org/packages/06/13/0e5d21a4bf3e00921d71497a3f98f72270f584d7ac1ceae8739f22b12c91/pipecat_ai-0.0.9-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e0a2ba1e9fe8ecc6ab3c05444d68f7cdc57c7e93903ce5be851a57d61b5465d8","md5":"a5f44f3bf6a249d77b77c1a54162dd63","sha256":"1ee91e17c52184bde9c025e84f4c2cc4cc355dcc8014c0800cdfabb9e283b602"},"downloads":-1,"filename":"pipecat_ai-0.0.9.tar.gz","has_sig":false,"md5_digest":"a5f44f3bf6a249d77b77c1a54162dd63","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":33485745,"upload_time":"2024-05-13T05:38:23","upload_time_iso_8601":"2024-05-13T05:38:23.315573Z","url":"https://files.pythonhosted.org/packages/e0/a2/ba1e9fe8ecc6ab3c05444d68f7cdc57c7e93903ce5be851a57d61b5465d8/pipecat_ai-0.0.9.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}