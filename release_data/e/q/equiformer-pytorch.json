{"0.0.1":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.1/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.1","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"ad467fab292c53dc499ccca40677e696f5580407283883a43aad328946d3d011","md5":"4d37a45b08fbd848b591d3aabda51555","sha256":"19bf1fc0da4124ccfdf4be83612d04e00351fb819a13482db23a87b913babe5d"},"downloads":-1,"filename":"equiformer-pytorch-0.0.1.tar.gz","has_sig":false,"md5_digest":"4d37a45b08fbd848b591d3aabda51555","packagetype":"sdist","python_version":"source","requires_python":null,"size":2817,"upload_time":"2022-11-15T21:10:46","upload_time_iso_8601":"2022-11-15T21:10:46.641795Z","url":"https://files.pythonhosted.org/packages/ad/46/7fab292c53dc499ccca40677e696f5580407283883a43aad328946d3d011/equiformer-pytorch-0.0.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.11":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.11/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.11","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"66d8b24a480a6f3fbba9c027b30b90fadd2251000b22310743f782095f1f238a","md5":"8b1eb978690920afd2a63fb36d971afb","sha256":"a1926326aafa319b2b88a856a1f788502ddd3c910bab25f3551bdffda2d1dee6"},"downloads":-1,"filename":"equiformer-pytorch-0.0.11.tar.gz","has_sig":false,"md5_digest":"8b1eb978690920afd2a63fb36d971afb","packagetype":"sdist","python_version":"source","requires_python":null,"size":18525,"upload_time":"2022-11-26T19:08:57","upload_time_iso_8601":"2022-11-26T19:08:57.460853Z","url":"https://files.pythonhosted.org/packages/66/d8/b24a480a6f3fbba9c027b30b90fadd2251000b22310743f782095f1f238a/equiformer-pytorch-0.0.11.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.12":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.12/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.12","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"5974b1ec99aa78f6e0b022c3dbc4359b308192b0448c7412fbcbe95f521aee91","md5":"47575bdf3cb5a357cf078f9bf554a219","sha256":"c693a82ae70e1b67136c84cef0225d57ee9a61b89b89e753203337e777ac9d7d"},"downloads":-1,"filename":"equiformer-pytorch-0.0.12.tar.gz","has_sig":false,"md5_digest":"47575bdf3cb5a357cf078f9bf554a219","packagetype":"sdist","python_version":"source","requires_python":null,"size":18580,"upload_time":"2022-11-26T19:28:03","upload_time_iso_8601":"2022-11-26T19:28:03.237138Z","url":"https://files.pythonhosted.org/packages/59/74/b1ec99aa78f6e0b022c3dbc4359b308192b0448c7412fbcbe95f521aee91/equiformer-pytorch-0.0.12.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.14":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.14/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.14","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"48511f4d183a0312fae4e3697fc82c82c79b05162d18c46696c0e44e632814fc","md5":"353cc41e361ff1f67704a87619e1c726","sha256":"5ad778df318d78e51f0424f703c1dcf449236079e5e90744e634d039907c4c61"},"downloads":-1,"filename":"equiformer-pytorch-0.0.14.tar.gz","has_sig":false,"md5_digest":"353cc41e361ff1f67704a87619e1c726","packagetype":"sdist","python_version":"source","requires_python":null,"size":18712,"upload_time":"2022-11-26T22:32:38","upload_time_iso_8601":"2022-11-26T22:32:38.160870Z","url":"https://files.pythonhosted.org/packages/48/51/1f4d183a0312fae4e3697fc82c82c79b05162d18c46696c0e44e632814fc/equiformer-pytorch-0.0.14.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.15":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.15/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.15","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"998ec342ec82e545f21a258ade3ead7e65e851b0cf8c3d1853f89a69cf63ed90","md5":"a017a5bf7caa05550e53aa9d5a33ab99","sha256":"e098839efbfbf03ea380e2bbb3abd3a6d3a38c92de2a07a1771bd92b1b240e4e"},"downloads":-1,"filename":"equiformer-pytorch-0.0.15.tar.gz","has_sig":false,"md5_digest":"a017a5bf7caa05550e53aa9d5a33ab99","packagetype":"sdist","python_version":"source","requires_python":null,"size":18742,"upload_time":"2022-11-26T22:45:45","upload_time_iso_8601":"2022-11-26T22:45:45.855556Z","url":"https://files.pythonhosted.org/packages/99/8e/c342ec82e545f21a258ade3ead7e65e851b0cf8c3d1853f89a69cf63ed90/equiformer-pytorch-0.0.15.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.16":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.16/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.16","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"33a46636a6b3104e2a206a60cfa3873c482bbd0c033f3999fb8ecee11cdd1d54","md5":"5cebeab2b31ef83680cb5e7154f55449","sha256":"bfc5654fd2fb4c45c9f68a22f25547d08eb83019219303da45def6bc012bc43c"},"downloads":-1,"filename":"equiformer-pytorch-0.0.16.tar.gz","has_sig":false,"md5_digest":"5cebeab2b31ef83680cb5e7154f55449","packagetype":"sdist","python_version":"source","requires_python":null,"size":18808,"upload_time":"2022-11-27T00:47:53","upload_time_iso_8601":"2022-11-27T00:47:53.244252Z","url":"https://files.pythonhosted.org/packages/33/a4/6636a6b3104e2a206a60cfa3873c482bbd0c033f3999fb8ecee11cdd1d54/equiformer-pytorch-0.0.16.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.17":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.17/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.17","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"86a3c6d703d68c4fd05a90b4f8e56c207b80a0e79b470440648a763e94cd2eba","md5":"fe8a45ad8d6af71704e12125a7f7c113","sha256":"4536dbabcb3de74ebf160b2abd2eb545a1aee2547bf6af55c2aa0cd33f97b8dd"},"downloads":-1,"filename":"equiformer-pytorch-0.0.17.tar.gz","has_sig":false,"md5_digest":"fe8a45ad8d6af71704e12125a7f7c113","packagetype":"sdist","python_version":"source","requires_python":null,"size":18817,"upload_time":"2022-11-27T00:55:37","upload_time_iso_8601":"2022-11-27T00:55:37.772734Z","url":"https://files.pythonhosted.org/packages/86/a3/c6d703d68c4fd05a90b4f8e56c207b80a0e79b470440648a763e94cd2eba/equiformer-pytorch-0.0.17.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.18":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.18/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.18","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"c08746e3c0bc2439fddf7d013049ab9f936da03cfba930cc977f9134a496674a","md5":"cd23bf85bb583cf4fe1823ac2ba35d9e","sha256":"1c3f4bacf1ad18bdbe0c03d75d8f3cd2158268388bb86e62c88f535e82f01aaa"},"downloads":-1,"filename":"equiformer-pytorch-0.0.18.tar.gz","has_sig":false,"md5_digest":"cd23bf85bb583cf4fe1823ac2ba35d9e","packagetype":"sdist","python_version":"source","requires_python":null,"size":18906,"upload_time":"2022-11-27T16:17:19","upload_time_iso_8601":"2022-11-27T16:17:19.256461Z","url":"https://files.pythonhosted.org/packages/c0/87/46e3c0bc2439fddf7d013049ab9f936da03cfba930cc977f9134a496674a/equiformer-pytorch-0.0.18.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.19":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.19/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.19","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"17cc595d0f83e762e93bdde2b4a97f8561e9a7e300f3ef092270c4213eee299b","md5":"5da9f49c9c849068fa755ef976367294","sha256":"7f73762b87fef9b2a073694a914ffbb67b5f27a5edee866ef89d69d27494cb47"},"downloads":-1,"filename":"equiformer-pytorch-0.0.19.tar.gz","has_sig":false,"md5_digest":"5da9f49c9c849068fa755ef976367294","packagetype":"sdist","python_version":"source","requires_python":null,"size":18901,"upload_time":"2022-11-27T16:21:34","upload_time_iso_8601":"2022-11-27T16:21:34.163220Z","url":"https://files.pythonhosted.org/packages/17/cc/595d0f83e762e93bdde2b4a97f8561e9a7e300f3ef092270c4213eee299b/equiformer-pytorch-0.0.19.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.21":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.21/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.21","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"340bbfb7758c1d7ea2ef33fa2f4876220af52a42779def5b24a4a6c9695575bd","md5":"a344614dfe04d2b09787d16e0c8d696e","sha256":"21dea3c626d29f09f711759dd9d15dd9b902811bb1726e3beb843ebee38cddf2"},"downloads":-1,"filename":"equiformer-pytorch-0.0.21.tar.gz","has_sig":false,"md5_digest":"a344614dfe04d2b09787d16e0c8d696e","packagetype":"sdist","python_version":"source","requires_python":null,"size":18860,"upload_time":"2022-11-27T16:22:49","upload_time_iso_8601":"2022-11-27T16:22:49.494207Z","url":"https://files.pythonhosted.org/packages/34/0b/bfb7758c1d7ea2ef33fa2f4876220af52a42779def5b24a4a6c9695575bd/equiformer-pytorch-0.0.21.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.22":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.22/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.22","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"e2d27e523de7aac0b6c3485b44ae023897f09b32b5a3a05c822701641db6c604","md5":"d6d0bc7d3764d7e3ef875b168651ea0d","sha256":"359f38c6566f552a20fed4dd38a5583b7a79be1a3a11c04e45ccb0433973bf54"},"downloads":-1,"filename":"equiformer-pytorch-0.0.22.tar.gz","has_sig":false,"md5_digest":"d6d0bc7d3764d7e3ef875b168651ea0d","packagetype":"sdist","python_version":"source","requires_python":null,"size":18799,"upload_time":"2022-11-27T16:48:43","upload_time_iso_8601":"2022-11-27T16:48:43.319958Z","url":"https://files.pythonhosted.org/packages/e2/d2/7e523de7aac0b6c3485b44ae023897f09b32b5a3a05c822701641db6c604/equiformer-pytorch-0.0.22.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.23":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.23/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.23","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"3b17ba3326c259725a94a970a257a0d30ac93e7cc7878d1f0be51a61f013f412","md5":"cc07cf9d628438f874ff868d20ce7991","sha256":"8a13414addf7dbf82cdb15d1efe94f065326f9304effe825a35d7ef5c871863f"},"downloads":-1,"filename":"equiformer-pytorch-0.0.23.tar.gz","has_sig":false,"md5_digest":"cc07cf9d628438f874ff868d20ce7991","packagetype":"sdist","python_version":"source","requires_python":null,"size":18927,"upload_time":"2022-11-28T19:52:42","upload_time_iso_8601":"2022-11-28T19:52:42.869346Z","url":"https://files.pythonhosted.org/packages/3b/17/ba3326c259725a94a970a257a0d30ac93e7cc7878d1f0be51a61f013f412/equiformer-pytorch-0.0.23.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.24":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.24/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.24","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"788f796b9e675e02e216b4c23937f818fc78b0b1bf632590368145dfa9bbf2ab","md5":"afb3de8e53f0890166de721980fc4b1f","sha256":"5094365257058e07b4dde230d768688eee11e12767022307b6dd7649f467d2bc"},"downloads":-1,"filename":"equiformer-pytorch-0.0.24.tar.gz","has_sig":false,"md5_digest":"afb3de8e53f0890166de721980fc4b1f","packagetype":"sdist","python_version":"source","requires_python":null,"size":18845,"upload_time":"2022-11-28T20:05:24","upload_time_iso_8601":"2022-11-28T20:05:24.680494Z","url":"https://files.pythonhosted.org/packages/78/8f/796b9e675e02e216b4c23937f818fc78b0b1bf632590368145dfa9bbf2ab/equiformer-pytorch-0.0.24.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.25":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.25/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.25","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"2c401016deb4df4a3334b81bd34be4ecd3460121fd2c97d3b5256f3642b00bf7","md5":"3631e0ed2639038ecc2cbaa5a2beb48b","sha256":"4365acb18439da1f26ee5b5ecd4f5f2b1837ab73746a87b72be25b08feae0e20"},"downloads":-1,"filename":"equiformer-pytorch-0.0.25.tar.gz","has_sig":false,"md5_digest":"3631e0ed2639038ecc2cbaa5a2beb48b","packagetype":"sdist","python_version":"source","requires_python":null,"size":18834,"upload_time":"2022-11-28T20:16:14","upload_time_iso_8601":"2022-11-28T20:16:14.594993Z","url":"https://files.pythonhosted.org/packages/2c/40/1016deb4df4a3334b81bd34be4ecd3460121fd2c97d3b5256f3642b00bf7/equiformer-pytorch-0.0.25.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.26":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.26/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.26","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"ec5a333b6b18a462290a75c926bf11f90625c41c179d1f5cf1e40ad6e347ca35","md5":"5779f0322638f15959b63d29c659837d","sha256":"2612c5d2d74776ebb9c3defcc39e154425215111245d866d60c49e2307c80d82"},"downloads":-1,"filename":"equiformer-pytorch-0.0.26.tar.gz","has_sig":false,"md5_digest":"5779f0322638f15959b63d29c659837d","packagetype":"sdist","python_version":"source","requires_python":null,"size":18872,"upload_time":"2022-11-28T21:09:23","upload_time_iso_8601":"2022-11-28T21:09:23.998738Z","url":"https://files.pythonhosted.org/packages/ec/5a/333b6b18a462290a75c926bf11f90625c41c179d1f5cf1e40ad6e347ca35/equiformer-pytorch-0.0.26.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.27":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.27/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.27","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"2be6e7ca2dfa045ba8572be70370a5fcd5b10bd6f21322b0ed56f4c3437a71d4","md5":"4efe291fff521b9623167aac2985b6e9","sha256":"12c6e1da4963a3b27b8533a03595bdf4a78a8f81f33956a6bac03bd47e90de59"},"downloads":-1,"filename":"equiformer-pytorch-0.0.27.tar.gz","has_sig":false,"md5_digest":"4efe291fff521b9623167aac2985b6e9","packagetype":"sdist","python_version":"source","requires_python":null,"size":19258,"upload_time":"2022-11-29T19:47:13","upload_time_iso_8601":"2022-11-29T19:47:13.433060Z","url":"https://files.pythonhosted.org/packages/2b/e6/e7ca2dfa045ba8572be70370a5fcd5b10bd6f21322b0ed56f4c3437a71d4/equiformer-pytorch-0.0.27.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.29":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.29/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.29","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"5a4b9fab276169443d9340435c174b36e38229cf1ecbcd228873d602debedd89","md5":"f14d7c6196c468562a4ed2e02da551c3","sha256":"af4ca458cc49a416f9debf6b8fc99d201a7f06849ca1478a38a521548cfbf76d"},"downloads":-1,"filename":"equiformer-pytorch-0.0.29.tar.gz","has_sig":false,"md5_digest":"f14d7c6196c468562a4ed2e02da551c3","packagetype":"sdist","python_version":"source","requires_python":null,"size":19123,"upload_time":"2022-11-29T20:51:04","upload_time_iso_8601":"2022-11-29T20:51:04.788965Z","url":"https://files.pythonhosted.org/packages/5a/4b/9fab276169443d9340435c174b36e38229cf1ecbcd228873d602debedd89/equiformer-pytorch-0.0.29.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.30":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.30/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.30","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"bb5418f622d9dd8a337c5ab981b7b1a291b43c290216723782ac3942a9d595b0","md5":"b17f2fc8b7cc1c3e87ce0d90c333506a","sha256":"c032e5ee831e3cd48c6090822fb6ba61847030a03b8911a16c503e64b8275a83"},"downloads":-1,"filename":"equiformer-pytorch-0.0.30.tar.gz","has_sig":false,"md5_digest":"b17f2fc8b7cc1c3e87ce0d90c333506a","packagetype":"sdist","python_version":"source","requires_python":null,"size":19357,"upload_time":"2022-11-29T21:36:28","upload_time_iso_8601":"2022-11-29T21:36:28.996796Z","url":"https://files.pythonhosted.org/packages/bb/54/18f622d9dd8a337c5ab981b7b1a291b43c290216723782ac3942a9d595b0/equiformer-pytorch-0.0.30.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.31":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.31/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.31","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"947f1606a470c04a9ec17218ee00d6a1febd3f17648ea6b34c91216c6b54e5fe","md5":"be76723a0e1cc626691ff381687afbb5","sha256":"fb26770f34f8d7cd963c8b498cb851bdcc80d37a28db6121ec9ce254ea3ad6ba"},"downloads":-1,"filename":"equiformer-pytorch-0.0.31.tar.gz","has_sig":false,"md5_digest":"be76723a0e1cc626691ff381687afbb5","packagetype":"sdist","python_version":"source","requires_python":null,"size":19545,"upload_time":"2022-11-29T21:49:55","upload_time_iso_8601":"2022-11-29T21:49:55.071476Z","url":"https://files.pythonhosted.org/packages/94/7f/1606a470c04a9ec17218ee00d6a1febd3f17648ea6b34c91216c6b54e5fe/equiformer-pytorch-0.0.31.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.32":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.32/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.32","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"89641beab86178450675c03ebe9280ee19d85d61f7d5964c85c23aa4292da22e","md5":"48937d657e773b08167aa16919bee06f","sha256":"a88663b3141e93143f21d11295e241248c1c5f731c03b7116eeaa4afa5fc7f4c"},"downloads":-1,"filename":"equiformer-pytorch-0.0.32.tar.gz","has_sig":false,"md5_digest":"48937d657e773b08167aa16919bee06f","packagetype":"sdist","python_version":"source","requires_python":null,"size":19877,"upload_time":"2022-12-04T15:50:07","upload_time_iso_8601":"2022-12-04T15:50:07.225352Z","url":"https://files.pythonhosted.org/packages/89/64/1beab86178450675c03ebe9280ee19d85d61f7d5964c85c23aa4292da22e/equiformer-pytorch-0.0.32.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.33":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.33/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.33","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"53190def68bab51cf314e7664dafef32c6c3c6d0521a39ff6f01b341995d591f","md5":"34c2029ba205745b2ba24734488cf3f9","sha256":"3d2904b1c4cfb34ade3b910ee8166f57980aed47b8fc822d82e1721ac0ca9130"},"downloads":-1,"filename":"equiformer-pytorch-0.0.33.tar.gz","has_sig":false,"md5_digest":"34c2029ba205745b2ba24734488cf3f9","packagetype":"sdist","python_version":"source","requires_python":null,"size":19871,"upload_time":"2022-12-04T16:05:32","upload_time_iso_8601":"2022-12-04T16:05:32.161036Z","url":"https://files.pythonhosted.org/packages/53/19/0def68bab51cf314e7664dafef32c6c3c6d0521a39ff6f01b341995d591f/equiformer-pytorch-0.0.33.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.34":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.34/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.34","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"c71a3babd9504676c242c36d0f7ade757417f42887845cde4d325e9603987cf2","md5":"1a8bd29e0d2df5b530892fb9096738aa","sha256":"54729b0c68b8e046d3d1b28ce4016ec6502636a5106a5d77531ea1369f776870"},"downloads":-1,"filename":"equiformer-pytorch-0.0.34.tar.gz","has_sig":false,"md5_digest":"1a8bd29e0d2df5b530892fb9096738aa","packagetype":"sdist","python_version":"source","requires_python":null,"size":20010,"upload_time":"2022-12-27T19:06:07","upload_time_iso_8601":"2022-12-27T19:06:07.472532Z","url":"https://files.pythonhosted.org/packages/c7/1a/3babd9504676c242c36d0f7ade757417f42887845cde4d325e9603987cf2/equiformer-pytorch-0.0.34.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.35":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.35/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.35","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"17b61ffaafd63f4a1859bc9b43bf365ca3566b13b03c295ccbe333920568253a","md5":"dcf9283efa5bb8385e943ed6a16c7178","sha256":"1fd3888589f6da059c08c94a336abd9704ac0e3735beab70e028c9fdd5f69304"},"downloads":-1,"filename":"equiformer-pytorch-0.0.35.tar.gz","has_sig":false,"md5_digest":"dcf9283efa5bb8385e943ed6a16c7178","packagetype":"sdist","python_version":"source","requires_python":null,"size":18388170,"upload_time":"2023-02-13T20:21:23","upload_time_iso_8601":"2023-02-13T20:21:23.167495Z","url":"https://files.pythonhosted.org/packages/17/b6/1ffaafd63f4a1859bc9b43bf365ca3566b13b03c295ccbe333920568253a/equiformer-pytorch-0.0.35.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.36":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.36/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.36","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"9c278f6b38730e86c726001d979d05d7be46775f68aec9c048de4df03b90fcb4","md5":"a4efe2a6aaf0a8b8ab97d8da9f71df64","sha256":"85d05005e01083ffe82689412077835446fa06f206c970e97979d7ccc717959d"},"downloads":-1,"filename":"equiformer-pytorch-0.0.36.tar.gz","has_sig":false,"md5_digest":"a4efe2a6aaf0a8b8ab97d8da9f71df64","packagetype":"sdist","python_version":"source","requires_python":null,"size":18388287,"upload_time":"2023-03-15T19:56:51","upload_time_iso_8601":"2023-03-15T19:56:51.713900Z","url":"https://files.pythonhosted.org/packages/9c/27/8f6b38730e86c726001d979d05d7be46775f68aec9c048de4df03b90fcb4/equiformer-pytorch-0.0.36.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.9":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.0.9/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.0.9","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"f0b0ca8a53161da3912de8fc9ad70706008d091cd9ab85b4259280ea08f09eec","md5":"841ec18c9f1d73b3ad4193c834026947","sha256":"f4e4b1215094655f751fcb70da177dbb0744bffa0778561b6ed528c39677b3d2"},"downloads":-1,"filename":"equiformer-pytorch-0.0.9.tar.gz","has_sig":false,"md5_digest":"841ec18c9f1d73b3ad4193c834026947","packagetype":"sdist","python_version":"source","requires_python":null,"size":17540,"upload_time":"2022-11-25T22:54:21","upload_time_iso_8601":"2022-11-25T22:54:21.848084Z","url":"https://files.pythonhosted.org/packages/f0/b0/ca8a53161da3912de8fc9ad70706008d091cd9ab85b4259280ea08f09eec/equiformer-pytorch-0.0.9.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.0":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.1.0/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.1.0","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"9bd4f45ed1fa01448c0e7b5e825bffa57c94c44abe48adefed6e53d65fbf45b3","md5":"2290dfeff97f5f0dc82593873f55a37e","sha256":"18a006a009549d8bf665424c27ea07555bdabeb6d6dce69f73f53795a29ffd5b"},"downloads":-1,"filename":"equiformer-pytorch-0.1.0.tar.gz","has_sig":false,"md5_digest":"2290dfeff97f5f0dc82593873f55a37e","packagetype":"sdist","python_version":"source","requires_python":null,"size":18388338,"upload_time":"2023-03-15T20:23:17","upload_time_iso_8601":"2023-03-15T20:23:17.502659Z","url":"https://files.pythonhosted.org/packages/9b/d4/f45ed1fa01448c0e7b5e825bffa57c94c44abe48adefed6e53d65fbf45b3/equiformer-pytorch-0.1.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.1":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.1.1/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.1.1","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"dc8463a06069cc9b267c357e7fc6b16a8906cc54702855a5ef03d787c09af14b","md5":"c169a058d1a6b6129961a2d2cc3f514e","sha256":"51fdb594ab80f1ece8aacf18d2574d94fbfc313130455850f3c7cdf68458d4a5"},"downloads":-1,"filename":"equiformer-pytorch-0.1.1.tar.gz","has_sig":false,"md5_digest":"c169a058d1a6b6129961a2d2cc3f514e","packagetype":"sdist","python_version":"source","requires_python":null,"size":18388796,"upload_time":"2023-03-17T01:12:18","upload_time_iso_8601":"2023-03-17T01:12:18.583487Z","url":"https://files.pythonhosted.org/packages/dc/84/63a06069cc9b267c357e7fc6b16a8906cc54702855a5ef03d787c09af14b/equiformer-pytorch-0.1.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.2":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.1.2/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.1.2","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"2e3e4c7728b249515847bcb44d2161cb4a3482e0a744d51e5e1d66448a2a07bd","md5":"b8f0e3e801eacc50ed491177bfed6afb","sha256":"e364fa69f0dbc637f1396feb0b231f2dc590c17e724311eec239b131ba01c572"},"downloads":-1,"filename":"equiformer-pytorch-0.1.2.tar.gz","has_sig":false,"md5_digest":"b8f0e3e801eacc50ed491177bfed6afb","packagetype":"sdist","python_version":"source","requires_python":null,"size":18388782,"upload_time":"2023-04-08T16:39:41","upload_time_iso_8601":"2023-04-08T16:39:41.086609Z","url":"https://files.pythonhosted.org/packages/2e/3e/4c7728b249515847bcb44d2161cb4a3482e0a744d51e5e1d66448a2a07bd/equiformer-pytorch-0.1.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.0":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.2.0/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.2.0","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"1922a372465c5e8a5b584c59946aae0f5e0f8ef0f4482b958765be91f919387f","md5":"b61e1d5e28c5479533698914fbaee388","sha256":"ca1082d65c384626ddf233eb2fe50790dd475a36ac821976445ec8a929a077dc"},"downloads":-1,"filename":"equiformer-pytorch-0.2.0.tar.gz","has_sig":false,"md5_digest":"b61e1d5e28c5479533698914fbaee388","packagetype":"sdist","python_version":"source","requires_python":null,"size":18389442,"upload_time":"2023-07-10T17:15:48","upload_time_iso_8601":"2023-07-10T17:15:48.188302Z","url":"https://files.pythonhosted.org/packages/19/22/a372465c5e8a5b584c59946aae0f5e0f8ef0f4482b958765be91f919387f/equiformer-pytorch-0.2.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.1":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.2.1/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.2.1","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"d026aa8bdb1dc478965de4e8f61ec79e24c6211035ce7cb36685b726e1f959de","md5":"2e0f4caccd2ba4dfcc56ee03854c8d39","sha256":"0c474bbbad63de602180e0b3fa49bf8490fc272e55bb5e8884ba79591eec3df0"},"downloads":-1,"filename":"equiformer-pytorch-0.2.1.tar.gz","has_sig":false,"md5_digest":"2e0f4caccd2ba4dfcc56ee03854c8d39","packagetype":"sdist","python_version":"source","requires_python":null,"size":18387787,"upload_time":"2023-07-10T17:22:28","upload_time_iso_8601":"2023-07-10T17:22:28.643530Z","url":"https://files.pythonhosted.org/packages/d0/26/aa8bdb1dc478965de4e8f61ec79e24c6211035ce7cb36685b726e1f959de/equiformer-pytorch-0.2.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.10":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.2.10/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.2.10","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"eedb1122fe3cb864d5bd0bbd3877141558481afd0cdeaa6e99334674f577912c","md5":"3c1b5fc7c47adeb6afe6917b31112128","sha256":"1fa484f6e841ac471dd8376211b324db609df31ffcc751e0c198b14d0ae57069"},"downloads":-1,"filename":"equiformer-pytorch-0.2.10.tar.gz","has_sig":false,"md5_digest":"3c1b5fc7c47adeb6afe6917b31112128","packagetype":"sdist","python_version":"source","requires_python":null,"size":9209432,"upload_time":"2023-07-11T19:53:40","upload_time_iso_8601":"2023-07-11T19:53:40.800332Z","url":"https://files.pythonhosted.org/packages/ee/db/1122fe3cb864d5bd0bbd3877141558481afd0cdeaa6e99334674f577912c/equiformer-pytorch-0.2.10.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.11":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.2.11/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.2.11","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"823a2a1d9284756b695f55a4cd65840ea3902de9551e8eacc7c67c7ba438b034","md5":"8a728da275fcb0c685c5fb66b964c9b2","sha256":"06c0e464cfc61cecddd24b563978d3cb9e050968ce9f5d87e53f0193b55d273f"},"downloads":-1,"filename":"equiformer-pytorch-0.2.11.tar.gz","has_sig":false,"md5_digest":"8a728da275fcb0c685c5fb66b964c9b2","packagetype":"sdist","python_version":"source","requires_python":null,"size":9209317,"upload_time":"2023-07-11T22:25:42","upload_time_iso_8601":"2023-07-11T22:25:42.885480Z","url":"https://files.pythonhosted.org/packages/82/3a/2a1d9284756b695f55a4cd65840ea3902de9551e8eacc7c67c7ba438b034/equiformer-pytorch-0.2.11.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.2":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.2.2/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.2.2","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"cbb152ffc32a2d5fe047ea21ce6b1a81c6a8c44f1758dcfd5b68e60baa7575aa","md5":"1520aa0712cd0193b327af8ec5b91821","sha256":"e14b3b2f5fb849237fc9d9192664211fbe9a8276797bb77713b511f241b72fae"},"downloads":-1,"filename":"equiformer-pytorch-0.2.2.tar.gz","has_sig":false,"md5_digest":"1520aa0712cd0193b327af8ec5b91821","packagetype":"sdist","python_version":"source","requires_python":null,"size":18387762,"upload_time":"2023-07-10T17:28:03","upload_time_iso_8601":"2023-07-10T17:28:03.129652Z","url":"https://files.pythonhosted.org/packages/cb/b1/52ffc32a2d5fe047ea21ce6b1a81c6a8c44f1758dcfd5b68e60baa7575aa/equiformer-pytorch-0.2.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.3":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.2.3/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.2.3","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"7093bf91b1467b8dac6ef8d04579d4a9a9f8252643ed9f2a26a910e1d7c47871","md5":"5672c2a7f7917fbd9e293df613ae7c29","sha256":"6d675dd7cccf9b60bfb07fb5a9ae060157baf75738f36c81027060140252640f"},"downloads":-1,"filename":"equiformer-pytorch-0.2.3.tar.gz","has_sig":false,"md5_digest":"5672c2a7f7917fbd9e293df613ae7c29","packagetype":"sdist","python_version":"source","requires_python":null,"size":18387371,"upload_time":"2023-07-10T21:01:53","upload_time_iso_8601":"2023-07-10T21:01:53.186382Z","url":"https://files.pythonhosted.org/packages/70/93/bf91b1467b8dac6ef8d04579d4a9a9f8252643ed9f2a26a910e1d7c47871/equiformer-pytorch-0.2.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.4":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.2.4/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.2.4","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"36a304ff5b127886b9dafd698bd8300e10462481b5c20f2a296a85a5d2e72309","md5":"f1498361df57dc7971275ae073959c7a","sha256":"187c6806342644069dd6dd200cc500ecb0f3aff1f30066e61d94ac35f77eaaa8"},"downloads":-1,"filename":"equiformer-pytorch-0.2.4.tar.gz","has_sig":false,"md5_digest":"f1498361df57dc7971275ae073959c7a","packagetype":"sdist","python_version":"source","requires_python":null,"size":18387662,"upload_time":"2023-07-10T23:04:24","upload_time_iso_8601":"2023-07-10T23:04:24.452870Z","url":"https://files.pythonhosted.org/packages/36/a3/04ff5b127886b9dafd698bd8300e10462481b5c20f2a296a85a5d2e72309/equiformer-pytorch-0.2.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.5":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.2.5/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.2.5","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"36f3d7f542d3e12ed75aef53dd08dc1c98c0f9633fc0a7fe574c67404ae2a207","md5":"b9a36bc0ba3249ba09f963deb66c2bd0","sha256":"9f1df56af7a60919f63ad0a3ba5673d6761aa3f273eb1a7df13d2b8f843332d5"},"downloads":-1,"filename":"equiformer-pytorch-0.2.5.tar.gz","has_sig":false,"md5_digest":"b9a36bc0ba3249ba09f963deb66c2bd0","packagetype":"sdist","python_version":"source","requires_python":null,"size":18387820,"upload_time":"2023-07-11T14:14:33","upload_time_iso_8601":"2023-07-11T14:14:33.018005Z","url":"https://files.pythonhosted.org/packages/36/f3/d7f542d3e12ed75aef53dd08dc1c98c0f9633fc0a7fe574c67404ae2a207/equiformer-pytorch-0.2.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.6":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.2.6/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.2.6","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"4fa01adf3519ce3cd7efcf7d076589f72fadb7a4c7992cc95568e0371edd7e96","md5":"3ed4600b050166a8aa88361a7a51d0d4","sha256":"df7e56ebd2b98cc5092cb9313fb5606833ec454c1b73713aa57e17e385c17a2f"},"downloads":-1,"filename":"equiformer-pytorch-0.2.6.tar.gz","has_sig":false,"md5_digest":"3ed4600b050166a8aa88361a7a51d0d4","packagetype":"sdist","python_version":"source","requires_python":null,"size":18388168,"upload_time":"2023-07-11T16:03:51","upload_time_iso_8601":"2023-07-11T16:03:51.863150Z","url":"https://files.pythonhosted.org/packages/4f/a0/1adf3519ce3cd7efcf7d076589f72fadb7a4c7992cc95568e0371edd7e96/equiformer-pytorch-0.2.6.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.7":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.2.7/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.2.7","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"7e01abdfcd9da97ccf6122eeb58498117e7710831f615435bc93b038235d690c","md5":"01829fd441d1bc5e69330d4752942e61","sha256":"6a9e287083b889f1d8a2536ceb54122238be010ae9d23b3eff9fb7dc0edbb8db"},"downloads":-1,"filename":"equiformer-pytorch-0.2.7.tar.gz","has_sig":false,"md5_digest":"01829fd441d1bc5e69330d4752942e61","packagetype":"sdist","python_version":"source","requires_python":null,"size":18388342,"upload_time":"2023-07-11T16:27:08","upload_time_iso_8601":"2023-07-11T16:27:08.348108Z","url":"https://files.pythonhosted.org/packages/7e/01/abdfcd9da97ccf6122eeb58498117e7710831f615435bc93b038235d690c/equiformer-pytorch-0.2.7.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.8":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.2.8/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.2.8","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"3a299cccd7c478aec6f613208073d0ed481b7a81e510138c56716bb7ff7e8974","md5":"68aa671d9f9b6e9beb01f925f74c04a5","sha256":"147d2ea6b9bdb102f440dcf6292cc1c1884c7474419cc7b32e0a41ee61b3933a"},"downloads":-1,"filename":"equiformer-pytorch-0.2.8.tar.gz","has_sig":false,"md5_digest":"68aa671d9f9b6e9beb01f925f74c04a5","packagetype":"sdist","python_version":"source","requires_python":null,"size":18388366,"upload_time":"2023-07-11T16:44:30","upload_time_iso_8601":"2023-07-11T16:44:30.800641Z","url":"https://files.pythonhosted.org/packages/3a/29/9cccd7c478aec6f613208073d0ed481b7a81e510138c56716bb7ff7e8974/equiformer-pytorch-0.2.8.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.9":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.2.9/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.2.9","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"f02a8d72cf92a297ceb34d8e705f29b19967fb7d493c64203e270203099f50b4","md5":"086898c34e7bbf0ac7873477d8d4dfd5","sha256":"488d05087a59222b0b3e0f2ccc37686773236449f105775ca750462e173030c8"},"downloads":-1,"filename":"equiformer-pytorch-0.2.9.tar.gz","has_sig":false,"md5_digest":"086898c34e7bbf0ac7873477d8d4dfd5","packagetype":"sdist","python_version":"source","requires_python":null,"size":18388299,"upload_time":"2023-07-11T17:40:37","upload_time_iso_8601":"2023-07-11T17:40:37.039509Z","url":"https://files.pythonhosted.org/packages/f0/2a/8d72cf92a297ceb34d8e705f29b19967fb7d493c64203e270203099f50b4/equiformer-pytorch-0.2.9.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.0":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.3.0/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.3.0","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"7a6ece9dd93cf244fbd2018b449fa8c095fd410f3f9334578c8a31c836cd1e6a","md5":"8adf6a633ab07be93273554415b16621","sha256":"3f4b36f2a7ef079a1ce9028d1da5ee969dbd0836513ee1620203f93a3d84044d"},"downloads":-1,"filename":"equiformer-pytorch-0.3.0.tar.gz","has_sig":false,"md5_digest":"8adf6a633ab07be93273554415b16621","packagetype":"sdist","python_version":"source","requires_python":null,"size":9211421,"upload_time":"2023-07-12T17:43:06","upload_time_iso_8601":"2023-07-12T17:43:06.152828Z","url":"https://files.pythonhosted.org/packages/7a/6e/ce9dd93cf244fbd2018b449fa8c095fd410f3f9334578c8a31c836cd1e6a/equiformer-pytorch-0.3.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.1":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.3.1/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.3.1","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"84eb8ac37fbe45b123394b603d3c68e517d4598de5c6adce641f17ca072a07c4","md5":"0eddd8ed101fdce6c878a89a7a3da120","sha256":"db5289a1b2e4c8676f52c544c38a0cfac7a31f447f82ef35efa04a8f02499b5a"},"downloads":-1,"filename":"equiformer-pytorch-0.3.1.tar.gz","has_sig":false,"md5_digest":"0eddd8ed101fdce6c878a89a7a3da120","packagetype":"sdist","python_version":"source","requires_python":null,"size":9211516,"upload_time":"2023-07-12T18:17:30","upload_time_iso_8601":"2023-07-12T18:17:30.594642Z","url":"https://files.pythonhosted.org/packages/84/eb/8ac37fbe45b123394b603d3c68e517d4598de5c6adce641f17ca072a07c4/equiformer-pytorch-0.3.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.10":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.3.10/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.3.10","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"0048950ad007c317900529d27bdad0b68837fc725eccded5fe9a62bda2014e3d","md5":"14a76efbe904f36b3d3e402074c44e6f","sha256":"953e815de7bf64aa7baec927e4f4955702f4b78239c2073bd30768b6d98846c2"},"downloads":-1,"filename":"equiformer-pytorch-0.3.10.tar.gz","has_sig":false,"md5_digest":"14a76efbe904f36b3d3e402074c44e6f","packagetype":"sdist","python_version":"source","requires_python":null,"size":9212915,"upload_time":"2023-09-08T08:55:38","upload_time_iso_8601":"2023-09-08T08:55:38.074056Z","url":"https://files.pythonhosted.org/packages/00/48/950ad007c317900529d27bdad0b68837fc725eccded5fe9a62bda2014e3d/equiformer-pytorch-0.3.10.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.2":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.3.2/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.3.2","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"fea42317b588a7eff3bf726ef68cdb01ee442fec69f0b8525576ab8641c58fc5","md5":"0a5bb0fd9fa86d27f7c1f4c2e09c8359","sha256":"abe46e5d545c6dcde56ca6dccbd33c13d5e5dc6897f1bda92eb82b89bd77845c"},"downloads":-1,"filename":"equiformer-pytorch-0.3.2.tar.gz","has_sig":false,"md5_digest":"0a5bb0fd9fa86d27f7c1f4c2e09c8359","packagetype":"sdist","python_version":"source","requires_python":null,"size":9211496,"upload_time":"2023-07-22T00:15:52","upload_time_iso_8601":"2023-07-22T00:15:52.270822Z","url":"https://files.pythonhosted.org/packages/fe/a4/2317b588a7eff3bf726ef68cdb01ee442fec69f0b8525576ab8641c58fc5/equiformer-pytorch-0.3.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.3":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.3.3/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.3.3","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"ac5318543ea9f564e3ff79d613aed59d0298eea2fe4dcaaafb1bd107cef03bb7","md5":"579fc9ff8c38e503f0ba9cb787c23900","sha256":"f15de2d40417267a8310323a98cbdb7a6e2c656dfdc04749ed2ae5cc716fe4eb"},"downloads":-1,"filename":"equiformer-pytorch-0.3.3.tar.gz","has_sig":false,"md5_digest":"579fc9ff8c38e503f0ba9cb787c23900","packagetype":"sdist","python_version":"source","requires_python":null,"size":9212730,"upload_time":"2023-08-22T15:34:47","upload_time_iso_8601":"2023-08-22T15:34:47.055294Z","url":"https://files.pythonhosted.org/packages/ac/53/18543ea9f564e3ff79d613aed59d0298eea2fe4dcaaafb1bd107cef03bb7/equiformer-pytorch-0.3.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.4":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.3.4/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.3.4","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"cfbe384a860daa114a1787e99a99df167f806b59e572ce1270c1597c210367ce","md5":"674b8b2a7a8169f32c308028fa9bd806","sha256":"ee06e7b9b45affe547d27164949e894721eec874278b79d89f7aad8cb82bd4dd"},"downloads":-1,"filename":"equiformer-pytorch-0.3.4.tar.gz","has_sig":false,"md5_digest":"674b8b2a7a8169f32c308028fa9bd806","packagetype":"sdist","python_version":"source","requires_python":null,"size":9212723,"upload_time":"2023-08-22T16:13:11","upload_time_iso_8601":"2023-08-22T16:13:11.384936Z","url":"https://files.pythonhosted.org/packages/cf/be/384a860daa114a1787e99a99df167f806b59e572ce1270c1597c210367ce/equiformer-pytorch-0.3.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.5":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.3.5/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.3.5","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"a18e0fbfcf0028313e781b3b41aae710c3eddd25aad543e8d4b319752154ffc5","md5":"ffbcbbf3382e4c0f69b78b2be66d527e","sha256":"204f2feda644c4919b9d44d4b5e3970de325498c9928bcb82d16026473272650"},"downloads":-1,"filename":"equiformer-pytorch-0.3.5.tar.gz","has_sig":false,"md5_digest":"ffbcbbf3382e4c0f69b78b2be66d527e","packagetype":"sdist","python_version":"source","requires_python":null,"size":9212774,"upload_time":"2023-08-23T14:18:57","upload_time_iso_8601":"2023-08-23T14:18:57.431857Z","url":"https://files.pythonhosted.org/packages/a1/8e/0fbfcf0028313e781b3b41aae710c3eddd25aad543e8d4b319752154ffc5/equiformer-pytorch-0.3.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.6":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.3.6/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.3.6","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"4f2e78bfc57afe6d981e166f3267499134c889ba0e8b720bd17ee6b18d73cc5f","md5":"083f62d899fb7a5fe7154aecf13f7ef5","sha256":"52530069297692e89fb2ebfa2cf19fa72b3a80d750da64fb36e740925fd8c3b8"},"downloads":-1,"filename":"equiformer-pytorch-0.3.6.tar.gz","has_sig":false,"md5_digest":"083f62d899fb7a5fe7154aecf13f7ef5","packagetype":"sdist","python_version":"source","requires_python":null,"size":9212902,"upload_time":"2023-08-23T14:55:35","upload_time_iso_8601":"2023-08-23T14:55:35.236527Z","url":"https://files.pythonhosted.org/packages/4f/2e/78bfc57afe6d981e166f3267499134c889ba0e8b720bd17ee6b18d73cc5f/equiformer-pytorch-0.3.6.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.7":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.3.7/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.3.7","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"922479356e48e69fe260b51318a1d04fad7673f5513b065dda46c2066740d92e","md5":"8f62744cd8d7a3b4b3b5dc68ccf9e14f","sha256":"18e1bf3515d86c3f2e3e77478be16e986c8ddd544398b330793a66af42d1ea8e"},"downloads":-1,"filename":"equiformer-pytorch-0.3.7.tar.gz","has_sig":false,"md5_digest":"8f62744cd8d7a3b4b3b5dc68ccf9e14f","packagetype":"sdist","python_version":"source","requires_python":null,"size":9212887,"upload_time":"2023-08-27T18:37:40","upload_time_iso_8601":"2023-08-27T18:37:40.003474Z","url":"https://files.pythonhosted.org/packages/92/24/79356e48e69fe260b51318a1d04fad7673f5513b065dda46c2066740d92e/equiformer-pytorch-0.3.7.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.8":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.3.8/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.3.8","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"6b3ee70d73b2c1a55d4afd5dcfcdb02c5d65317452f0323fcfe28b3147ba9263","md5":"9ff21e020f092fe71ceda230122947ed","sha256":"788043d48e23e9c7c985031fd9ae503601ea12138a998cd019ac076423bb4eee"},"downloads":-1,"filename":"equiformer-pytorch-0.3.8.tar.gz","has_sig":false,"md5_digest":"9ff21e020f092fe71ceda230122947ed","packagetype":"sdist","python_version":"source","requires_python":null,"size":9212920,"upload_time":"2023-08-27T18:55:34","upload_time_iso_8601":"2023-08-27T18:55:34.539146Z","url":"https://files.pythonhosted.org/packages/6b/3e/e70d73b2c1a55d4afd5dcfcdb02c5d65317452f0323fcfe28b3147ba9263/equiformer-pytorch-0.3.8.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.9":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.3.9/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.3.9","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"93d02240a00563a3b556f4de79d772882e6e6c6e107ef71e1a57040148fedd22","md5":"4f0d448301ef4f5453d0818fb8bff355","sha256":"acd2d81bdd53da5add45177e9f9d10a24a9d0c754f3f13d86c2b98d126aa6b01"},"downloads":-1,"filename":"equiformer-pytorch-0.3.9.tar.gz","has_sig":false,"md5_digest":"4f0d448301ef4f5453d0818fb8bff355","packagetype":"sdist","python_version":"source","requires_python":null,"size":9212910,"upload_time":"2023-08-27T18:56:34","upload_time_iso_8601":"2023-08-27T18:56:34.676776Z","url":"https://files.pythonhosted.org/packages/93/d0/2240a00563a3b556f4de79d772882e6e6c6e107ef71e1a57040148fedd22/equiformer-pytorch-0.3.9.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.0":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.4.0/","requires_dist":null,"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.4.0","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"b3bde65c77928dc3df97f2727c86eafa0573329cc9a9aebc16de9b8a15635737","md5":"5ef38a798819395b5d8eccc68aba0929","sha256":"52b06effe0c621b032991a2eaff8cb5116049dd5ab035ba33b7d7ead3d458f6f"},"downloads":-1,"filename":"equiformer-pytorch-0.4.0.tar.gz","has_sig":false,"md5_digest":"5ef38a798819395b5d8eccc68aba0929","packagetype":"sdist","python_version":"source","requires_python":null,"size":9213342,"upload_time":"2023-10-18T15:37:12","upload_time_iso_8601":"2023-10-18T15:37:12.629415Z","url":"https://files.pythonhosted.org/packages/b3/bd/e65c77928dc3df97f2727c86eafa0573329cc9a9aebc16de9b8a15635737/equiformer-pytorch-0.4.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.1":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.5.1/","requires_dist":["beartype","einops>=0.6","filelock","opt-einsum","taylor-series-linear-attention>=0.1.4","torch>=1.6"],"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.5.1","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"8ea3f9c3392d0c37ea8186cee402313aa00e2a32d185836d61ba652df8880a27","md5":"5cff547dd5d6e4c5ca134e241242ca10","sha256":"4aad861b9c84093c08260add32b50d259dfba56b4aa030c268d2d4bd1eabaf4a"},"downloads":-1,"filename":"equiformer-pytorch-0.5.1.tar.gz","has_sig":false,"md5_digest":"5cff547dd5d6e4c5ca134e241242ca10","packagetype":"sdist","python_version":"source","requires_python":null,"size":9214617,"upload_time":"2024-01-15T15:39:15","upload_time_iso_8601":"2024-01-15T15:39:15.925727Z","url":"https://files.pythonhosted.org/packages/8e/a3/f9c3392d0c37ea8186cee402313aa00e2a32d185836d61ba652df8880a27/equiformer-pytorch-0.5.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.2":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.5.2/","requires_dist":["beartype","einops>=0.6","einx","filelock","opt-einsum","taylor-series-linear-attention>=0.1.4","torch>=1.6"],"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.5.2","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"157967e7ffc935c61a7d522353929c871c444b5d9025c9e4d8058b1ba304dd1f","md5":"0a58df162666c78223d76dc5a29a58bc","sha256":"79662e922ff32372cb03a134946ae9b49a6f042f7fa18860f020be66ee6293e7"},"downloads":-1,"filename":"equiformer-pytorch-0.5.2.tar.gz","has_sig":false,"md5_digest":"0a58df162666c78223d76dc5a29a58bc","packagetype":"sdist","python_version":"source","requires_python":null,"size":9214495,"upload_time":"2024-01-17T18:57:40","upload_time_iso_8601":"2024-01-17T18:57:40.306039Z","url":"https://files.pythonhosted.org/packages/15/79/67e7ffc935c61a7d522353929c871c444b5d9025c9e4d8058b1ba304dd1f/equiformer-pytorch-0.5.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.3":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/equiformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,equivariance,molecules,proteins","license":"MIT","maintainer":"","maintainer_email":"","name":"equiformer-pytorch","package_url":"https://pypi.org/project/equiformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/equiformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/equiformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/equiformer-pytorch/0.5.3/","requires_dist":["beartype","einops>=0.6","einx","filelock","opt-einsum","taylor-series-linear-attention>=0.1.4","torch>=1.6"],"requires_python":"","summary":"Equiformer - SE3/E3 Graph Attention Transformer for Molecules and Proteins","version":"0.5.3","yanked":false,"yanked_reason":null},"last_serial":21504285,"urls":[{"comment_text":"","digests":{"blake2b_256":"19abd0330af3397a24f3678a8ab44b781eb6375bf812c6f66d1d93ed19b9d341","md5":"6603e386bf93e49510a0e8c1db21112a","sha256":"2b724b05dd7c414ac3fb5dcbab51c281aa79299a577f1a50090e305527442c63"},"downloads":-1,"filename":"equiformer-pytorch-0.5.3.tar.gz","has_sig":false,"md5_digest":"6603e386bf93e49510a0e8c1db21112a","packagetype":"sdist","python_version":"source","requires_python":null,"size":9214506,"upload_time":"2024-01-20T01:07:13","upload_time_iso_8601":"2024-01-20T01:07:13.029627Z","url":"https://files.pythonhosted.org/packages/19/ab/d0330af3397a24f3678a8ab44b781eb6375bf812c6f66d1d93ed19b9d341/equiformer-pytorch-0.5.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}