{"1.6.0.0":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer-icx","package_url":"https://pypi.org/project/xfastertransformer-icx/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer-icx/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer-icx/1.6.0.0/","requires_dist":["torch<2.1.0,>=2.0.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.6.0.0","yanked":false,"yanked_reason":null},"last_serial":25409940,"urls":[{"comment_text":"","digests":{"blake2b_256":"8f2a200d80a5ad2781789269e86adb39a576a4373db6e7518220e4941be4f8a0","md5":"6f32228a725739cd2a663d2e5d4c65d1","sha256":"f676ee6e8aeb93356bccc2bb25e4a306075e283268d217811d20003329817e19"},"downloads":-1,"filename":"xfastertransformer_icx-1.6.0.0-py3-none-any.whl","has_sig":false,"md5_digest":"6f32228a725739cd2a663d2e5d4c65d1","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":22266649,"upload_time":"2024-05-16T07:21:07","upload_time_iso_8601":"2024-05-16T07:21:07.562630Z","url":"https://files.pythonhosted.org/packages/8f/2a/200d80a5ad2781789269e86adb39a576a4373db6e7518220e4941be4f8a0/xfastertransformer_icx-1.6.0.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.7.0":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer-icx","package_url":"https://pypi.org/project/xfastertransformer-icx/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer-icx/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer-icx/1.7.0/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.7.0","yanked":false,"yanked_reason":null},"last_serial":25409940,"urls":[{"comment_text":"","digests":{"blake2b_256":"2eaf1501017536aa5f4ad2cda38eaa723c099deb7066943a8df67b04aef6dffb","md5":"9d7b968b3405cad024b97154c85b2c9f","sha256":"414316a63039b077d783ad4fbff8b69caf452368926f3a225fdf663db621a266"},"downloads":-1,"filename":"xfastertransformer_icx-1.7.0-py3-none-any.whl","has_sig":false,"md5_digest":"9d7b968b3405cad024b97154c85b2c9f","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":23131394,"upload_time":"2024-06-05T05:47:58","upload_time_iso_8601":"2024-06-05T05:47:58.995354Z","url":"https://files.pythonhosted.org/packages/2e/af/1501017536aa5f4ad2cda38eaa723c099deb7066943a8df67b04aef6dffb/xfastertransformer_icx-1.7.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.7.1":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer-icx","package_url":"https://pypi.org/project/xfastertransformer-icx/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer-icx/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer-icx/1.7.1/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.7.1","yanked":false,"yanked_reason":null},"last_serial":25409940,"urls":[{"comment_text":"","digests":{"blake2b_256":"2a9b9c0cf37a7fb9af184d6d67fb98ec9bceb3d39e396512aad7351aed816c78","md5":"a360990558269d45d17207fdfd482b8b","sha256":"e5f399a23cdfd5326ff24f59874eca0110825c6e0b76b24a43950312d41a92ef"},"downloads":-1,"filename":"xfastertransformer_icx-1.7.1-py3-none-any.whl","has_sig":false,"md5_digest":"a360990558269d45d17207fdfd482b8b","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":23141799,"upload_time":"2024-06-12T05:48:01","upload_time_iso_8601":"2024-06-12T05:48:01.632568Z","url":"https://files.pythonhosted.org/packages/2a/9b/9c0cf37a7fb9af184d6d67fb98ec9bceb3d39e396512aad7351aed816c78/xfastertransformer_icx-1.7.1-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.7.2":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer-icx","package_url":"https://pypi.org/project/xfastertransformer-icx/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer-icx/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer-icx/1.7.2/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.7.2","yanked":false,"yanked_reason":null},"last_serial":25409940,"urls":[{"comment_text":"","digests":{"blake2b_256":"cf05ac800e49e05235ecb778d39a622c4b3bfb3ce28384505fa594c8a5d6b5a8","md5":"94227bd4100e95e273bdd723aa90037e","sha256":"60e6fbebf1dbbe4df9290302fe38b238a079f2c198304ab6dd131674b19df363"},"downloads":-1,"filename":"xfastertransformer_icx-1.7.2-py3-none-any.whl","has_sig":false,"md5_digest":"94227bd4100e95e273bdd723aa90037e","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":23301296,"upload_time":"2024-06-18T05:08:19","upload_time_iso_8601":"2024-06-18T05:08:19.691902Z","url":"https://files.pythonhosted.org/packages/cf/05/ac800e49e05235ecb778d39a622c4b3bfb3ce28384505fa594c8a5d6b5a8/xfastertransformer_icx-1.7.2-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.7.3":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer-icx","package_url":"https://pypi.org/project/xfastertransformer-icx/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer-icx/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer-icx/1.7.3/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.7.3","yanked":false,"yanked_reason":null},"last_serial":25409940,"urls":[{"comment_text":"","digests":{"blake2b_256":"3d10ef35e30738c5b84af5dac0041ac578f1c71aa582c6d6498b1dc9aa6c04ca","md5":"c1ed474f81907a21acbf2e95e0c07cf5","sha256":"e5284f5807fa7b5c4cf761b42b4d67f250fafbe1b2fff0c2de5726f66757da07"},"downloads":-1,"filename":"xfastertransformer_icx-1.7.3-py3-none-any.whl","has_sig":false,"md5_digest":"c1ed474f81907a21acbf2e95e0c07cf5","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":23303817,"upload_time":"2024-06-27T01:10:44","upload_time_iso_8601":"2024-06-27T01:10:44.200621Z","url":"https://files.pythonhosted.org/packages/3d/10/ef35e30738c5b84af5dac0041ac578f1c71aa582c6d6498b1dc9aa6c04ca/xfastertransformer_icx-1.7.3-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.8.0":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer-icx","package_url":"https://pypi.org/project/xfastertransformer-icx/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer-icx/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer-icx/1.8.0/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.8.0","yanked":false,"yanked_reason":null},"last_serial":25409940,"urls":[{"comment_text":"","digests":{"blake2b_256":"96917ca8c6d52bca3c4c50d0fff85f8f1c9f37084116f61ccce1173222724c51","md5":"39915d3badf32ede3d3fa6fd20ef29f3","sha256":"b2423e288f3f82a673a683b24b3592081491329b6943e79b27fdd55556cc3cee"},"downloads":-1,"filename":"xfastertransformer_icx-1.8.0-py3-none-any.whl","has_sig":false,"md5_digest":"39915d3badf32ede3d3fa6fd20ef29f3","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":26690528,"upload_time":"2024-07-23T01:49:32","upload_time_iso_8601":"2024-07-23T01:49:32.709135Z","url":"https://files.pythonhosted.org/packages/96/91/7ca8c6d52bca3c4c50d0fff85f8f1c9f37084116f61ccce1173222724c51/xfastertransformer_icx-1.8.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.8.1":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer-icx","package_url":"https://pypi.org/project/xfastertransformer-icx/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer-icx/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer-icx/1.8.1/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.8.1","yanked":false,"yanked_reason":null},"last_serial":25409940,"urls":[{"comment_text":"","digests":{"blake2b_256":"c0474a685a1e71bda04c8b382d90afba08827a8c809d91d710bdb7a2172d2672","md5":"10889ba3e09e1d2a1444f8b8ba2c6564","sha256":"bb534dad5fc976c26306a98b8ff21019ceb389129abd0a36599c357a805cf452"},"downloads":-1,"filename":"xfastertransformer_icx-1.8.1-py3-none-any.whl","has_sig":false,"md5_digest":"10889ba3e09e1d2a1444f8b8ba2c6564","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":26680613,"upload_time":"2024-07-31T08:35:34","upload_time_iso_8601":"2024-07-31T08:35:34.882889Z","url":"https://files.pythonhosted.org/packages/c0/47/4a685a1e71bda04c8b382d90afba08827a8c809d91d710bdb7a2172d2672/xfastertransformer_icx-1.8.1-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.8.2":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer-icx","package_url":"https://pypi.org/project/xfastertransformer-icx/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer-icx/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer-icx/1.8.2/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.8.2","yanked":false,"yanked_reason":null},"last_serial":25409940,"urls":[{"comment_text":"","digests":{"blake2b_256":"2e03ac8dd5a245396c360a8bf65057b223214913923118e165b5af03c45b3abf","md5":"8d129328cb11cb846d1635f9affdcb88","sha256":"8a434df47976c51764ed7a4f4df046a940d5a9d721b507a55ad8be27be3cc2b7"},"downloads":-1,"filename":"xfastertransformer_icx-1.8.2-py3-none-any.whl","has_sig":false,"md5_digest":"8d129328cb11cb846d1635f9affdcb88","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":27878425,"upload_time":"2024-10-10T07:45:32","upload_time_iso_8601":"2024-10-10T07:45:32.658158Z","url":"https://files.pythonhosted.org/packages/2e/03/ac8dd5a245396c360a8bf65057b223214913923118e165b5af03c45b3abf/xfastertransformer_icx-1.8.2-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}