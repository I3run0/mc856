{"0.0.0.dev0":{"info":{"author":"IntelAI","author_email":"IntelAI@intel.com","bugtrack_url":null,"classifiers":["Development Status :: 3 - Alpha","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.5","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Text Processing :: Linguistic"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"http://github.com/ashahba/hello-world-pypi","keywords":"simplest hello world pypi package","license":"MIT","maintainer":"","maintainer_email":"","name":"xfastertransformer","package_url":"https://pypi.org/project/xfastertransformer/","platform":null,"project_url":"https://pypi.org/project/xfastertransformer/","project_urls":{"Homepage":"http://github.com/ashahba/hello-world-pypi"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer/0.0.0.dev0/","requires_dist":null,"requires_python":"","summary":"The simplest Hello World PyPi package","version":"0.0.0.dev0","yanked":true,"yanked_reason":"This was just a test upload to create the project"},"last_serial":25409938,"urls":[{"comment_text":"","digests":{"blake2b_256":"e9a1e6bc2861a31e25e213a67e6949b6fe9109c1655f70befb4fc131876723c6","md5":"7ef6565c847f6972a20a5cb855fc2d06","sha256":"6d3c50763adffd1afb87bcb1ec78b154b50c9e5335494f4a939d1042f9850ab6"},"downloads":-1,"filename":"xfastertransformer-0.0.0.dev0-py3-none-any.whl","has_sig":false,"md5_digest":"7ef6565c847f6972a20a5cb855fc2d06","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":3533,"upload_time":"2023-10-12T00:29:20","upload_time_iso_8601":"2023-10-12T00:29:20.976281Z","url":"https://files.pythonhosted.org/packages/e9/a1/e6bc2861a31e25e213a67e6949b6fe9109c1655f70befb4fc131876723c6/xfastertransformer-0.0.0.dev0-py3-none-any.whl","yanked":true,"yanked_reason":"This was just a test upload to create the project"}],"vulnerabilities":[]},"1.0.0":{"info":{"author":"xFasterTransformer","author_email":"","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":"","maintainer_email":"","name":"xfastertransformer","package_url":"https://pypi.org/project/xfastertransformer/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer/1.0.0/","requires_dist":["torch (<2.1.0,>=2.0.0)"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.0.0","yanked":false,"yanked_reason":null},"last_serial":25409938,"urls":[{"comment_text":"","digests":{"blake2b_256":"c3f79cf07f9c60b8fbf9197f9aba12909d625db8722a6dd4565c80090b970f3c","md5":"c42b964d479ac449ad2a845f71530dd7","sha256":"3e55d1828f4262c1f5f6831330a60a0fb9a341730a440ddda0656d0a73b6e0e4"},"downloads":-1,"filename":"xfastertransformer-1.0.0-py3-none-any.whl","has_sig":false,"md5_digest":"c42b964d479ac449ad2a845f71530dd7","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":20558457,"upload_time":"2023-10-17T03:21:31","upload_time_iso_8601":"2023-10-17T03:21:31.272782Z","url":"https://files.pythonhosted.org/packages/c3/f7/9cf07f9c60b8fbf9197f9aba12909d625db8722a6dd4565c80090b970f3c/xfastertransformer-1.0.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.1.0":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":"","maintainer_email":"","name":"xfastertransformer","package_url":"https://pypi.org/project/xfastertransformer/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer/1.1.0/","requires_dist":["torch (<2.1.0,>=2.0.0)"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.1.0","yanked":false,"yanked_reason":null},"last_serial":25409938,"urls":[{"comment_text":"","digests":{"blake2b_256":"6eed69dc90e5af8d2301b14b1d71db60b793ccda3eb3bf6b23a56e39ff4865c8","md5":"01ffe1eb366db001a1dd57b2e45081d5","sha256":"d8a55071951f666451db32648150815b868c6b0bf662e808b1e0264b08c533f4"},"downloads":-1,"filename":"xfastertransformer-1.1.0-py3-none-any.whl","has_sig":false,"md5_digest":"01ffe1eb366db001a1dd57b2e45081d5","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":19218867,"upload_time":"2023-12-01T02:26:07","upload_time_iso_8601":"2023-12-01T02:26:07.736755Z","url":"https://files.pythonhosted.org/packages/6e/ed/69dc90e5af8d2301b14b1d71db60b793ccda3eb3bf6b23a56e39ff4865c8/xfastertransformer-1.1.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.2.0":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":"","maintainer_email":"","name":"xfastertransformer","package_url":"https://pypi.org/project/xfastertransformer/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer/1.2.0/","requires_dist":["torch (<2.1.0,>=2.0.0)"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.2.0","yanked":false,"yanked_reason":null},"last_serial":25409938,"urls":[{"comment_text":"","digests":{"blake2b_256":"e2e0fed340046a973fb9d588589e3f9799ebad61feb1f0ac7625bbf19b314df8","md5":"920016123cc95e7a66264bd7ab589591","sha256":"f8cd28c9e342fc2d73234d94e432a28179edca60e5a45683709587ffe5f7ee68"},"downloads":-1,"filename":"xfastertransformer-1.2.0-py3-none-any.whl","has_sig":false,"md5_digest":"920016123cc95e7a66264bd7ab589591","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":25368816,"upload_time":"2023-12-22T02:07:59","upload_time_iso_8601":"2023-12-22T02:07:59.592939Z","url":"https://files.pythonhosted.org/packages/e2/e0/fed340046a973fb9d588589e3f9799ebad61feb1f0ac7625bbf19b314df8/xfastertransformer-1.2.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.3.0":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":"","maintainer_email":"","name":"xfastertransformer","package_url":"https://pypi.org/project/xfastertransformer/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer/1.3.0/","requires_dist":["torch (<2.1.0,>=2.0.0)"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.3.0","yanked":false,"yanked_reason":null},"last_serial":25409938,"urls":[{"comment_text":"","digests":{"blake2b_256":"d3847fa26834a074444ce6747db62ff837cb37955bf3a6199732352012173b02","md5":"34aa8ffb745a3abda7c213748269c737","sha256":"6b44de530e17127b63f00adaabefc995922fb54b4f6d2ef201b1d538ed623772"},"downloads":-1,"filename":"xfastertransformer-1.3.0-py3-none-any.whl","has_sig":false,"md5_digest":"34aa8ffb745a3abda7c213748269c737","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":25626274,"upload_time":"2024-01-23T08:15:55","upload_time_iso_8601":"2024-01-23T08:15:55.250872Z","url":"https://files.pythonhosted.org/packages/d3/84/7fa26834a074444ce6747db62ff837cb37955bf3a6199732352012173b02/xfastertransformer-1.3.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.3.1":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":"","maintainer_email":"","name":"xfastertransformer","package_url":"https://pypi.org/project/xfastertransformer/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer/1.3.1/","requires_dist":["torch (<2.1.0,>=2.0.0)"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.3.1","yanked":false,"yanked_reason":null},"last_serial":25409938,"urls":[{"comment_text":"","digests":{"blake2b_256":"90f5d670ed556ac67c7be6a521c8070da01e498281985f502606babad812e083","md5":"7374f1874b6e0128a3e334cd24b9928e","sha256":"cfe6364cee0484d967a4e9c0d1874406430a0b8cbd38c203280de56171b88f2e"},"downloads":-1,"filename":"xfastertransformer-1.3.1-py3-none-any.whl","has_sig":false,"md5_digest":"7374f1874b6e0128a3e334cd24b9928e","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":25627021,"upload_time":"2024-01-24T05:31:58","upload_time_iso_8601":"2024-01-24T05:31:58.395695Z","url":"https://files.pythonhosted.org/packages/90/f5/d670ed556ac67c7be6a521c8070da01e498281985f502606babad812e083/xfastertransformer-1.3.1-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.4.0":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":"","maintainer_email":"","name":"xfastertransformer","package_url":"https://pypi.org/project/xfastertransformer/","platform":null,"project_url":"https://pypi.org/project/xfastertransformer/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer/1.4.0/","requires_dist":["torch (<2.1.0,>=2.0.0)"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.4.0","yanked":false,"yanked_reason":null},"last_serial":25409938,"urls":[{"comment_text":"","digests":{"blake2b_256":"e3ba95983451ecd9e06a412cf81bc8dcf92781f1719455830594f5db74ab8763","md5":"d3b7daf0d03e4f255aee4af9dea4d297","sha256":"fb687a54a894e6b9a7d19ab06b40f915e8a3a9e4439c28ca450b9d2f84fda1be"},"downloads":-1,"filename":"xfastertransformer-1.4.0-py3-none-any.whl","has_sig":false,"md5_digest":"d3b7daf0d03e4f255aee4af9dea4d297","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":28202194,"upload_time":"2024-03-08T07:31:16","upload_time_iso_8601":"2024-03-08T07:31:16.023002Z","url":"https://files.pythonhosted.org/packages/e3/ba/95983451ecd9e06a412cf81bc8dcf92781f1719455830594f5db74ab8763/xfastertransformer-1.4.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.5.0":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer","package_url":"https://pypi.org/project/xfastertransformer/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer/1.5.0/","requires_dist":["torch<2.1.0,>=2.0.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.5.0","yanked":false,"yanked_reason":null},"last_serial":25409938,"urls":[{"comment_text":"","digests":{"blake2b_256":"16cd0bfd5706a96365534474a07cf40717fc29c06688bc8b1b933a7bc84cff62","md5":"7e86822377019b6453461dd5a0d4792b","sha256":"644f3708fffb9f22334cb1a4ec2a4be676941b7e9901bd2432652bcdf0106499"},"downloads":-1,"filename":"xfastertransformer-1.5.0-py3-none-any.whl","has_sig":false,"md5_digest":"7e86822377019b6453461dd5a0d4792b","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":30176690,"upload_time":"2024-04-15T06:56:29","upload_time_iso_8601":"2024-04-15T06:56:29.377986Z","url":"https://files.pythonhosted.org/packages/16/cd/0bfd5706a96365534474a07cf40717fc29c06688bc8b1b933a7bc84cff62/xfastertransformer-1.5.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.6.0":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer","package_url":"https://pypi.org/project/xfastertransformer/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer/1.6.0/","requires_dist":["torch<2.1.0,>=2.0.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.6.0","yanked":false,"yanked_reason":null},"last_serial":25409938,"urls":[{"comment_text":"","digests":{"blake2b_256":"86a394a8474927645cdac912ac7a5870a789c6ff5a23f9b22241e2fce7a916a0","md5":"2f2194ba4d33eeee29514e8912d668d7","sha256":"428963750fb1e0f3a515ae68b64e08c47a3e6525365074dd73ce25fe171bf4d3"},"downloads":-1,"filename":"xfastertransformer-1.6.0-py3-none-any.whl","has_sig":false,"md5_digest":"2f2194ba4d33eeee29514e8912d668d7","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":29746023,"upload_time":"2024-04-28T02:28:13","upload_time_iso_8601":"2024-04-28T02:28:13.923663Z","url":"https://files.pythonhosted.org/packages/86/a3/94a8474927645cdac912ac7a5870a789c6ff5a23f9b22241e2fce7a916a0/xfastertransformer-1.6.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.7.0":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer","package_url":"https://pypi.org/project/xfastertransformer/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer/1.7.0/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.7.0","yanked":false,"yanked_reason":null},"last_serial":25409938,"urls":[{"comment_text":"","digests":{"blake2b_256":"5dc49ec392874d815162c4e6822f1c77ac0e159a9a34c1fea9b136fc1dd0d399","md5":"cba4fe360c9cf894267ecf0e1706a02c","sha256":"59c22ef568a4e0d8784abcb1a5b0f509102e925d4821b04dd4687edc9956162e"},"downloads":-1,"filename":"xfastertransformer-1.7.0-py3-none-any.whl","has_sig":false,"md5_digest":"cba4fe360c9cf894267ecf0e1706a02c","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":30604042,"upload_time":"2024-06-05T05:20:12","upload_time_iso_8601":"2024-06-05T05:20:12.660668Z","url":"https://files.pythonhosted.org/packages/5d/c4/9ec392874d815162c4e6822f1c77ac0e159a9a34c1fea9b136fc1dd0d399/xfastertransformer-1.7.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.7.1":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer","package_url":"https://pypi.org/project/xfastertransformer/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer/1.7.1/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.7.1","yanked":false,"yanked_reason":null},"last_serial":25409938,"urls":[{"comment_text":"","digests":{"blake2b_256":"d8f388c388126e71739fabb3eea8e7b4962f25fc76015dd08961dc6c8b65ba9d","md5":"63790e7f49ceaab89e342ba79a7024ce","sha256":"d993761ff6ffc096a0658cb92ffacf410f968f4988412d799212ccc7c3155bce"},"downloads":-1,"filename":"xfastertransformer-1.7.1-py3-none-any.whl","has_sig":false,"md5_digest":"63790e7f49ceaab89e342ba79a7024ce","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":30614054,"upload_time":"2024-06-12T05:38:22","upload_time_iso_8601":"2024-06-12T05:38:22.807489Z","url":"https://files.pythonhosted.org/packages/d8/f3/88c388126e71739fabb3eea8e7b4962f25fc76015dd08961dc6c8b65ba9d/xfastertransformer-1.7.1-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.7.2":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer","package_url":"https://pypi.org/project/xfastertransformer/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer/1.7.2/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.7.2","yanked":false,"yanked_reason":null},"last_serial":25409938,"urls":[{"comment_text":"","digests":{"blake2b_256":"01bc75358f25f005414635fad8ae1b3bef81f9ff951a3d4ec52425ef2023b823","md5":"440348a0e9a5e16ce5a9114de0c9ad7e","sha256":"9d88353a529fd7b25bdb174cde6b9629f8a86c23550c47463e301280068c2b07"},"downloads":-1,"filename":"xfastertransformer-1.7.2-py3-none-any.whl","has_sig":false,"md5_digest":"440348a0e9a5e16ce5a9114de0c9ad7e","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":30786799,"upload_time":"2024-06-18T05:08:43","upload_time_iso_8601":"2024-06-18T05:08:43.109966Z","url":"https://files.pythonhosted.org/packages/01/bc/75358f25f005414635fad8ae1b3bef81f9ff951a3d4ec52425ef2023b823/xfastertransformer-1.7.2-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.7.3":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer","package_url":"https://pypi.org/project/xfastertransformer/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer/1.7.3/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.7.3","yanked":false,"yanked_reason":null},"last_serial":25409938,"urls":[{"comment_text":"","digests":{"blake2b_256":"69e64f1f0f0dd4153bb8fef52dc4450960f41c2de6f89a5897ab695a09bb88eb","md5":"b8441d96fab381a63f92590b6a8598b1","sha256":"43961278963ea78e5207570f17dcc959f21db9e5ee2b1f97ef76796335552319"},"downloads":-1,"filename":"xfastertransformer-1.7.3-py3-none-any.whl","has_sig":false,"md5_digest":"b8441d96fab381a63f92590b6a8598b1","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":30787054,"upload_time":"2024-06-27T01:11:12","upload_time_iso_8601":"2024-06-27T01:11:12.562640Z","url":"https://files.pythonhosted.org/packages/69/e6/4f1f0f0dd4153bb8fef52dc4450960f41c2de6f89a5897ab695a09bb88eb/xfastertransformer-1.7.3-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.8.0":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer","package_url":"https://pypi.org/project/xfastertransformer/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer/1.8.0/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.8.0","yanked":false,"yanked_reason":null},"last_serial":25409938,"urls":[{"comment_text":"","digests":{"blake2b_256":"ce5582f3c7d76e6de7282cb8d3f5a28c16361d9d022c5853151312cf5a830d05","md5":"d3ae2a0c5f874db3821e38f4c61c9f26","sha256":"b675e9739fef2f109ede2d1f78627262158a743623803941c7cb288d5b61c1d7"},"downloads":-1,"filename":"xfastertransformer-1.8.0-py3-none-any.whl","has_sig":false,"md5_digest":"d3ae2a0c5f874db3821e38f4c61c9f26","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":39447506,"upload_time":"2024-07-23T01:49:10","upload_time_iso_8601":"2024-07-23T01:49:10.984283Z","url":"https://files.pythonhosted.org/packages/ce/55/82f3c7d76e6de7282cb8d3f5a28c16361d9d022c5853151312cf5a830d05/xfastertransformer-1.8.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.8.1":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer","package_url":"https://pypi.org/project/xfastertransformer/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer/1.8.1/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.8.1","yanked":false,"yanked_reason":null},"last_serial":25409938,"urls":[{"comment_text":"","digests":{"blake2b_256":"3017925fb9063151f96093c2e9bb47b538d712e45e9640d21e11ccd673090b66","md5":"a1f371bbaba0611a338d3e08c7cf88ba","sha256":"8c0d9e719ef810368ec4f40c0de5855a6beeb4c0fe2d07b6b8d06b8b2bea256d"},"downloads":-1,"filename":"xfastertransformer-1.8.1-py3-none-any.whl","has_sig":false,"md5_digest":"a1f371bbaba0611a338d3e08c7cf88ba","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":39541767,"upload_time":"2024-07-31T08:34:50","upload_time_iso_8601":"2024-07-31T08:34:50.149993Z","url":"https://files.pythonhosted.org/packages/30/17/925fb9063151f96093c2e9bb47b538d712e45e9640d21e11ccd673090b66/xfastertransformer-1.8.1-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.8.2":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer","package_url":"https://pypi.org/project/xfastertransformer/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer/1.8.2/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.8.2","yanked":false,"yanked_reason":null},"last_serial":25409938,"urls":[{"comment_text":"","digests":{"blake2b_256":"88c4001ecea3b168835837c673c0a55e564b9b11bc06f68c516e7ce68fb89d87","md5":"45da1b8d1b3737e54bc0f717ee74227e","sha256":"40c336182d9978395240851d639d98f0e7afeff45cde186391fa3c69a15fb777"},"downloads":-1,"filename":"xfastertransformer-1.8.2-py3-none-any.whl","has_sig":false,"md5_digest":"45da1b8d1b3737e54bc0f717ee74227e","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":40758164,"upload_time":"2024-10-10T07:45:14","upload_time_iso_8601":"2024-10-10T07:45:14.210746Z","url":"https://files.pythonhosted.org/packages/88/c4/001ecea3b168835837c673c0a55e564b9b11bc06f68c516e7ce68fb89d87/xfastertransformer-1.8.2-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}