{"1.8.0":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer-gnr","package_url":"https://pypi.org/project/xfastertransformer-gnr/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer-gnr/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer-gnr/1.8.0/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.8.0","yanked":false,"yanked_reason":null},"last_serial":25409956,"urls":[{"comment_text":"","digests":{"blake2b_256":"4f3ffca16ace190f9c4e1a3352286d9ef925ebd1ecbeb9a3cb0b10e6bc37504d","md5":"88835551b666a5b5d4f47d7f67017fb3","sha256":"1d273cb96c0c02ae578308d2cf59e0802dd16a7e1c3679f5f7805fe8c427d8d6"},"downloads":-1,"filename":"xfastertransformer_gnr-1.8.0-py3-none-any.whl","has_sig":false,"md5_digest":"88835551b666a5b5d4f47d7f67017fb3","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":37590315,"upload_time":"2024-07-23T01:49:58","upload_time_iso_8601":"2024-07-23T01:49:58.587017Z","url":"https://files.pythonhosted.org/packages/4f/3f/fca16ace190f9c4e1a3352286d9ef925ebd1ecbeb9a3cb0b10e6bc37504d/xfastertransformer_gnr-1.8.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.8.1":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer-gnr","package_url":"https://pypi.org/project/xfastertransformer-gnr/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer-gnr/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer-gnr/1.8.1/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.8.1","yanked":false,"yanked_reason":null},"last_serial":25409956,"urls":[{"comment_text":"","digests":{"blake2b_256":"3cbf4e61b1c8f0533f66f51a95efbea00a26c57b0700485916fe1553ab63c245","md5":"86d8d4061fd866c06c1d3e41b65c08a0","sha256":"e93376b699277e1dee6c4e3740cbda3bc1e6008cd8209f92093212cc43e083c5"},"downloads":-1,"filename":"xfastertransformer_gnr-1.8.1-py3-none-any.whl","has_sig":false,"md5_digest":"86d8d4061fd866c06c1d3e41b65c08a0","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":37729245,"upload_time":"2024-07-31T08:35:09","upload_time_iso_8601":"2024-07-31T08:35:09.500592Z","url":"https://files.pythonhosted.org/packages/3c/bf/4e61b1c8f0533f66f51a95efbea00a26c57b0700485916fe1553ab63c245/xfastertransformer_gnr-1.8.1-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.8.2":{"info":{"author":"xFasterTransformer","author_email":"xft.maintainer@intel.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/intel/xFasterTransformer","keywords":"LLM","license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"xfastertransformer-gnr","package_url":"https://pypi.org/project/xfastertransformer-gnr/","platform":"x86_64","project_url":"https://pypi.org/project/xfastertransformer-gnr/","project_urls":{"Homepage":"https://github.com/intel/xFasterTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/xfastertransformer-gnr/1.8.2/","requires_dist":["torch<2.4.0,>=2.3.0"],"requires_python":">=3.8","summary":"Boost large language model inference performance on CPU platform.","version":"1.8.2","yanked":false,"yanked_reason":null},"last_serial":25409956,"urls":[{"comment_text":"","digests":{"blake2b_256":"742af3885d19df4bb33140e7442fab6e4e477acfcec0a257cc5a508bd45900c4","md5":"a9579376251831af385881627d09da10","sha256":"1e31187167be5e5c091a7e2de70f1151c089cc23a0e16776ee2aa7558c1328f7"},"downloads":-1,"filename":"xfastertransformer_gnr-1.8.2-py3-none-any.whl","has_sig":false,"md5_digest":"a9579376251831af385881627d09da10","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":38947392,"upload_time":"2024-10-10T07:45:57","upload_time_iso_8601":"2024-10-10T07:45:57.969116Z","url":"https://files.pythonhosted.org/packages/74/2a/f3885d19df4bb33140e7442fab6e4e477acfcec0a257cc5a508bd45900c4/xfastertransformer_gnr-1.8.2-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}