{"0.1.0":{"info":{"author":"ZHIRUI ZHOU","author_email":"evilpsycho42@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/EvilPsyCHo/Open-LLM-Benchmark","keywords":null,"license":null,"maintainer":null,"maintainer_email":null,"name":"open-llm-benchmark","package_url":"https://pypi.org/project/open-llm-benchmark/","platform":null,"project_url":"https://pypi.org/project/open-llm-benchmark/","project_urls":{"Homepage":"https://github.com/EvilPsyCHo/Open-LLM-Benchmark"},"provides_extra":null,"release_url":"https://pypi.org/project/open-llm-benchmark/0.1.0/","requires_dist":null,"requires_python":">=3.8.4","summary":"Evaluate the capability of open-source LLMs in Agent, formatted output, instruction following, long context retrieval, multilingual, coding, math and custom task.","version":"0.1.0","yanked":false,"yanked_reason":null},"last_serial":23034766,"urls":[{"comment_text":"","digests":{"blake2b_256":"83b6ca1527699dd4285db751bfa09cc06cf26f6f84696b0fd389e42b77c206cf","md5":"6a7d927e2273f84490765d7a169a83c7","sha256":"761d662ad93b86ce13c5635b2f50df2c6d51012bca8ed33717c9807eeb5269fb"},"downloads":-1,"filename":"open_llm_benchmark-0.1.0.tar.gz","has_sig":false,"md5_digest":"6a7d927e2273f84490765d7a169a83c7","packagetype":"sdist","python_version":"source","requires_python":">=3.8.4","size":1642559,"upload_time":"2024-05-02T17:32:35","upload_time_iso_8601":"2024-05-02T17:32:35.340266Z","url":"https://files.pythonhosted.org/packages/83/b6/ca1527699dd4285db751bfa09cc06cf26f6f84696b0fd389e42b77c206cf/open_llm_benchmark-0.1.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}