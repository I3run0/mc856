{"0.1.0":{"info":{"author":"IBM Research","author_email":"mayank.agarwal@ibm.com, aldo.pareja@ibm.com, onkarbhardwaj@ibm.com, mikhail.yurochkin@ibm.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/IBM/inFairness","keywords":"individual fairness,ai fairness,trustworthy ai,machine learning","license":"","maintainer":"","maintainer_email":"","name":"inFairness","package_url":"https://pypi.org/project/inFairness/","platform":null,"project_url":"https://pypi.org/project/inFairness/","project_urls":{"Homepage":"https://github.com/IBM/inFairness"},"provides_extra":null,"release_url":"https://pypi.org/project/inFairness/0.1.0/","requires_dist":["tabulate (~=0.8.9)","setuptools (~=52.0.0)","pyyaml (~=5.4.1)","yacs (~=0.1.8)","torch (~=1.11.0)","numpy (~=1.22.2)","scikit-learn (~=0.24.2)","cloudpickle (~=2.0.0)","omegaconf (~=2.0.6)","pandas (~=1.3.5)","scipy (~=1.7.3)"],"requires_python":">=3.8","summary":"inFairness is a Python package to train and audit individually fair PyTorch models","version":"0.1.0","yanked":false,"yanked_reason":null},"last_serial":17649455,"urls":[{"comment_text":"","digests":{"blake2b_256":"2b83b72c0efc22bf546acbfd25ca35e7b26d8c9cf92ac3515d956a090638901c","md5":"b0a5f730e7fcc504744325a70ad2d457","sha256":"67e1127bf28dd31491a025c2c81ae25052ba966b3d7beaa6c9c47c1baafe9b4d"},"downloads":-1,"filename":"inFairness-0.1.0-py3-none-any.whl","has_sig":false,"md5_digest":"b0a5f730e7fcc504744325a70ad2d457","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":27363,"upload_time":"2022-06-09T15:28:30","upload_time_iso_8601":"2022-06-09T15:28:30.144941Z","url":"https://files.pythonhosted.org/packages/2b/83/b72c0efc22bf546acbfd25ca35e7b26d8c9cf92ac3515d956a090638901c/inFairness-0.1.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e36201af3ecca91d6c64e8242966d9d0aa0f12176ec2aed8acfd1c1622295523","md5":"5c60b4f561afeebc73b616b22b214882","sha256":"2df554c2af46d7fd7898aa8aae5801567d7b8bb77765635da8a294e4bcf81d1d"},"downloads":-1,"filename":"inFairness-0.1.0.tar.gz","has_sig":false,"md5_digest":"5c60b4f561afeebc73b616b22b214882","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":20717,"upload_time":"2022-06-09T15:28:32","upload_time_iso_8601":"2022-06-09T15:28:32.024417Z","url":"https://files.pythonhosted.org/packages/e3/62/01af3ecca91d6c64e8242966d9d0aa0f12176ec2aed8acfd1c1622295523/inFairness-0.1.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.0":{"info":{"author":"IBM Research","author_email":"mayank.agarwal@ibm.com, aldo.pareja@ibm.com, onkarbhardwaj@ibm.com, mikhail.yurochkin@ibm.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/IBM/inFairness","keywords":"individual fairness,ai fairness,trustworthy ai,machine learning","license":"","maintainer":"","maintainer_email":"","name":"inFairness","package_url":"https://pypi.org/project/inFairness/","platform":null,"project_url":"https://pypi.org/project/inFairness/","project_urls":{"Homepage":"https://github.com/IBM/inFairness"},"provides_extra":null,"release_url":"https://pypi.org/project/inFairness/0.2.0/","requires_dist":["torch (>=1.11.0)","numpy (>=1.21.6)","scikit-learn (>=0.24.2)","pandas (>=1.3.5)","scipy (>=1.5.4)","functorch (~=0.1.1)"],"requires_python":">=3.8","summary":"inFairness is a Python package to train and audit individually fair PyTorch models","version":"0.2.0","yanked":false,"yanked_reason":null},"last_serial":17649455,"urls":[{"comment_text":"","digests":{"blake2b_256":"5156a3aa025ffdb1e07fec5cfd47b0f7a47746ca3064292c903bb2989a8cbcb2","md5":"09d87802bed3102fde2770ed85e77140","sha256":"af3cf0b34b74d3832e9d2fec1ab7674e17aca74f1052aba772490086009ae4f8"},"downloads":-1,"filename":"inFairness-0.2.0-py3-none-any.whl","has_sig":false,"md5_digest":"09d87802bed3102fde2770ed85e77140","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":37540,"upload_time":"2022-08-07T00:49:17","upload_time_iso_8601":"2022-08-07T00:49:17.513254Z","url":"https://files.pythonhosted.org/packages/51/56/a3aa025ffdb1e07fec5cfd47b0f7a47746ca3064292c903bb2989a8cbcb2/inFairness-0.2.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"9c3442acae7c4460ce26d3a2f4242df6d5f7dbc52805acef481fd5bac5d19ca5","md5":"966ccdbb25c71bbdb7eee6b6a60bcd03","sha256":"783e575bb38902cff9176d53e46179fe6d02a4a19189d0385575b4354c1d13ec"},"downloads":-1,"filename":"inFairness-0.2.0.tar.gz","has_sig":false,"md5_digest":"966ccdbb25c71bbdb7eee6b6a60bcd03","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":28839,"upload_time":"2022-08-07T00:49:19","upload_time_iso_8601":"2022-08-07T00:49:19.003871Z","url":"https://files.pythonhosted.org/packages/9c/34/42acae7c4460ce26d3a2f4242df6d5f7dbc52805acef481fd5bac5d19ca5/inFairness-0.2.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.1":{"info":{"author":"IBM Research","author_email":"mayank.agarwal@ibm.com, aldo.pareja@ibm.com, onkarbhardwaj@ibm.com, mikhail.yurochkin@ibm.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/IBM/inFairness","keywords":"individual fairness,ai fairness,trustworthy ai,machine learning","license":"","maintainer":"","maintainer_email":"","name":"inFairness","package_url":"https://pypi.org/project/inFairness/","platform":null,"project_url":"https://pypi.org/project/inFairness/","project_urls":{"Homepage":"https://github.com/IBM/inFairness"},"provides_extra":null,"release_url":"https://pypi.org/project/inFairness/0.2.1/","requires_dist":["torch (>=1.11.0)","numpy (>=1.21.6)","scikit-learn (>=0.24.2)","pandas (>=1.3.5)","scipy (>=1.5.4)","functorch (~=0.1.1)"],"requires_python":">=3.8","summary":"inFairness is a Python package to train and audit individually fair PyTorch models","version":"0.2.1","yanked":false,"yanked_reason":null},"last_serial":17649455,"urls":[{"comment_text":"","digests":{"blake2b_256":"dc239a277c1f36a7fb870b4a9e5f190ac16b98b6cc3de9ed76c4b9b5a367812a","md5":"baf243613af88d5863c663d8d3ebf9f1","sha256":"9ae2cc6e169b2a4629c1968135a301239fe85c8bd7e41d581848787bd9c807a9"},"downloads":-1,"filename":"inFairness-0.2.1-py3-none-any.whl","has_sig":false,"md5_digest":"baf243613af88d5863c663d8d3ebf9f1","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":37543,"upload_time":"2022-08-09T23:19:57","upload_time_iso_8601":"2022-08-09T23:19:57.484846Z","url":"https://files.pythonhosted.org/packages/dc/23/9a277c1f36a7fb870b4a9e5f190ac16b98b6cc3de9ed76c4b9b5a367812a/inFairness-0.2.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"05f6f48fb737223a3b285f70b0fa7962e5e6d0fec70999524da9dd121e7d3830","md5":"9ca32949dda352c87ee1cdda50a73d46","sha256":"c5204df2e01fd53a2ed5c4143c302376bc6988e6217b9255ae54f9f914d30161"},"downloads":-1,"filename":"inFairness-0.2.1.tar.gz","has_sig":false,"md5_digest":"9ca32949dda352c87ee1cdda50a73d46","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":28842,"upload_time":"2022-08-09T23:19:58","upload_time_iso_8601":"2022-08-09T23:19:58.945321Z","url":"https://files.pythonhosted.org/packages/05/f6/f48fb737223a3b285f70b0fa7962e5e6d0fec70999524da9dd121e7d3830/inFairness-0.2.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.2":{"info":{"author":"IBM Research","author_email":"mayank.agarwal@ibm.com, aldo.pareja@ibm.com, onkarbhardwaj@ibm.com, mikhail.yurochkin@ibm.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/IBM/inFairness","keywords":"individual fairness,ai fairness,trustworthy ai,machine learning","license":"","maintainer":"","maintainer_email":"","name":"inFairness","package_url":"https://pypi.org/project/inFairness/","platform":null,"project_url":"https://pypi.org/project/inFairness/","project_urls":{"Homepage":"https://github.com/IBM/inFairness"},"provides_extra":null,"release_url":"https://pypi.org/project/inFairness/0.2.2/","requires_dist":["functorch (~=0.1.1)","numpy (>=1.21.6)","pandas (>=1.3.5)","POT (>=0.8.0)","scikit-learn (>=0.24.2)","scipy (>=1.5.4)","torch (>=1.11.0)"],"requires_python":">=3.7","summary":"inFairness is a Python package to train and audit individually fair PyTorch models","version":"0.2.2","yanked":false,"yanked_reason":null},"last_serial":17649455,"urls":[{"comment_text":"","digests":{"blake2b_256":"b5a2f69c17d7c53a435031eb0fd6cbb83323ac2022fd2a207ff53aa57f9900a0","md5":"d6d27503a2540844e278269a25085f40","sha256":"aed6e357d2d4dacd731f0491b93deecfe12abeebad7c4fee82995d987ace3a3e"},"downloads":-1,"filename":"inFairness-0.2.2-py3-none-any.whl","has_sig":false,"md5_digest":"d6d27503a2540844e278269a25085f40","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":38657,"upload_time":"2022-09-06T19:57:22","upload_time_iso_8601":"2022-09-06T19:57:22.267322Z","url":"https://files.pythonhosted.org/packages/b5/a2/f69c17d7c53a435031eb0fd6cbb83323ac2022fd2a207ff53aa57f9900a0/inFairness-0.2.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7bba3a7122562b51a3ee23c38362147622089652d32500b0d59c691100677e6b","md5":"ed1caa4faf2e0672f7ac713c1d225888","sha256":"9519cafb0998c8d92430c87ccbdf55a4d96ada53a8e2d29b69c7dbccd85ba6ab"},"downloads":-1,"filename":"inFairness-0.2.2.tar.gz","has_sig":false,"md5_digest":"ed1caa4faf2e0672f7ac713c1d225888","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":29483,"upload_time":"2022-09-06T19:57:23","upload_time_iso_8601":"2022-09-06T19:57:23.957999Z","url":"https://files.pythonhosted.org/packages/7b/ba/3a7122562b51a3ee23c38362147622089652d32500b0d59c691100677e6b/inFairness-0.2.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.3":{"info":{"author":"IBM Research","author_email":"mayank.agarwal@ibm.com, aldo.pareja@ibm.com, onkarbhardwaj@ibm.com, mikhail.yurochkin@ibm.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/IBM/inFairness","keywords":"individual fairness,ai fairness,trustworthy ai,machine learning","license":"","maintainer":"","maintainer_email":"","name":"inFairness","package_url":"https://pypi.org/project/inFairness/","platform":null,"project_url":"https://pypi.org/project/inFairness/","project_urls":{"Homepage":"https://github.com/IBM/inFairness"},"provides_extra":null,"release_url":"https://pypi.org/project/inFairness/0.2.3/","requires_dist":["numpy (>=1.21.6)","pandas (>=1.3.5)","POT (>=0.8.0)","scikit-learn (>=0.24.2)","scipy (>=1.5.4)","torch (>=1.13.0)"],"requires_python":">=3.7","summary":"inFairness is a Python package to train and audit individually fair PyTorch models","version":"0.2.3","yanked":false,"yanked_reason":null},"last_serial":17649455,"urls":[{"comment_text":"","digests":{"blake2b_256":"282660e9a18cfbfdd0e3f4c38d4d2707664e161dd9cddceeaa1ce1b5c001f9f6","md5":"9c5323ba4b3cc0c3979dac24ce3bec4f","sha256":"85a39fc0a68d5b895a6794e722cf0548ff0f4fd52751ed3661e7a6f6365f8a22"},"downloads":-1,"filename":"inFairness-0.2.3-py3-none-any.whl","has_sig":false,"md5_digest":"9c5323ba4b3cc0c3979dac24ce3bec4f","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.7","size":45765,"upload_time":"2023-04-10T19:16:11","upload_time_iso_8601":"2023-04-10T19:16:11.038454Z","url":"https://files.pythonhosted.org/packages/28/26/60e9a18cfbfdd0e3f4c38d4d2707664e161dd9cddceeaa1ce1b5c001f9f6/inFairness-0.2.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"5d6c312f52fac23c579678c4e4e2ede03083739ae5f644318baa9a4fdf0d36c2","md5":"05a6e38ede6aa9c3579b4485ea47582b","sha256":"a50caed2253ce0ab42d3f2a73d39871682ce2e3617160823aa72db43c5bb158b"},"downloads":-1,"filename":"inFairness-0.2.3.tar.gz","has_sig":false,"md5_digest":"05a6e38ede6aa9c3579b4485ea47582b","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":34273,"upload_time":"2023-04-10T19:16:12","upload_time_iso_8601":"2023-04-10T19:16:12.563316Z","url":"https://files.pythonhosted.org/packages/5d/6c/312f52fac23c579678c4e4e2ede03083739ae5f644318baa9a4fdf0d36c2/inFairness-0.2.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}