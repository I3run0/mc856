{"0.0.1":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.0.1/","requires_dist":["beartype","einops >=0.7.0","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.0.1","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"46666e306687c4a24461b81d6148a7472b3aeb69582ec037ada0c8cd3b95add2","md5":"7010fe1198eb81269fff29f767d5382f","sha256":"ff9127656aab6639a16061307fba7465bca3b2d834d1b7cbf5463f807d233573"},"downloads":-1,"filename":"iTransformer-0.0.1-py3-none-any.whl","has_sig":false,"md5_digest":"7010fe1198eb81269fff29f767d5382f","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":3975,"upload_time":"2023-10-11T20:02:14","upload_time_iso_8601":"2023-10-11T20:02:14.679502Z","url":"https://files.pythonhosted.org/packages/46/66/6e306687c4a24461b81d6148a7472b3aeb69582ec037ada0c8cd3b95add2/iTransformer-0.0.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"838910a13d9976cff91dc93f2266e3b7a2bc93d7bf821d29e2023ae3a6115807","md5":"efc2f713886444ff0a10fd8e8e7ff4c0","sha256":"073e22c2598d4ae55e95b61e23912ae113c19753f0d536a569f4be36dc698bf1"},"downloads":-1,"filename":"iTransformer-0.0.1.tar.gz","has_sig":false,"md5_digest":"efc2f713886444ff0a10fd8e8e7ff4c0","packagetype":"sdist","python_version":"source","requires_python":null,"size":4261,"upload_time":"2023-10-11T20:02:16","upload_time_iso_8601":"2023-10-11T20:02:16.389350Z","url":"https://files.pythonhosted.org/packages/83/89/10a13d9976cff91dc93f2266e3b7a2bc93d7bf821d29e2023ae3a6115807/iTransformer-0.0.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.2":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.0.2/","requires_dist":["beartype","einops >=0.7.0","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.0.2","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"79993acfea32c1298ca29a90536c56faa3bd8564228fad90ccb3f37643283d20","md5":"c54b08dd3366181055f3c225060af565","sha256":"233c7a31ccccc6db6358f470ecd6167cb3df53d82fef965dcdeb49eedea66849"},"downloads":-1,"filename":"iTransformer-0.0.2-py3-none-any.whl","has_sig":false,"md5_digest":"c54b08dd3366181055f3c225060af565","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":3984,"upload_time":"2023-10-11T20:06:56","upload_time_iso_8601":"2023-10-11T20:06:56.819364Z","url":"https://files.pythonhosted.org/packages/79/99/3acfea32c1298ca29a90536c56faa3bd8564228fad90ccb3f37643283d20/iTransformer-0.0.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"696d9d33fc027bacfa51c4533be10195c97340a1724470ee7248184704debcbc","md5":"72a36dd07a7e16f3d15e255bca9a5ced","sha256":"4f7491fb171cebaedc5ab9b6911772ddada5205af901b461e95afa41f21f0f6a"},"downloads":-1,"filename":"iTransformer-0.0.2.tar.gz","has_sig":false,"md5_digest":"72a36dd07a7e16f3d15e255bca9a5ced","packagetype":"sdist","python_version":"source","requires_python":null,"size":4480,"upload_time":"2023-10-11T20:06:57","upload_time_iso_8601":"2023-10-11T20:06:57.969020Z","url":"https://files.pythonhosted.org/packages/69/6d/9d33fc027bacfa51c4533be10195c97340a1724470ee7248184704debcbc/iTransformer-0.0.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.3":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.0.3/","requires_dist":["beartype","einops >=0.7.0","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.0.3","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"d8494433dc9085d87b28721cc2177cc691106b6b3184d433763e872cc41d4e19","md5":"23810fd6d2c59b31f98f864e0137a3b1","sha256":"ccf4084008742cbc4b46d9f9bfc7eb4a9e6ff057b54b42a4d733d070ab05dc63"},"downloads":-1,"filename":"iTransformer-0.0.3-py3-none-any.whl","has_sig":false,"md5_digest":"23810fd6d2c59b31f98f864e0137a3b1","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":4007,"upload_time":"2023-10-11T20:10:42","upload_time_iso_8601":"2023-10-11T20:10:42.826970Z","url":"https://files.pythonhosted.org/packages/d8/49/4433dc9085d87b28721cc2177cc691106b6b3184d433763e872cc41d4e19/iTransformer-0.0.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"dcd1b4bbdf5285c99f8f33639b2ef1d5b936cf29b7e9bb5feef824bd6b5199cd","md5":"3debd824fa29dc3700b39873b2a4f4ff","sha256":"39bd64f321f9af1b68557695a4ae17b795ac046004300c3c745dff5c5894f8be"},"downloads":-1,"filename":"iTransformer-0.0.3.tar.gz","has_sig":false,"md5_digest":"3debd824fa29dc3700b39873b2a4f4ff","packagetype":"sdist","python_version":"source","requires_python":null,"size":4514,"upload_time":"2023-10-11T20:10:44","upload_time_iso_8601":"2023-10-11T20:10:44.290125Z","url":"https://files.pythonhosted.org/packages/dc/d1/b4bbdf5285c99f8f33639b2ef1d5b936cf29b7e9bb5feef824bd6b5199cd/iTransformer-0.0.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.4":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.0.4/","requires_dist":["beartype","einops >=0.7.0","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.0.4","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"892ee1ef8b328bcbcfc98988668405fe51cb595c0aa625207d4eb75ce4f3001c","md5":"4d71ba2ab36013a757318540e9def0f8","sha256":"ef84ae6a633fc9a24d072f8ad7bd945ccf59061520fbedc34cf9256538b69b46"},"downloads":-1,"filename":"iTransformer-0.0.4-py3-none-any.whl","has_sig":false,"md5_digest":"4d71ba2ab36013a757318540e9def0f8","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":4155,"upload_time":"2023-10-11T20:16:55","upload_time_iso_8601":"2023-10-11T20:16:55.151947Z","url":"https://files.pythonhosted.org/packages/89/2e/e1ef8b328bcbcfc98988668405fe51cb595c0aa625207d4eb75ce4f3001c/iTransformer-0.0.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"c0bcfbf972bc2a46650d0edce9e02d91139a267b038e38e05269b53585e031ae","md5":"f6c49c90d89a1bce3255a349ddb751e5","sha256":"57cc23d542640b00447b7f7bc18eaafd617ce654d61ac1b376fedf532317cefd"},"downloads":-1,"filename":"iTransformer-0.0.4.tar.gz","has_sig":false,"md5_digest":"f6c49c90d89a1bce3255a349ddb751e5","packagetype":"sdist","python_version":"source","requires_python":null,"size":4932,"upload_time":"2023-10-11T20:16:56","upload_time_iso_8601":"2023-10-11T20:16:56.617498Z","url":"https://files.pythonhosted.org/packages/c0/bc/fbf972bc2a46650d0edce9e02d91139a267b038e38e05269b53585e031ae/iTransformer-0.0.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.5":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.0.5/","requires_dist":["beartype","einops >=0.7.0","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.0.5","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"7d4abd13e89fee86ec1164598b446d97d848c1cb000fb8efa674ea44dcb1a82e","md5":"4adfcb32005b60baf365d1409ac12733","sha256":"8b2ec77aef94aa572f9d11782d1eacf4b2ad9441a275420d8cc0b58162087312"},"downloads":-1,"filename":"iTransformer-0.0.5-py3-none-any.whl","has_sig":false,"md5_digest":"4adfcb32005b60baf365d1409ac12733","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":4212,"upload_time":"2023-10-11T20:29:39","upload_time_iso_8601":"2023-10-11T20:29:39.599278Z","url":"https://files.pythonhosted.org/packages/7d/4a/bd13e89fee86ec1164598b446d97d848c1cb000fb8efa674ea44dcb1a82e/iTransformer-0.0.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7583bb70ed305a7468037c32de0b51895683724a4ae9415eee89b995f7adb10e","md5":"08e8ebc6e8f9aad1b9f024ab8d6ba8b3","sha256":"8ca6af30f439655877fd1c34b6bbc48057f0a410e335939d34212ea6fe216817"},"downloads":-1,"filename":"iTransformer-0.0.5.tar.gz","has_sig":false,"md5_digest":"08e8ebc6e8f9aad1b9f024ab8d6ba8b3","packagetype":"sdist","python_version":"source","requires_python":null,"size":4974,"upload_time":"2023-10-11T20:29:41","upload_time_iso_8601":"2023-10-11T20:29:41.076220Z","url":"https://files.pythonhosted.org/packages/75/83/bb70ed305a7468037c32de0b51895683724a4ae9415eee89b995f7adb10e/iTransformer-0.0.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.6":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.0.6/","requires_dist":["beartype","einops >=0.7.0","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.0.6","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"470f7f60cf4b42f2db051780a5d737601318f372f6cd87a12f3db7bc79af24d2","md5":"f1a99ae0943c98c11833b4be41cbda9e","sha256":"77c7e4e8a5840eca9131eb94ef4a5b6b47c908d191a25b08a33cdb7ce6f4c876"},"downloads":-1,"filename":"iTransformer-0.0.6-py3-none-any.whl","has_sig":false,"md5_digest":"f1a99ae0943c98c11833b4be41cbda9e","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":5731,"upload_time":"2023-10-11T20:35:59","upload_time_iso_8601":"2023-10-11T20:35:59.794761Z","url":"https://files.pythonhosted.org/packages/47/0f/7f60cf4b42f2db051780a5d737601318f372f6cd87a12f3db7bc79af24d2/iTransformer-0.0.6-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"bd756e7300a9a335c7f0b62cfeeaf33724d818d695072f4553a3e16fc9c21746","md5":"7e624668a3d6a8afc4d1e0eb4f512d20","sha256":"5f30ca56c7c3e59799a921d5ef7f10fa23698afef5fe269ca16d6fc9f7d8b17c"},"downloads":-1,"filename":"iTransformer-0.0.6.tar.gz","has_sig":false,"md5_digest":"7e624668a3d6a8afc4d1e0eb4f512d20","packagetype":"sdist","python_version":"source","requires_python":null,"size":6290,"upload_time":"2023-10-11T20:36:03","upload_time_iso_8601":"2023-10-11T20:36:03.098050Z","url":"https://files.pythonhosted.org/packages/bd/75/6e7300a9a335c7f0b62cfeeaf33724d818d695072f4553a3e16fc9c21746/iTransformer-0.0.6.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.7":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.0.7/","requires_dist":["beartype","einops >=0.7.0","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.0.7","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"6d4e60ef96b1b33294c1d9270d7a3cd518d1e21bdcd1898568cb217a0329370f","md5":"8dbac215707254ccff85ee7644b6d68f","sha256":"0769b8cf909c64331b0046b2aa9008e246ced937916922d043a10d3ea25370f1"},"downloads":-1,"filename":"iTransformer-0.0.7-py3-none-any.whl","has_sig":false,"md5_digest":"8dbac215707254ccff85ee7644b6d68f","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":5729,"upload_time":"2023-10-15T00:14:45","upload_time_iso_8601":"2023-10-15T00:14:45.210364Z","url":"https://files.pythonhosted.org/packages/6d/4e/60ef96b1b33294c1d9270d7a3cd518d1e21bdcd1898568cb217a0329370f/iTransformer-0.0.7-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"9f1ccb7fe4a2e222dd91a7305610ca24b87d9069c5b0045d00a43a48fff4d708","md5":"f37b1f552e4a748f95734ff82fc6bdb9","sha256":"f57ad938ef47aff7ec88887bc2662a4e5bb5b8d95fd10bd28d20ae8e770bb8a1"},"downloads":-1,"filename":"iTransformer-0.0.7.tar.gz","has_sig":false,"md5_digest":"f37b1f552e4a748f95734ff82fc6bdb9","packagetype":"sdist","python_version":"source","requires_python":null,"size":6412,"upload_time":"2023-10-15T00:14:46","upload_time_iso_8601":"2023-10-15T00:14:46.331174Z","url":"https://files.pythonhosted.org/packages/9f/1c/cb7fe4a2e222dd91a7305610ca24b87d9069c5b0045d00a43a48fff4d708/iTransformer-0.0.7.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.0":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.1.0/","requires_dist":["beartype","einops >=0.7.0","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.1.0","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"1e4db66b0fe10174889b364e316f25e32dd4d42b975206fd3b9c5a29474f0af7","md5":"018fba685205ff75eacc897bf6501455","sha256":"9c3afb3b55fa67e7e55af1ab3bcb1f3232ebe5def51a715dfecf0f0efa517e94"},"downloads":-1,"filename":"iTransformer-0.1.0-py3-none-any.whl","has_sig":false,"md5_digest":"018fba685205ff75eacc897bf6501455","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":5806,"upload_time":"2023-10-23T15:53:57","upload_time_iso_8601":"2023-10-23T15:53:57.071525Z","url":"https://files.pythonhosted.org/packages/1e/4d/b66b0fe10174889b364e316f25e32dd4d42b975206fd3b9c5a29474f0af7/iTransformer-0.1.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8c560cc89d663c0b3982cabc209c25590605b2ae694488f15362b2aa6eb79443","md5":"f08f18fdfe4b3e6c226f1f50c8945fcf","sha256":"dd80b01f729a0d6130216dbf3ec3100c58c481e053ba410df5f5a52fd34aa1a5"},"downloads":-1,"filename":"iTransformer-0.1.0.tar.gz","has_sig":false,"md5_digest":"f08f18fdfe4b3e6c226f1f50c8945fcf","packagetype":"sdist","python_version":"source","requires_python":null,"size":7038,"upload_time":"2023-10-23T15:53:59","upload_time_iso_8601":"2023-10-23T15:53:59.078903Z","url":"https://files.pythonhosted.org/packages/8c/56/0cc89d663c0b3982cabc209c25590605b2ae694488f15362b2aa6eb79443/iTransformer-0.1.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.0":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.2.0/","requires_dist":["beartype","einops >=0.7.0","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.2.0","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"95eab0f92c35334ce0d040000808ac5a052f64596160e900e1289fae3823eae7","md5":"bf36aed5e6eff18080624a34b5761ba1","sha256":"6e29e003991717fda43446ebc4be78fbf1837b91decf36ff1b4f08f768cd014e"},"downloads":-1,"filename":"iTransformer-0.2.0-py3-none-any.whl","has_sig":false,"md5_digest":"bf36aed5e6eff18080624a34b5761ba1","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6242,"upload_time":"2023-10-25T17:19:51","upload_time_iso_8601":"2023-10-25T17:19:51.400590Z","url":"https://files.pythonhosted.org/packages/95/ea/b0f92c35334ce0d040000808ac5a052f64596160e900e1289fae3823eae7/iTransformer-0.2.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"9135388db26058f6aeebb5cb829d3e6c680c0fcf16441981146030508aeb887a","md5":"19b9d6bcce5cf026d345d7dd452fc734","sha256":"76c3d7428e9a6d314dfe597397fd4180b7c0a67ad5eb6bd32bcdde1ba345f0c7"},"downloads":-1,"filename":"iTransformer-0.2.0.tar.gz","has_sig":false,"md5_digest":"19b9d6bcce5cf026d345d7dd452fc734","packagetype":"sdist","python_version":"source","requires_python":null,"size":7843,"upload_time":"2023-10-25T17:19:52","upload_time_iso_8601":"2023-10-25T17:19:52.875930Z","url":"https://files.pythonhosted.org/packages/91/35/388db26058f6aeebb5cb829d3e6c680c0fcf16441981146030508aeb887a/iTransformer-0.2.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.0":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.3.0/","requires_dist":["beartype","einops >=0.7.0","rotary-embedding-torch","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.3.0","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"d2e20d6a0b46d19ddcbd68a7aa00332bc90434f25c787f0d7767db4899fcc37a","md5":"25f76e1224f0806133849e0ff7d2ad2d","sha256":"5327ac5976447ae6c225c780864aab421880d1fbe0e0bdfd5086409fb6adcc3d"},"downloads":-1,"filename":"iTransformer-0.3.0-py3-none-any.whl","has_sig":false,"md5_digest":"25f76e1224f0806133849e0ff7d2ad2d","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":9426,"upload_time":"2023-10-29T16:53:34","upload_time_iso_8601":"2023-10-29T16:53:34.036765Z","url":"https://files.pythonhosted.org/packages/d2/e2/0d6a0b46d19ddcbd68a7aa00332bc90434f25c787f0d7767db4899fcc37a/iTransformer-0.3.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"ad85b6f649df47a2c3af7f209654491f62ba0bb52dc0553e3c3c24cf8c147c49","md5":"1cf26ef97897993aa86bf527f5830354","sha256":"19445b03b10d395ef0c1db5cfe30388f3d12540310fc344178afcc1610cf8f81"},"downloads":-1,"filename":"iTransformer-0.3.0.tar.gz","has_sig":false,"md5_digest":"1cf26ef97897993aa86bf527f5830354","packagetype":"sdist","python_version":"source","requires_python":null,"size":9571,"upload_time":"2023-10-29T16:53:35","upload_time_iso_8601":"2023-10-29T16:53:35.509867Z","url":"https://files.pythonhosted.org/packages/ad/85/b6f649df47a2c3af7f209654491f62ba0bb52dc0553e3c3c24cf8c147c49/iTransformer-0.3.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.1":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.3.1/","requires_dist":["beartype","einops >=0.7.0","rotary-embedding-torch","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.3.1","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"c4eaf0cbe31b72246fa7870e3ce14f66c262a9103e58eaadb9f792a4a454a367","md5":"b3d887946e9c4cfd1361d5713a73e735","sha256":"c4b1783c62643e140e96028688587b77344e993db8efbb71c5ba6b6535e228f8"},"downloads":-1,"filename":"iTransformer-0.3.1-py3-none-any.whl","has_sig":false,"md5_digest":"b3d887946e9c4cfd1361d5713a73e735","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":9422,"upload_time":"2023-10-29T16:54:10","upload_time_iso_8601":"2023-10-29T16:54:10.344529Z","url":"https://files.pythonhosted.org/packages/c4/ea/f0cbe31b72246fa7870e3ce14f66c262a9103e58eaadb9f792a4a454a367/iTransformer-0.3.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"688ddca10282795ca2a97c9375d00fe7224c9837fb0e80c3054e141cbbbd0510","md5":"308dce5eb6be0d8ebf4a75929745f93a","sha256":"f688682c6cde53b7b9a3fa4cb049980d818caa6338fc52eec4138b5fa28de033"},"downloads":-1,"filename":"iTransformer-0.3.1.tar.gz","has_sig":false,"md5_digest":"308dce5eb6be0d8ebf4a75929745f93a","packagetype":"sdist","python_version":"source","requires_python":null,"size":9543,"upload_time":"2023-10-29T16:54:11","upload_time_iso_8601":"2023-10-29T16:54:11.985990Z","url":"https://files.pythonhosted.org/packages/68/8d/dca10282795ca2a97c9375d00fe7224c9837fb0e80c3054e141cbbbd0510/iTransformer-0.3.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.2":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.3.2/","requires_dist":["beartype","einops >=0.7.0","rotary-embedding-torch","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.3.2","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"623317ef6c6b2dbee9c3389ca2db33c3dff35ede1443bdb3e9c4730e1200b735","md5":"687754bd95c754a63c1681dd8daf13db","sha256":"78a8a936fe78f86a41dfdac8e7fb7116f7a28c047c2cf0e1d3199b51fe07eb53"},"downloads":-1,"filename":"iTransformer-0.3.2-py3-none-any.whl","has_sig":false,"md5_digest":"687754bd95c754a63c1681dd8daf13db","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":9551,"upload_time":"2023-10-29T17:32:48","upload_time_iso_8601":"2023-10-29T17:32:48.832429Z","url":"https://files.pythonhosted.org/packages/62/33/17ef6c6b2dbee9c3389ca2db33c3dff35ede1443bdb3e9c4730e1200b735/iTransformer-0.3.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d271781d8d69e7eb069a0d814d4e3a73ff65d4ff903099309f5738c878d66175","md5":"76f4f11a1f714873b52d7e0584dc909b","sha256":"905175918ab2096aa12f653bb5184975b73108bf86da10064726837170bcfc52"},"downloads":-1,"filename":"iTransformer-0.3.2.tar.gz","has_sig":false,"md5_digest":"76f4f11a1f714873b52d7e0584dc909b","packagetype":"sdist","python_version":"source","requires_python":null,"size":9678,"upload_time":"2023-10-29T17:32:50","upload_time_iso_8601":"2023-10-29T17:32:50.418607Z","url":"https://files.pythonhosted.org/packages/d2/71/781d8d69e7eb069a0d814d4e3a73ff65d4ff903099309f5738c878d66175/iTransformer-0.3.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.3":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.3.3/","requires_dist":["beartype","einops >=0.7.0","rotary-embedding-torch","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.3.3","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"11d5941b351f2fd1f602db08641e8ef206b9c8a19a6c4b25f888e9e218c23575","md5":"a01c50d8004492521dee610aae351cab","sha256":"86e027d69ebde9ffec63664338fb74c63f2cdc4871ce81e81735b113803ce50d"},"downloads":-1,"filename":"iTransformer-0.3.3-py3-none-any.whl","has_sig":false,"md5_digest":"a01c50d8004492521dee610aae351cab","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":9614,"upload_time":"2023-10-29T17:47:09","upload_time_iso_8601":"2023-10-29T17:47:09.749344Z","url":"https://files.pythonhosted.org/packages/11/d5/941b351f2fd1f602db08641e8ef206b9c8a19a6c4b25f888e9e218c23575/iTransformer-0.3.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b72f47cb356c3199759c8a1ce3a4c89db62da497f3f2ce856823794ea783958e","md5":"5c8970b921e8ff2242911d7588fdd87a","sha256":"c435c6423a2e5b79e3d8d2a3563268ab7d3d896f4ffc8d06e30ae86eea3f33cd"},"downloads":-1,"filename":"iTransformer-0.3.3.tar.gz","has_sig":false,"md5_digest":"5c8970b921e8ff2242911d7588fdd87a","packagetype":"sdist","python_version":"source","requires_python":null,"size":9700,"upload_time":"2023-10-29T17:47:10","upload_time_iso_8601":"2023-10-29T17:47:10.937725Z","url":"https://files.pythonhosted.org/packages/b7/2f/47cb356c3199759c8a1ce3a4c89db62da497f3f2ce856823794ea783958e/iTransformer-0.3.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.4":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.3.4/","requires_dist":["beartype","einops >=0.7.0","rotary-embedding-torch","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.3.4","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"d8dd813a79ffca32dd5426eab1261e5f34de22b4490d87c2f0ad9fa32996a39b","md5":"f442a2c5b5cbc4e769eb0a71b310f587","sha256":"19871606e9b677c74576a383fda7f565b7bdd1373c5a5b0d70c28df70b469965"},"downloads":-1,"filename":"iTransformer-0.3.4-py3-none-any.whl","has_sig":false,"md5_digest":"f442a2c5b5cbc4e769eb0a71b310f587","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":9606,"upload_time":"2023-10-29T21:53:47","upload_time_iso_8601":"2023-10-29T21:53:47.615040Z","url":"https://files.pythonhosted.org/packages/d8/dd/813a79ffca32dd5426eab1261e5f34de22b4490d87c2f0ad9fa32996a39b/iTransformer-0.3.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"373d83826022f6205140a35fac61647428480c7e5da50cdf9ae9d4713d139d5a","md5":"617fa9d95ba2f5c25891c82ebe2d3822","sha256":"d368188f0540917eb9be2d0a0fa25a972a558588c2ebe2c855df624c6947f177"},"downloads":-1,"filename":"iTransformer-0.3.4.tar.gz","has_sig":false,"md5_digest":"617fa9d95ba2f5c25891c82ebe2d3822","packagetype":"sdist","python_version":"source","requires_python":null,"size":9689,"upload_time":"2023-10-29T21:53:49","upload_time_iso_8601":"2023-10-29T21:53:49.026073Z","url":"https://files.pythonhosted.org/packages/37/3d/83826022f6205140a35fac61647428480c7e5da50cdf9ae9d4713d139d5a/iTransformer-0.3.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.5":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.3.5/","requires_dist":["beartype","einops >=0.7.0","rotary-embedding-torch","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.3.5","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"a296ef4698f0e9cb12d879cdefc03e3e632f213e95c3a361aeace2ff362dc6f2","md5":"b7e6238a98bddf153d3612a6a6893f6b","sha256":"71129b8d0bfb0d73b6f7c3d483f2c5ad0dca3894fe6b3f6066caa93f94fe6c80"},"downloads":-1,"filename":"iTransformer-0.3.5-py3-none-any.whl","has_sig":false,"md5_digest":"b7e6238a98bddf153d3612a6a6893f6b","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":9675,"upload_time":"2023-11-16T15:17:37","upload_time_iso_8601":"2023-11-16T15:17:37.407085Z","url":"https://files.pythonhosted.org/packages/a2/96/ef4698f0e9cb12d879cdefc03e3e632f213e95c3a361aeace2ff362dc6f2/iTransformer-0.3.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"ee8a4e080a98c55209ad47b1c09e2915aac0854ad20bea7a2b23d906bf5ae31e","md5":"3f94d40085cb3b52683df42e7e52cc8f","sha256":"fbd64f4dfac7cf9266b5d828d20ec521ae3e875a20c056af31abbb308d06df42"},"downloads":-1,"filename":"iTransformer-0.3.5.tar.gz","has_sig":false,"md5_digest":"3f94d40085cb3b52683df42e7e52cc8f","packagetype":"sdist","python_version":"source","requires_python":null,"size":9915,"upload_time":"2023-11-16T15:17:38","upload_time_iso_8601":"2023-11-16T15:17:38.898308Z","url":"https://files.pythonhosted.org/packages/ee/8a/4e080a98c55209ad47b1c09e2915aac0854ad20bea7a2b23d906bf5ae31e/iTransformer-0.3.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.0":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.4.0/","requires_dist":["beartype","einops >=0.7.0","rotary-embedding-torch","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.4.0","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"9e15986b558182e11d12bc2cd1d6d941d9caf4e445f9abef49053d2dad4380a3","md5":"527f3d51f708396654562e7bd1583140","sha256":"f07ee1a9a4462337ad71fee9cae06b96a2d27900fe176f95266c168f187e2adc"},"downloads":-1,"filename":"iTransformer-0.4.0-py3-none-any.whl","has_sig":false,"md5_digest":"527f3d51f708396654562e7bd1583140","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":11861,"upload_time":"2023-11-19T18:30:58","upload_time_iso_8601":"2023-11-19T18:30:58.408361Z","url":"https://files.pythonhosted.org/packages/9e/15/986b558182e11d12bc2cd1d6d941d9caf4e445f9abef49053d2dad4380a3/iTransformer-0.4.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a6e25ce7f5addd1fca0c9040d86036b11d080cac4643b4d8b57f51366377b4d0","md5":"e1f8bab2ef0fe37bdace598250190bae","sha256":"ff13588abc1ecf35464cc3941266dbd101dda15a7cd160c59df44f3ce1b481c5"},"downloads":-1,"filename":"iTransformer-0.4.0.tar.gz","has_sig":false,"md5_digest":"e1f8bab2ef0fe37bdace598250190bae","packagetype":"sdist","python_version":"source","requires_python":null,"size":10461,"upload_time":"2023-11-19T18:30:59","upload_time_iso_8601":"2023-11-19T18:30:59.543901Z","url":"https://files.pythonhosted.org/packages/a6/e2/5ce7f5addd1fca0c9040d86036b11d080cac4643b4d8b57f51366377b4d0/iTransformer-0.4.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.1":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.4.1/","requires_dist":["beartype","einops >=0.7.0","rotary-embedding-torch","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.4.1","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"ded756d269288647d4aa0337913b07c3aeb501e8796d3833516e704bfee8760f","md5":"3cc1ccd6d6c90ab9f1a7c7d2fe17d121","sha256":"e031199b5aded238de29adc7d06c0fc3e2de6c8d592f065db02e413d10058a84"},"downloads":-1,"filename":"iTransformer-0.4.1-py3-none-any.whl","has_sig":false,"md5_digest":"3cc1ccd6d6c90ab9f1a7c7d2fe17d121","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":14156,"upload_time":"2023-11-19T22:50:53","upload_time_iso_8601":"2023-11-19T22:50:53.218239Z","url":"https://files.pythonhosted.org/packages/de/d7/56d269288647d4aa0337913b07c3aeb501e8796d3833516e704bfee8760f/iTransformer-0.4.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e08749e0952eae01b25a7b4a1dd8eb628d57ef89a800b29a3ff6b7ca46376d9c","md5":"e8c47a9c80c8ecf3242dcdf2c5703538","sha256":"4275d866e3de60e1c6e2c3bd2db3a0ee08ecde76c775f15890bf0fc6dfb07397"},"downloads":-1,"filename":"iTransformer-0.4.1.tar.gz","has_sig":false,"md5_digest":"e8c47a9c80c8ecf3242dcdf2c5703538","packagetype":"sdist","python_version":"source","requires_python":null,"size":11033,"upload_time":"2023-11-19T22:50:54","upload_time_iso_8601":"2023-11-19T22:50:54.724236Z","url":"https://files.pythonhosted.org/packages/e0/87/49e0952eae01b25a7b4a1dd8eb628d57ef89a800b29a3ff6b7ca46376d9c/iTransformer-0.4.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.2":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.4.2/","requires_dist":["beartype","einops >=0.7.0","rotary-embedding-torch","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.4.2","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"6a65a3dab86e29a7cee216bc5c46a3443bd0b856a70194cc9c6364d259e408de","md5":"448bf6632ccb1e848eac25bedac0e072","sha256":"70d46e9bc1803f65175f51ce63c9353320875c25241fb422cadbd1d4ec354b87"},"downloads":-1,"filename":"iTransformer-0.4.2-py3-none-any.whl","has_sig":false,"md5_digest":"448bf6632ccb1e848eac25bedac0e072","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":14157,"upload_time":"2023-11-27T15:33:12","upload_time_iso_8601":"2023-11-27T15:33:12.274724Z","url":"https://files.pythonhosted.org/packages/6a/65/a3dab86e29a7cee216bc5c46a3443bd0b856a70194cc9c6364d259e408de/iTransformer-0.4.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8b1cb30ea1b1d3b1be58714aadab0a55430dd8181c01e1314de256f44c9ec66e","md5":"7a9e26e75818bb1fae42f4549f217ce7","sha256":"bd4fe3f7c665836b3b8953d1f15647ee1a9f81f153d8bc43a1601853d65d1aea"},"downloads":-1,"filename":"iTransformer-0.4.2.tar.gz","has_sig":false,"md5_digest":"7a9e26e75818bb1fae42f4549f217ce7","packagetype":"sdist","python_version":"source","requires_python":null,"size":11025,"upload_time":"2023-11-27T15:33:13","upload_time_iso_8601":"2023-11-27T15:33:13.334731Z","url":"https://files.pythonhosted.org/packages/8b/1c/b30ea1b1d3b1be58714aadab0a55430dd8181c01e1314de256f44c9ec66e/iTransformer-0.4.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.4":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.4.4/","requires_dist":["beartype","einops >=0.7.0","rotary-embedding-torch","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.4.4","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"4f8c540a4e716f6b8f07efbd29e5dc6d70d31ca7605e4d3dd0663f620e38b49e","md5":"260e250b6bc29bffb8fa76f601974b02","sha256":"e96303ed6473f683723d75084c7e0b0aa298d8705b532f25010340f19d146c8f"},"downloads":-1,"filename":"iTransformer-0.4.4-py3-none-any.whl","has_sig":false,"md5_digest":"260e250b6bc29bffb8fa76f601974b02","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":14215,"upload_time":"2023-11-30T15:16:33","upload_time_iso_8601":"2023-11-30T15:16:33.655940Z","url":"https://files.pythonhosted.org/packages/4f/8c/540a4e716f6b8f07efbd29e5dc6d70d31ca7605e4d3dd0663f620e38b49e/iTransformer-0.4.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8d3abc1f99925e967977abb00f1df02ed14e6f89e19c7c19618d03adbed3f921","md5":"d029bb05b0ed83d484a0a21fada7b635","sha256":"1b2e9e449831137e5d6ddacfe196fd5e0e55a7396257aee7ed081a3ff8f8376d"},"downloads":-1,"filename":"iTransformer-0.4.4.tar.gz","has_sig":false,"md5_digest":"d029bb05b0ed83d484a0a21fada7b635","packagetype":"sdist","python_version":"source","requires_python":null,"size":11093,"upload_time":"2023-11-30T15:16:35","upload_time_iso_8601":"2023-11-30T15:16:35.246745Z","url":"https://files.pythonhosted.org/packages/8d/3a/bc1f99925e967977abb00f1df02ed14e6f89e19c7c19618d03adbed3f921/iTransformer-0.4.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.0":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.5.0/","requires_dist":["beartype","einops >=0.7.0","gateloop-transformer >=0.5.1","rotary-embedding-torch","torch >=1.6"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.5.0","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"2f355f4790c6467669a64e74377af3e8f4388ec6b6b65e5748bfb7b1c1765b16","md5":"3594b403a212c10a2c771d3b3432be56","sha256":"2f33a93b79f2791569643187d19c97e9f9f5fe90f453f1b4bc96eb2b0655341f"},"downloads":-1,"filename":"iTransformer-0.5.0-py3-none-any.whl","has_sig":false,"md5_digest":"3594b403a212c10a2c771d3b3432be56","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":14279,"upload_time":"2023-12-21T19:21:24","upload_time_iso_8601":"2023-12-21T19:21:24.486757Z","url":"https://files.pythonhosted.org/packages/2f/35/5f4790c6467669a64e74377af3e8f4388ec6b6b65e5748bfb7b1c1765b16/iTransformer-0.5.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"c864aa4d5d6a4c0f47cadcad3d3464fb5b89012eaa06893d962814eaf68c57fc","md5":"c45d2cc3d454f293f8b50b8cb239e9b1","sha256":"820751656d3df28fe2ae4b6b9b981eb9e041818e053093bd7f9ce6b2c534cd15"},"downloads":-1,"filename":"iTransformer-0.5.0.tar.gz","has_sig":false,"md5_digest":"c45d2cc3d454f293f8b50b8cb239e9b1","packagetype":"sdist","python_version":"source","requires_python":null,"size":11193,"upload_time":"2023-12-21T19:21:25","upload_time_iso_8601":"2023-12-21T19:21:25.503262Z","url":"https://files.pythonhosted.org/packages/c8/64/aa4d5d6a4c0f47cadcad3d3464fb5b89012eaa06893d962814eaf68c57fc/iTransformer-0.5.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.1":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.5.1/","requires_dist":["beartype","einops >=0.7.0","gateloop-transformer >=0.5.1","rotary-embedding-torch","torch >=2.1"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.5.1","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"6a685542fa492ef45ac9876d238a1a52ac9ed1684185ff9a4e0392f0cf189ed9","md5":"63218fff459efad75645e511a746bbc7","sha256":"75bae0018f35e4fc2cd24ed619f18e569d96571b9b771559afb4ce4a5836fffc"},"downloads":-1,"filename":"iTransformer-0.5.1-py3-none-any.whl","has_sig":false,"md5_digest":"63218fff459efad75645e511a746bbc7","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":14275,"upload_time":"2023-12-21T19:24:24","upload_time_iso_8601":"2023-12-21T19:24:24.196897Z","url":"https://files.pythonhosted.org/packages/6a/68/5542fa492ef45ac9876d238a1a52ac9ed1684185ff9a4e0392f0cf189ed9/iTransformer-0.5.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"489958ebd4d9d8505c2d1041ab35701cf273f99048d0f2b56d1368131823f371","md5":"46ddf98f9decf59c7e8288531490a105","sha256":"ff504a9037876e6f5d4a99381568d03d99d559b5dc5861404ba4e2fe722eb12e"},"downloads":-1,"filename":"iTransformer-0.5.1.tar.gz","has_sig":false,"md5_digest":"46ddf98f9decf59c7e8288531490a105","packagetype":"sdist","python_version":"source","requires_python":null,"size":11247,"upload_time":"2023-12-21T19:24:25","upload_time_iso_8601":"2023-12-21T19:24:25.865567Z","url":"https://files.pythonhosted.org/packages/48/99/58ebd4d9d8505c2d1041ab35701cf273f99048d0f2b56d1368131823f371/iTransformer-0.5.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.2":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.5.2/","requires_dist":["beartype","einops >=0.7.0","gateloop-transformer >=0.5.1","rotary-embedding-torch","torch >=2.1"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.5.2","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"d88a736d6b61f9e91547e7896ad30a02a3d7175636b178dbba6eaca89b1454e1","md5":"c04d7e55226d128839688780b2ab81ba","sha256":"fb00b36b03f69e20f13590e6cfab26fe6d7a70fd358a23a8f2eec338e5571ccd"},"downloads":-1,"filename":"iTransformer-0.5.2-py3-none-any.whl","has_sig":false,"md5_digest":"c04d7e55226d128839688780b2ab81ba","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":14307,"upload_time":"2024-01-02T01:20:37","upload_time_iso_8601":"2024-01-02T01:20:37.796955Z","url":"https://files.pythonhosted.org/packages/d8/8a/736d6b61f9e91547e7896ad30a02a3d7175636b178dbba6eaca89b1454e1/iTransformer-0.5.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"18af6646aeb5c1dc3d41cd86f5db62aaddafc651883dfe8046cd09ffb6d66336","md5":"5b8a5e2b21016487a6c6c49d7bc81e89","sha256":"9525d0f747fd964b8d7067a4d4451ead412d027459d2d64152f58c02ca8822e6"},"downloads":-1,"filename":"iTransformer-0.5.2.tar.gz","has_sig":false,"md5_digest":"5b8a5e2b21016487a6c6c49d7bc81e89","packagetype":"sdist","python_version":"source","requires_python":null,"size":11280,"upload_time":"2024-01-02T01:20:39","upload_time_iso_8601":"2024-01-02T01:20:39.336198Z","url":"https://files.pythonhosted.org/packages/18/af/6646aeb5c1dc3d41cd86f5db62aaddafc651883dfe8046cd09ffb6d66336/iTransformer-0.5.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.3":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.5.3/","requires_dist":["beartype","einops >=0.7.0","gateloop-transformer >=0.5.1","rotary-embedding-torch","torch >=2.1"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.5.3","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"41bc29ca9c592766f7f32bb4d1c936fabaa33be3883d8787728684e0789e67ef","md5":"db8dff6f36c6a915a40e00011095e486","sha256":"b33b8d9ba84195c3875ebc3e3aeb8b213f179c6f25f074a3ac4a188b8852cb82"},"downloads":-1,"filename":"iTransformer-0.5.3-py3-none-any.whl","has_sig":false,"md5_digest":"db8dff6f36c6a915a40e00011095e486","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":12002,"upload_time":"2024-01-06T13:48:04","upload_time_iso_8601":"2024-01-06T13:48:04.705355Z","url":"https://files.pythonhosted.org/packages/41/bc/29ca9c592766f7f32bb4d1c936fabaa33be3883d8787728684e0789e67ef/iTransformer-0.5.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"38ad51bf7cab1af599d3085f81f1ebc0350bd385a0c87ad184bbf75bf8617a75","md5":"c5d52e427fa72757d4390c1cb6640ef7","sha256":"2c5a87bf8517b45ee9c18ec342b87513e94ddcf502148ae77d3a14dc367cd71e"},"downloads":-1,"filename":"iTransformer-0.5.3.tar.gz","has_sig":false,"md5_digest":"c5d52e427fa72757d4390c1cb6640ef7","packagetype":"sdist","python_version":"source","requires_python":null,"size":10743,"upload_time":"2024-01-06T13:48:06","upload_time_iso_8601":"2024-01-06T13:48:06.241229Z","url":"https://files.pythonhosted.org/packages/38/ad/51bf7cab1af599d3085f81f1ebc0350bd385a0c87ad184bbf75bf8617a75/iTransformer-0.5.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.4":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.5.4/","requires_dist":["beartype","einops >=0.7.0","gateloop-transformer >=0.2.3","rotary-embedding-torch","torch >=2.1"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.5.4","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"067309a1d5fd48db0cc14bfde8fa28abb857e103a4eac5b3a27c516a2c523b54","md5":"cd6e088ce3ea99d6187ffe141ea33bc5","sha256":"05a3cf6a84c2b8fec723ac327c9f118e775622af492cd7297f8f72d2eccca469"},"downloads":-1,"filename":"iTransformer-0.5.4-py3-none-any.whl","has_sig":false,"md5_digest":"cd6e088ce3ea99d6187ffe141ea33bc5","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":12004,"upload_time":"2024-01-08T14:39:15","upload_time_iso_8601":"2024-01-08T14:39:15.087233Z","url":"https://files.pythonhosted.org/packages/06/73/09a1d5fd48db0cc14bfde8fa28abb857e103a4eac5b3a27c516a2c523b54/iTransformer-0.5.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"de97aff936c9e195327cd69d67dac16e8e2d132edb0bcbbc6dc7c941355cc9e6","md5":"6414bb7cbc5e372bf7ff4fe4dca53092","sha256":"297e1c4329a5c7f0db73f10905b7185f44c4c9af95b5fabe616481a97dde1775"},"downloads":-1,"filename":"iTransformer-0.5.4.tar.gz","has_sig":false,"md5_digest":"6414bb7cbc5e372bf7ff4fe4dca53092","packagetype":"sdist","python_version":"source","requires_python":null,"size":10738,"upload_time":"2024-01-08T14:39:16","upload_time_iso_8601":"2024-01-08T14:39:16.923756Z","url":"https://files.pythonhosted.org/packages/de/97/aff936c9e195327cd69d67dac16e8e2d132edb0bcbbc6dc7c941355cc9e6/iTransformer-0.5.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.5":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,time series forecasting","license":"MIT","maintainer":"","maintainer_email":"","name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.5.5/","requires_dist":["beartype","einops >=0.7.0","gateloop-transformer >=0.2.3","rotary-embedding-torch","torch >=2.1"],"requires_python":"","summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.5.5","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"c3d5ecc18425de7895979c87f81c5be7bfd57ab0d930df00aa6424e90f86063a","md5":"b7e229c4ea258a2c4438e979457beb48","sha256":"dccca25f466bb834405134d8d40c7a5b85739b0436a29a420800bbbcc2803021"},"downloads":-1,"filename":"iTransformer-0.5.5-py3-none-any.whl","has_sig":false,"md5_digest":"b7e229c4ea258a2c4438e979457beb48","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":11983,"upload_time":"2024-01-30T16:38:04","upload_time_iso_8601":"2024-01-30T16:38:04.917077Z","url":"https://files.pythonhosted.org/packages/c3/d5/ecc18425de7895979c87f81c5be7bfd57ab0d930df00aa6424e90f86063a/iTransformer-0.5.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"927f09b93edc29cd446f1569e9cf76e24a5b9b29f1fbea4fa14e6b3b25498b8f","md5":"5fb6b6aa497caae971e9bad7875aa6ac","sha256":"b1241e99f335a08ce99ad86d416e2f645fe002301d6976ae7a8ca66b210a66f7"},"downloads":-1,"filename":"iTransformer-0.5.5.tar.gz","has_sig":false,"md5_digest":"5fb6b6aa497caae971e9bad7875aa6ac","packagetype":"sdist","python_version":"source","requires_python":null,"size":10720,"upload_time":"2024-01-30T16:38:06","upload_time_iso_8601":"2024-01-30T16:38:06.448569Z","url":"https://files.pythonhosted.org/packages/92/7f/09b93edc29cd446f1569e9cf76e24a5b9b29f1fbea4fa14e6b3b25498b8f/iTransformer-0.5.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.6.0":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/iTransformer","keywords":"artificial intelligence, deep learning, transformers, attention mechanism, time series forecasting","license":"MIT","maintainer":null,"maintainer_email":null,"name":"iTransformer","package_url":"https://pypi.org/project/iTransformer/","platform":null,"project_url":"https://pypi.org/project/iTransformer/","project_urls":{"Homepage":"https://github.com/lucidrains/iTransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/iTransformer/0.6.0/","requires_dist":["beartype","einops>=0.7.0","gateloop-transformer>=0.2.3","rotary-embedding-torch","torch>=2.1"],"requires_python":null,"summary":"iTransformer - Inverted Transformer Are Effective for Time Series Forecasting","version":"0.6.0","yanked":false,"yanked_reason":null},"last_serial":23148083,"urls":[{"comment_text":"","digests":{"blake2b_256":"3468190ba2a385bfe863076c261d876d457b779287b2c14bc368d4ff325a7808","md5":"b9939156db8f14fbfee14a88cf01e08b","sha256":"e456a9f2202da9d94382267db4e85a2fd919d6d458e5d9e0fc4a67bfc5d969a3"},"downloads":-1,"filename":"iTransformer-0.6.0-py3-none-any.whl","has_sig":false,"md5_digest":"b9939156db8f14fbfee14a88cf01e08b","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":12012,"upload_time":"2024-05-10T14:33:22","upload_time_iso_8601":"2024-05-10T14:33:22.511155Z","url":"https://files.pythonhosted.org/packages/34/68/190ba2a385bfe863076c261d876d457b779287b2c14bc368d4ff325a7808/iTransformer-0.6.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"c6830fd5d01498c0165755b9b4cebdfbcb8ce555bc25bc1238bd378a633155de","md5":"3e41d0f9b0d01c7f45db1b41d82687e9","sha256":"04c6d1ffb6138fba5c679943bace12e7e0cee163fb653566ebd6dbcd965fd05c"},"downloads":-1,"filename":"itransformer-0.6.0.tar.gz","has_sig":false,"md5_digest":"3e41d0f9b0d01c7f45db1b41d82687e9","packagetype":"sdist","python_version":"source","requires_python":null,"size":10738,"upload_time":"2024-05-10T14:33:23","upload_time_iso_8601":"2024-05-10T14:33:23.742182Z","url":"https://files.pythonhosted.org/packages/c6/83/0fd5d01498c0165755b9b4cebdfbcb8ce555bc25bc1238bd378a633155de/itransformer-0.6.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}