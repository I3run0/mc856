{"0.2.1":{"info":{"author":"vLLM Team","author_email":"","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/vllm-project/vllm","keywords":"","license":"Apache 2.0","maintainer":"","maintainer_email":"","name":"vllm-consul","package_url":"https://pypi.org/project/vllm-consul/","platform":null,"project_url":"https://pypi.org/project/vllm-consul/","project_urls":{"Documentation":"https://vllm.readthedocs.io/en/latest/","Homepage":"https://github.com/vllm-project/vllm"},"provides_extra":null,"release_url":"https://pypi.org/project/vllm-consul/0.2.1/","requires_dist":["ninja","psutil","ray >=2.5.1","pandas","pyarrow","sentencepiece","numpy","torch ==2.0.1","transformers >=4.34.0","xformers ==0.0.22","fastapi","uvicorn[standard]","pydantic ==1.10.13","python-consul","fschat","python-json-logger"],"requires_python":">=3.8","summary":"A high-throughput and memory-efficient inference and serving engine for LLMs","version":"0.2.1","yanked":false,"yanked_reason":null},"last_serial":20396431,"urls":[{"comment_text":"","digests":{"blake2b_256":"d9097636945dd6cfa55f5b1b77cf8ac1233ef1ba715166a037a1e4cc16b4cfbe","md5":"6a32c0cca46ff40fca7363ee8508a1b9","sha256":"fb0c8e9c8d9eff4fe42e8a0bb8484e602e0ec482eb5c027fa86fbfe62f259683"},"downloads":-1,"filename":"vllm_consul-0.2.1-cp310-cp310-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"6a32c0cca46ff40fca7363ee8508a1b9","packagetype":"bdist_wheel","python_version":"cp310","requires_python":">=3.8","size":23281152,"upload_time":"2023-10-26T07:04:38","upload_time_iso_8601":"2023-10-26T07:04:38.947394Z","url":"https://files.pythonhosted.org/packages/d9/09/7636945dd6cfa55f5b1b77cf8ac1233ef1ba715166a037a1e4cc16b4cfbe/vllm_consul-0.2.1-cp310-cp310-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"bc32a915ac0357694ceb99bd17444f2188592eee6bbfc7d9c411a30731881368","md5":"85861e69a0844f4d3a448df5761f4271","sha256":"68e1317515330f10b0b376b74de5d27e57e91d0f16eafd30e0d2ed2fbfc723ef"},"downloads":-1,"filename":"vllm-consul-0.2.1.tar.gz","has_sig":false,"md5_digest":"85861e69a0844f4d3a448df5761f4271","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":133417,"upload_time":"2023-10-26T07:04:42","upload_time_iso_8601":"2023-10-26T07:04:42.577253Z","url":"https://files.pythonhosted.org/packages/bc/32/a915ac0357694ceb99bd17444f2188592eee6bbfc7d9c411a30731881368/vllm-consul-0.2.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.1.dev1":{"info":{"author":"vLLM Team","author_email":"","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/vllm-project/vllm","keywords":"","license":"Apache 2.0","maintainer":"","maintainer_email":"","name":"vllm-consul","package_url":"https://pypi.org/project/vllm-consul/","platform":null,"project_url":"https://pypi.org/project/vllm-consul/","project_urls":{"Documentation":"https://vllm.readthedocs.io/en/latest/","Homepage":"https://github.com/vllm-project/vllm"},"provides_extra":null,"release_url":"https://pypi.org/project/vllm-consul/0.2.1.dev1/","requires_dist":["ninja","psutil","ray >=2.5.1","pandas","pyarrow","sentencepiece","numpy","torch ==2.0.1","transformers >=4.34.0","xformers ==0.0.22","fastapi","uvicorn[standard]","pydantic ==1.10.13","python-consul","fschat","python-json-logger"],"requires_python":">=3.8","summary":"A high-throughput and memory-efficient inference and serving engine for LLMs","version":"0.2.1.dev1","yanked":false,"yanked_reason":null},"last_serial":20396431,"urls":[{"comment_text":"","digests":{"blake2b_256":"d624d7d9730403a59911325daf8c1d42badcd76c7e1106ac2611bdf386a987ec","md5":"274a863fe3b31aeb55cbbc53c848d32c","sha256":"a708b5a916644e80647a9c54033ca541f1a2401e22bef1c7edf4ab26b333f1d2"},"downloads":-1,"filename":"vllm_consul-0.2.1.dev1-cp310-cp310-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"274a863fe3b31aeb55cbbc53c848d32c","packagetype":"bdist_wheel","python_version":"cp310","requires_python":">=3.8","size":23281482,"upload_time":"2023-10-26T09:00:44","upload_time_iso_8601":"2023-10-26T09:00:44.031709Z","url":"https://files.pythonhosted.org/packages/d6/24/d7d9730403a59911325daf8c1d42badcd76c7e1106ac2611bdf386a987ec/vllm_consul-0.2.1.dev1-cp310-cp310-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"eadd8f394059f15e0c46a861fc0d82c34988f79e65d6e3dca0889962667a19c5","md5":"b00eb25fb88f97f02513915979cf6b55","sha256":"39b21db13c92812a387627e7dc0abcd25a25a21b69ba9ae98bde489691929f9a"},"downloads":-1,"filename":"vllm-consul-0.2.1.dev1.tar.gz","has_sig":false,"md5_digest":"b00eb25fb88f97f02513915979cf6b55","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":133496,"upload_time":"2023-10-26T09:00:47","upload_time_iso_8601":"2023-10-26T09:00:47.548295Z","url":"https://files.pythonhosted.org/packages/ea/dd/8f394059f15e0c46a861fc0d82c34988f79e65d6e3dca0889962667a19c5/vllm-consul-0.2.1.dev1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.1.dev2":{"info":{"author":"vLLM Team","author_email":"","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/vllm-project/vllm","keywords":"","license":"Apache 2.0","maintainer":"","maintainer_email":"","name":"vllm-consul","package_url":"https://pypi.org/project/vllm-consul/","platform":null,"project_url":"https://pypi.org/project/vllm-consul/","project_urls":{"Documentation":"https://vllm.readthedocs.io/en/latest/","Homepage":"https://github.com/vllm-project/vllm"},"provides_extra":null,"release_url":"https://pypi.org/project/vllm-consul/0.2.1.dev2/","requires_dist":["ninja","psutil","ray >=2.5.1","pandas","pyarrow","sentencepiece","numpy","torch ==2.0.1","transformers >=4.34.0","xformers ==0.0.22","fastapi","uvicorn[standard]","pydantic ==1.10.13","python-consul","fschat","python-json-logger"],"requires_python":">=3.8","summary":"A high-throughput and memory-efficient inference and serving engine for LLMs","version":"0.2.1.dev2","yanked":false,"yanked_reason":null},"last_serial":20396431,"urls":[{"comment_text":"","digests":{"blake2b_256":"98be7b1167bb45112ea6f4999f8c3ad78686766ea958f17d5f0ad9401d79e0fe","md5":"fb3bb81736a2e3aa561199ad199bd889","sha256":"94b4298edfa0e9ee544668f8b3403ac3379a4da9cd43da972a6bee57dbbe89eb"},"downloads":-1,"filename":"vllm_consul-0.2.1.dev2-cp310-cp310-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"fb3bb81736a2e3aa561199ad199bd889","packagetype":"bdist_wheel","python_version":"cp310","requires_python":">=3.8","size":23281472,"upload_time":"2023-10-26T09:32:03","upload_time_iso_8601":"2023-10-26T09:32:03.824116Z","url":"https://files.pythonhosted.org/packages/98/be/7b1167bb45112ea6f4999f8c3ad78686766ea958f17d5f0ad9401d79e0fe/vllm_consul-0.2.1.dev2-cp310-cp310-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d4a7f060995ad6298023adc284d479e64764197c8f496131d6da1c96cf82a85b","md5":"3539d991d60a794ad8eab6674a49ff69","sha256":"191f360c1dcbd560d454993f3b920515d08f0dfeef3061e1753e159ab410d385"},"downloads":-1,"filename":"vllm-consul-0.2.1.dev2.tar.gz","has_sig":false,"md5_digest":"3539d991d60a794ad8eab6674a49ff69","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":133502,"upload_time":"2023-10-26T09:32:07","upload_time_iso_8601":"2023-10-26T09:32:07.102829Z","url":"https://files.pythonhosted.org/packages/d4/a7/f060995ad6298023adc284d479e64764197c8f496131d6da1c96cf82a85b/vllm-consul-0.2.1.dev2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.1.dev4":{"info":{"author":"vLLM Team","author_email":"","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/vllm-project/vllm","keywords":"","license":"Apache 2.0","maintainer":"","maintainer_email":"","name":"vllm-consul","package_url":"https://pypi.org/project/vllm-consul/","platform":null,"project_url":"https://pypi.org/project/vllm-consul/","project_urls":{"Documentation":"https://vllm.readthedocs.io/en/latest/","Homepage":"https://github.com/vllm-project/vllm"},"provides_extra":null,"release_url":"https://pypi.org/project/vllm-consul/0.2.1.dev4/","requires_dist":["ninja","psutil","ray >=2.5.1","pandas","pyarrow","sentencepiece","numpy","torch ==2.0.1","transformers >=4.34.0","xformers ==0.0.22","fastapi","uvicorn[standard]","pydantic ==1.10.13","python-consul","fschat","python-json-logger"],"requires_python":">=3.8","summary":"A high-throughput and memory-efficient inference and serving engine for LLMs","version":"0.2.1.dev4","yanked":false,"yanked_reason":null},"last_serial":20396431,"urls":[{"comment_text":"","digests":{"blake2b_256":"360c8856909c8e400ccd61eda114fb6beb4cbad36645ad77643a61ed33a92d7d","md5":"8f0e2c091b05ab4b8473328e4011a728","sha256":"1f9dde5c18314cbd8b4c6b05f8944643d0545ea6d676e7ee0801eb8d6fe10984"},"downloads":-1,"filename":"vllm_consul-0.2.1.dev4-cp310-cp310-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"8f0e2c091b05ab4b8473328e4011a728","packagetype":"bdist_wheel","python_version":"cp310","requires_python":">=3.8","size":28688226,"upload_time":"2023-10-30T06:24:59","upload_time_iso_8601":"2023-10-30T06:24:59.659312Z","url":"https://files.pythonhosted.org/packages/36/0c/8856909c8e400ccd61eda114fb6beb4cbad36645ad77643a61ed33a92d7d/vllm_consul-0.2.1.dev4-cp310-cp310-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.1.dev5":{"info":{"author":"vLLM Team","author_email":"","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/vllm-project/vllm","keywords":"","license":"Apache 2.0","maintainer":"","maintainer_email":"","name":"vllm-consul","package_url":"https://pypi.org/project/vllm-consul/","platform":null,"project_url":"https://pypi.org/project/vllm-consul/","project_urls":{"Documentation":"https://vllm.readthedocs.io/en/latest/","Homepage":"https://github.com/vllm-project/vllm"},"provides_extra":null,"release_url":"https://pypi.org/project/vllm-consul/0.2.1.dev5/","requires_dist":["ninja","psutil","ray >=2.5.1","pandas","pyarrow","sentencepiece","numpy","torch ==2.0.1","transformers >=4.34.0","xformers ==0.0.22","fastapi","uvicorn[standard]","pydantic ==1.10.13","python-consul","fschat","python-json-logger"],"requires_python":">=3.8","summary":"A high-throughput and memory-efficient inference and serving engine for LLMs","version":"0.2.1.dev5","yanked":false,"yanked_reason":null},"last_serial":20396431,"urls":[{"comment_text":"","digests":{"blake2b_256":"21930b1d18b242a1431b4de7e1459a4b304e393fc690d1eedd28a8a41f52052b","md5":"1a820fa00a355c0de0686c994a392376","sha256":"8e00ae85084d286d2d6fb4c27083b05de5e7e10215788c0eb865bf57c80cb08a"},"downloads":-1,"filename":"vllm_consul-0.2.1.dev5-cp310-cp310-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"1a820fa00a355c0de0686c994a392376","packagetype":"bdist_wheel","python_version":"cp310","requires_python":">=3.8","size":28677017,"upload_time":"2023-10-30T12:46:50","upload_time_iso_8601":"2023-10-30T12:46:50.077707Z","url":"https://files.pythonhosted.org/packages/21/93/0b1d18b242a1431b4de7e1459a4b304e393fc690d1eedd28a8a41f52052b/vllm_consul-0.2.1.dev5-cp310-cp310-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}