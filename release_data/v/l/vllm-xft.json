{"0.3.3.0":{"info":{"author":"vLLM Team","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/vllm-project/vllm","keywords":null,"license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"vllm-xft","package_url":"https://pypi.org/project/vllm-xft/","platform":null,"project_url":"https://pypi.org/project/vllm-xft/","project_urls":{"Documentation":"https://vllm.readthedocs.io/en/latest/","Homepage":"https://github.com/vllm-project/vllm"},"provides_extra":null,"release_url":"https://pypi.org/project/vllm-xft/0.3.3.0/","requires_dist":["transformers>=4.38.0","fastapi","uvicorn[standard]","prometheus-client>=0.18.0","xfastertransformer"],"requires_python":">=3.8","summary":"A high-throughput and memory-efficient inference and serving engine for LLMs","version":"0.3.3.0","yanked":false,"yanked_reason":null},"last_serial":24788754,"urls":[{"comment_text":"","digests":{"blake2b_256":"319c15f6f0e14fdcb2134c6c78f0f0c409719631c60a6024543453d7183b704d","md5":"187bb6df6fde3313173be34051a5fb4c","sha256":"5bc6e7aaa4841dab0f74467f660098a0ff193e4722df81bc6201fd5d23ee7d38"},"downloads":-1,"filename":"vllm_xft-0.3.3.0-py3-none-any.whl","has_sig":false,"md5_digest":"187bb6df6fde3313173be34051a5fb4c","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":318761,"upload_time":"2024-03-29T05:29:00","upload_time_iso_8601":"2024-03-29T05:29:00.788065Z","url":"https://files.pythonhosted.org/packages/31/9c/15f6f0e14fdcb2134c6c78f0f0c409719631c60a6024543453d7183b704d/vllm_xft-0.3.3.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.3.1":{"info":{"author":"vLLM Team","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/vllm-project/vllm","keywords":null,"license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"vllm-xft","package_url":"https://pypi.org/project/vllm-xft/","platform":null,"project_url":"https://pypi.org/project/vllm-xft/","project_urls":{"Documentation":"https://vllm.readthedocs.io/en/latest/","Homepage":"https://github.com/vllm-project/vllm"},"provides_extra":null,"release_url":"https://pypi.org/project/vllm-xft/0.3.3.1/","requires_dist":["transformers>=4.38.0","fastapi","uvicorn[standard]","prometheus-client>=0.18.0","xfastertransformer"],"requires_python":">=3.8","summary":"A high-throughput and memory-efficient inference and serving engine for LLMs","version":"0.3.3.1","yanked":false,"yanked_reason":null},"last_serial":24788754,"urls":[{"comment_text":"","digests":{"blake2b_256":"c211ddb91e8ecce33230b542cdec888bc3e0d98a7a0ce5758700b09107e55470","md5":"0a814de5cb262f6af5b9a798e350cd97","sha256":"90498fbfea099ba384b47974053181d4be597b975b3779c1503e747f102cbdf1"},"downloads":-1,"filename":"vllm_xft-0.3.3.1-py3-none-any.whl","has_sig":false,"md5_digest":"0a814de5cb262f6af5b9a798e350cd97","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":318993,"upload_time":"2024-05-10T06:07:44","upload_time_iso_8601":"2024-05-10T06:07:44.069340Z","url":"https://files.pythonhosted.org/packages/c2/11/ddb91e8ecce33230b542cdec888bc3e0d98a7a0ce5758700b09107e55470/vllm_xft-0.3.3.1-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.2.0":{"info":{"author":"vLLM Team","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/vllm-project/vllm","keywords":null,"license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"vllm-xft","package_url":"https://pypi.org/project/vllm-xft/","platform":null,"project_url":"https://pypi.org/project/vllm-xft/","project_urls":{"Documentation":"https://vllm.readthedocs.io/en/latest/","Homepage":"https://github.com/vllm-project/vllm"},"provides_extra":["tensorizer"],"release_url":"https://pypi.org/project/vllm-xft/0.4.2.0/","requires_dist":["cmake>=3.21","ninja","psutil","sentencepiece","numpy","requests","py-cpuinfo","transformers>=4.40.0","tokenizers>=0.19.1","fastapi","openai","uvicorn[standard]","pydantic>=2.0","prometheus-client>=0.18.0","prometheus-fastapi-instrumentator>=7.0.0","tiktoken==0.6.0","lm-format-enforcer==0.9.8","outlines==0.0.34","typing-extensions","filelock>=3.10.4","triton>=2.2.0","xfastertransformer>1.6.0","tensorizer==2.9.0; extra == \"tensorizer\""],"requires_python":">=3.8","summary":"A high-throughput and memory-efficient inference and serving engine for LLMs","version":"0.4.2.0","yanked":false,"yanked_reason":null},"last_serial":24788754,"urls":[{"comment_text":"","digests":{"blake2b_256":"ce10ebb79e8921a14562035d2e51e0bef9c5a94a30e21a70a55ae71e8d635619","md5":"b751877fd708154a116662a32f4ab8a2","sha256":"0df2f59ae97a4eaf90c5e63410ba2966f4aafd10a0ea62503ace62945d9306b5"},"downloads":-1,"filename":"vllm_xft-0.4.2.0-py3-none-any.whl","has_sig":false,"md5_digest":"b751877fd708154a116662a32f4ab8a2","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":522743,"upload_time":"2024-06-05T01:38:39","upload_time_iso_8601":"2024-06-05T01:38:39.840839Z","url":"https://files.pythonhosted.org/packages/ce/10/ebb79e8921a14562035d2e51e0bef9c5a94a30e21a70a55ae71e8d635619/vllm_xft-0.4.2.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.2.1":{"info":{"author":"vLLM Team","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/vllm-project/vllm","keywords":null,"license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"vllm-xft","package_url":"https://pypi.org/project/vllm-xft/","platform":null,"project_url":"https://pypi.org/project/vllm-xft/","project_urls":{"Documentation":"https://vllm.readthedocs.io/en/latest/","Homepage":"https://github.com/vllm-project/vllm"},"provides_extra":["tensorizer"],"release_url":"https://pypi.org/project/vllm-xft/0.4.2.1/","requires_dist":["cmake>=3.21","ninja","psutil","sentencepiece","numpy","requests","py-cpuinfo","transformers>=4.40.0","tokenizers>=0.19.1","fastapi","openai","uvicorn[standard]","pydantic>=2.0","prometheus-client>=0.18.0","prometheus-fastapi-instrumentator>=7.0.0","tiktoken==0.6.0","lm-format-enforcer==0.9.8","outlines==0.0.34","typing-extensions","filelock>=3.10.4","triton>=2.2.0","xfastertransformer>1.6.0","tensorizer==2.9.0; extra == \"tensorizer\""],"requires_python":">=3.8","summary":"A high-throughput and memory-efficient inference and serving engine for LLMs","version":"0.4.2.1","yanked":false,"yanked_reason":null},"last_serial":24788754,"urls":[{"comment_text":"","digests":{"blake2b_256":"40e1e17f8f3f60d60dc38e51ebba4eeb56293bb09d59c0feba5139d5889b4c1c","md5":"2e6bfdea9f2ba3d0036c5f09d326bad6","sha256":"230732acff4996a7e6a7f2cab0267fd2817af9cf3b126eda5150af1577baa3c4"},"downloads":-1,"filename":"vllm_xft-0.4.2.1-py3-none-any.whl","has_sig":false,"md5_digest":"2e6bfdea9f2ba3d0036c5f09d326bad6","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":522743,"upload_time":"2024-06-24T05:31:21","upload_time_iso_8601":"2024-06-24T05:31:21.014496Z","url":"https://files.pythonhosted.org/packages/40/e1/e17f8f3f60d60dc38e51ebba4eeb56293bb09d59c0feba5139d5889b4c1c/vllm_xft-0.4.2.1-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.2.2":{"info":{"author":"vLLM Team","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/vllm-project/vllm","keywords":null,"license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"vllm-xft","package_url":"https://pypi.org/project/vllm-xft/","platform":null,"project_url":"https://pypi.org/project/vllm-xft/","project_urls":{"Documentation":"https://vllm.readthedocs.io/en/latest/","Homepage":"https://github.com/vllm-project/vllm"},"provides_extra":["tensorizer"],"release_url":"https://pypi.org/project/vllm-xft/0.4.2.2/","requires_dist":["cmake>=3.21","ninja","psutil","sentencepiece","numpy","requests","py-cpuinfo","transformers>=4.40.0","tokenizers>=0.19.1","fastapi","openai","uvicorn[standard]","pydantic>=2.0","prometheus-client>=0.18.0","prometheus-fastapi-instrumentator>=7.0.0","tiktoken==0.6.0","lm-format-enforcer==0.9.8","outlines==0.0.34","typing-extensions","filelock>=3.10.4","triton>=2.2.0","xfastertransformer>1.6.0","tensorizer==2.9.0; extra == \"tensorizer\""],"requires_python":">=3.8","summary":"A high-throughput and memory-efficient inference and serving engine for LLMs","version":"0.4.2.2","yanked":false,"yanked_reason":null},"last_serial":24788754,"urls":[{"comment_text":"","digests":{"blake2b_256":"a9c4d3b0730cb3dfdc9d5e49c082023a28180339d6e432e53b8050f8cde88e97","md5":"e200b0c68f907ba702e54864c7219356","sha256":"044a741ceea532d1e16de89d29a087a91be18e1563657d1340b80dfcfbd36bdc"},"downloads":-1,"filename":"vllm_xft-0.4.2.2-py3-none-any.whl","has_sig":false,"md5_digest":"e200b0c68f907ba702e54864c7219356","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":522650,"upload_time":"2024-07-04T07:16:02","upload_time_iso_8601":"2024-07-04T07:16:02.763781Z","url":"https://files.pythonhosted.org/packages/a9/c4/d3b0730cb3dfdc9d5e49c082023a28180339d6e432e53b8050f8cde88e97/vllm_xft-0.4.2.2-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.3.0":{"info":{"author":"vLLM Team","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/vllm-project/vllm","keywords":null,"license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"vllm-xft","package_url":"https://pypi.org/project/vllm-xft/","platform":null,"project_url":"https://pypi.org/project/vllm-xft/","project_urls":{"Documentation":"https://vllm.readthedocs.io/en/latest/","Homepage":"https://github.com/vllm-project/vllm"},"provides_extra":["tensorizer"],"release_url":"https://pypi.org/project/vllm-xft/0.5.3.0/","requires_dist":["cmake>=3.21","ninja","psutil","sentencepiece","numpy<2.0.0","requests","tqdm","py-cpuinfo","transformers>=4.42.4","tokenizers>=0.19.1","fastapi","aiohttp","openai","uvicorn[standard]","pydantic>=2.0","pillow","prometheus-client>=0.18.0","prometheus-fastapi-instrumentator>=7.0.0","tiktoken>=0.6.0","lm-format-enforcer==0.10.3","outlines<0.1,>=0.0.43","typing-extensions","filelock>=3.10.4","pyzmq","triton>=2.2.0","xfastertransformer>=1.8.0","tensorizer>=2.9.0; extra == \"tensorizer\""],"requires_python":">=3.8","summary":"A high-throughput and memory-efficient inference and serving engine for LLMs","version":"0.5.3.0","yanked":false,"yanked_reason":null},"last_serial":24788754,"urls":[{"comment_text":"","digests":{"blake2b_256":"91ec629a9c124dff11187b335d5092af8c9a45c1ec055322cd80926218d06718","md5":"9e22fffdf14e4cdb639adfb0d68992d1","sha256":"7db4434509d953a95e4666fe4270d30adc986078ae577441d2a333e125bdc645"},"downloads":-1,"filename":"vllm_xft-0.5.3.0-py3-none-any.whl","has_sig":false,"md5_digest":"9e22fffdf14e4cdb639adfb0d68992d1","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":896522,"upload_time":"2024-07-29T07:40:04","upload_time_iso_8601":"2024-07-29T07:40:04.159672Z","url":"https://files.pythonhosted.org/packages/91/ec/629a9c124dff11187b335d5092af8c9a45c1ec055322cd80926218d06718/vllm_xft-0.5.3.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.3.1":{"info":{"author":"vLLM Team","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/vllm-project/vllm","keywords":null,"license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"vllm-xft","package_url":"https://pypi.org/project/vllm-xft/","platform":null,"project_url":"https://pypi.org/project/vllm-xft/","project_urls":{"Documentation":"https://vllm.readthedocs.io/en/latest/","Homepage":"https://github.com/vllm-project/vllm"},"provides_extra":["tensorizer"],"release_url":"https://pypi.org/project/vllm-xft/0.5.3.1/","requires_dist":["cmake>=3.21","ninja","psutil","sentencepiece","numpy<2.0.0","requests","tqdm","py-cpuinfo","transformers>=4.42.4","tokenizers>=0.19.1","fastapi","aiohttp","openai","uvicorn[standard]","pydantic>=2.0","pillow","prometheus-client>=0.18.0","prometheus-fastapi-instrumentator>=7.0.0","tiktoken>=0.6.0","lm-format-enforcer==0.10.3","outlines<0.1,>=0.0.43","typing-extensions","filelock>=3.10.4","pyzmq","xfastertransformer>=1.8.0","tensorizer>=2.9.0; extra == \"tensorizer\""],"requires_python":">=3.8","summary":"A high-throughput and memory-efficient inference and serving engine for LLMs","version":"0.5.3.1","yanked":false,"yanked_reason":null},"last_serial":24788754,"urls":[{"comment_text":"","digests":{"blake2b_256":"f6d3fdae50bbe2ab3a7c4f5f49b6f31943c0062147383c7f96f3b141e51583a4","md5":"310b7050013aa0ecf679fea325a6fd81","sha256":"74d40ac3c4ec834633aafa5db92967ca61f587dc7c56764ac97a9ecd05537bd1"},"downloads":-1,"filename":"vllm_xft-0.5.3.1-py3-none-any.whl","has_sig":false,"md5_digest":"310b7050013aa0ecf679fea325a6fd81","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":897337,"upload_time":"2024-08-01T07:01:16","upload_time_iso_8601":"2024-08-01T07:01:16.991920Z","url":"https://files.pythonhosted.org/packages/f6/d3/fdae50bbe2ab3a7c4f5f49b6f31943c0062147383c7f96f3b141e51583a4/vllm_xft-0.5.3.1-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.5.0":{"info":{"author":"vLLM Team","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/vllm-project/vllm","keywords":null,"license":"Apache 2.0","maintainer":null,"maintainer_email":null,"name":"vllm-xft","package_url":"https://pypi.org/project/vllm-xft/","platform":null,"project_url":"https://pypi.org/project/vllm-xft/","project_urls":{"Documentation":"https://vllm.readthedocs.io/en/latest/","Homepage":"https://github.com/vllm-project/vllm"},"provides_extra":["tensorizer"],"release_url":"https://pypi.org/project/vllm-xft/0.5.5.0/","requires_dist":["psutil","sentencepiece","numpy<2.0.0","requests","tqdm","py-cpuinfo","transformers>=4.43.2","tokenizers>=0.19.1","protobuf","fastapi","aiohttp","openai>=1.0","uvicorn[standard]","pydantic>=2.8","pillow","prometheus-client>=0.18.0","prometheus-fastapi-instrumentator>=7.0.0","tiktoken>=0.6.0","lm-format-enforcer==0.10.6","outlines<0.1,>=0.0.43","typing-extensions>=4.10","filelock>=3.10.4","pyzmq","msgspec","librosa","soundfile","gguf==0.9.1","importlib-metadata","xfastertransformer>=1.8.0","tensorizer>=2.9.0; extra == \"tensorizer\""],"requires_python":">=3.8","summary":"A high-throughput and memory-efficient inference and serving engine for LLMs","version":"0.5.5.0","yanked":false,"yanked_reason":null},"last_serial":24788754,"urls":[{"comment_text":"","digests":{"blake2b_256":"65a7ba9d06d827320dbb07d5bff91d02420dfd4138dc89992c80b3af79fe6a09","md5":"d67854c57e0fbce6ca79d7ac730ebd97","sha256":"65a120bdfa8e581ed45218b8bf5cbd75f317e56bd5610fa3a938cdbe0bb386fb"},"downloads":-1,"filename":"vllm_xft-0.5.5.0-py3-none-any.whl","has_sig":false,"md5_digest":"d67854c57e0fbce6ca79d7ac730ebd97","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":1108142,"upload_time":"2024-08-29T08:38:30","upload_time_iso_8601":"2024-08-29T08:38:30.163127Z","url":"https://files.pythonhosted.org/packages/65/a7/ba9d06d827320dbb07d5bff91d02420dfd4138dc89992c80b3af79fe6a09/vllm_xft-0.5.5.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}