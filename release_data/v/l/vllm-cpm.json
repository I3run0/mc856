{"0.2.2":{"info":{"author":"ModelBest Inc.","author_email":"","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"Apache 2.0","maintainer":"","maintainer_email":"","name":"vllm-cpm","package_url":"https://pypi.org/project/vllm-cpm/","platform":null,"project_url":"https://pypi.org/project/vllm-cpm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/vllm-cpm/0.2.2/","requires_dist":["ninja","psutil","ray>=2.5.1","pandas","pyarrow","sentencepiece","numpy","einops","torch>=2.1.0","transformers>=4.34.0","xformers>=0.0.22.post7","fastapi","uvicorn[standard]","pydantic==1.10.13"],"requires_python":">=3.8","summary":"A high-throughput and memory-efficient inference and serving engine for LLMs","version":"0.2.2","yanked":false,"yanked_reason":null},"last_serial":21676418,"urls":[{"comment_text":"","digests":{"blake2b_256":"23b1669c089fb2d3f3e257fdcb73bf8682e9e91ca6a4e0ecd2614cd7e57a64bb","md5":"7c8506abc79c81015cc5592effa488aa","sha256":"52d98511273274c9cc2d02f9e73db5755f5b50ea55b29968695fff7f483194a2"},"downloads":-1,"filename":"vllm-cpm-0.2.2.tar.gz","has_sig":false,"md5_digest":"7c8506abc79c81015cc5592effa488aa","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":149617,"upload_time":"2024-01-31T19:12:15","upload_time_iso_8601":"2024-01-31T19:12:15.434003Z","url":"https://files.pythonhosted.org/packages/23/b1/669c089fb2d3f3e257fdcb73bf8682e9e91ca6a4e0ecd2614cd7e57a64bb/vllm-cpm-0.2.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}