{"0.0.0":{"info":{"author":"Jina AI","author_email":"hello@jina.ai","bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Environment :: Console","Intended Audience :: Developers","Intended Audience :: Education","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Programming Language :: Unix Shell","Topic :: Database :: Database Engines/Servers","Topic :: Internet :: WWW/HTTP :: Indexing/Search","Topic :: Multimedia :: Video","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Scientific/Engineering :: Mathematics","Topic :: Software Development","Topic :: Software Development :: Libraries","Topic :: Software Development :: Libraries :: Python Modules"],"description_content_type":"text/markdown","docs_url":null,"download_url":"https://github.com/jina-ai/clip-as-service/tags","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/jina-ai/clip-as-service","keywords":"jina openai clip deep-learning cross-modal multi-modal neural-search","license":"Apache 2.0","maintainer":"","maintainer_email":"","name":"v-clip-server","package_url":"https://pypi.org/project/v-clip-server/","platform":null,"project_url":"https://pypi.org/project/v-clip-server/","project_urls":{"Documentation":"https://clip-as-service.jina.ai","Download":"https://github.com/jina-ai/clip-as-service/tags","Homepage":"https://github.com/jina-ai/clip-as-service","Source":"https://github.com/jina-ai/clip-as-service/","Tracker":"https://github.com/jina-ai/clip-as-service/issues"},"provides_extra":null,"release_url":"https://pypi.org/project/v-clip-server/0.0.0/","requires_dist":["ftfy","torch","regex","torchvision","jina (>=3.12.0)","prometheus-client","open-clip-torch (>=2.7.0)","flash-attn ; extra == 'flash-attn'","onnxruntime ; extra == 'onnx'","onnx ; extra == 'onnx'","onnxruntime-gpu (>=1.8.0) ; extra == 'onnx'","annlite (>=0.3.10) ; extra == 'search'","nvidia-tensorrt ; extra == 'tensorrt'","transformers (>=4.16.2) ; extra == 'transformers'"],"requires_python":"","summary":"Embed images and sentences into fixed-length vectors via CLIP","version":"0.0.0","yanked":false,"yanked_reason":null},"last_serial":15983267,"urls":[{"comment_text":"","digests":{"blake2b_256":"715d82d6fffa235002b9a87c2b2bc5da8ffeab175b1a840cc0d153ce5103c877","md5":"7e9646a61501141051ece0e961743687","sha256":"400c938d404a047be7aef706115ba44c25a7e75f6b30b5ae76f4a12dbabb74b1"},"downloads":-1,"filename":"v_clip_server-0.0.0-py3-none-any.whl","has_sig":false,"md5_digest":"7e9646a61501141051ece0e961743687","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":1402631,"upload_time":"2022-12-04T05:04:57","upload_time_iso_8601":"2022-12-04T05:04:57.479993Z","url":"https://files.pythonhosted.org/packages/71/5d/82d6fffa235002b9a87c2b2bc5da8ffeab175b1a840cc0d153ce5103c877/v_clip_server-0.0.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}