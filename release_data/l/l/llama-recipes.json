{"0.0.1":{"info":{"author":"","author_email":"Hamid Shojanazeri <hamidnazeri@meta.com>, Matthias Reso <mreso@meta.com>, Geeta Chauhan <gchauhan@meta.com>","bugtrack_url":null,"classifiers":["License :: Other/Proprietary License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"llama-recipes","package_url":"https://pypi.org/project/llama-recipes/","platform":null,"project_url":"https://pypi.org/project/llama-recipes/","project_urls":{"Bug Tracker":"https://github.com/facebookresearch/llama-recipes/issues","Homepage":"https://github.com/facebookresearch/llama-recipes/"},"provides_extra":null,"release_url":"https://pypi.org/project/llama-recipes/0.0.1/","requires_dist":["accelerate","appdirs","bitsandbytes","black","black[jupyter]","datasets","fire","loralib","optimum","peft","py7zr","scipy","sentencepiece","torch>=2.0.1","transformers>=4.31.0","auditnlg; extra == 'auditnlg'","pytest-mock; extra == 'tests'","vllm; extra == 'vllm'"],"requires_python":">=3.8","summary":"Llama-recipes is a companion project to the Llama 2 model. It's goal is to provide examples to quickly get started with fine-tuning for domain adaptation and how to run inference for the fine-tuned models.","version":"0.0.1","yanked":false,"yanked_reason":null},"last_serial":25212431,"urls":[{"comment_text":"","digests":{"blake2b_256":"724f897b16599a9fd3462412273db8094fc8192ddcb3a962fbbca0828cebbd0e","md5":"bbbef02fa2a55aa2ab128bb23fa080fe","sha256":"9a207fd5756fce25c56eda81af6f6c1d7e2a0f67bf575c6a44e0c9a6e7598e0b"},"downloads":-1,"filename":"llama_recipes-0.0.1-py3-none-any.whl","has_sig":false,"md5_digest":"bbbef02fa2a55aa2ab128bb23fa080fe","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":43842,"upload_time":"2023-09-06T23:17:15","upload_time_iso_8601":"2023-09-06T23:17:15.295191Z","url":"https://files.pythonhosted.org/packages/72/4f/897b16599a9fd3462412273db8094fc8192ddcb3a962fbbca0828cebbd0e/llama_recipes-0.0.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"acf0aab45d0834b777404d51b63a531b0006f1f5299dbe3f5b1dac5e4caef3da","md5":"f8cec3df8601de97a67b6604621c96ce","sha256":"59ea01099561d6f8707103d2c369618b4829c2b70c41def8eb3da1bf5004e9a0"},"downloads":-1,"filename":"llama_recipes-0.0.1.tar.gz","has_sig":false,"md5_digest":"f8cec3df8601de97a67b6604621c96ce","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":483919,"upload_time":"2023-09-06T23:17:17","upload_time_iso_8601":"2023-09-06T23:17:17.245387Z","url":"https://files.pythonhosted.org/packages/ac/f0/aab45d0834b777404d51b63a531b0006f1f5299dbe3f5b1dac5e4caef3da/llama_recipes-0.0.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.2":{"info":{"author":null,"author_email":"Hamid Shojanazeri <hamidnazeri@meta.com>, Matthias Reso <mreso@meta.com>, Geeta Chauhan <gchauhan@meta.com>","bugtrack_url":null,"classifiers":["License :: Other/Proprietary License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":null,"maintainer":null,"maintainer_email":null,"name":"llama-recipes","package_url":"https://pypi.org/project/llama-recipes/","platform":null,"project_url":"https://pypi.org/project/llama-recipes/","project_urls":{"Bug Tracker":"https://github.com/facebookresearch/llama-recipes/issues","Homepage":"https://github.com/facebookresearch/llama-recipes/"},"provides_extra":["auditnlg","tests","vllm"],"release_url":"https://pypi.org/project/llama-recipes/0.0.2/","requires_dist":["accelerate","appdirs","bitsandbytes","black","black[jupyter]","chardet","datasets","fire","gradio","loralib","matplotlib","openai","optimum","peft","py7zr","scipy","sentencepiece","tabulate","torch>=2.2","transformers>=4.40.0","typing-extensions==4.8.0","auditnlg; extra == \"auditnlg\"","pytest-mock; extra == \"tests\"","vllm; extra == \"vllm\""],"requires_python":">=3.8","summary":"Llama-recipes is a companion project to the Llama 2 model. It's goal is to provide examples to quickly get started with fine-tuning for domain adaptation and how to run inference for the fine-tuned models.","version":"0.0.2","yanked":false,"yanked_reason":null},"last_serial":25212431,"urls":[{"comment_text":"","digests":{"blake2b_256":"d49f670a3278878df58cc1da42fb0fa7241e15900ad399cf1f085c8f7296b88c","md5":"57ae7cde57f026ba61d27872509f6a39","sha256":"e3205912409a9b7dd6bdd0b2160275ded04a18003d80caab7fb186e01dae2421"},"downloads":-1,"filename":"llama_recipes-0.0.2-py3-none-any.whl","has_sig":false,"md5_digest":"57ae7cde57f026ba61d27872509f6a39","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":64859,"upload_time":"2024-05-17T21:12:29","upload_time_iso_8601":"2024-05-17T21:12:29.629501Z","url":"https://files.pythonhosted.org/packages/d4/9f/670a3278878df58cc1da42fb0fa7241e15900ad399cf1f085c8f7296b88c/llama_recipes-0.0.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"177f23bc30ababb9fda8fbf45ea9e48f923e5d18e03435f638af2c9606413f8e","md5":"d2841d418344854dd919bddbd7885258","sha256":"37b1043fd0f584172a38a8418273089574d2859d168d4c37a95c51e5af3668ee"},"downloads":-1,"filename":"llama_recipes-0.0.2.tar.gz","has_sig":false,"md5_digest":"d2841d418344854dd919bddbd7885258","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":12377420,"upload_time":"2024-05-17T21:12:31","upload_time_iso_8601":"2024-05-17T21:12:31.511975Z","url":"https://files.pythonhosted.org/packages/17/7f/23bc30ababb9fda8fbf45ea9e48f923e5d18e03435f638af2c9606413f8e/llama_recipes-0.0.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.3":{"info":{"author":null,"author_email":"Hamid Shojanazeri <hamidnazeri@meta.com>, Matthias Reso <mreso@meta.com>, Geeta Chauhan <gchauhan@meta.com>","bugtrack_url":null,"classifiers":["License :: Other/Proprietary License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":null,"maintainer":null,"maintainer_email":null,"name":"llama-recipes","package_url":"https://pypi.org/project/llama-recipes/","platform":null,"project_url":"https://pypi.org/project/llama-recipes/","project_urls":{"Bug Tracker":"https://github.com/facebookresearch/llama-recipes/issues","Homepage":"https://github.com/facebookresearch/llama-recipes/"},"provides_extra":["auditnlg","tests","vllm"],"release_url":"https://pypi.org/project/llama-recipes/0.0.3/","requires_dist":["accelerate","appdirs","bitsandbytes","black","black[jupyter]","chardet","codeshield","datasets","fire","gradio","loralib","matplotlib","openai","optimum","peft","py7zr","scipy","sentencepiece","tabulate","torch>=2.2","transformers>=4.43.1","typing-extensions==4.8.0","auditnlg; extra == \"auditnlg\"","pytest-mock; extra == \"tests\"","vllm; extra == \"vllm\""],"requires_python":">=3.8","summary":"Llama-recipes is a companion project to the Llama 2 model. It's goal is to provide examples to quickly get started with fine-tuning for domain adaptation and how to run inference for the fine-tuned models.","version":"0.0.3","yanked":false,"yanked_reason":null},"last_serial":25212431,"urls":[{"comment_text":"","digests":{"blake2b_256":"616101f9ada98129422cf3adc6ee25f1e8edb3865f9046b73d5f1b08e547a0f6","md5":"dab34ec78974b583f058cd9787d35456","sha256":"4af7ff22b63978dd2ea0f200a1407727d9c99aa5b3cd5ddeff1593a04b7cb3e6"},"downloads":-1,"filename":"llama_recipes-0.0.3-py3-none-any.whl","has_sig":false,"md5_digest":"dab34ec78974b583f058cd9787d35456","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":68996,"upload_time":"2024-07-23T17:08:38","upload_time_iso_8601":"2024-07-23T17:08:38.875844Z","url":"https://files.pythonhosted.org/packages/61/61/01f9ada98129422cf3adc6ee25f1e8edb3865f9046b73d5f1b08e547a0f6/llama_recipes-0.0.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"5dccfd6e700a042caa9fb6b4c3c3df371d72d7c0f1abb05e3a311d61f45e65cb","md5":"bafc76149baabfe33dda69ec2d296edb","sha256":"7398848b4863c7d651887ceea20494bf45cb773a79394b9788bc61022dc923f4"},"downloads":-1,"filename":"llama_recipes-0.0.3.tar.gz","has_sig":false,"md5_digest":"bafc76149baabfe33dda69ec2d296edb","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":22803858,"upload_time":"2024-07-23T17:08:40","upload_time_iso_8601":"2024-07-23T17:08:40.602403Z","url":"https://files.pythonhosted.org/packages/5d/cc/fd6e700a042caa9fb6b4c3c3df371d72d7c0f1abb05e3a311d61f45e65cb/llama_recipes-0.0.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.4":{"info":{"author":null,"author_email":"Hamid Shojanazeri <hamidnazeri@meta.com>, Matthias Reso <mreso@meta.com>, Geeta Chauhan <gchauhan@meta.com>","bugtrack_url":null,"classifiers":["License :: Other/Proprietary License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":null,"maintainer":null,"maintainer_email":null,"name":"llama-recipes","package_url":"https://pypi.org/project/llama-recipes/","platform":null,"project_url":"https://pypi.org/project/llama-recipes/","project_urls":{"Bug Tracker":"https://github.com/facebookresearch/llama-recipes/issues","Homepage":"https://github.com/facebookresearch/llama-recipes/"},"provides_extra":["auditnlg","langchain","tests","vllm"],"release_url":"https://pypi.org/project/llama-recipes/0.0.4/","requires_dist":["accelerate","appdirs","bitsandbytes","black","black[jupyter]","chardet","codeshield","datasets","evaluate","faiss-gpu; python_version < \"3.11\"","fire","loralib","matplotlib","openai","optimum","peft","py7zr","pyyaml==6.0.1","rouge-score","scipy","sentence-transformers","sentencepiece","tabulate","torch>=2.2","transformers>=4.43.1","typing-extensions==4.8.0","unstructured[pdf]","auditnlg; extra == \"auditnlg\"","langchain; extra == \"langchain\"","langchain-community; extra == \"langchain\"","langchain-openai; extra == \"langchain\"","pytest-mock; extra == \"tests\"","vllm; extra == \"vllm\""],"requires_python":">=3.8","summary":"Llama-recipes is a companion project to the Llama models. It's goal is to provide examples to quickly get started with fine-tuning for domain adaptation and how to run inference for the fine-tuned models.","version":"0.0.4","yanked":false,"yanked_reason":null},"last_serial":25212431,"urls":[{"comment_text":"","digests":{"blake2b_256":"05fa58415c3ae96dba7c678134ef3efddbb9d4c71bdd864cca4bd21ff5c228ea","md5":"186c34c401868a64227ba126e9b8c317","sha256":"783469db284f251dbc8b5b9427cba1b09f2c87e137f6d777220bbd7e337c96d2"},"downloads":-1,"filename":"llama_recipes-0.0.4-py3-none-any.whl","has_sig":false,"md5_digest":"186c34c401868a64227ba126e9b8c317","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":71137,"upload_time":"2024-09-25T18:16:57","upload_time_iso_8601":"2024-09-25T18:16:57.986116Z","url":"https://files.pythonhosted.org/packages/05/fa/58415c3ae96dba7c678134ef3efddbb9d4c71bdd864cca4bd21ff5c228ea/llama_recipes-0.0.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"bb02d9a8331a671b37c50c27e7c2e5c5909daf0682e01720b12bcd458fbb8e0c","md5":"2f3b46ab1f1dba33304fe1892a6bae71","sha256":"4299f5d049074600bbee9f3295eb98f79e0f1f845115c3962a70bc1b9f8cadd3"},"downloads":-1,"filename":"llama_recipes-0.0.4.tar.gz","has_sig":false,"md5_digest":"2f3b46ab1f1dba33304fe1892a6bae71","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":24626984,"upload_time":"2024-09-25T18:16:59","upload_time_iso_8601":"2024-09-25T18:16:59.756775Z","url":"https://files.pythonhosted.org/packages/bb/02/d9a8331a671b37c50c27e7c2e5c5909daf0682e01720b12bcd458fbb8e0c/llama_recipes-0.0.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.4.post1":{"info":{"author":null,"author_email":"Hamid Shojanazeri <hamidnazeri@meta.com>, Matthias Reso <mreso@meta.com>, Geeta Chauhan <gchauhan@meta.com>","bugtrack_url":null,"classifiers":["License :: Other/Proprietary License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":null,"license":null,"maintainer":null,"maintainer_email":null,"name":"llama-recipes","package_url":"https://pypi.org/project/llama-recipes/","platform":null,"project_url":"https://pypi.org/project/llama-recipes/","project_urls":{"Bug Tracker":"https://github.com/facebookresearch/llama-recipes/issues","Homepage":"https://github.com/facebookresearch/llama-recipes/"},"provides_extra":["auditnlg","langchain","tests","vllm"],"release_url":"https://pypi.org/project/llama-recipes/0.0.4.post1/","requires_dist":["accelerate","appdirs","bitsandbytes","black","black[jupyter]","chardet","codeshield","datasets","evaluate","faiss-gpu; python_version < \"3.11\"","fire","loralib","matplotlib","openai","optimum","peft","py7zr","pyyaml==6.0.1","rouge-score","scipy","sentence-transformers","sentencepiece","tabulate","torch>=2.2","transformers>=4.45.1","typing-extensions==4.8.0","unstructured[pdf]","auditnlg; extra == \"auditnlg\"","langchain; extra == \"langchain\"","langchain-community; extra == \"langchain\"","langchain-openai; extra == \"langchain\"","pytest-mock; extra == \"tests\"","vllm; extra == \"vllm\""],"requires_python":">=3.8","summary":"Llama-recipes is a companion project to the Llama models. It's goal is to provide examples to quickly get started with fine-tuning for domain adaptation and how to run inference for the fine-tuned models.","version":"0.0.4.post1","yanked":false,"yanked_reason":null},"last_serial":25212431,"urls":[{"comment_text":"","digests":{"blake2b_256":"f20714ee96ad31847dac1a034e6ebb6d3dd9fcab0d2f5dc72e26636e1bfc090c","md5":"f50503468240045a5e24e2f9488d8611","sha256":"924ea2b6d9d2b4cef6d9d767f2ecbe59d75623bf2c9904b51e007ebab80e0de9"},"downloads":-1,"filename":"llama_recipes-0.0.4.post1-py3-none-any.whl","has_sig":false,"md5_digest":"f50503468240045a5e24e2f9488d8611","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":1039844,"upload_time":"2024-09-26T19:24:59","upload_time_iso_8601":"2024-09-26T19:24:59.243588Z","url":"https://files.pythonhosted.org/packages/f2/07/14ee96ad31847dac1a034e6ebb6d3dd9fcab0d2f5dc72e26636e1bfc090c/llama_recipes-0.0.4.post1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"154e62adac846b531a8982ef0129e6baae8c39099c4fa647f716f9bf3c89a4a8","md5":"e4600ac9868ae1ba7c87744d36b71cad","sha256":"a27b152f573a55dc53db5586ee9b50f9d0892d4d3d872896aeebfcc50326d83c"},"downloads":-1,"filename":"llama_recipes-0.0.4.post1.tar.gz","has_sig":false,"md5_digest":"e4600ac9868ae1ba7c87744d36b71cad","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":25594880,"upload_time":"2024-09-26T19:25:01","upload_time_iso_8601":"2024-09-26T19:25:01.636559Z","url":"https://files.pythonhosted.org/packages/15/4e/62adac846b531a8982ef0129e6baae8c39099c4fa647f716f9bf3c89a4a8/llama_recipes-0.0.4.post1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}