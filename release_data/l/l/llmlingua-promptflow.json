{"0.0.1":{"info":{"author":"The LLMLingua team","author_email":"llmlingua@microsoft.com","bugtrack_url":null,"classifiers":["Development Status :: 3 - Alpha","Intended Audience :: Science/Research","Programming Language :: Python :: 3","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":null,"docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://llmlingua.com","keywords":"Prompt Compression, LLMs, Inference Acceleration, Black-box LLMs, Efficient LLMs","license":"MIT License","maintainer":null,"maintainer_email":null,"name":"llmlingua-promptflow","package_url":"https://pypi.org/project/llmlingua-promptflow/","platform":null,"project_url":"https://pypi.org/project/llmlingua-promptflow/","project_urls":{"Homepage":"https://llmlingua.com"},"provides_extra":null,"release_url":"https://pypi.org/project/llmlingua-promptflow/0.0.1/","requires_dist":["transformers>=4.26.0","tiktoken","nltk","numpy","transformers>=4.26.0; extra == \"dev\"","tiktoken; extra == \"dev\"","nltk; extra == \"dev\"","numpy; extra == \"dev\""],"requires_python":">=3.8.0","summary":"To speed up LLMs' inference and enhance LLM's perceive of key information, compress the prompt and KV-Cache, which achieves up to 20x compression with minimal performance loss.","version":"0.0.1","yanked":false,"yanked_reason":null},"last_serial":23109180,"urls":[{"comment_text":"","digests":{"blake2b_256":"7dd2011daff14477204efbde48f04dd0bb0aa38b5ade9a7ccac5d5a7173aedea","md5":"5a580f8cd4dbd0bd5abfb0a9af12ad33","sha256":"8a2e15c61482418a9d772e7c33f41d710ca574426aaf33946f3e43cae402aa79"},"downloads":-1,"filename":"llmlingua_promptflow-0.0.1-py3-none-any.whl","has_sig":false,"md5_digest":"5a580f8cd4dbd0bd5abfb0a9af12ad33","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8.0","size":18825,"upload_time":"2024-05-08T06:38:19","upload_time_iso_8601":"2024-05-08T06:38:19.838255Z","url":"https://files.pythonhosted.org/packages/7d/d2/011daff14477204efbde48f04dd0bb0aa38b5ade9a7ccac5d5a7173aedea/llmlingua_promptflow-0.0.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"91272c18dc293f2f28cf18755de49ee732e80ab87daac4f9ed2fbc8bb734e2bd","md5":"401bf6183f45a7c5533839b73292eaa1","sha256":"472b2257e2e67924228232066bd8523d92f73130865c2f062944418669686100"},"downloads":-1,"filename":"llmlingua_promptflow-0.0.1.tar.gz","has_sig":false,"md5_digest":"401bf6183f45a7c5533839b73292eaa1","packagetype":"sdist","python_version":"source","requires_python":">=3.8.0","size":17794,"upload_time":"2024-05-08T06:38:21","upload_time_iso_8601":"2024-05-08T06:38:21.786565Z","url":"https://files.pythonhosted.org/packages/91/27/2c18dc293f2f28cf18755de49ee732e80ab87daac4f9ed2fbc8bb734e2bd/llmlingua_promptflow-0.0.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}