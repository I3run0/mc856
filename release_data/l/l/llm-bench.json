{"0.4.10":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.10/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.10","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"56c741f0ff3b58a6d93132998971da63db81c3f8d2fa754000b84680e7728f4a","md5":"7872d5cb7d2dfc95e3bbfa2fd96402a4","sha256":"5b5b711d72027a277290837fc35625eefb81279cf5277d15c8b0433457a89a6a"},"downloads":-1,"filename":"llm_bench-0.4.10-py3-none-any.whl","has_sig":false,"md5_digest":"7872d5cb7d2dfc95e3bbfa2fd96402a4","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":15367,"upload_time":"2024-05-12T15:05:22","upload_time_iso_8601":"2024-05-12T15:05:22.638003Z","url":"https://files.pythonhosted.org/packages/56/c7/41f0ff3b58a6d93132998971da63db81c3f8d2fa754000b84680e7728f4a/llm_bench-0.4.10-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a544fdf7540dab779b6c490e801f59ee523791a65ddcca7585a788bb3965c521","md5":"564b4785b5d306f63edfbb6a9bfe9ce3","sha256":"af8d86d982dc8ba8d878608c5e4a2017b7e3a5bd29f9af76b5a1549bbe1341e1"},"downloads":-1,"filename":"llm_bench-0.4.10.tar.gz","has_sig":false,"md5_digest":"564b4785b5d306f63edfbb6a9bfe9ce3","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":10626,"upload_time":"2024-05-12T15:05:24","upload_time_iso_8601":"2024-05-12T15:05:24.155043Z","url":"https://files.pythonhosted.org/packages/a5/44/fdf7540dab779b6c490e801f59ee523791a65ddcca7585a788bb3965c521/llm_bench-0.4.10.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.11":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.11/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.11","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"1db1ff5db4c10cf4ce2f5d6813c6ceba6b621f458c074ac38d353b7fd33ccb8d","md5":"ff7d0d0f7295e71757c3a1d3e7a16796","sha256":"f328fe25250041e2cc10d359ef7c6cd44900b51b8696d6b659ab47e5d133e36b"},"downloads":-1,"filename":"llm_bench-0.4.11-py3-none-any.whl","has_sig":false,"md5_digest":"ff7d0d0f7295e71757c3a1d3e7a16796","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":15345,"upload_time":"2024-05-12T15:10:10","upload_time_iso_8601":"2024-05-12T15:10:10.166383Z","url":"https://files.pythonhosted.org/packages/1d/b1/ff5db4c10cf4ce2f5d6813c6ceba6b621f458c074ac38d353b7fd33ccb8d/llm_bench-0.4.11-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"bf89cf294d42adcda32ae02419f60b8628ca1393508fa87e604dad082b619477","md5":"533fcc80435ba3f587133133ac4338ec","sha256":"bcdf7b1990f5ca5c8972e259a3f61da796b3ddfa23d6331e94f6c58657f21e28"},"downloads":-1,"filename":"llm_bench-0.4.11.tar.gz","has_sig":false,"md5_digest":"533fcc80435ba3f587133133ac4338ec","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":10600,"upload_time":"2024-05-12T15:10:11","upload_time_iso_8601":"2024-05-12T15:10:11.828556Z","url":"https://files.pythonhosted.org/packages/bf/89/cf294d42adcda32ae02419f60b8628ca1393508fa87e604dad082b619477/llm_bench-0.4.11.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.12":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.12/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.12","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"9486af0d725260e869ef16b1b19198975650c79720533b8f1293b74c6738a7d3","md5":"ca903126c7e2456dee4e7a32e0d6b09d","sha256":"8f084355d6ccebfcb26fbf93f8defc7f84d7aa7de2f4460a9662e0c43e6738b1"},"downloads":-1,"filename":"llm_bench-0.4.12-py3-none-any.whl","has_sig":false,"md5_digest":"ca903126c7e2456dee4e7a32e0d6b09d","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":15471,"upload_time":"2024-05-12T15:16:53","upload_time_iso_8601":"2024-05-12T15:16:53.832415Z","url":"https://files.pythonhosted.org/packages/94/86/af0d725260e869ef16b1b19198975650c79720533b8f1293b74c6738a7d3/llm_bench-0.4.12-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"5cd16b14d9331b34e81d1b5f89e94dce99c2838846419439198b24fd7c1a16ad","md5":"eba678697717e35a987d7432d6f98d9f","sha256":"4c84ccc13898fdcbcba20cbef9fef6a599b09534f1d838269c7da1c48aafe631"},"downloads":-1,"filename":"llm_bench-0.4.12.tar.gz","has_sig":false,"md5_digest":"eba678697717e35a987d7432d6f98d9f","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":10721,"upload_time":"2024-05-12T15:16:55","upload_time_iso_8601":"2024-05-12T15:16:55.640913Z","url":"https://files.pythonhosted.org/packages/5c/d1/6b14d9331b34e81d1b5f89e94dce99c2838846419439198b24fd7c1a16ad/llm_bench-0.4.12.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.13":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.13/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.13","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"d327f44dcc9076aef3af47a4cee1df4974232554b67ee6fb16c7dfc95192e0ab","md5":"13c64ca977671e9b0fee9e77b96e72ca","sha256":"e693e71eff34d2fe948ca81baa11d108bddd82391d84815a52fdfad6897887f4"},"downloads":-1,"filename":"llm_bench-0.4.13-py3-none-any.whl","has_sig":false,"md5_digest":"13c64ca977671e9b0fee9e77b96e72ca","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":15327,"upload_time":"2024-05-12T15:21:26","upload_time_iso_8601":"2024-05-12T15:21:26.023853Z","url":"https://files.pythonhosted.org/packages/d3/27/f44dcc9076aef3af47a4cee1df4974232554b67ee6fb16c7dfc95192e0ab/llm_bench-0.4.13-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"319ef707f40809a828cc426e9c5b27ae02f8addfa2fddb9608c979c395e7d91a","md5":"8b7a744633c768aa0ac8e13c01d5b886","sha256":"fe94ff072ef00fa091fdee440f66d7e97dd680083fb31b348492769b3c2f3d48"},"downloads":-1,"filename":"llm_bench-0.4.13.tar.gz","has_sig":false,"md5_digest":"8b7a744633c768aa0ac8e13c01d5b886","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":10593,"upload_time":"2024-05-12T15:21:27","upload_time_iso_8601":"2024-05-12T15:21:27.599242Z","url":"https://files.pythonhosted.org/packages/31/9e/f707f40809a828cc426e9c5b27ae02f8addfa2fddb9608c979c395e7d91a/llm_bench-0.4.13.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.14":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.14/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.14","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"5d5d807fc967e30eb783e5ee2237d54b989a5b3f067b0a8e7516f0948d193a18","md5":"da973144b77020006191ddea6b0234cf","sha256":"f7acb1a1c7b04238d09130629f08268237ffc1914b1dad1f40a2559254f33823"},"downloads":-1,"filename":"llm_bench-0.4.14-py3-none-any.whl","has_sig":false,"md5_digest":"da973144b77020006191ddea6b0234cf","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":15269,"upload_time":"2024-05-12T15:25:57","upload_time_iso_8601":"2024-05-12T15:25:57.313175Z","url":"https://files.pythonhosted.org/packages/5d/5d/807fc967e30eb783e5ee2237d54b989a5b3f067b0a8e7516f0948d193a18/llm_bench-0.4.14-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7208da2f7cfdee8be79b1a09f463bb4932762046cc7905f472e93daa4a95b829","md5":"29355845fdeb4b10292a0ea3e9ffe40b","sha256":"18c3bfd9ccc8fd3f9f7389a7c8dc4f3b8a7c040e4de5f19f0cac5c2f43cd0c6a"},"downloads":-1,"filename":"llm_bench-0.4.14.tar.gz","has_sig":false,"md5_digest":"29355845fdeb4b10292a0ea3e9ffe40b","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":10525,"upload_time":"2024-05-12T15:25:58","upload_time_iso_8601":"2024-05-12T15:25:58.988086Z","url":"https://files.pythonhosted.org/packages/72/08/da2f7cfdee8be79b1a09f463bb4932762046cc7905f472e93daa4a95b829/llm_bench-0.4.14.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.15":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.15/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.15","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"997206f9d1f7f49f0608b31e7ddc74bb58689335185f98f4a2e1aa4342f5c0dd","md5":"9d9df85e2c2eed8cb11c7ac985fb9070","sha256":"ff519b2c2efdc2620bcfbee3b62cffae4c0c1752469dbbce2246a158ce936f5e"},"downloads":-1,"filename":"llm_bench-0.4.15-py3-none-any.whl","has_sig":false,"md5_digest":"9d9df85e2c2eed8cb11c7ac985fb9070","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":15319,"upload_time":"2024-05-12T15:45:29","upload_time_iso_8601":"2024-05-12T15:45:29.516457Z","url":"https://files.pythonhosted.org/packages/99/72/06f9d1f7f49f0608b31e7ddc74bb58689335185f98f4a2e1aa4342f5c0dd/llm_bench-0.4.15-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8db81accde963598f8e7488f1cf312d4762e03dae68cc7bbf643450384bae6ac","md5":"c4052fb0e5605d93cca0e635c5266b2e","sha256":"cc00a229b998f271ff9a67540cc63749553b7bc6abfc6efbb0b2f9da6663aba7"},"downloads":-1,"filename":"llm_bench-0.4.15.tar.gz","has_sig":false,"md5_digest":"c4052fb0e5605d93cca0e635c5266b2e","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":10546,"upload_time":"2024-05-12T15:45:31","upload_time_iso_8601":"2024-05-12T15:45:31.090447Z","url":"https://files.pythonhosted.org/packages/8d/b8/1accde963598f8e7488f1cf312d4762e03dae68cc7bbf643450384bae6ac/llm_bench-0.4.15.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.16":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.16/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.16","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"7b4c7775d7a31e3528a6ae2f04553847b046527400117a8f294574fa1b96ab6d","md5":"6ae4fea9e117780a981fff6e9fbb6bc0","sha256":"4c52e2385f23ec9f269192d7ed4a134c1c45edbf3cff08081dfdf91b86ebc1e5"},"downloads":-1,"filename":"llm_bench-0.4.16-py3-none-any.whl","has_sig":false,"md5_digest":"6ae4fea9e117780a981fff6e9fbb6bc0","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":15370,"upload_time":"2024-05-14T11:39:02","upload_time_iso_8601":"2024-05-14T11:39:02.507544Z","url":"https://files.pythonhosted.org/packages/7b/4c/7775d7a31e3528a6ae2f04553847b046527400117a8f294574fa1b96ab6d/llm_bench-0.4.16-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e97588c38ada7e89a2f0a345ea852de3317740e12351be56c9aa6359ea9479d4","md5":"6e1c70287182fe4924c46e55b71b4c6e","sha256":"228324eb35784b0e0a600a13b67aa1969c8c61014d9695b9b5270f2115701d5a"},"downloads":-1,"filename":"llm_bench-0.4.16.tar.gz","has_sig":false,"md5_digest":"6e1c70287182fe4924c46e55b71b4c6e","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":10652,"upload_time":"2024-05-14T11:39:03","upload_time_iso_8601":"2024-05-14T11:39:03.955580Z","url":"https://files.pythonhosted.org/packages/e9/75/88c38ada7e89a2f0a345ea852de3317740e12351be56c9aa6359ea9479d4/llm_bench-0.4.16.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.17":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.17/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.17","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"84ab5bfbb2c219e6f07b761768c490095cfc513fc755c0d177c0f640d3373181","md5":"cefcfc285165afa6f0d883138adb4ed8","sha256":"6c08f11aeb6b046e5a297c73922b9352311abba951f92e4e078c5148afd955c7"},"downloads":-1,"filename":"llm_bench-0.4.17-py3-none-any.whl","has_sig":false,"md5_digest":"cefcfc285165afa6f0d883138adb4ed8","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":17904,"upload_time":"2024-05-15T08:20:13","upload_time_iso_8601":"2024-05-15T08:20:13.068333Z","url":"https://files.pythonhosted.org/packages/84/ab/5bfbb2c219e6f07b761768c490095cfc513fc755c0d177c0f640d3373181/llm_bench-0.4.17-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"57495a37ab1ade27965a80925ff7d1d6ac81e2639be806fbf7a3027af3c5ef09","md5":"eae01eaf613da8fe29cc1d70d0ade71b","sha256":"c28e12bfa80e3bf82e815c51338982140274053028e1e8fa7a3e6146a132f730"},"downloads":-1,"filename":"llm_bench-0.4.17.tar.gz","has_sig":false,"md5_digest":"eae01eaf613da8fe29cc1d70d0ade71b","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":11625,"upload_time":"2024-05-15T08:20:14","upload_time_iso_8601":"2024-05-15T08:20:14.747697Z","url":"https://files.pythonhosted.org/packages/57/49/5a37ab1ade27965a80925ff7d1d6ac81e2639be806fbf7a3027af3c5ef09/llm_bench-0.4.17.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.18":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.18/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.18","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"7719ef00b152db61444b105b9647a65acb72d2a42d9d43e6f11899bf3abe9e27","md5":"7b4b81a909abc6e59da3b0968d9ece92","sha256":"2550f73c4feb3b075a2867cade30184250dd756e394e819fdcec7cc2c28bfa48"},"downloads":-1,"filename":"llm_bench-0.4.18-py3-none-any.whl","has_sig":false,"md5_digest":"7b4b81a909abc6e59da3b0968d9ece92","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":17815,"upload_time":"2024-05-15T10:03:22","upload_time_iso_8601":"2024-05-15T10:03:22.932723Z","url":"https://files.pythonhosted.org/packages/77/19/ef00b152db61444b105b9647a65acb72d2a42d9d43e6f11899bf3abe9e27/llm_bench-0.4.18-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"c7a1f51060b942790e02cac4c1a4d3e3bf467cb53728ba2c4908796cc5038c36","md5":"2d8200be923d15ba31846338d9f0b308","sha256":"c68cfcc3355c2ac610da22cdd2d93eb192cd78e81f112d4248ef6f8bc46e076a"},"downloads":-1,"filename":"llm_bench-0.4.18.tar.gz","has_sig":false,"md5_digest":"2d8200be923d15ba31846338d9f0b308","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":11547,"upload_time":"2024-05-15T10:03:23","upload_time_iso_8601":"2024-05-15T10:03:23.977624Z","url":"https://files.pythonhosted.org/packages/c7/a1/f51060b942790e02cac4c1a4d3e3bf467cb53728ba2c4908796cc5038c36/llm_bench-0.4.18.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.19":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.19/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.19","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"6c6600a6ad695584f6032d96d1677f2f207ec041b3109e78bdefade2adcbb14c","md5":"c1525042c1387bb99b320e0a0fe67317","sha256":"22c4eece4d36fd41e3d2f6e901179db187f5a4cd31e9640401999f4456569b82"},"downloads":-1,"filename":"llm_bench-0.4.19-py3-none-any.whl","has_sig":false,"md5_digest":"c1525042c1387bb99b320e0a0fe67317","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":17924,"upload_time":"2024-05-15T10:08:29","upload_time_iso_8601":"2024-05-15T10:08:29.703299Z","url":"https://files.pythonhosted.org/packages/6c/66/00a6ad695584f6032d96d1677f2f207ec041b3109e78bdefade2adcbb14c/llm_bench-0.4.19-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"acb3a530b00fd0ca83d0f029ef8d4315a8a1ba33ae08c1178d79a477fcb72017","md5":"35cd52af459df78dc06961dca7886167","sha256":"b6d04690c0429d21fef979128c04010bb3a3b527080cd1212ed8ff55e0732fdb"},"downloads":-1,"filename":"llm_bench-0.4.19.tar.gz","has_sig":false,"md5_digest":"35cd52af459df78dc06961dca7886167","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":11663,"upload_time":"2024-05-15T10:08:30","upload_time_iso_8601":"2024-05-15T10:08:30.807036Z","url":"https://files.pythonhosted.org/packages/ac/b3/a530b00fd0ca83d0f029ef8d4315a8a1ba33ae08c1178d79a477fcb72017/llm_bench-0.4.19.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.20":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.20/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.20","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"c496405d36e8c42e8854aa3b7e3509feb671bf8ae27394c9b58f965b0080e96c","md5":"1915d58ace510ccbd88337e8efb0e16a","sha256":"feaba10e83c0eaa950ffea4c299904df12815c2ba217bd3a3e88abecb07efd10"},"downloads":-1,"filename":"llm_bench-0.4.20-py3-none-any.whl","has_sig":false,"md5_digest":"1915d58ace510ccbd88337e8efb0e16a","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":17573,"upload_time":"2024-05-21T17:18:28","upload_time_iso_8601":"2024-05-21T17:18:28.702060Z","url":"https://files.pythonhosted.org/packages/c4/96/405d36e8c42e8854aa3b7e3509feb671bf8ae27394c9b58f965b0080e96c/llm_bench-0.4.20-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"0b54458df3452fb0da5565e630e51f2c7e15ca8a2193246159d3248d8cba5c2d","md5":"4a4fe38b9b623257881f1fa5249ac9da","sha256":"f19c336066670d05a0096691b3012a19244413280fef3b6ff482ede9af632c95"},"downloads":-1,"filename":"llm_bench-0.4.20.tar.gz","has_sig":false,"md5_digest":"4a4fe38b9b623257881f1fa5249ac9da","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":11312,"upload_time":"2024-05-21T17:18:30","upload_time_iso_8601":"2024-05-21T17:18:30.617423Z","url":"https://files.pythonhosted.org/packages/0b/54/458df3452fb0da5565e630e51f2c7e15ca8a2193246159d3248d8cba5c2d/llm_bench-0.4.20.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.21":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.21/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.21","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"5a61323687dc3d6663aad2941fbad186de9c9702d86945ef37d722936f3a2893","md5":"de734be9a1f57f460fe2a86b94d16538","sha256":"2853361281256892d4257eb5a1de86a98039becb288b21596c9e570c091f1c18"},"downloads":-1,"filename":"llm_bench-0.4.21-py3-none-any.whl","has_sig":false,"md5_digest":"de734be9a1f57f460fe2a86b94d16538","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":17201,"upload_time":"2024-05-21T18:33:58","upload_time_iso_8601":"2024-05-21T18:33:58.268409Z","url":"https://files.pythonhosted.org/packages/5a/61/323687dc3d6663aad2941fbad186de9c9702d86945ef37d722936f3a2893/llm_bench-0.4.21-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"194e9993d349108d04542f30e4baf01b9931ee153a56d05b7865152d2a1e157f","md5":"3bac5dd4f7ec37c7c7a60bb9ff10c9fa","sha256":"2860607e10941f5cd60606c0b3f8c8a317fd236d4f248ab4a30caebfbe673efb"},"downloads":-1,"filename":"llm_bench-0.4.21.tar.gz","has_sig":false,"md5_digest":"3bac5dd4f7ec37c7c7a60bb9ff10c9fa","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":10972,"upload_time":"2024-05-21T18:34:00","upload_time_iso_8601":"2024-05-21T18:34:00.745690Z","url":"https://files.pythonhosted.org/packages/19/4e/9993d349108d04542f30e4baf01b9931ee153a56d05b7865152d2a1e157f/llm_bench-0.4.21.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.22":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.22/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.22","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"dcd79b017a5a5542bb154147ce127de730adbf713f49dd74928ded0beae11e9a","md5":"e7102f17ddc678077c4b58c6950c95dd","sha256":"36708fa1a962361be8d97191d984992d4feced11f3950038cd14feb63cd831f7"},"downloads":-1,"filename":"llm_bench-0.4.22-py3-none-any.whl","has_sig":false,"md5_digest":"e7102f17ddc678077c4b58c6950c95dd","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":17400,"upload_time":"2024-05-28T10:31:23","upload_time_iso_8601":"2024-05-28T10:31:23.139005Z","url":"https://files.pythonhosted.org/packages/dc/d7/9b017a5a5542bb154147ce127de730adbf713f49dd74928ded0beae11e9a/llm_bench-0.4.22-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b7fc312ececbb6fcdcf631b1fcc968967301e564ae387f38a78a4527a1ba5423","md5":"412ab0cd9f6803db0dfc304288cdb9fe","sha256":"5c11192b1cbc2d15e87cce07e444da81ded529bb220e3b1d887080f9a89e9e96"},"downloads":-1,"filename":"llm_bench-0.4.22.tar.gz","has_sig":false,"md5_digest":"412ab0cd9f6803db0dfc304288cdb9fe","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":11020,"upload_time":"2024-05-28T10:31:25","upload_time_iso_8601":"2024-05-28T10:31:25.276276Z","url":"https://files.pythonhosted.org/packages/b7/fc/312ececbb6fcdcf631b1fcc968967301e564ae387f38a78a4527a1ba5423/llm_bench-0.4.22.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.23":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.23/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.23","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"7c2da9f187f696fb7a0a713bb0af2da29f03b517b8503b1f298ee82e4a964e35","md5":"de8886d37ee3a9e3e27332a88444f634","sha256":"14da6915305b29904b2771370ff3e2827b957fe63831d1891328fef9f82c3fc3"},"downloads":-1,"filename":"llm_bench-0.4.23-py3-none-any.whl","has_sig":false,"md5_digest":"de8886d37ee3a9e3e27332a88444f634","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":17433,"upload_time":"2024-05-28T10:37:37","upload_time_iso_8601":"2024-05-28T10:37:37.371515Z","url":"https://files.pythonhosted.org/packages/7c/2d/a9f187f696fb7a0a713bb0af2da29f03b517b8503b1f298ee82e4a964e35/llm_bench-0.4.23-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"42c1ac14379cb8f3edc115c9d468bc7effc261cac6e13ea968f9f89129a89e72","md5":"063313dd5af49ccd5cc6a3a537df95c9","sha256":"1288a2bb6179fbfc5703492273c95799a3ce383c51dc1693b7fd76bf4a4a01bb"},"downloads":-1,"filename":"llm_bench-0.4.23.tar.gz","has_sig":false,"md5_digest":"063313dd5af49ccd5cc6a3a537df95c9","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":11027,"upload_time":"2024-05-28T10:37:39","upload_time_iso_8601":"2024-05-28T10:37:39.136406Z","url":"https://files.pythonhosted.org/packages/42/c1/ac14379cb8f3edc115c9d468bc7effc261cac6e13ea968f9f89129a89e72/llm_bench-0.4.23.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.24":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.24/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.24","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"10c1699095bf07a3f37e1e5c4a5b36be3298b7f35ccc15be11fd49c322b29cc3","md5":"8548cf50bb645cd7687521a7acb03fde","sha256":"9c3c9b725e09d711c7be109192f9c0f8d801157e7dc549022706cafb7dcac21f"},"downloads":-1,"filename":"llm_bench-0.4.24-py3-none-any.whl","has_sig":false,"md5_digest":"8548cf50bb645cd7687521a7acb03fde","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":17438,"upload_time":"2024-06-18T11:39:56","upload_time_iso_8601":"2024-06-18T11:39:56.999538Z","url":"https://files.pythonhosted.org/packages/10/c1/699095bf07a3f37e1e5c4a5b36be3298b7f35ccc15be11fd49c322b29cc3/llm_bench-0.4.24-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e50a728c585dfe84c266ad215b90ce23db65efa6faf08e8c1d37980fc140ccd5","md5":"1e09f31b58beabaa0c4b1acdb1650f41","sha256":"a4ebd6490518aa8198928691396fdd3994cd3a9a3d8285f1e861f1b368f84a81"},"downloads":-1,"filename":"llm_bench-0.4.24.tar.gz","has_sig":false,"md5_digest":"1e09f31b58beabaa0c4b1acdb1650f41","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":11029,"upload_time":"2024-06-18T11:40:00","upload_time_iso_8601":"2024-06-18T11:40:00.373093Z","url":"https://files.pythonhosted.org/packages/e5/0a/728c585dfe84c266ad215b90ce23db65efa6faf08e8c1d37980fc140ccd5/llm_bench-0.4.24.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.25":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.25/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.25","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"f7ce3e7a832138b038721dc42861f53d8182874fd7c65cc88fa76e4c8411afec","md5":"1a6abd1ee07e10c2dfadb6ff344c29e1","sha256":"c69646658308d8a0fb157e30a84135c77d72bb9bae098ea059b0c8632501e0ec"},"downloads":-1,"filename":"llm_bench-0.4.25-py3-none-any.whl","has_sig":false,"md5_digest":"1a6abd1ee07e10c2dfadb6ff344c29e1","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":17426,"upload_time":"2024-06-18T11:51:21","upload_time_iso_8601":"2024-06-18T11:51:21.246363Z","url":"https://files.pythonhosted.org/packages/f7/ce/3e7a832138b038721dc42861f53d8182874fd7c65cc88fa76e4c8411afec/llm_bench-0.4.25-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"f7b845875196735d2c086be55d25e2676d4ee246123a1218deafe8250f136509","md5":"dad0f9a7772ed5d9cc4d6a5c87e177aa","sha256":"47776df8f7701c9fd7bdb978e851cae4175eb3e5b055d10045714c97ce45f4da"},"downloads":-1,"filename":"llm_bench-0.4.25.tar.gz","has_sig":false,"md5_digest":"dad0f9a7772ed5d9cc4d6a5c87e177aa","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":11031,"upload_time":"2024-06-18T11:51:22","upload_time_iso_8601":"2024-06-18T11:51:22.895011Z","url":"https://files.pythonhosted.org/packages/f7/b8/45875196735d2c086be55d25e2676d4ee246123a1218deafe8250f136509/llm_bench-0.4.25.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.26":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.26/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"LLM Benchmarking tool for OLLAMA","version":"0.4.26","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"607597d3d5a4723107aafc98d9e8b3083f46639b575d63100a875081f3aab34d","md5":"d28322fc908d084554017541e6dbbcc9","sha256":"c20b53f95c1023bfb87a0e76a2f18c1010ae1ba0199f0b069c8c228a2f991e26"},"downloads":-1,"filename":"llm_bench-0.4.26-py3-none-any.whl","has_sig":false,"md5_digest":"d28322fc908d084554017541e6dbbcc9","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":18687,"upload_time":"2024-06-28T18:37:14","upload_time_iso_8601":"2024-06-28T18:37:14.338388Z","url":"https://files.pythonhosted.org/packages/60/75/97d3d5a4723107aafc98d9e8b3083f46639b575d63100a875081f3aab34d/llm_bench-0.4.26-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"822f2a45ae81ef5c6b1b93b2ffdf4917ffc716fdf05402db86c21f9e5c31d8f8","md5":"7e73e8947611caac34011879a70b0cdc","sha256":"bf8041a2aa125208d97c1711079bc7876fae53d2ad0dbd05a5649f194b8a31f6"},"downloads":-1,"filename":"llm_bench-0.4.26.tar.gz","has_sig":false,"md5_digest":"7e73e8947611caac34011879a70b0cdc","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":12565,"upload_time":"2024-06-28T18:37:16","upload_time_iso_8601":"2024-06-28T18:37:16.097030Z","url":"https://files.pythonhosted.org/packages/82/2f/2a45ae81ef5c6b1b93b2ffdf4917ffc716fdf05402db86c21f9e5c31d8f8/llm_bench-0.4.26.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.27":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.27/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"LLM Benchmarking tool for OLLAMA","version":"0.4.27","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"414f0317a91095d1538918963cc915aedd0986972e2390cddb785f64c99fa1b3","md5":"e1504f1d52aab847d4b0de54a6228792","sha256":"887f7dc8a72b5f49f7fb61a24a7a6b55fe3c9a96180a1a859fe239bd0fe3e2e0"},"downloads":-1,"filename":"llm_bench-0.4.27-py3-none-any.whl","has_sig":false,"md5_digest":"e1504f1d52aab847d4b0de54a6228792","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":18667,"upload_time":"2024-07-01T10:03:21","upload_time_iso_8601":"2024-07-01T10:03:21.439372Z","url":"https://files.pythonhosted.org/packages/41/4f/0317a91095d1538918963cc915aedd0986972e2390cddb785f64c99fa1b3/llm_bench-0.4.27-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"f5d3793520855ea79dba46a520dae4aa2b9b649211c54abb9e9973d831335883","md5":"71fa1e3b5ed68e743d5e0c80529d86c4","sha256":"e73325f6cb8aff0879f5d3f523b4533537a58ae7e5a9352e591d60ba7bdef78d"},"downloads":-1,"filename":"llm_bench-0.4.27.tar.gz","has_sig":false,"md5_digest":"71fa1e3b5ed68e743d5e0c80529d86c4","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":12538,"upload_time":"2024-07-01T10:03:23","upload_time_iso_8601":"2024-07-01T10:03:23.545084Z","url":"https://files.pythonhosted.org/packages/f5/d3/793520855ea79dba46a520dae4aa2b9b649211c54abb9e9973d831335883/llm_bench-0.4.27.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.28":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.28/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"LLM Benchmarking tool for OLLAMA","version":"0.4.28","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"f93a2a92af953b1e66920fdfafda4009648d0e81bbef8c841ea477d845efc03f","md5":"f630d41e0d306bc36f262b018484a14f","sha256":"2c1bc67786554fda13e619b7649478cdd3e1b45d6a5db060e204209549e52f5a"},"downloads":-1,"filename":"llm_bench-0.4.28-py3-none-any.whl","has_sig":false,"md5_digest":"f630d41e0d306bc36f262b018484a14f","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":19027,"upload_time":"2024-07-07T16:27:01","upload_time_iso_8601":"2024-07-07T16:27:01.716869Z","url":"https://files.pythonhosted.org/packages/f9/3a/2a92af953b1e66920fdfafda4009648d0e81bbef8c841ea477d845efc03f/llm_bench-0.4.28-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"c3dccfcea1ac8d788214257cce4f826b68e12fb0fac9d31c1b1b26e66399862a","md5":"c007cd00128e8e6e862c7fb3619c8f71","sha256":"d7a89038362e78d2535422e99299c9e4b03b17226ba97c1451063b399ea43cd7"},"downloads":-1,"filename":"llm_bench-0.4.28.tar.gz","has_sig":false,"md5_digest":"c007cd00128e8e6e862c7fb3619c8f71","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":12918,"upload_time":"2024-07-07T16:27:03","upload_time_iso_8601":"2024-07-07T16:27:03.484320Z","url":"https://files.pythonhosted.org/packages/c3/dc/cfcea1ac8d788214257cce4f826b68e12fb0fac9d31c1b1b26e66399862a/llm_bench-0.4.28.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.29":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.29/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"LLM Benchmarking tool for OLLAMA","version":"0.4.29","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"3fb295d8f34752fa0149d8c5fe1c06e42b5aa346f51ba651d66be443344730a0","md5":"1b9fd92eaf1c7d2cb40356aa6179af2d","sha256":"41732971ed4aaf9ba7302c8e660d5fa04fa382dc1145e6dd79191f3f814bfff2"},"downloads":-1,"filename":"llm_bench-0.4.29-py3-none-any.whl","has_sig":false,"md5_digest":"1b9fd92eaf1c7d2cb40356aa6179af2d","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":19484,"upload_time":"2024-07-09T11:57:50","upload_time_iso_8601":"2024-07-09T11:57:50.532664Z","url":"https://files.pythonhosted.org/packages/3f/b2/95d8f34752fa0149d8c5fe1c06e42b5aa346f51ba651d66be443344730a0/llm_bench-0.4.29-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"3d33f6b57ce0184f55fc89a9c2b3a26ce6691e8e1c7aef250b50d35b61a060b0","md5":"28657f1c834dd363299d9a4b9f39f56d","sha256":"1a494958cab42241b4936376c1128f3f7c8218dba356f50ce981e3eaaa4b0ddf"},"downloads":-1,"filename":"llm_bench-0.4.29.tar.gz","has_sig":false,"md5_digest":"28657f1c834dd363299d9a4b9f39f56d","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":13630,"upload_time":"2024-07-09T11:57:52","upload_time_iso_8601":"2024-07-09T11:57:52.121685Z","url":"https://files.pythonhosted.org/packages/3d/33/f6b57ce0184f55fc89a9c2b3a26ce6691e8e1c7aef250b50d35b61a060b0/llm_bench-0.4.29.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.3":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.3/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.3","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"599650e9efa7f08968125edbd30fed9242e93a2599ac806a1831b7c860d99b90","md5":"8f779eb41bec3d802be3f0c921719f6e","sha256":"afb6637b3e8a7a56441af09fba2e14e149737faf411bdb3dafdb6c832168acf5"},"downloads":-1,"filename":"llm_bench-0.4.3-py3-none-any.whl","has_sig":false,"md5_digest":"8f779eb41bec3d802be3f0c921719f6e","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":2129143,"upload_time":"2024-05-11T14:45:51","upload_time_iso_8601":"2024-05-11T14:45:51.429713Z","url":"https://files.pythonhosted.org/packages/59/96/50e9efa7f08968125edbd30fed9242e93a2599ac806a1831b7c860d99b90/llm_bench-0.4.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b0376fde4336fef4348f67644c3425bd3c6bcaf99282026daa63da40995af549","md5":"13d00ff29caa4d7744569e4b87f8d8e1","sha256":"fa9599bc37b04972d5be0f2bdc93ab0eb22586e4f794b1435fe61bd09fefe11b"},"downloads":-1,"filename":"llm_bench-0.4.3.tar.gz","has_sig":false,"md5_digest":"13d00ff29caa4d7744569e4b87f8d8e1","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":2126418,"upload_time":"2024-05-11T14:45:53","upload_time_iso_8601":"2024-05-11T14:45:53.721672Z","url":"https://files.pythonhosted.org/packages/b0/37/6fde4336fef4348f67644c3425bd3c6bcaf99282026daa63da40995af549/llm_bench-0.4.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.30":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.30/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"LLM Benchmarking tool for OLLAMA","version":"0.4.30","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"efcb3d39f845876303749a2e4eb59d2e160107792c39346ec870bd05c4175fc7","md5":"2ee60377b75d92a55fcfaf7543c5938c","sha256":"cdf9ee81b7f3c3a03c1d610428ab232bc53054c952a9012578fda1e4c79c1e3e"},"downloads":-1,"filename":"llm_bench-0.4.30-py3-none-any.whl","has_sig":false,"md5_digest":"2ee60377b75d92a55fcfaf7543c5938c","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":19860,"upload_time":"2024-07-12T07:26:09","upload_time_iso_8601":"2024-07-12T07:26:09.860305Z","url":"https://files.pythonhosted.org/packages/ef/cb/3d39f845876303749a2e4eb59d2e160107792c39346ec870bd05c4175fc7/llm_bench-0.4.30-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7b940e3dff5a5961fea3f3cb78585fe81e50150ab5191471ec0b55557d78f632","md5":"2af0749109b4678a496fe1831ffdd6be","sha256":"83ae6096d48fa4e4dc02d9b6d92ee9b53aab464c46ef971aa8c445508ba3aa16"},"downloads":-1,"filename":"llm_bench-0.4.30.tar.gz","has_sig":false,"md5_digest":"2af0749109b4678a496fe1831ffdd6be","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":13978,"upload_time":"2024-07-12T07:26:13","upload_time_iso_8601":"2024-07-12T07:26:13.680084Z","url":"https://files.pythonhosted.org/packages/7b/94/0e3dff5a5961fea3f3cb78585fe81e50150ab5191471ec0b55557d78f632/llm_bench-0.4.30.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.31":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.31/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"LLM Benchmarking tool for OLLAMA","version":"0.4.31","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"f64f3a834d479227a065574edad9ee3b2b8b2565b1f115df5ec42484d0a92b3d","md5":"fbd1d5b7037dc03fe5ab85477c873dfe","sha256":"e555857a3a315822560cbd64d66d49c59989bd59d0c89b3c648cf8ffae21f66a"},"downloads":-1,"filename":"llm_bench-0.4.31-py3-none-any.whl","has_sig":false,"md5_digest":"fbd1d5b7037dc03fe5ab85477c873dfe","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":19901,"upload_time":"2024-07-23T16:34:19","upload_time_iso_8601":"2024-07-23T16:34:19.815144Z","url":"https://files.pythonhosted.org/packages/f6/4f/3a834d479227a065574edad9ee3b2b8b2565b1f115df5ec42484d0a92b3d/llm_bench-0.4.31-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"f7250bd3e4aff748ffa72a6e4812c3f67f2e62784e73db11e66825d7f359e6dd","md5":"3aecc506ed23157efecd145ebbc5b8e5","sha256":"bd5b261bb31cd6b0cb97849a611e7466509e19f77f6b267dfb11dd2e92f6783c"},"downloads":-1,"filename":"llm_bench-0.4.31.tar.gz","has_sig":false,"md5_digest":"3aecc506ed23157efecd145ebbc5b8e5","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":14009,"upload_time":"2024-07-23T16:34:21","upload_time_iso_8601":"2024-07-23T16:34:21.292422Z","url":"https://files.pythonhosted.org/packages/f7/25/0bd3e4aff748ffa72a6e4812c3f67f2e62784e73db11e66825d7f359e6dd/llm_bench-0.4.31.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.32":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.32/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"LLM Benchmarking tool for OLLAMA","version":"0.4.32","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"6ee3ef108ae54c3e946f4aa84c08df42b00252212dc0eccd78c3944f0609904f","md5":"08cada252d7343d3ab1502242888554d","sha256":"f76d9fe5687ad72a7c5ad714e69a9f6e14bfbba11ba528ade9d49d044c340dd6"},"downloads":-1,"filename":"llm_bench-0.4.32-py3-none-any.whl","has_sig":false,"md5_digest":"08cada252d7343d3ab1502242888554d","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":19897,"upload_time":"2024-07-23T16:39:42","upload_time_iso_8601":"2024-07-23T16:39:42.989713Z","url":"https://files.pythonhosted.org/packages/6e/e3/ef108ae54c3e946f4aa84c08df42b00252212dc0eccd78c3944f0609904f/llm_bench-0.4.32-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"0b9324e32e3430f7d397862edbabb00a6fe09313b865dcc34aaa1cf433f3d7e2","md5":"4bc68ca95743dbf1a846853d067bd91c","sha256":"e2ba3787f872dd96bf29fe9198b5e8981af2f3db6de3ceac05b4d1dc4e026a4b"},"downloads":-1,"filename":"llm_bench-0.4.32.tar.gz","has_sig":false,"md5_digest":"4bc68ca95743dbf1a846853d067bd91c","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":14003,"upload_time":"2024-07-23T16:39:44","upload_time_iso_8601":"2024-07-23T16:39:44.412377Z","url":"https://files.pythonhosted.org/packages/0b/93/24e32e3430f7d397862edbabb00a6fe09313b865dcc34aaa1cf433f3d7e2/llm_bench-0.4.32.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.4":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.4/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.4","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"27ce97a58d9da84ddf6060fe19ba46dd875376359175746608d52a382626948c","md5":"cee816c3a2a808e37019b4cbd00ba526","sha256":"8dc3937bfbf2f105cf0532c47c4538ce4d6d978d39fda4af1bb7686ff35ebead"},"downloads":-1,"filename":"llm_bench-0.4.4-py3-none-any.whl","has_sig":false,"md5_digest":"cee816c3a2a808e37019b4cbd00ba526","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":14208,"upload_time":"2024-05-12T09:29:22","upload_time_iso_8601":"2024-05-12T09:29:22.100018Z","url":"https://files.pythonhosted.org/packages/27/ce/97a58d9da84ddf6060fe19ba46dd875376359175746608d52a382626948c/llm_bench-0.4.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"548b02f4eb36f9a34beec79d420f9bb82f07d84d54fb67bd28a5458f74544956","md5":"76bcf9c59d65bad1e46879cabb13e6a2","sha256":"f2c6546cdf004534f42142b62a278b60c3147b4422af097b99784ffc6d4eff83"},"downloads":-1,"filename":"llm_bench-0.4.4.tar.gz","has_sig":false,"md5_digest":"76bcf9c59d65bad1e46879cabb13e6a2","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":9865,"upload_time":"2024-05-12T09:29:23","upload_time_iso_8601":"2024-05-12T09:29:23.736273Z","url":"https://files.pythonhosted.org/packages/54/8b/02f4eb36f9a34beec79d420f9bb82f07d84d54fb67bd28a5458f74544956/llm_bench-0.4.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.5":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.5/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.5","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"0d07e137437e4d1fb334f12456ac6b7c92c4cccc9c879e87da9a64da94d53010","md5":"c70e1529d9373355508c3624de04ff1e","sha256":"f453829160a6c3ef186dbb60c984b6c1297ea2ede4b811bf932889ab89628382"},"downloads":-1,"filename":"llm_bench-0.4.5-py3-none-any.whl","has_sig":false,"md5_digest":"c70e1529d9373355508c3624de04ff1e","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":14320,"upload_time":"2024-05-12T14:19:49","upload_time_iso_8601":"2024-05-12T14:19:49.575515Z","url":"https://files.pythonhosted.org/packages/0d/07/e137437e4d1fb334f12456ac6b7c92c4cccc9c879e87da9a64da94d53010/llm_bench-0.4.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"f7e5c647c04d817e87abbf191b2d27de541a2c821b7bbcae632fad20a897501d","md5":"fa62ff0d10651dde2c3768f03fb93732","sha256":"da911c91f2651bfd049b8231485ec6f0a838399a93a6f5cb570f912eaec9df5a"},"downloads":-1,"filename":"llm_bench-0.4.5.tar.gz","has_sig":false,"md5_digest":"fa62ff0d10651dde2c3768f03fb93732","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":9986,"upload_time":"2024-05-12T14:19:51","upload_time_iso_8601":"2024-05-12T14:19:51.080535Z","url":"https://files.pythonhosted.org/packages/f7/e5/c647c04d817e87abbf191b2d27de541a2c821b7bbcae632fad20a897501d/llm_bench-0.4.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.6":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.6/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.6","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"411b967e5cc94b8ddce607d32db5d16f5373237b364995ead335897ff7095452","md5":"ea17481bf85fcc11a211b02d308df9d5","sha256":"18ce038eb881bbd31bd76e6de539fc57a8fbc0e507712a9ea0c2209303105a39"},"downloads":-1,"filename":"llm_bench-0.4.6-py3-none-any.whl","has_sig":false,"md5_digest":"ea17481bf85fcc11a211b02d308df9d5","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":14877,"upload_time":"2024-05-12T14:37:08","upload_time_iso_8601":"2024-05-12T14:37:08.422987Z","url":"https://files.pythonhosted.org/packages/41/1b/967e5cc94b8ddce607d32db5d16f5373237b364995ead335897ff7095452/llm_bench-0.4.6-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e18bffe1bb73ea8706ad33c03e5eca0ec8107a41fd69d41702dab09d10f13c79","md5":"ae4155245c1c1ef567be404c4f78a232","sha256":"66259e06dcb7401d5bbb37b05d03953649c0dd6ab2e68c0d7f5952ce7b28eca5"},"downloads":-1,"filename":"llm_bench-0.4.6.tar.gz","has_sig":false,"md5_digest":"ae4155245c1c1ef567be404c4f78a232","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":10253,"upload_time":"2024-05-12T14:37:10","upload_time_iso_8601":"2024-05-12T14:37:10.017404Z","url":"https://files.pythonhosted.org/packages/e1/8b/ffe1bb73ea8706ad33c03e5eca0ec8107a41fd69d41702dab09d10f13c79/llm_bench-0.4.6.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.7":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.7/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.7","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"0649dc6ed383bbcaa9e1840e5f99471357c1ca31c9d7d238ca1192ee380ea12f","md5":"f86a48843eecb075496c0c70a6c5abdf","sha256":"51e62401cf99671b2853a25f2467b2d65974826adb3edede03ac06fc90b35ea8"},"downloads":-1,"filename":"llm_bench-0.4.7-py3-none-any.whl","has_sig":false,"md5_digest":"f86a48843eecb075496c0c70a6c5abdf","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":14877,"upload_time":"2024-05-12T14:41:27","upload_time_iso_8601":"2024-05-12T14:41:27.810230Z","url":"https://files.pythonhosted.org/packages/06/49/dc6ed383bbcaa9e1840e5f99471357c1ca31c9d7d238ca1192ee380ea12f/llm_bench-0.4.7-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"30ee4d888659cc0afb687767dc7eaa03ae8d7e211da89cea96287509b5f2d96f","md5":"d84a60fd5ce3945f223849d6158f50d6","sha256":"43809135e905a9f82767435d9099afc1a0c1acd7155d476dc42b205926b395f8"},"downloads":-1,"filename":"llm_bench-0.4.7.tar.gz","has_sig":false,"md5_digest":"d84a60fd5ce3945f223849d6158f50d6","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":10259,"upload_time":"2024-05-12T14:41:29","upload_time_iso_8601":"2024-05-12T14:41:29.504772Z","url":"https://files.pythonhosted.org/packages/30/ee/4d888659cc0afb687767dc7eaa03ae8d7e211da89cea96287509b5f2d96f/llm_bench-0.4.7.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.8":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.8/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.8","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"cb903708e45bb8879b6a8e87e8791c24288b45e577783ef6f8424da6c81eb91a","md5":"f3ea88eb6109366cfd7650ba4d2a94c4","sha256":"b82a55621bb562686236b0eea4313eee741d20d2d2beba6a51fd5c882519a41b"},"downloads":-1,"filename":"llm_bench-0.4.8-py3-none-any.whl","has_sig":false,"md5_digest":"f3ea88eb6109366cfd7650ba4d2a94c4","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":15210,"upload_time":"2024-05-12T14:53:41","upload_time_iso_8601":"2024-05-12T14:53:41.111501Z","url":"https://files.pythonhosted.org/packages/cb/90/3708e45bb8879b6a8e87e8791c24288b45e577783ef6f8424da6c81eb91a/llm_bench-0.4.8-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e41e96e8e21a12cce6b75d40ef58ee187c01da8c44ea854f32fe4678648dcb90","md5":"71bc779978e3e41ffd8f8c923248775d","sha256":"e08ef602257ac57a84189221cb9aa1ceeea2054d8c26f6966726efffe3e68f70"},"downloads":-1,"filename":"llm_bench-0.4.8.tar.gz","has_sig":false,"md5_digest":"71bc779978e3e41ffd8f8c923248775d","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":10450,"upload_time":"2024-05-12T14:53:42","upload_time_iso_8601":"2024-05-12T14:53:42.091363Z","url":"https://files.pythonhosted.org/packages/e4/1e/96e8e21a12cce6b75d40ef58ee187c01da8c44ea854f32fe4678648dcb90/llm_bench-0.4.8.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.9":{"info":{"author":"Snaas","author_email":null,"bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/b-Snaas/ollama-benchmark.git","keywords":"benchmark, llama, ollama, llms, local","license":"MIT","maintainer":null,"maintainer_email":null,"name":"llm-bench","package_url":"https://pypi.org/project/llm-bench/","platform":null,"project_url":"https://pypi.org/project/llm-bench/","project_urls":{"Homepage":"https://github.com/b-Snaas/ollama-benchmark.git"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-bench/0.4.9/","requires_dist":["GPUtil<2.0.0,>=1.4.0","lib-platform<2.0.0,>=1.2.10","ollama<0.2.0,>=0.1.8","psutil<6.0.0,>=5.9.8","pyyaml<7.0.0,>=6.0.1","requests<3.0.0,>=2.31.0","setuptools<70.0.0,>=69.1.0","speedtest-cli<3.0.0,>=2.1.3","typer[all]<0.10.0,>=0.9.0"],"requires_python":"<4.0,>=3.8","summary":"Forked off of LLM Benchmark for Throughputs via Ollama","version":"0.4.9","yanked":false,"yanked_reason":null},"last_serial":24257814,"urls":[{"comment_text":"","digests":{"blake2b_256":"b2634a78871f161546ac8231dc5871a5f2ae490e9b2bb2b7568a2cc611e2b2eb","md5":"db5afbcaa09401ab8243e2276da2b4cb","sha256":"2eb47092c848eb922cfec9f31cf154c9196bf0736773dfe4d33b9fdfd507a67c"},"downloads":-1,"filename":"llm_bench-0.4.9-py3-none-any.whl","has_sig":false,"md5_digest":"db5afbcaa09401ab8243e2276da2b4cb","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4.0,>=3.8","size":15210,"upload_time":"2024-05-12T14:57:29","upload_time_iso_8601":"2024-05-12T14:57:29.734052Z","url":"https://files.pythonhosted.org/packages/b2/63/4a78871f161546ac8231dc5871a5f2ae490e9b2bb2b7568a2cc611e2b2eb/llm_bench-0.4.9-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e4752d98ade554705da63eb2766a12984f3f6fc8b6925b37f796ffa48846b3ef","md5":"4e89479d22db2fd448505f9c1d866ec1","sha256":"e1e5cfd8e13c35214091429645daed49581a38b7e07b235e8f872cab36651187"},"downloads":-1,"filename":"llm_bench-0.4.9.tar.gz","has_sig":false,"md5_digest":"4e89479d22db2fd448505f9c1d866ec1","packagetype":"sdist","python_version":"source","requires_python":"<4.0,>=3.8","size":10457,"upload_time":"2024-05-12T14:57:31","upload_time_iso_8601":"2024-05-12T14:57:31.245747Z","url":"https://files.pythonhosted.org/packages/e4/75/2d98ade554705da63eb2766a12984f3f6fc8b6925b37f796ffa48846b3ef/llm_bench-0.4.9.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}