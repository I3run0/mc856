{"0.1a0":{"info":{"author":"Simon Willison","author_email":"","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"Apache-2.0","maintainer":"","maintainer_email":"","name":"llm-llama-cpp","package_url":"https://pypi.org/project/llm-llama-cpp/","platform":null,"project_url":"https://pypi.org/project/llm-llama-cpp/","project_urls":{"CI":"https://github.com/simonw/llm-llama-cpp/actions","Changelog":"https://github.com/simonw/llm-llama-cpp/releases","Homepage":"https://github.com/simonw/llm-llama-cpp","Issues":"https://github.com/simonw/llm-llama-cpp/issues"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-llama-cpp/0.1a0/","requires_dist":["llm","httpx","pytest ; extra == 'test'"],"requires_python":"","summary":"LLM plugin for running models using llama.cpp","version":"0.1a0","yanked":false,"yanked_reason":null},"last_serial":20981688,"urls":[{"comment_text":"","digests":{"blake2b_256":"7f2528a4e52387725ab5884fa3cb494c46da898016f5b24af37fb6e439d22d2b","md5":"5d1d1674601840bbb6a6ba71378347f9","sha256":"f915e431f9291eaded03fd408148ceb133658c4967571dcf8c762c4d17636051"},"downloads":-1,"filename":"llm_llama_cpp-0.1a0-py3-none-any.whl","has_sig":false,"md5_digest":"5d1d1674601840bbb6a6ba71378347f9","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":10245,"upload_time":"2023-08-01T17:43:32","upload_time_iso_8601":"2023-08-01T17:43:32.992551Z","url":"https://files.pythonhosted.org/packages/7f/25/28a4e52387725ab5884fa3cb494c46da898016f5b24af37fb6e439d22d2b/llm_llama_cpp-0.1a0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a69a6b0cb790083f8840c547efd39e646057a5ceb2428b3fe391d8d4066d7880","md5":"1d44106658f1d2f88360965bcbd99bb7","sha256":"01f5bb85051215a16aadfcc9b21c157bba5985ef732870d76d71d709e9a746b7"},"downloads":-1,"filename":"llm-llama-cpp-0.1a0.tar.gz","has_sig":false,"md5_digest":"1d44106658f1d2f88360965bcbd99bb7","packagetype":"sdist","python_version":"source","requires_python":null,"size":10022,"upload_time":"2023-08-01T17:43:34","upload_time_iso_8601":"2023-08-01T17:43:34.644772Z","url":"https://files.pythonhosted.org/packages/a6/9a/6b0cb790083f8840c547efd39e646057a5ceb2428b3fe391d8d4066d7880/llm-llama-cpp-0.1a0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2b0":{"info":{"author":"Simon Willison","author_email":"","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"Apache-2.0","maintainer":"","maintainer_email":"","name":"llm-llama-cpp","package_url":"https://pypi.org/project/llm-llama-cpp/","platform":null,"project_url":"https://pypi.org/project/llm-llama-cpp/","project_urls":{"CI":"https://github.com/simonw/llm-llama-cpp/actions","Changelog":"https://github.com/simonw/llm-llama-cpp/releases","Homepage":"https://github.com/simonw/llm-llama-cpp","Issues":"https://github.com/simonw/llm-llama-cpp/issues"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-llama-cpp/0.2b0/","requires_dist":["llm","httpx","pytest ; extra == 'test'"],"requires_python":"","summary":"LLM plugin for running models using llama.cpp","version":"0.2b0","yanked":false,"yanked_reason":null},"last_serial":20981688,"urls":[{"comment_text":"","digests":{"blake2b_256":"bc16c1ed55996cba1ba8b40346b669ba9c9a11ebee4f737fb16ebf6ff93bc5e9","md5":"f4df6f41e7be3763d403d20325bb0453","sha256":"9f5d8730bf34ce2dc76afef6d3c3a654a5d6252bae53416e44dbe7b126a09b84"},"downloads":-1,"filename":"llm_llama_cpp-0.2b0-py3-none-any.whl","has_sig":false,"md5_digest":"f4df6f41e7be3763d403d20325bb0453","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":10865,"upload_time":"2023-09-22T03:25:28","upload_time_iso_8601":"2023-09-22T03:25:28.271908Z","url":"https://files.pythonhosted.org/packages/bc/16/c1ed55996cba1ba8b40346b669ba9c9a11ebee4f737fb16ebf6ff93bc5e9/llm_llama_cpp-0.2b0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"3785403e1e940ca5a2e7f254fd287773a0ef80dfa7fe7327b0d0b9c856f83e00","md5":"9a51bb89346688a794fca2fceaaf574e","sha256":"4a727cddec5ec42fcb8d54ff0cd229280e25fbf220e746d4b40ca74924cc14a6"},"downloads":-1,"filename":"llm-llama-cpp-0.2b0.tar.gz","has_sig":false,"md5_digest":"9a51bb89346688a794fca2fceaaf574e","packagetype":"sdist","python_version":"source","requires_python":null,"size":10660,"upload_time":"2023-09-22T03:25:29","upload_time_iso_8601":"2023-09-22T03:25:29.719147Z","url":"https://files.pythonhosted.org/packages/37/85/403e1e940ca5a2e7f254fd287773a0ef80dfa7fe7327b0d0b9c856f83e00/llm-llama-cpp-0.2b0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2b1":{"info":{"author":"Simon Willison","author_email":"","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"Apache-2.0","maintainer":"","maintainer_email":"","name":"llm-llama-cpp","package_url":"https://pypi.org/project/llm-llama-cpp/","platform":null,"project_url":"https://pypi.org/project/llm-llama-cpp/","project_urls":{"CI":"https://github.com/simonw/llm-llama-cpp/actions","Changelog":"https://github.com/simonw/llm-llama-cpp/releases","Homepage":"https://github.com/simonw/llm-llama-cpp","Issues":"https://github.com/simonw/llm-llama-cpp/issues"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-llama-cpp/0.2b1/","requires_dist":["llm","httpx","pytest ; extra == 'test'"],"requires_python":"","summary":"LLM plugin for running models using llama.cpp","version":"0.2b1","yanked":false,"yanked_reason":null},"last_serial":20981688,"urls":[{"comment_text":"","digests":{"blake2b_256":"703b94dda8440a64f219ac466573e248789f83ec619c9f86b21d8e0c655e9155","md5":"d5955c57d371ecbf3a03d7ee92c0158f","sha256":"6714d1580e94063277202890edac3579f2ff927281a457440bf42b086910485e"},"downloads":-1,"filename":"llm_llama_cpp-0.2b1-py3-none-any.whl","has_sig":false,"md5_digest":"d5955c57d371ecbf3a03d7ee92c0158f","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":11024,"upload_time":"2023-09-28T03:23:20","upload_time_iso_8601":"2023-09-28T03:23:20.662665Z","url":"https://files.pythonhosted.org/packages/70/3b/94dda8440a64f219ac466573e248789f83ec619c9f86b21d8e0c655e9155/llm_llama_cpp-0.2b1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"10bfd8145f969d45d9df8243b02f60f9cb5ef045b740c24c5097158c87c037e4","md5":"8fd0caab389fa447886547ee2e760ac3","sha256":"b00cd90c5f1804dc74a826e3bd57fa77bbdcb146966e626775400cab5d258898"},"downloads":-1,"filename":"llm-llama-cpp-0.2b1.tar.gz","has_sig":false,"md5_digest":"8fd0caab389fa447886547ee2e760ac3","packagetype":"sdist","python_version":"source","requires_python":null,"size":10826,"upload_time":"2023-09-28T03:23:22","upload_time_iso_8601":"2023-09-28T03:23:22.133769Z","url":"https://files.pythonhosted.org/packages/10/bf/d8145f969d45d9df8243b02f60f9cb5ef045b740c24c5097158c87c037e4/llm-llama-cpp-0.2b1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3":{"info":{"author":"Simon Willison","author_email":"","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"Apache-2.0","maintainer":"","maintainer_email":"","name":"llm-llama-cpp","package_url":"https://pypi.org/project/llm-llama-cpp/","platform":null,"project_url":"https://pypi.org/project/llm-llama-cpp/","project_urls":{"CI":"https://github.com/simonw/llm-llama-cpp/actions","Changelog":"https://github.com/simonw/llm-llama-cpp/releases","Homepage":"https://github.com/simonw/llm-llama-cpp","Issues":"https://github.com/simonw/llm-llama-cpp/issues"},"provides_extra":null,"release_url":"https://pypi.org/project/llm-llama-cpp/0.3/","requires_dist":["llm","httpx","pytest ; extra == 'test'"],"requires_python":"","summary":"LLM plugin for running models using llama.cpp","version":"0.3","yanked":false,"yanked_reason":null},"last_serial":20981688,"urls":[{"comment_text":"","digests":{"blake2b_256":"129d696c621382c439ccff25535e3b09fad5c990cfae11ec4bdf65c2eaecd690","md5":"1bc71704c36b1dd7d01f53c24c24a8e8","sha256":"a67d30ca7724a202b96d6d1f6dd9cbf1a6e44bde03db03820a487282eb857588"},"downloads":-1,"filename":"llm_llama_cpp-0.3-py3-none-any.whl","has_sig":false,"md5_digest":"1bc71704c36b1dd7d01f53c24c24a8e8","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":11627,"upload_time":"2023-12-09T05:49:26","upload_time_iso_8601":"2023-12-09T05:49:26.702530Z","url":"https://files.pythonhosted.org/packages/12/9d/696c621382c439ccff25535e3b09fad5c990cfae11ec4bdf65c2eaecd690/llm_llama_cpp-0.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"5c3a0163b63b1cce4b52877fd29bd25ec1b1335f2757c785d3f022b0f5c44997","md5":"12a81286f02b77e3dbfa9ba29b10d08c","sha256":"8de7ab99fc62510e96ff8d5ca084aebf7b8f6051eae114409a7c35cd6d26c557"},"downloads":-1,"filename":"llm-llama-cpp-0.3.tar.gz","has_sig":false,"md5_digest":"12a81286f02b77e3dbfa9ba29b10d08c","packagetype":"sdist","python_version":"source","requires_python":null,"size":11469,"upload_time":"2023-12-09T05:49:28","upload_time_iso_8601":"2023-12-09T05:49:28.094016Z","url":"https://files.pythonhosted.org/packages/5c/3a/0163b63b1cce4b52877fd29bd25ec1b1335f2757c785d3f022b0f5c44997/llm-llama-cpp-0.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}