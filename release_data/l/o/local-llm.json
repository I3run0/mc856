{"0.0.10":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.10/","requires_dist":["fastapi","pydantic","requests","uvicorn","argparse","pyjwt","tiktoken","llama-cpp-python","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.10","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"9a461e55cf1893d887ae1aeeef8b56236e789ca191d874b58b5c3c388cebc3f0","md5":"e34fdadd2170d6cce5cfe2b480dc3399","sha256":"e07e78438c7438e4cfa6a86fd79ab41a196b81cd1cc78193437d970d91dffae0"},"downloads":-1,"filename":"local_llm-0.0.10-py3-none-any.whl","has_sig":false,"md5_digest":"e34fdadd2170d6cce5cfe2b480dc3399","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":6812,"upload_time":"2023-10-04T19:44:26","upload_time_iso_8601":"2023-10-04T19:44:26.508823Z","url":"https://files.pythonhosted.org/packages/9a/46/1e55cf1893d887ae1aeeef8b56236e789ca191d874b58b5c3c388cebc3f0/local_llm-0.0.10-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"fcd79f8ab743b385162ef14d36ab3da6d1806bd65c52827c30baa92a5d7d545b","md5":"acf4f9d22d4bc0a0d245cb47abb30a24","sha256":"54088bd53645fd0384ae69924f4ff09ce7411fef30ec95153cb5eb11b93a83aa"},"downloads":-1,"filename":"local-llm-0.0.10.tar.gz","has_sig":false,"md5_digest":"acf4f9d22d4bc0a0d245cb47abb30a24","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":58527,"upload_time":"2023-10-04T19:44:27","upload_time_iso_8601":"2023-10-04T19:44:27.689332Z","url":"https://files.pythonhosted.org/packages/fc/d7/9f8ab743b385162ef14d36ab3da6d1806bd65c52827c30baa92a5d7d545b/local-llm-0.0.10.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.11":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.11/","requires_dist":["fastapi","pydantic","requests","uvicorn","argparse","pyjwt","tiktoken","llama-cpp-python","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.11","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"342403dd80c9e2085e408aa047e3284c8c504e3aa7d01cd2078f8c6f7a1cce9d","md5":"6ff2a6c8343d267e15b0167eb6e37a26","sha256":"a357f07b1b327fa2d8d7f2194b852f046b3d19f7c53e57cf74c4014119cc0fa7"},"downloads":-1,"filename":"local_llm-0.0.11-py3-none-any.whl","has_sig":false,"md5_digest":"6ff2a6c8343d267e15b0167eb6e37a26","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":6871,"upload_time":"2023-10-04T19:58:23","upload_time_iso_8601":"2023-10-04T19:58:23.119455Z","url":"https://files.pythonhosted.org/packages/34/24/03dd80c9e2085e408aa047e3284c8c504e3aa7d01cd2078f8c6f7a1cce9d/local_llm-0.0.11-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"9dd06212b7209f7a87666a7f562b1d273acf43def94bb86998fb7a020dcb06d9","md5":"4729379e65c8a899e1955c16944ff994","sha256":"2084634cb8f9200a7b5f0ee345c0c6bbe69ac380587f79cfe4c311d95e07fed5"},"downloads":-1,"filename":"local-llm-0.0.11.tar.gz","has_sig":false,"md5_digest":"4729379e65c8a899e1955c16944ff994","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":58588,"upload_time":"2023-10-04T19:58:24","upload_time_iso_8601":"2023-10-04T19:58:24.624932Z","url":"https://files.pythonhosted.org/packages/9d/d0/6212b7209f7a87666a7f562b1d273acf43def94bb86998fb7a020dcb06d9/local-llm-0.0.11.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.12":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.12/","requires_dist":["fastapi","pydantic","requests","uvicorn","argparse","pyjwt","tiktoken","llama-cpp-python","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.12","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"aac80c789ada9de755e09e62e73ed7a38321c35024a5ff507ec6ea5bd27f2ed0","md5":"10fa2e84bb370cb1529f91681d20205f","sha256":"2f54a69ab13ad50140604e790e80cd9ddcd69c460881d7c5e91f2a8dbe5d4d82"},"downloads":-1,"filename":"local_llm-0.0.12-py3-none-any.whl","has_sig":false,"md5_digest":"10fa2e84bb370cb1529f91681d20205f","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":6897,"upload_time":"2023-10-04T20:07:51","upload_time_iso_8601":"2023-10-04T20:07:51.819879Z","url":"https://files.pythonhosted.org/packages/aa/c8/0c789ada9de755e09e62e73ed7a38321c35024a5ff507ec6ea5bd27f2ed0/local_llm-0.0.12-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a18a61486ae098f0bc269993d89e783ce35875ae2d0f39be6fac35ce2e8ea802","md5":"e366eb9d1d2663ddae0ea18d9d2d4c5c","sha256":"655041371e8dd9f2d614c6486b42bde3dcf07658424f1edfc5ed742af82f2fa1"},"downloads":-1,"filename":"local-llm-0.0.12.tar.gz","has_sig":false,"md5_digest":"e366eb9d1d2663ddae0ea18d9d2d4c5c","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":58619,"upload_time":"2023-10-04T20:07:53","upload_time_iso_8601":"2023-10-04T20:07:53.324058Z","url":"https://files.pythonhosted.org/packages/a1/8a/61486ae098f0bc269993d89e783ce35875ae2d0f39be6fac35ce2e8ea802/local-llm-0.0.12.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.13":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.13/","requires_dist":["fastapi","pydantic","requests","uvicorn","argparse","pyjwt","tiktoken","llama-cpp-python","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.13","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"932c95068331281a1456196f1d642a4c0439704b9cfd715d1684bd426bba6943","md5":"2268302cb8b9f2f26b63f070729d9d60","sha256":"2179dbbe9689f451818476f0d79074178b8653d507448d33a918b793242ed323"},"downloads":-1,"filename":"local_llm-0.0.13-py3-none-any.whl","has_sig":false,"md5_digest":"2268302cb8b9f2f26b63f070729d9d60","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":6904,"upload_time":"2023-10-04T20:13:02","upload_time_iso_8601":"2023-10-04T20:13:02.269922Z","url":"https://files.pythonhosted.org/packages/93/2c/95068331281a1456196f1d642a4c0439704b9cfd715d1684bd426bba6943/local_llm-0.0.13-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"3803a65e1be23e9822cf54e764e5fa7d52fad0d45f06d8dee9d4271fcca6703e","md5":"e540fe97b62b139fe0a134c34551a4c8","sha256":"8a1660727af96c9107e06ca8515347a15611ac273545c5001156ccf6965247e2"},"downloads":-1,"filename":"local-llm-0.0.13.tar.gz","has_sig":false,"md5_digest":"e540fe97b62b139fe0a134c34551a4c8","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":58618,"upload_time":"2023-10-04T20:13:04","upload_time_iso_8601":"2023-10-04T20:13:04.001993Z","url":"https://files.pythonhosted.org/packages/38/03/a65e1be23e9822cf54e764e5fa7d52fad0d45f06d8dee9d4271fcca6703e/local-llm-0.0.13.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.14":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.14/","requires_dist":["fastapi","pydantic","requests","uvicorn","argparse","pyjwt","tiktoken","llama-cpp-python ==0.2.11","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.14","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"d84da5fddf4adb564dd2800642c012f21210b9bcfb8451200fdf39350a76c776","md5":"26fa51eff98971d108211f2e719a9ecb","sha256":"5eb9ec169e97eadfa827034f42184825ebedb6caf7bf2bb3856cbf2b77008f52"},"downloads":-1,"filename":"local_llm-0.0.14-py3-none-any.whl","has_sig":false,"md5_digest":"26fa51eff98971d108211f2e719a9ecb","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":6937,"upload_time":"2023-10-05T00:38:32","upload_time_iso_8601":"2023-10-05T00:38:32.995411Z","url":"https://files.pythonhosted.org/packages/d8/4d/a5fddf4adb564dd2800642c012f21210b9bcfb8451200fdf39350a76c776/local_llm-0.0.14-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7bb648419a1700cf1d9c80042f7239c8295eb1dcf2156d374a8b09936f1f8d16","md5":"8edf7918ad0ab0ac03c53ab1a5e24d32","sha256":"c4d6d0f0852f211345f487a967c184b86b6f484b458774bc4399c70335442547"},"downloads":-1,"filename":"local-llm-0.0.14.tar.gz","has_sig":false,"md5_digest":"8edf7918ad0ab0ac03c53ab1a5e24d32","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":58838,"upload_time":"2023-10-05T00:38:34","upload_time_iso_8601":"2023-10-05T00:38:34.618362Z","url":"https://files.pythonhosted.org/packages/7b/b6/48419a1700cf1d9c80042f7239c8295eb1dcf2156d374a8b09936f1f8d16/local-llm-0.0.14.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.15":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.15/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.11","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.15","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"7f1352495e29d152b4e3285874c4ea5be8ccd6e0ffe51172c33fca5c2413fbee","md5":"9c5f90f013f59d2e2266e721439e9bc6","sha256":"81df8e29a1f6df5efc4425935d11571ffb45147db80c53dd06f36c7bb5668c73"},"downloads":-1,"filename":"local_llm-0.0.15-py3-none-any.whl","has_sig":false,"md5_digest":"9c5f90f013f59d2e2266e721439e9bc6","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":6931,"upload_time":"2023-10-18T19:30:56","upload_time_iso_8601":"2023-10-18T19:30:56.901694Z","url":"https://files.pythonhosted.org/packages/7f/13/52495e29d152b4e3285874c4ea5be8ccd6e0ffe51172c33fca5c2413fbee/local_llm-0.0.15-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"90eddea696d7697e7079fc773ad9826e917c5d4b5de7fa5755d4f49b92c2cb7e","md5":"012fed1dfc89e3eb558553de41b973b5","sha256":"842b81b15a0d48dde4d52c2e6bc4ca3adb712d97c630b8121b7c1a0aee79e63a"},"downloads":-1,"filename":"local-llm-0.0.15.tar.gz","has_sig":false,"md5_digest":"012fed1dfc89e3eb558553de41b973b5","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":58834,"upload_time":"2023-10-18T19:30:58","upload_time_iso_8601":"2023-10-18T19:30:58.031377Z","url":"https://files.pythonhosted.org/packages/90/ed/dea696d7697e7079fc773ad9826e917c5d4b5de7fa5755d4f49b92c2cb7e/local-llm-0.0.15.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.16":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.16/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.11","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.16","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"9b554ef93c3435289c7c410b18f60ac3744e3f6add07625b5871a5298e7d2dc5","md5":"7bbd05ab6a4325542a7362b8d45a262b","sha256":"c3b5c9af575b0017282c4846b1d6c5a38de0f5ceaaa7aa912b1e9119f40a0261"},"downloads":-1,"filename":"local_llm-0.0.16-py3-none-any.whl","has_sig":false,"md5_digest":"7bbd05ab6a4325542a7362b8d45a262b","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":6968,"upload_time":"2023-10-25T13:37:08","upload_time_iso_8601":"2023-10-25T13:37:08.729808Z","url":"https://files.pythonhosted.org/packages/9b/55/4ef93c3435289c7c410b18f60ac3744e3f6add07625b5871a5298e7d2dc5/local_llm-0.0.16-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d14968237e764b430251a81336daba7539de91968bb992ce6fa4732d02244a45","md5":"b4d9110e05548814dfd8554ebe0abcc5","sha256":"ea84fe3b6a6363cbfd1bd8c36b4098526adf34a691be9cb6ad58895bf7425f17"},"downloads":-1,"filename":"local-llm-0.0.16.tar.gz","has_sig":false,"md5_digest":"b4d9110e05548814dfd8554ebe0abcc5","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":58862,"upload_time":"2023-10-25T13:37:10","upload_time_iso_8601":"2023-10-25T13:37:10.417579Z","url":"https://files.pythonhosted.org/packages/d1/49/68237e764b430251a81336daba7539de91968bb992ce6fa4732d02244a45/local-llm-0.0.16.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.17":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.17/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.16","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.17","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"cc40a94404d6e5d7d1b2a6955a751bee72f93b32b841b838790ec40e296a1b87","md5":"5f5eeb5ff1e4243017bc65a9823ebb71","sha256":"871cc6680662642f727f3263bf3a245223f22f4f5fb5edc66d6f5ea673331798"},"downloads":-1,"filename":"local_llm-0.0.17-py3-none-any.whl","has_sig":false,"md5_digest":"5f5eeb5ff1e4243017bc65a9823ebb71","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7219,"upload_time":"2023-11-10T14:40:06","upload_time_iso_8601":"2023-11-10T14:40:06.683992Z","url":"https://files.pythonhosted.org/packages/cc/40/a94404d6e5d7d1b2a6955a751bee72f93b32b841b838790ec40e296a1b87/local_llm-0.0.17-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"ecdf75d78cf2f870e0160000c597d0c98eda5787b80fba6e23402367d4c517bb","md5":"16e6ce2e43bf5accf6e2c355c75e45e7","sha256":"0ba7920e039967bcc37b3e3505e281364bf23cfb3586e4a9f8157e4a3377bf26"},"downloads":-1,"filename":"local-llm-0.0.17.tar.gz","has_sig":false,"md5_digest":"16e6ce2e43bf5accf6e2c355c75e45e7","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":59102,"upload_time":"2023-11-10T14:40:08","upload_time_iso_8601":"2023-11-10T14:40:08.561186Z","url":"https://files.pythonhosted.org/packages/ec/df/75d78cf2f870e0160000c597d0c98eda5787b80fba6e23402367d4c517bb/local-llm-0.0.17.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.18":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.18/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.17","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.18","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"d453d373d80d06998cc72427e53173f34ba99e40850e7a8ffec1bcf648aeb1aa","md5":"08219ffb29949b8ca9756eef9a2dc9da","sha256":"689ad6fab6e7f1b54fffe81c76408576ffaaf1c78c3ea7efa3834ef0cd5e541b"},"downloads":-1,"filename":"local_llm-0.0.18-py3-none-any.whl","has_sig":false,"md5_digest":"08219ffb29949b8ca9756eef9a2dc9da","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7219,"upload_time":"2023-11-11T16:58:23","upload_time_iso_8601":"2023-11-11T16:58:23.521758Z","url":"https://files.pythonhosted.org/packages/d4/53/d373d80d06998cc72427e53173f34ba99e40850e7a8ffec1bcf648aeb1aa/local_llm-0.0.18-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"6c5a3197d83eb115cbf6c0d90d9fb3d915f0e18fb4abae3c166ec47b6340bfd5","md5":"7fcbe228a1c647a0b18cb94b14b37c36","sha256":"0937d58534a34c3af58e98e856534d75cdf88dc627f74f35c5ff29d1b81abcba"},"downloads":-1,"filename":"local-llm-0.0.18.tar.gz","has_sig":false,"md5_digest":"7fcbe228a1c647a0b18cb94b14b37c36","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":59107,"upload_time":"2023-11-11T16:58:25","upload_time_iso_8601":"2023-11-11T16:58:25.005996Z","url":"https://files.pythonhosted.org/packages/6c/5a/3197d83eb115cbf6c0d90d9fb3d915f0e18fb4abae3c166ec47b6340bfd5/local-llm-0.0.18.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.19":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.19/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.17","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.19","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"acdccb20ff67fa108c9803369aeeb64a745a223e5a6941c30b25c5e499d47939","md5":"ea621eda0ee41d4e042c34a92cfcbe28","sha256":"4f3ee6ad8f2d2badaf8f9c2981013b520a3f63385d10502fd82bb01bc5a48c87"},"downloads":-1,"filename":"local_llm-0.0.19-py3-none-any.whl","has_sig":false,"md5_digest":"ea621eda0ee41d4e042c34a92cfcbe28","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7047,"upload_time":"2023-11-13T12:47:03","upload_time_iso_8601":"2023-11-13T12:47:03.799553Z","url":"https://files.pythonhosted.org/packages/ac/dc/cb20ff67fa108c9803369aeeb64a745a223e5a6941c30b25c5e499d47939/local_llm-0.0.19-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7c0e301f3e02608c84fddb8da5092aa4322b94a7885b0035e5ed4da9068f60ce","md5":"25dd625733ef89747f7d6cea261ad4d3","sha256":"27ea0053b831066287b60ff2927e9435bcbffdbbe4c6456d733e8fbfd294788c"},"downloads":-1,"filename":"local-llm-0.0.19.tar.gz","has_sig":false,"md5_digest":"25dd625733ef89747f7d6cea261ad4d3","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":58946,"upload_time":"2023-11-13T12:47:05","upload_time_iso_8601":"2023-11-13T12:47:05.361959Z","url":"https://files.pythonhosted.org/packages/7c/0e/301f3e02608c84fddb8da5092aa4322b94a7885b0035e5ed4da9068f60ce/local-llm-0.0.19.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.20":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.20/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.18","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.20","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"7676992dd5ee9426faf630ee05d0594a4e946b622e7c5e133d9f66e3cf492475","md5":"97d103c09624aa9ddd2431457a8d75a8","sha256":"26fc805478259571dc9ebe68d48c61f27d27b1731f1d856b97f34092a62cab63"},"downloads":-1,"filename":"local_llm-0.0.20-py3-none-any.whl","has_sig":false,"md5_digest":"97d103c09624aa9ddd2431457a8d75a8","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7048,"upload_time":"2023-11-14T19:45:12","upload_time_iso_8601":"2023-11-14T19:45:12.872300Z","url":"https://files.pythonhosted.org/packages/76/76/992dd5ee9426faf630ee05d0594a4e946b622e7c5e133d9f66e3cf492475/local_llm-0.0.20-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"51b7b218e625eb76a13bc2e7c3a69d8b68b7a2bd84311f8ea330caed512fd237","md5":"7710085eb5706530feb508bf9e4a6aa5","sha256":"f843d259c1b43d7e674775e277368406686f101ad2f107948ae2b64b57fe0e57"},"downloads":-1,"filename":"local-llm-0.0.20.tar.gz","has_sig":false,"md5_digest":"7710085eb5706530feb508bf9e4a6aa5","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":59496,"upload_time":"2023-11-14T19:45:14","upload_time_iso_8601":"2023-11-14T19:45:14.596639Z","url":"https://files.pythonhosted.org/packages/51/b7/b218e625eb76a13bc2e7c3a69d8b68b7a2bd84311f8ea330caed512fd237/local-llm-0.0.20.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.21":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.21/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.18","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.21","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"814eb9db4aa4737d8f5327891ee7cef72eae573c2e26f3fd73d7cc4eab5fe6c2","md5":"05ba017b1debbd69fb33481d0d443f14","sha256":"5e4e2f7fe0f0ec5c4cae3f509af1b5c2922e935431073484630db191f97173ef"},"downloads":-1,"filename":"local_llm-0.0.21-py3-none-any.whl","has_sig":false,"md5_digest":"05ba017b1debbd69fb33481d0d443f14","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7049,"upload_time":"2023-11-18T02:04:08","upload_time_iso_8601":"2023-11-18T02:04:08.224458Z","url":"https://files.pythonhosted.org/packages/81/4e/b9db4aa4737d8f5327891ee7cef72eae573c2e26f3fd73d7cc4eab5fe6c2/local_llm-0.0.21-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"081a9a48630460609fe7f9ee327f9057be0faec8825c72832d82418b6cc13a70","md5":"507a436296084ef417fc7fe24a27faac","sha256":"bc28790617fc36e6bb0e35c4dcde24fff32a4266caadeb0bde5dde807e282083"},"downloads":-1,"filename":"local-llm-0.0.21.tar.gz","has_sig":false,"md5_digest":"507a436296084ef417fc7fe24a27faac","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":59502,"upload_time":"2023-11-18T02:04:09","upload_time_iso_8601":"2023-11-18T02:04:09.675529Z","url":"https://files.pythonhosted.org/packages/08/1a/9a48630460609fe7f9ee327f9057be0faec8825c72832d82418b6cc13a70/local-llm-0.0.21.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.22":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.22/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.18","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.22","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"e9de1c1c4b40145d9959fa54f1860c455a2f325e1ee116aa0fc74d44c23805c1","md5":"ef67a33edd857f200d0c36e7648bc372","sha256":"91572dc29226283552419675f4964a4d24bca464475d2aeddbd560b6f6031187"},"downloads":-1,"filename":"local_llm-0.0.22-py3-none-any.whl","has_sig":false,"md5_digest":"ef67a33edd857f200d0c36e7648bc372","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7048,"upload_time":"2023-11-18T13:39:21","upload_time_iso_8601":"2023-11-18T13:39:21.890987Z","url":"https://files.pythonhosted.org/packages/e9/de/1c1c4b40145d9959fa54f1860c455a2f325e1ee116aa0fc74d44c23805c1/local_llm-0.0.22-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"057caa2755f15ce8ee408d2451601435d79a94d0e07b0b4d80b4e888ef1dfda6","md5":"371aeac2851473b2a55d034c6b718a3e","sha256":"11995e54b52fa4800cf7528d18e7639c3605f459ac1c1df3e608dfb5a6a544a2"},"downloads":-1,"filename":"local-llm-0.0.22.tar.gz","has_sig":false,"md5_digest":"371aeac2851473b2a55d034c6b718a3e","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":59513,"upload_time":"2023-11-18T13:39:23","upload_time_iso_8601":"2023-11-18T13:39:23.370818Z","url":"https://files.pythonhosted.org/packages/05/7c/aa2755f15ce8ee408d2451601435d79a94d0e07b0b4d80b4e888ef1dfda6/local-llm-0.0.22.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.23":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.23/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.18","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.23","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"9eb25f7ffb6f64da8b0fb898eb5b2d9d158198c5657963df6df09af76dcbcf67","md5":"827446f44e22d8cbef11d7c3f9c125d2","sha256":"254083e498cbefd400564de7b0eab31702ef116568320d2992114fcbe418edc1"},"downloads":-1,"filename":"local_llm-0.0.23-py3-none-any.whl","has_sig":false,"md5_digest":"827446f44e22d8cbef11d7c3f9c125d2","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7233,"upload_time":"2023-11-18T14:58:33","upload_time_iso_8601":"2023-11-18T14:58:33.652555Z","url":"https://files.pythonhosted.org/packages/9e/b2/5f7ffb6f64da8b0fb898eb5b2d9d158198c5657963df6df09af76dcbcf67/local_llm-0.0.23-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"af33498f81bb00ca540f9ac22dafd1c4bb2baf6a70b3347fefa3695b81f269f9","md5":"8ac9a33d26f2c87d71b113582da689b6","sha256":"6f42bcffe8e381f9add9a92c6d94a2e4fe6966e55d605db27bbebe1699c4f557"},"downloads":-1,"filename":"local-llm-0.0.23.tar.gz","has_sig":false,"md5_digest":"8ac9a33d26f2c87d71b113582da689b6","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":59887,"upload_time":"2023-11-18T14:58:35","upload_time_iso_8601":"2023-11-18T14:58:35.325079Z","url":"https://files.pythonhosted.org/packages/af/33/498f81bb00ca540f9ac22dafd1c4bb2baf6a70b3347fefa3695b81f269f9/local-llm-0.0.23.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.24":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.24/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.18","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.24","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"458f12ffddb0c795c2d1f1b0eb1f0927341c2685636cf6605404ba5e0cf70855","md5":"384816aade700bb0dc20fd80103d0abd","sha256":"18e470a6ee0fe782922830a009aaf298a257c32634b3139ea9ca5bedd465fb98"},"downloads":-1,"filename":"local_llm-0.0.24-py3-none-any.whl","has_sig":false,"md5_digest":"384816aade700bb0dc20fd80103d0abd","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7232,"upload_time":"2023-11-18T16:30:29","upload_time_iso_8601":"2023-11-18T16:30:29.360413Z","url":"https://files.pythonhosted.org/packages/45/8f/12ffddb0c795c2d1f1b0eb1f0927341c2685636cf6605404ba5e0cf70855/local_llm-0.0.24-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"685909574e2f8aca379a88cacda9aabf55e245424874f7d6050604813030cc34","md5":"8ebf32084cc6775f655f02ffa1547923","sha256":"3a88132e51aedec2a699a41630cd54d4d9428e0925fbcb1f7f713a9ba9fec321"},"downloads":-1,"filename":"local-llm-0.0.24.tar.gz","has_sig":false,"md5_digest":"8ebf32084cc6775f655f02ffa1547923","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":59914,"upload_time":"2023-11-18T16:30:30","upload_time_iso_8601":"2023-11-18T16:30:30.695505Z","url":"https://files.pythonhosted.org/packages/68/59/09574e2f8aca379a88cacda9aabf55e245424874f7d6050604813030cc34/local-llm-0.0.24.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.25":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.25/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.18","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.25","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"54d609a0d05769e6cf00ea5b9c2355ff00436799e477f4eac58fa53ea83eb1aa","md5":"bfacc5c9b1807d1282d4e288631111ab","sha256":"87f2bbf96c899b04f1cd5620290ea2912f9ea0d4abeed1a1bc53b10b7c1ec500"},"downloads":-1,"filename":"local_llm-0.0.25-py3-none-any.whl","has_sig":false,"md5_digest":"bfacc5c9b1807d1282d4e288631111ab","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7236,"upload_time":"2023-11-18T16:49:19","upload_time_iso_8601":"2023-11-18T16:49:19.422253Z","url":"https://files.pythonhosted.org/packages/54/d6/09a0d05769e6cf00ea5b9c2355ff00436799e477f4eac58fa53ea83eb1aa/local_llm-0.0.25-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"52028a24bf2a20ce10e976a0aa151d9114ec44c2a5b8dba9311a1c6753f16cd9","md5":"0b38d74b497039d74e259c085a5874aa","sha256":"f5acd3a66e480a070a2235b4fc56df38f1dd3023a23d9504565c474060831a4d"},"downloads":-1,"filename":"local-llm-0.0.25.tar.gz","has_sig":false,"md5_digest":"0b38d74b497039d74e259c085a5874aa","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":61130,"upload_time":"2023-11-18T16:49:20","upload_time_iso_8601":"2023-11-18T16:49:20.954078Z","url":"https://files.pythonhosted.org/packages/52/02/8a24bf2a20ce10e976a0aa151d9114ec44c2a5b8dba9311a1c6753f16cd9/local-llm-0.0.25.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.26":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.26/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.18","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.26","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"d5f9a1d73b86eff21fdc67d57901256ef5d32395a6261e20f9e9648016cffcb8","md5":"0e3b8660683adce79406ccefc355383a","sha256":"1ae58484b757c7d539ca7db194c1aed96b6d3f21ab33d3a63c4451632cbe05eb"},"downloads":-1,"filename":"local_llm-0.0.26-py3-none-any.whl","has_sig":false,"md5_digest":"0e3b8660683adce79406ccefc355383a","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7246,"upload_time":"2023-11-18T17:51:48","upload_time_iso_8601":"2023-11-18T17:51:48.872095Z","url":"https://files.pythonhosted.org/packages/d5/f9/a1d73b86eff21fdc67d57901256ef5d32395a6261e20f9e9648016cffcb8/local_llm-0.0.26-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e6812d046285febe23d52ff2c518e34fe499e6958f16742daae40453a474afe6","md5":"cdcc3412d25173a77f64222337637cfd","sha256":"cbb37b704653b9b3a0f8daddb716cdb3678adc51085928fffd632ed0605e4756"},"downloads":-1,"filename":"local-llm-0.0.26.tar.gz","has_sig":false,"md5_digest":"cdcc3412d25173a77f64222337637cfd","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":61146,"upload_time":"2023-11-18T17:51:50","upload_time_iso_8601":"2023-11-18T17:51:50.246945Z","url":"https://files.pythonhosted.org/packages/e6/81/2d046285febe23d52ff2c518e34fe499e6958f16742daae40453a474afe6/local-llm-0.0.26.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.27":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.27/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.18","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.27","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"df6ca03b4f49a011c5431a63a093b16590e52f723cd83fa7a7429e59ceb2b898","md5":"c13b01691418e95e26356b221b953c02","sha256":"59b631ac81909bf581266f72b50511c017230546ca6b0fc8fcecd8cc641118d8"},"downloads":-1,"filename":"local_llm-0.0.27-py3-none-any.whl","has_sig":false,"md5_digest":"c13b01691418e95e26356b221b953c02","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7284,"upload_time":"2023-11-18T17:59:23","upload_time_iso_8601":"2023-11-18T17:59:23.306892Z","url":"https://files.pythonhosted.org/packages/df/6c/a03b4f49a011c5431a63a093b16590e52f723cd83fa7a7429e59ceb2b898/local_llm-0.0.27-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d037fdb4d841e546c8d8e8fc590f6d64360a5188e9db655308ff29b0ee68690d","md5":"cbb5eaca23b8aa276225d0c524018723","sha256":"32040ee0e489a5cec0ccc4eef61d5c0056891f29850a1d004866d28dcec0d166"},"downloads":-1,"filename":"local-llm-0.0.27.tar.gz","has_sig":false,"md5_digest":"cbb5eaca23b8aa276225d0c524018723","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":61179,"upload_time":"2023-11-18T17:59:24","upload_time_iso_8601":"2023-11-18T17:59:24.441499Z","url":"https://files.pythonhosted.org/packages/d0/37/fdb4d841e546c8d8e8fc590f6d64360a5188e9db655308ff29b0ee68690d/local-llm-0.0.27.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.28":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.28/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.18","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.28","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"70ff54b807669931282a0d8fcfa4adda384b307bee65bcd9a511008194d0405b","md5":"3499f4411610e7e6844e562ae56fbd23","sha256":"d384ce2a4326d7222394a6e3a5cce8cf6814ec02e5b875685fe127a5b80b4906"},"downloads":-1,"filename":"local_llm-0.0.28-py3-none-any.whl","has_sig":false,"md5_digest":"3499f4411610e7e6844e562ae56fbd23","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7261,"upload_time":"2023-11-18T18:17:39","upload_time_iso_8601":"2023-11-18T18:17:39.152079Z","url":"https://files.pythonhosted.org/packages/70/ff/54b807669931282a0d8fcfa4adda384b307bee65bcd9a511008194d0405b/local_llm-0.0.28-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"f5bb4183a2ae13278e4eb09ecdaec15334053d06a010240bd4d675bf6d167b30","md5":"bf918f4e7ee100a42ca985c85cf96708","sha256":"c0e4c49ee669a00d14f5600abdf9f24e172125739726b9a9c610b7ee33c80d22"},"downloads":-1,"filename":"local-llm-0.0.28.tar.gz","has_sig":false,"md5_digest":"bf918f4e7ee100a42ca985c85cf96708","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":61125,"upload_time":"2023-11-18T18:17:40","upload_time_iso_8601":"2023-11-18T18:17:40.581526Z","url":"https://files.pythonhosted.org/packages/f5/bb/4183a2ae13278e4eb09ecdaec15334053d06a010240bd4d675bf6d167b30/local-llm-0.0.28.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.29":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.29/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.18","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.29","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"9c009c552a416d3b66662933bac5735590c3b548df3832f1ea7501aa6aba670d","md5":"760051165d4c3bf7cfec7cdf768c6bbf","sha256":"1b091744cc3f1dbcfbc83e2a734feb417bc2afd68104aede6d08c8737e115132"},"downloads":-1,"filename":"local_llm-0.0.29-py3-none-any.whl","has_sig":false,"md5_digest":"760051165d4c3bf7cfec7cdf768c6bbf","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7279,"upload_time":"2023-11-19T14:31:45","upload_time_iso_8601":"2023-11-19T14:31:45.900587Z","url":"https://files.pythonhosted.org/packages/9c/00/9c552a416d3b66662933bac5735590c3b548df3832f1ea7501aa6aba670d/local_llm-0.0.29-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"86b2149854bb643ae5b3c66b9a170de49fe6f352c627ee01a56afa6a66b9892a","md5":"0080d3ff898ba60a26383a65bf5b22e9","sha256":"5321766cd9b67fa3c7deaa3294571a08163f1a9f49887d7c0628de68e3bde583"},"downloads":-1,"filename":"local-llm-0.0.29.tar.gz","has_sig":false,"md5_digest":"0080d3ff898ba60a26383a65bf5b22e9","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":61145,"upload_time":"2023-11-19T14:31:47","upload_time_iso_8601":"2023-11-19T14:31:47.289483Z","url":"https://files.pythonhosted.org/packages/86/b2/149854bb643ae5b3c66b9a170de49fe6f352c627ee01a56afa6a66b9892a/local-llm-0.0.29.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.30":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.30/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.18","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.30","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"7512deb007091c34c1dadadefa0b48301a46505f47a38c597cc0cb96b4f88e1b","md5":"d5c300bd4f9ac38cec737479d31a8711","sha256":"b83af0671627bde9b5280189d34012399e28f597b4af02e27873432a7701f460"},"downloads":-1,"filename":"local_llm-0.0.30-py3-none-any.whl","has_sig":false,"md5_digest":"d5c300bd4f9ac38cec737479d31a8711","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7280,"upload_time":"2023-11-20T20:41:18","upload_time_iso_8601":"2023-11-20T20:41:18.733377Z","url":"https://files.pythonhosted.org/packages/75/12/deb007091c34c1dadadefa0b48301a46505f47a38c597cc0cb96b4f88e1b/local_llm-0.0.30-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8b7939c857d6929d89018679cb6ca36438d7fbb8b29f62fb801a7348d9708dcc","md5":"b77ad6a880d059277f0323c733a6ba3a","sha256":"db548cce12d2916e1d29841bc7c819a940d105dec3db1fe1df9f04a6c5f7aeae"},"downloads":-1,"filename":"local-llm-0.0.30.tar.gz","has_sig":false,"md5_digest":"b77ad6a880d059277f0323c733a6ba3a","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":61138,"upload_time":"2023-11-20T20:41:20","upload_time_iso_8601":"2023-11-20T20:41:20.504720Z","url":"https://files.pythonhosted.org/packages/8b/79/39c857d6929d89018679cb6ca36438d7fbb8b29f62fb801a7348d9708dcc/local-llm-0.0.30.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.31":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.31/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.18","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.31","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"d85cda721bfe2a48217f20aea1bb2fb01021ae5b41b18c71799807447414eac4","md5":"1266e6ee786d1e26a4a22ff34db07336","sha256":"709d3abcc4317ffe730c329122c964f8f3d65f2cd1d4ae2c9c4f63dbc074f6fb"},"downloads":-1,"filename":"local_llm-0.0.31-py3-none-any.whl","has_sig":false,"md5_digest":"1266e6ee786d1e26a4a22ff34db07336","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7293,"upload_time":"2023-11-20T20:57:23","upload_time_iso_8601":"2023-11-20T20:57:23.363119Z","url":"https://files.pythonhosted.org/packages/d8/5c/da721bfe2a48217f20aea1bb2fb01021ae5b41b18c71799807447414eac4/local_llm-0.0.31-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"fc25f1f5a1a062235d05e76f86ab229e7b06d43e99ca8013c5f24ec2f49ee16e","md5":"17f0941ef64921a51d2d1475b6f9b45d","sha256":"20e15c9495f09c40458608c017a897a020c95173d9ac96235f8b27a443acc0ce"},"downloads":-1,"filename":"local-llm-0.0.31.tar.gz","has_sig":false,"md5_digest":"17f0941ef64921a51d2d1475b6f9b45d","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":61155,"upload_time":"2023-11-20T20:57:25","upload_time_iso_8601":"2023-11-20T20:57:25.973369Z","url":"https://files.pythonhosted.org/packages/fc/25/f1f5a1a062235d05e76f86ab229e7b06d43e99ca8013c5f24ec2f49ee16e/local-llm-0.0.31.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.33":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.33/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.19","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.33","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"7d60340045843996a4a67c05815cafb6f77a8b6c2fe20dddcc57db39f64153cc","md5":"d6150289e52c328d3b22820461c418de","sha256":"0ad89f28d8a1c1e1daa9c95632f156518045b4bdcad7d208d58a078a28ffd7c1"},"downloads":-1,"filename":"local_llm-0.0.33-py3-none-any.whl","has_sig":false,"md5_digest":"d6150289e52c328d3b22820461c418de","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7285,"upload_time":"2023-11-21T17:29:34","upload_time_iso_8601":"2023-11-21T17:29:34.657790Z","url":"https://files.pythonhosted.org/packages/7d/60/340045843996a4a67c05815cafb6f77a8b6c2fe20dddcc57db39f64153cc/local_llm-0.0.33-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"aba53e19ccf75245328a61ea0fd489375bdff0ba704d692d27b2a64561bca5d3","md5":"a47f373829d93ed7da21ea70bd36b8f6","sha256":"fa2ab46b5f78aa1aeff2454d753be8e8583f92a979548ccc227f34822b957473"},"downloads":-1,"filename":"local-llm-0.0.33.tar.gz","has_sig":false,"md5_digest":"a47f373829d93ed7da21ea70bd36b8f6","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":61141,"upload_time":"2023-11-21T17:29:37","upload_time_iso_8601":"2023-11-21T17:29:37.056930Z","url":"https://files.pythonhosted.org/packages/ab/a5/3e19ccf75245328a61ea0fd489375bdff0ba704d692d27b2a64561bca5d3/local-llm-0.0.33.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.34":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.34/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.22","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.34","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"3dee2a4d4401573de62a0f921eae6e21ba5fb6f4e4f88bf0400b6e40692503e6","md5":"baead7819ade7845129b7d5971d265f4","sha256":"2f8d44a2c3538b20f6e3bf613cb66dceb1a0702d463f4278edbbabab3cafb1a1"},"downloads":-1,"filename":"local_llm-0.0.34-py3-none-any.whl","has_sig":false,"md5_digest":"baead7819ade7845129b7d5971d265f4","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7283,"upload_time":"2023-12-13T20:03:30","upload_time_iso_8601":"2023-12-13T20:03:30.835520Z","url":"https://files.pythonhosted.org/packages/3d/ee/2a4d4401573de62a0f921eae6e21ba5fb6f4e4f88bf0400b6e40692503e6/local_llm-0.0.34-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"dea8b25a1615fababe8cf12566584862d534bd53b60f51ed3885a4e70e28fb66","md5":"6bbcedaa5b6f50fdfaa0573562411d9e","sha256":"3652ce074d5cdc2df4043dcb2944510ce36684749a0c3a30f215e5dc5c3fde9a"},"downloads":-1,"filename":"local-llm-0.0.34.tar.gz","has_sig":false,"md5_digest":"6bbcedaa5b6f50fdfaa0573562411d9e","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":61144,"upload_time":"2023-12-13T20:03:32","upload_time_iso_8601":"2023-12-13T20:03:32.286884Z","url":"https://files.pythonhosted.org/packages/de/a8/b25a1615fababe8cf12566584862d534bd53b60f51ed3885a4e70e28fb66/local-llm-0.0.34.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.35":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.35/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.24","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.35","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"6c9fe8f25ad59ec7e7c45a738005ea367888fac4c396eb6aca8c0f8202195bd2","md5":"bd9ce69c645cb92ce1c39ded1aed1bbd","sha256":"69d6bf7efbdc255d97083fa539be7e37a91662191c4a4b4f6c57961be8a248df"},"downloads":-1,"filename":"local_llm-0.0.35-py3-none-any.whl","has_sig":false,"md5_digest":"bd9ce69c645cb92ce1c39ded1aed1bbd","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7283,"upload_time":"2023-12-22T10:06:55","upload_time_iso_8601":"2023-12-22T10:06:55.075582Z","url":"https://files.pythonhosted.org/packages/6c/9f/e8f25ad59ec7e7c45a738005ea367888fac4c396eb6aca8c0f8202195bd2/local_llm-0.0.35-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7495b7f05ab295023478472acb8bdd607258f9040a059cbe08330e525c37c530","md5":"77c9a59fdbe4ab6f663ba93efa4ae3a0","sha256":"c2dbc5920f48bdb83b43c49ae4f97d4d53d52f0bff20b48c653bb77c204ff1d5"},"downloads":-1,"filename":"local-llm-0.0.35.tar.gz","has_sig":false,"md5_digest":"77c9a59fdbe4ab6f663ba93efa4ae3a0","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":61137,"upload_time":"2023-12-22T10:06:56","upload_time_iso_8601":"2023-12-22T10:06:56.649093Z","url":"https://files.pythonhosted.org/packages/74/95/b7f05ab295023478472acb8bdd607258f9040a059cbe08330e525c37c530/local-llm-0.0.35.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.36":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.36/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.25","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.36","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"64a2ab85e46eed6549efe9ba8c18092274870b6306e48fa519ef53f8423dccd3","md5":"0854b2c6f23d52b947ddcd9dd7bacca8","sha256":"adc7963eadcd9bdf4c9c345e24403a3d99f6442281408e5a4a0286e0e13bd63e"},"downloads":-1,"filename":"local_llm-0.0.36-py3-none-any.whl","has_sig":false,"md5_digest":"0854b2c6f23d52b947ddcd9dd7bacca8","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7282,"upload_time":"2023-12-26T12:04:36","upload_time_iso_8601":"2023-12-26T12:04:36.556274Z","url":"https://files.pythonhosted.org/packages/64/a2/ab85e46eed6549efe9ba8c18092274870b6306e48fa519ef53f8423dccd3/local_llm-0.0.36-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"1a20619399ac1119430cca518b838efa183f847437cb124a0442347ffeb94fd1","md5":"7e456f622b8405543186f06802794b87","sha256":"9d5b56510897ff368f282bdd26448af0ae17566e36f564256e16ad42ee6e4696"},"downloads":-1,"filename":"local-llm-0.0.36.tar.gz","has_sig":false,"md5_digest":"7e456f622b8405543186f06802794b87","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":61137,"upload_time":"2023-12-26T12:04:38","upload_time_iso_8601":"2023-12-26T12:04:38.340490Z","url":"https://files.pythonhosted.org/packages/1a/20/619399ac1119430cca518b838efa183f847437cb124a0442347ffeb94fd1/local-llm-0.0.36.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.37":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.37/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.26","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.37","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"74aa944680fb831c62a51a36b50a930c6ab5b679b24d385d80374dfe4d8ba772","md5":"8eaf9c2aeb426890b673a039eeea5752","sha256":"fb6194ea450fb40f2927480f558c08aa7d032d68eeef90548dec40739bc87047"},"downloads":-1,"filename":"local_llm-0.0.37-py3-none-any.whl","has_sig":false,"md5_digest":"8eaf9c2aeb426890b673a039eeea5752","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7282,"upload_time":"2023-12-31T12:53:52","upload_time_iso_8601":"2023-12-31T12:53:52.938351Z","url":"https://files.pythonhosted.org/packages/74/aa/944680fb831c62a51a36b50a930c6ab5b679b24d385d80374dfe4d8ba772/local_llm-0.0.37-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"1c68cae9bbc8aed2063b785578985f74249a1d58d5bf176c960f4389ec1e5d17","md5":"ae355644d000d2b90bbc147633317b1a","sha256":"9bb05b7602c993d534862f2deec8bee8b214f2ffb472338b39bec471034df7a7"},"downloads":-1,"filename":"local-llm-0.0.37.tar.gz","has_sig":false,"md5_digest":"ae355644d000d2b90bbc147633317b1a","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":61131,"upload_time":"2023-12-31T12:53:54","upload_time_iso_8601":"2023-12-31T12:53:54.643203Z","url":"https://files.pythonhosted.org/packages/1c/68/cae9bbc8aed2063b785578985f74249a1d58d5bf176c960f4389ec1e5d17/local-llm-0.0.37.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.38":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.38/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.27","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.38","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"7a37d052248861b043f9aad1f8c397a7d47b4a187dcec81c7ecedbb8e55ba404","md5":"0e043782ca2ce5099975c81c7604cab4","sha256":"54b777bceb7750181de969fd8f830ac8b739f4fdba3537f4dd1bddca1067dbd1"},"downloads":-1,"filename":"local_llm-0.0.38-py3-none-any.whl","has_sig":false,"md5_digest":"0e043782ca2ce5099975c81c7604cab4","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7283,"upload_time":"2024-01-05T12:33:51","upload_time_iso_8601":"2024-01-05T12:33:51.019049Z","url":"https://files.pythonhosted.org/packages/7a/37/d052248861b043f9aad1f8c397a7d47b4a187dcec81c7ecedbb8e55ba404/local_llm-0.0.38-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7b2ec460937161951a3fc3ca47f8a9730f491cc3d6a7b83067a62d849cfae3fe","md5":"5355811a3afa2a271564246c93ed1b25","sha256":"a12e4d8ef75f62a9e3cbc22fe6f25f81b35b55c2a64f1a31e76fad9875d77745"},"downloads":-1,"filename":"local-llm-0.0.38.tar.gz","has_sig":false,"md5_digest":"5355811a3afa2a271564246c93ed1b25","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":61144,"upload_time":"2024-01-05T12:33:52","upload_time_iso_8601":"2024-01-05T12:33:52.723051Z","url":"https://files.pythonhosted.org/packages/7b/2e/c460937161951a3fc3ca47f8a9730f491cc3d6a7b83067a62d849cfae3fe/local-llm-0.0.38.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.39":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.39/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.27","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.39","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"c988a79838716bc32f8cdc7538b47e9d1607eda6471b6e1dc38f7200ba6c48d7","md5":"33c266c8a4534f31c9990bca4a126397","sha256":"c5f3156387d66e1eadaf2bca3b9ff98f636e89dd09833f9442c3920fdde4c62e"},"downloads":-1,"filename":"local_llm-0.0.39-py3-none-any.whl","has_sig":false,"md5_digest":"33c266c8a4534f31c9990bca4a126397","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7311,"upload_time":"2024-01-07T01:02:53","upload_time_iso_8601":"2024-01-07T01:02:53.327970Z","url":"https://files.pythonhosted.org/packages/c9/88/a79838716bc32f8cdc7538b47e9d1607eda6471b6e1dc38f7200ba6c48d7/local_llm-0.0.39-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"44ffa4917eb2fec22d200845299f543af2753d4035c3c894f56f431099c20f2a","md5":"bc032c88dcf2e86b21577144382a4f63","sha256":"57e838cd761b6a7878622449bde79b47c3a33f875074cb4bcf3e432c55fb02f2"},"downloads":-1,"filename":"local-llm-0.0.39.tar.gz","has_sig":false,"md5_digest":"bc032c88dcf2e86b21577144382a4f63","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":61162,"upload_time":"2024-01-07T01:02:54","upload_time_iso_8601":"2024-01-07T01:02:54.498452Z","url":"https://files.pythonhosted.org/packages/44/ff/a4917eb2fec22d200845299f543af2753d4035c3c894f56f431099c20f2a/local-llm-0.0.39.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.40":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.40/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.27","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.40","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"e87839d17867a16bdb2e559ea9597d5545625ba67c0e7e7a0f506a4d580d54c7","md5":"266df33a535df845209f7c79a3481abf","sha256":"74e29a0b82d37b03ea9d62638e47de056de7d71c737ec78470da020d408b9c55"},"downloads":-1,"filename":"local_llm-0.0.40-py3-none-any.whl","has_sig":false,"md5_digest":"266df33a535df845209f7c79a3481abf","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7267,"upload_time":"2024-01-07T14:32:11","upload_time_iso_8601":"2024-01-07T14:32:11.864974Z","url":"https://files.pythonhosted.org/packages/e8/78/39d17867a16bdb2e559ea9597d5545625ba67c0e7e7a0f506a4d580d54c7/local_llm-0.0.40-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"45cbeeff1a9e10c60c78294f59ae7ff35f1f3aed87691ceb0da43be94fc6769e","md5":"e0a61f2e67879ccc013e5ece35aeec5d","sha256":"0f71e053e73f85944e5e0ef8134c0e1d33ff8452e70304da775bde273dd762ed"},"downloads":-1,"filename":"local-llm-0.0.40.tar.gz","has_sig":false,"md5_digest":"e0a61f2e67879ccc013e5ece35aeec5d","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":61124,"upload_time":"2024-01-07T14:32:13","upload_time_iso_8601":"2024-01-07T14:32:13.555799Z","url":"https://files.pythonhosted.org/packages/45/cb/eeff1a9e10c60c78294f59ae7ff35f1f3aed87691ceb0da43be94fc6769e/local-llm-0.0.40.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.41":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.41/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.28","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.41","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"dda3c89a4a4d12571af3a7d9bee199999d8c5e8add4403e26188b75fc0a9a270","md5":"aff37de3fee7aa40b1b4c3a027f2b7fa","sha256":"f449929a7b1d26f40615349abff9d83185e0c1ac8d237d558bb482ae6a9796d7"},"downloads":-1,"filename":"local_llm-0.0.41-py3-none-any.whl","has_sig":false,"md5_digest":"aff37de3fee7aa40b1b4c3a027f2b7fa","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7266,"upload_time":"2024-01-10T18:39:33","upload_time_iso_8601":"2024-01-10T18:39:33.223461Z","url":"https://files.pythonhosted.org/packages/dd/a3/c89a4a4d12571af3a7d9bee199999d8c5e8add4403e26188b75fc0a9a270/local_llm-0.0.41-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"3f27383950a9224bdc64fd229005a0e5f5db51bf313165fb14602f6a38c0848a","md5":"fde97c3f56c914a7207e59329ea93960","sha256":"c454c54528402badec687b350985a385b5c91d9719abddd1d138fbc1185b1d87"},"downloads":-1,"filename":"local-llm-0.0.41.tar.gz","has_sig":false,"md5_digest":"fde97c3f56c914a7207e59329ea93960","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":61119,"upload_time":"2024-01-10T18:39:34","upload_time_iso_8601":"2024-01-10T18:39:34.604303Z","url":"https://files.pythonhosted.org/packages/3f/27/383950a9224bdc64fd229005a0e5f5db51bf313165fb14602f6a38c0848a/local-llm-0.0.41.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.42":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.42/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.29","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.42","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"912374e9880041e848037043ca807b0c7c7eb8d4c4b85eb1332dad25e7a99cc8","md5":"cc6f5c18f0aa84a6698492d9069bd61c","sha256":"088838144d1f9ba5fd34016511107b981347975443757cdc7a0133c51e59af7a"},"downloads":-1,"filename":"local_llm-0.0.42-py3-none-any.whl","has_sig":false,"md5_digest":"cc6f5c18f0aa84a6698492d9069bd61c","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":6578,"upload_time":"2024-01-17T17:39:08","upload_time_iso_8601":"2024-01-17T17:39:08.502764Z","url":"https://files.pythonhosted.org/packages/91/23/74e9880041e848037043ca807b0c7c7eb8d4c4b85eb1332dad25e7a99cc8/local_llm-0.0.42-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"99cae0d3ab39514ae85a9b5dd40157b534e150319600e151b291b0d6fb3adecd","md5":"b6cfa03bf14c82b3867d41ca652a4a84","sha256":"560f0490c4fec69732571d5e4f08a87d039b757546c2640f134859277e881067"},"downloads":-1,"filename":"local-llm-0.0.42.tar.gz","has_sig":false,"md5_digest":"b6cfa03bf14c82b3867d41ca652a4a84","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":60094,"upload_time":"2024-01-17T17:39:10","upload_time_iso_8601":"2024-01-17T17:39:10.336585Z","url":"https://files.pythonhosted.org/packages/99/ca/e0d3ab39514ae85a9b5dd40157b534e150319600e151b291b0d6fb3adecd/local-llm-0.0.42.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.43":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.43/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.29","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.43","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"5943862f39891702bc587b1acae6475881448b338e3aeaa1708979cd2b9282fc","md5":"cea2137ada0a6c539b3b43e485796f21","sha256":"e2a9eb0e1f6455c3c44b62b502ad4f8a3949bb0b088b2c17ca9bed6412712d3b"},"downloads":-1,"filename":"local_llm-0.0.43-py3-none-any.whl","has_sig":false,"md5_digest":"cea2137ada0a6c539b3b43e485796f21","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":6583,"upload_time":"2024-01-17T17:52:03","upload_time_iso_8601":"2024-01-17T17:52:03.967121Z","url":"https://files.pythonhosted.org/packages/59/43/862f39891702bc587b1acae6475881448b338e3aeaa1708979cd2b9282fc/local_llm-0.0.43-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b17cd3a4b5dfa85a3ce482f8658615c8da1e77226568a37852eb107567fa2fcc","md5":"23b8baeec831f7117b1a22b9d2651125","sha256":"ad0a59da53d2b10168505afd12943d23b7c06fe0463daa0be5c8c9486c8c55c1"},"downloads":-1,"filename":"local-llm-0.0.43.tar.gz","has_sig":false,"md5_digest":"23b8baeec831f7117b1a22b9d2651125","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":60101,"upload_time":"2024-01-17T17:52:06","upload_time_iso_8601":"2024-01-17T17:52:06.374144Z","url":"https://files.pythonhosted.org/packages/b1/7c/d3a4b5dfa85a3ce482f8658615c8da1e77226568a37852eb107567fa2fcc/local-llm-0.0.43.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.44":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.44/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python ==0.2.29","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.44","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"83bcee6d1e092c378ca40558104eafc43a9426ba78e925b7229612099a3ce5a5","md5":"f640141b21579c2ba4b6b4ef5c2735db","sha256":"0b75e912e5c1308bdb3bfe1bca0098a934a0e160561c10bdcd45129b205c3168"},"downloads":-1,"filename":"local_llm-0.0.44-py3-none-any.whl","has_sig":false,"md5_digest":"f640141b21579c2ba4b6b4ef5c2735db","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":6869,"upload_time":"2024-01-17T18:47:56","upload_time_iso_8601":"2024-01-17T18:47:56.115204Z","url":"https://files.pythonhosted.org/packages/83/bc/ee6d1e092c378ca40558104eafc43a9426ba78e925b7229612099a3ce5a5/local_llm-0.0.44-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d4fd4a45b9877f906b5666643ab58e2b963dd0be1a178d166ec18f7d26007626","md5":"f486a7ffc4137323cc1d24f68d7f8af4","sha256":"5aa6070ba957e77c8df58f6d48064cdfd1ccf79736f30d38d43ed74493100a44"},"downloads":-1,"filename":"local-llm-0.0.44.tar.gz","has_sig":false,"md5_digest":"f486a7ffc4137323cc1d24f68d7f8af4","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":12580,"upload_time":"2024-01-17T18:47:57","upload_time_iso_8601":"2024-01-17T18:47:57.851378Z","url":"https://files.pythonhosted.org/packages/d4/fd/4a45b9877f906b5666643ab58e2b963dd0be1a178d166ec18f7d26007626/local-llm-0.0.44.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.45":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.45/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.45","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"1836de1ebac4ce9efc7ac3a152d3ced3caf3957cffd2eddd5dd109aee8a88d76","md5":"89742af67ab3ba9d4efa35ec3cbd54b6","sha256":"e726b39385b7a985ab4a0b5be02a0615c49dd0ca5041af2a90ac031b6c056ed2"},"downloads":-1,"filename":"local_llm-0.0.45-py3-none-any.whl","has_sig":false,"md5_digest":"89742af67ab3ba9d4efa35ec3cbd54b6","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":6896,"upload_time":"2024-01-18T17:23:31","upload_time_iso_8601":"2024-01-18T17:23:31.448145Z","url":"https://files.pythonhosted.org/packages/18/36/de1ebac4ce9efc7ac3a152d3ced3caf3957cffd2eddd5dd109aee8a88d76/local_llm-0.0.45-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"00179de7560ef765fb2a358bcc9c432c515c10078652d6639df56e43d8cde871","md5":"94bc73941581f62a29cd186582076c64","sha256":"3f851c36b2af45f4fe7c94e0c636119fafcaac97aba6eb0dbe7ceef540f85610"},"downloads":-1,"filename":"local-llm-0.0.45.tar.gz","has_sig":false,"md5_digest":"94bc73941581f62a29cd186582076c64","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":11546,"upload_time":"2024-01-18T17:24:13","upload_time_iso_8601":"2024-01-18T17:24:13.665876Z","url":"https://files.pythonhosted.org/packages/00/17/9de7560ef765fb2a358bcc9c432c515c10078652d6639df56e43d8cde871/local-llm-0.0.45.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.46":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.46/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.46","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"1e8fdaf59a3cbcec24de052af4f3b0d7151db452a40ac8677c9ad326ead5704d","md5":"20edbe07d3f177ac329b63e17f4cda4b","sha256":"d655bbe3c4403237a8f3c336db8c2463b40785d752c8def67cdaa2e4366915b8"},"downloads":-1,"filename":"local_llm-0.0.46-py3-none-any.whl","has_sig":false,"md5_digest":"20edbe07d3f177ac329b63e17f4cda4b","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7167,"upload_time":"2024-01-19T21:00:36","upload_time_iso_8601":"2024-01-19T21:00:36.367717Z","url":"https://files.pythonhosted.org/packages/1e/8f/daf59a3cbcec24de052af4f3b0d7151db452a40ac8677c9ad326ead5704d/local_llm-0.0.46-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7881cf61d176c5d4b59265be1cca311fe62c9a664945c39b4acadd27c700c602","md5":"8d5a3ab0c9a94e62bb130afceb849286","sha256":"da4ae54c8ecb0423ab4f919f5e1721382ff8f99e4c2d273770a6d4239cc8b7f4"},"downloads":-1,"filename":"local-llm-0.0.46.tar.gz","has_sig":false,"md5_digest":"8d5a3ab0c9a94e62bb130afceb849286","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":12403,"upload_time":"2024-01-19T21:00:38","upload_time_iso_8601":"2024-01-19T21:00:38.089773Z","url":"https://files.pythonhosted.org/packages/78/81/cf61d176c5d4b59265be1cca311fe62c9a664945c39b4acadd27c700c602/local-llm-0.0.46.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.5":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.5/","requires_dist":["fastapi","pydantic","requests","uvicorn","argparse","pyjwt","tiktoken","llama-cpp-python","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.5","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"fadcf9fc95f4dbb2a70421ca494c017f2bcb7b0486c88e2502338260f113b6d8","md5":"5ad93c5e348a2371e57ef8f70a0ed84c","sha256":"a94310173af2d1a4548bfaf5b236a20ca6c080a3126fa743b16d9b7729a5d020"},"downloads":-1,"filename":"local_llm-0.0.5-py3-none-any.whl","has_sig":false,"md5_digest":"5ad93c5e348a2371e57ef8f70a0ed84c","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":3599,"upload_time":"2023-10-04T19:19:13","upload_time_iso_8601":"2023-10-04T19:19:13.623804Z","url":"https://files.pythonhosted.org/packages/fa/dc/f9fc95f4dbb2a70421ca494c017f2bcb7b0486c88e2502338260f113b6d8/local_llm-0.0.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"873d814a75c3f5395f670ab483c3f4d15995e4ba199c43d3287f0ae0a3bf4467","md5":"c9763991a700181ad014b97dd6298cf4","sha256":"71fb388bc1751c22a5448a55b018f1f667115e093aea6f67b25fb4f518e33416"},"downloads":-1,"filename":"local-llm-0.0.5.tar.gz","has_sig":false,"md5_digest":"c9763991a700181ad014b97dd6298cf4","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":58658,"upload_time":"2023-10-04T19:19:15","upload_time_iso_8601":"2023-10-04T19:19:15.282648Z","url":"https://files.pythonhosted.org/packages/87/3d/814a75c3f5395f670ab483c3f4d15995e4ba199c43d3287f0ae0a3bf4467/local-llm-0.0.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.6":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.6/","requires_dist":["fastapi","pydantic","requests","uvicorn","argparse","pyjwt","tiktoken","llama-cpp-python","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.6","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"33446d79116d17b6b3086fde3a2a7fa36351ebc872a7642c5d113c9b04211ef0","md5":"6d108461c8b6b286e08068811268d036","sha256":"e50ab837a58818b03605b2233b3197ad4f31b656d9caee127973b2b0a8919177"},"downloads":-1,"filename":"local_llm-0.0.6-py3-none-any.whl","has_sig":false,"md5_digest":"6d108461c8b6b286e08068811268d036","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":3799,"upload_time":"2023-10-04T19:23:36","upload_time_iso_8601":"2023-10-04T19:23:36.478846Z","url":"https://files.pythonhosted.org/packages/33/44/6d79116d17b6b3086fde3a2a7fa36351ebc872a7642c5d113c9b04211ef0/local_llm-0.0.6-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"04bf348ca14af56e63831b9bd490793868ea29c0660f3d7e0e3b546b28a8997b","md5":"07e154425f69a2da94db52915514cb65","sha256":"c1dc19052d7f6b4a787af35a78a59758477a74447be0dd12655b10f13f083f9a"},"downloads":-1,"filename":"local-llm-0.0.6.tar.gz","has_sig":false,"md5_digest":"07e154425f69a2da94db52915514cb65","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":58686,"upload_time":"2023-10-04T19:23:38","upload_time_iso_8601":"2023-10-04T19:23:38.318093Z","url":"https://files.pythonhosted.org/packages/04/bf/348ca14af56e63831b9bd490793868ea29c0660f3d7e0e3b546b28a8997b/local-llm-0.0.6.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.7":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.7/","requires_dist":["fastapi","pydantic","requests","uvicorn","argparse","pyjwt","tiktoken","llama-cpp-python","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.7","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"71ed91b86d180e90963c32b8046c605e852c09db12440be7c8fc51f287ce2d75","md5":"1a6a00806bd1ad968233738de1d9eb27","sha256":"5e005aab8cd23818119b35e0e6135d7b0d261241de26d844a4ddf97a4b713dcf"},"downloads":-1,"filename":"local_llm-0.0.7-py3-none-any.whl","has_sig":false,"md5_digest":"1a6a00806bd1ad968233738de1d9eb27","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":7114,"upload_time":"2023-10-04T19:32:49","upload_time_iso_8601":"2023-10-04T19:32:49.314333Z","url":"https://files.pythonhosted.org/packages/71/ed/91b86d180e90963c32b8046c605e852c09db12440be7c8fc51f287ce2d75/local_llm-0.0.7-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"4796ad5edc0e9940453bc6a0907696485d23dbdfae11886e3d06b6b6e37ca9f7","md5":"abdf87bd07481a59fcbc53773eab4960","sha256":"3a90a4b11c148b1ff7cebcd8a5155bb990b077d52d9273d61a2744fbe04b9274"},"downloads":-1,"filename":"local-llm-0.0.7.tar.gz","has_sig":false,"md5_digest":"abdf87bd07481a59fcbc53773eab4960","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":58670,"upload_time":"2023-10-04T19:32:50","upload_time_iso_8601":"2023-10-04T19:32:50.425073Z","url":"https://files.pythonhosted.org/packages/47/96/ad5edc0e9940453bc6a0907696485d23dbdfae11886e3d06b6b6e37ca9f7/local-llm-0.0.7.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.8":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.8/","requires_dist":["fastapi","pydantic","requests","uvicorn","argparse","pyjwt","tiktoken","llama-cpp-python","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.8","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"4ff31d6d8c5f091f5e31d6ebe8bae05a3b08a7a31c0c53fc671f90e0712bf563","md5":"cd58132c8134fa4e76ceeb0532a2daed","sha256":"e4d6e64c8628f9b004e5055e7566d9f47aac5e29118d258892b4d1560f414544"},"downloads":-1,"filename":"local_llm-0.0.8-py3-none-any.whl","has_sig":false,"md5_digest":"cd58132c8134fa4e76ceeb0532a2daed","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":6803,"upload_time":"2023-10-04T19:36:12","upload_time_iso_8601":"2023-10-04T19:36:12.848379Z","url":"https://files.pythonhosted.org/packages/4f/f3/1d6d8c5f091f5e31d6ebe8bae05a3b08a7a31c0c53fc671f90e0712bf563/local_llm-0.0.8-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"9edd50578e87cfd5f76ac845979a180c08c40dbecd71e32e7f93d7c5c54408b9","md5":"58cd46ebeef04e8d3a8585d1ba9bfe48","sha256":"c66e64652437800a24e888d5f681931659c0d12037ca084f27912b20ffdd04ad"},"downloads":-1,"filename":"local-llm-0.0.8.tar.gz","has_sig":false,"md5_digest":"58cd46ebeef04e8d3a8585d1ba9bfe48","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":58515,"upload_time":"2023-10-04T19:36:14","upload_time_iso_8601":"2023-10-04T19:36:14.426863Z","url":"https://files.pythonhosted.org/packages/9e/dd/50578e87cfd5f76ac845979a180c08c40dbecd71e32e7f93d7c5c54408b9/local-llm-0.0.8.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.9":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.0.9/","requires_dist":["fastapi","pydantic","requests","uvicorn","argparse","pyjwt","tiktoken","llama-cpp-python","python-dotenv","GPUtil","psutil","beautifulsoup4"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.0.9","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"d52aa970fb202d04dfe8989515038117d407243820dceb86504c51f66d7d7b8e","md5":"4654b3e67df0246501d3174fbe674b3e","sha256":"216acd7f054080b2a3b6a753a23386acb4a3f3b2487ccb17b9ccf915968d3b02"},"downloads":-1,"filename":"local_llm-0.0.9-py3-none-any.whl","has_sig":false,"md5_digest":"4654b3e67df0246501d3174fbe674b3e","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":6802,"upload_time":"2023-10-04T19:40:19","upload_time_iso_8601":"2023-10-04T19:40:19.481010Z","url":"https://files.pythonhosted.org/packages/d5/2a/a970fb202d04dfe8989515038117d407243820dceb86504c51f66d7d7b8e/local_llm-0.0.9-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"061324e5a58bb880eb45d96cff6d2f3fb5564ae7a3a93170287e53a6e57c2faf","md5":"688eefd3204b8d6b49438436a2fdadb0","sha256":"c7b33daed42c6e09dc4704436556ebea8d06655c7fa37e5956d6ab1e803efaee"},"downloads":-1,"filename":"local-llm-0.0.9.tar.gz","has_sig":false,"md5_digest":"688eefd3204b8d6b49438436a2fdadb0","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":58521,"upload_time":"2023-10-04T19:40:20","upload_time_iso_8601":"2023-10-04T19:40:20.937989Z","url":"https://files.pythonhosted.org/packages/06/13/24e5a58bb880eb45d96cff6d2f3fb5564ae7a3a93170287e53a6e57c2faf/local-llm-0.0.9.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.0":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.1.0/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python","python-dotenv","GPUtil","psutil","beautifulsoup4","whisper-cpp-pybind","pydub","ffmpeg","numpy >=1.22.0","soundfile >=0.12.1","transformers ==4.36.2","TTS >=0.21.3","requests >=2.31.0","tqdm >=4.66.1","importlib-metadata >=4.8.1","packaging >=23.2","pydantic >=1.10.13","sounddevice >=0.4.6","python-multipart >=0.0.6","cutlet >=0.3.0","unidic-lite >=1.0.8","torch >=2.1.0","torchaudio >=2.1.0"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.1.0","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"0483e52939e97f0ee3c1228cb485c055738b6e7d35e917c3225047290a75be11","md5":"af50f03d73617c5b57c0a8205e795104","sha256":"e3dde679402ca3cf83ab93a679a8f29cf2ee84b124bda05186f74d2dad7852b4"},"downloads":-1,"filename":"local_llm-0.1.0-py3-none-any.whl","has_sig":false,"md5_digest":"af50f03d73617c5b57c0a8205e795104","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":10284,"upload_time":"2024-01-26T21:18:32","upload_time_iso_8601":"2024-01-26T21:18:32.044454Z","url":"https://files.pythonhosted.org/packages/04/83/e52939e97f0ee3c1228cb485c055738b6e7d35e917c3225047290a75be11/local_llm-0.1.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b3a69abead06f9bb3e74112b68f3ec2fa986ab6ece4c0a3313e6e86928f446ae","md5":"e4796c9cbecac717dba50e057ca9045f","sha256":"e6fb0903997f9d3aa3f1e08e2338e4224428b5b6f6c35c5208101a243d32e0e0"},"downloads":-1,"filename":"local-llm-0.1.0.tar.gz","has_sig":false,"md5_digest":"e4796c9cbecac717dba50e057ca9045f","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":16798,"upload_time":"2024-01-26T21:18:33","upload_time_iso_8601":"2024-01-26T21:18:33.871467Z","url":"https://files.pythonhosted.org/packages/b3/a6/9abead06f9bb3e74112b68f3ec2fa986ab6ece4c0a3313e6e86928f446ae/local-llm-0.1.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.1":{"info":{"author":"Josh XT","author_email":"josh@devxt.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"local-llm","package_url":"https://pypi.org/project/local-llm/","platform":null,"project_url":"https://pypi.org/project/local-llm/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/local-llm/0.1.1/","requires_dist":["fastapi","pydantic","requests","uvicorn","pyjwt","tiktoken","llama-cpp-python","python-dotenv","GPUtil","psutil","beautifulsoup4","whisper-cpp-pybind","pydub","ffmpeg","numpy >=1.22.0","soundfile >=0.12.1","transformers ==4.36.2","TTS >=0.21.3","requests >=2.31.0","tqdm >=4.66.1","importlib-metadata >=4.8.1","packaging >=23.2","pydantic >=1.10.13","sounddevice >=0.4.6","python-multipart >=0.0.6","cutlet >=0.3.0","unidic-lite >=1.0.8","torch >=2.1.0","torchaudio >=2.1.0"],"requires_python":">=3.10","summary":"Local-LLM is a llama.cpp server in Docker with OpenAI Style Endpoints.","version":"0.1.1","yanked":false,"yanked_reason":null},"last_serial":21617985,"urls":[{"comment_text":"","digests":{"blake2b_256":"2bcbaa50cf01cdbfe455c7c5d511001362d35014e33b6cf02120cc6637651f77","md5":"1251c1d7aff574e0881c68509f668db8","sha256":"1c8b07526addc8a711dfd7ae8ff00f5ac9aaa745aaa9d2cfc1591192f1c41b8a"},"downloads":-1,"filename":"local_llm-0.1.1-py3-none-any.whl","has_sig":false,"md5_digest":"1251c1d7aff574e0881c68509f668db8","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.10","size":10576,"upload_time":"2024-01-27T19:34:15","upload_time_iso_8601":"2024-01-27T19:34:15.483566Z","url":"https://files.pythonhosted.org/packages/2b/cb/aa50cf01cdbfe455c7c5d511001362d35014e33b6cf02120cc6637651f77/local_llm-0.1.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b3d040137a7636e81062f5a7f835e332351808002620e376a4b96de4858d584c","md5":"5eedae926e33a1308c55867cb65342a4","sha256":"a1b80761ec74e1d2fc5120d6eb10350a9c74b8282c705aa729e43203b17bc4c4"},"downloads":-1,"filename":"local-llm-0.1.1.tar.gz","has_sig":false,"md5_digest":"5eedae926e33a1308c55867cb65342a4","packagetype":"sdist","python_version":"source","requires_python":">=3.10","size":17274,"upload_time":"2024-01-27T19:34:17","upload_time_iso_8601":"2024-01-27T19:34:17.213595Z","url":"https://files.pythonhosted.org/packages/b3/d0/40137a7636e81062f5a7f835e332351808002620e376a4b96de4858d584c/local-llm-0.1.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}