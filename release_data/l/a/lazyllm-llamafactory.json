{"0.8.3":{"info":{"author":"hiyouga","author_email":"hiyouga@buaa.edu.cn","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","Intended Audience :: Education","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/hiyouga/LLaMA-Factory","keywords":"LLaMA, BLOOM, Falcon, LLM, ChatGPT, transformer, pytorch, deep learning","license":"Apache 2.0 License","maintainer":null,"maintainer_email":null,"name":"lazyllm-llamafactory","package_url":"https://pypi.org/project/lazyllm-llamafactory/","platform":null,"project_url":"https://pypi.org/project/lazyllm-llamafactory/","project_urls":{"Homepage":"https://github.com/hiyouga/LLaMA-Factory"},"provides_extra":["aqlm","awq","badam","bitsandbytes","deepspeed","dev","eetq","galore","gptq","hqq","metrics","modelscope","qwen","torch","torch-npu","vllm"],"release_url":"https://pypi.org/project/lazyllm-llamafactory/0.8.3/","requires_dist":["transformers>=4.41.2","datasets>=2.16.0","accelerate>=0.30.1","peft>=0.11.1","trl>=0.8.6","gradio>=4.0.0","pandas>=2.0.0","scipy","einops","sentencepiece","tiktoken","protobuf","uvicorn","pydantic","fastapi","sse-starlette","matplotlib>=3.7.0","fire","packaging","pyyaml","numpy<2.0.0","aqlm[gpu]>=1.1.0; extra == \"aqlm\"","autoawq; extra == \"awq\"","badam>=1.2.1; extra == \"badam\"","bitsandbytes>=0.39.0; extra == \"bitsandbytes\"","deepspeed>=0.10.0; extra == \"deepspeed\"","ruff; extra == \"dev\"","pytest; extra == \"dev\"","eetq; extra == \"eetq\"","galore-torch; extra == \"galore\"","optimum>=1.17.0; extra == \"gptq\"","auto-gptq>=0.5.0; extra == \"gptq\"","hqq; extra == \"hqq\"","nltk; extra == \"metrics\"","jieba; extra == \"metrics\"","rouge-chinese; extra == \"metrics\"","modelscope; extra == \"modelscope\"","transformers-stream-generator; extra == \"qwen\"","torch>=1.13.1; extra == \"torch\"","torch==2.1.0; extra == \"torch-npu\"","torch-npu==2.1.0.post3; extra == \"torch-npu\"","decorator; extra == \"torch-npu\"","vllm>=0.4.3; extra == \"vllm\""],"requires_python":">=3.8.0","summary":"Easy-to-use LLM fine-tuning framework","version":"0.8.3","yanked":false,"yanked_reason":null},"last_serial":24805173,"urls":[{"comment_text":"","digests":{"blake2b_256":"294384b3ea2875ccc1b059f650e07c53d537f00ecb3faf1f3b4467caea050578","md5":"646d57e4f3fd6fca1949a1ee5f30a3c3","sha256":"d69c021007678ffd3f330a4242d0bc77442fa4d2fa3c9aaac0458efe53970db7"},"downloads":-1,"filename":"lazyllm_llamafactory-0.8.3-py3-none-any.whl","has_sig":false,"md5_digest":"646d57e4f3fd6fca1949a1ee5f30a3c3","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8.0","size":224973,"upload_time":"2024-08-30T08:01:50","upload_time_iso_8601":"2024-08-30T08:01:50.782623Z","url":"https://files.pythonhosted.org/packages/29/43/84b3ea2875ccc1b059f650e07c53d537f00ecb3faf1f3b4467caea050578/lazyllm_llamafactory-0.8.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e05f62195ca937469df597617a6f2ad122131c1aaa6e3b8a371139e1a78a9614","md5":"c36f3ce99f3073088963bf7ea63e784a","sha256":"5f6f9617ff90fafda979ef129eec9da0fe10666981aa7bb13c89cb69be0d8069"},"downloads":-1,"filename":"lazyllm_llamafactory-0.8.3.tar.gz","has_sig":false,"md5_digest":"c36f3ce99f3073088963bf7ea63e784a","packagetype":"sdist","python_version":"source","requires_python":">=3.8.0","size":173361,"upload_time":"2024-08-30T08:01:53","upload_time_iso_8601":"2024-08-30T08:01:53.438678Z","url":"https://files.pythonhosted.org/packages/e0/5f/62195ca937469df597617a6f2ad122131c1aaa6e3b8a371139e1a78a9614/lazyllm_llamafactory-0.8.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.8.3.dev0":{"info":{"author":"hiyouga","author_email":"hiyouga@buaa.edu.cn","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","Intended Audience :: Education","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Operating System :: OS Independent","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/hiyouga/LLaMA-Factory","keywords":"LLaMA, BLOOM, Falcon, LLM, ChatGPT, transformer, pytorch, deep learning","license":"Apache 2.0 License","maintainer":null,"maintainer_email":null,"name":"lazyllm-llamafactory","package_url":"https://pypi.org/project/lazyllm-llamafactory/","platform":null,"project_url":"https://pypi.org/project/lazyllm-llamafactory/","project_urls":{"Homepage":"https://github.com/hiyouga/LLaMA-Factory"},"provides_extra":["aqlm","awq","badam","bitsandbytes","deepspeed","dev","eetq","galore","gptq","hqq","metrics","modelscope","qwen","torch","torch-npu","vllm"],"release_url":"https://pypi.org/project/lazyllm-llamafactory/0.8.3.dev0/","requires_dist":["transformers>=4.41.2","datasets>=2.16.0","accelerate>=0.30.1","peft>=0.11.1","trl>=0.8.6","gradio>=4.0.0","pandas>=2.0.0","scipy","einops","sentencepiece","tiktoken","protobuf","uvicorn","pydantic","fastapi","sse-starlette","matplotlib>=3.7.0","fire","packaging","pyyaml","numpy<2.0.0","aqlm[gpu]>=1.1.0; extra == \"aqlm\"","autoawq; extra == \"awq\"","badam>=1.2.1; extra == \"badam\"","bitsandbytes>=0.39.0; extra == \"bitsandbytes\"","deepspeed>=0.10.0; extra == \"deepspeed\"","ruff; extra == \"dev\"","pytest; extra == \"dev\"","eetq; extra == \"eetq\"","galore-torch; extra == \"galore\"","optimum>=1.17.0; extra == \"gptq\"","auto-gptq>=0.5.0; extra == \"gptq\"","hqq; extra == \"hqq\"","nltk; extra == \"metrics\"","jieba; extra == \"metrics\"","rouge-chinese; extra == \"metrics\"","modelscope; extra == \"modelscope\"","transformers-stream-generator; extra == \"qwen\"","torch>=1.13.1; extra == \"torch\"","torch==2.1.0; extra == \"torch-npu\"","torch-npu==2.1.0.post3; extra == \"torch-npu\"","decorator; extra == \"torch-npu\"","vllm>=0.4.3; extra == \"vllm\""],"requires_python":">=3.8.0","summary":"Easy-to-use LLM fine-tuning framework","version":"0.8.3.dev0","yanked":false,"yanked_reason":null},"last_serial":24805173,"urls":[{"comment_text":"","digests":{"blake2b_256":"e594a6124366c7fc0e7884d9d013ab885d9168c1e99140bc0ce0a93c9a3f3c90","md5":"1557bd7868b02d8c0f4d04e8bdaa5559","sha256":"11c4da5ac40b72c4aa85aa84a88da80cf8d2c91b6c17aa2a47ce08041c28a2d4"},"downloads":-1,"filename":"lazyllm_llamafactory-0.8.3.dev0-py3-none-any.whl","has_sig":false,"md5_digest":"1557bd7868b02d8c0f4d04e8bdaa5559","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8.0","size":225045,"upload_time":"2024-08-28T05:42:22","upload_time_iso_8601":"2024-08-28T05:42:22.565869Z","url":"https://files.pythonhosted.org/packages/e5/94/a6124366c7fc0e7884d9d013ab885d9168c1e99140bc0ce0a93c9a3f3c90/lazyllm_llamafactory-0.8.3.dev0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d4a9683893016f9982f1d390009b71b50ae12ce1334fd430b225700718db4946","md5":"d4e2e28078e2bc3cbb6d705d94fd349f","sha256":"9a73520ac0edff30a220ba404cd3b005bb4852be91d03dd85da2075a981ed4e1"},"downloads":-1,"filename":"lazyllm-llamafactory-0.8.3.dev0.tar.gz","has_sig":false,"md5_digest":"d4e2e28078e2bc3cbb6d705d94fd349f","packagetype":"sdist","python_version":"source","requires_python":">=3.8.0","size":172524,"upload_time":"2024-08-28T05:42:24","upload_time_iso_8601":"2024-08-28T05:42:24.646942Z","url":"https://files.pythonhosted.org/packages/d4/a9/683893016f9982f1d390009b71b50ae12ce1334fd430b225700718db4946/lazyllm-llamafactory-0.8.3.dev0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}