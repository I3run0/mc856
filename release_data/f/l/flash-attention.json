{"1.0.0":{"info":{"author":"Huawei","author_email":"","bugtrack_url":null,"classifiers":[],"description_content_type":"","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://gitee.com/mindspore/acctransformer","keywords":"","license":"Apache License, Version 2.0","maintainer":"","maintainer_email":"","name":"flash-attention","package_url":"https://pypi.org/project/flash-attention/","platform":null,"project_url":"https://pypi.org/project/flash-attention/","project_urls":{"Homepage":"https://gitee.com/mindspore/acctransformer"},"provides_extra":null,"release_url":"https://pypi.org/project/flash-attention/1.0.0/","requires_dist":null,"requires_python":"","summary":"Flash Attention2 operator on Huawei Ascend 910A.","version":"1.0.0","yanked":false,"yanked_reason":null},"last_serial":21151127,"urls":[{"comment_text":"","digests":{"blake2b_256":"7c62a3ffe7a541645e72298f055ec894bc5b9d890ec7cacbf068c7734e2c0998","md5":"8765571c910a9f76d03e58f228a5425c","sha256":"9f8293b16dda6e46149cf73631158c40afec1393db66698fa45f8ba4b64b5f3e"},"downloads":-1,"filename":"flash_attention-1.0.0-py3-none-any.whl","has_sig":false,"md5_digest":"8765571c910a9f76d03e58f228a5425c","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":31405,"upload_time":"2023-12-21T02:45:23","upload_time_iso_8601":"2023-12-21T02:45:23.997065Z","url":"https://files.pythonhosted.org/packages/7c/62/a3ffe7a541645e72298f055ec894bc5b9d890ec7cacbf068c7734e2c0998/flash_attention-1.0.0-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}