{"1.0.7":{"info":{"author":"Tri Dao","author_email":"trid@stanford.edu","bugtrack_url":null,"classifiers":["License :: OSI Approved :: BSD License","Operating System :: Unix","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/HazyResearch/flash-attention","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"flash-attn-xwyzsn","package_url":"https://pypi.org/project/flash-attn-xwyzsn/","platform":null,"project_url":"https://pypi.org/project/flash-attn-xwyzsn/","project_urls":{"Homepage":"https://github.com/HazyResearch/flash-attention"},"provides_extra":null,"release_url":"https://pypi.org/project/flash-attn-xwyzsn/1.0.7/","requires_dist":null,"requires_python":">=3.7","summary":"Flash Attention: Fast and Memory-Efficient Exact Attention","version":"1.0.7","yanked":false,"yanked_reason":null},"last_serial":18328003,"urls":[{"comment_text":"","digests":{"blake2b_256":"a17c252d6d5733c7e06a4bfaa47c436ec6733562435df380696cbea74824039e","md5":"d47ce61de1123f631f15416b1bcd0a61","sha256":"7af3ffa9e4192a4e4b9c448ba2a62cd16b43a37b6f59fdec1495e34efc85ba04"},"downloads":-1,"filename":"flash_attn_xwyzsn-1.0.7.tar.gz","has_sig":false,"md5_digest":"d47ce61de1123f631f15416b1bcd0a61","packagetype":"sdist","python_version":"source","requires_python":">=3.7","size":1414928,"upload_time":"2023-06-01T03:53:40","upload_time_iso_8601":"2023-06-01T03:53:40.964687Z","url":"https://files.pythonhosted.org/packages/a1/7c/252d6d5733c7e06a4bfaa47c436ec6733562435df380696cbea74824039e/flash_attn_xwyzsn-1.0.7.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}