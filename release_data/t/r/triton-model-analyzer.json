{"0.0.1.dev5":{"info":{"author":"Jonathan Dekhtiar","author_email":"jdekhtiar@nvidia.com","bugtrack_url":null,"classifiers":["Development Status :: 3 - Alpha","Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: Apache Software License","Natural Language :: English","Operating System :: OS Independent","Programming Language :: Python :: 3.5","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"","docs_url":null,"download_url":"https://github.com/NVIDIA","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/NVIDIA","keywords":"nvidia,deep learning,machine learning,supervised learning,unsupervised learning,reinforcement learning,logging","license":"Apache2","maintainer":"Jonathan Dekhtiar","maintainer_email":"jdekhtiar@nvidia.com","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":"Linux","project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Download":"https://github.com/NVIDIA","Homepage":"https://github.com/NVIDIA"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/0.0.1.dev5/","requires_dist":null,"requires_python":"","summary":"A fake package to warn the user they are not installing the correct package.","version":"0.0.1.dev5","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"c27347d233317cd410a67836581f6f8e99c12abea5149baeae91d2f6a710988e","md5":"931b8cbb920370c0cbf192fb337bdf31","sha256":"3f3c66aa3a46fbfee8dd9ecf5904d14450a9dd96acc0067cf2cbf8a94ccbe39a"},"downloads":-1,"filename":"triton-model-analyzer-0.0.1.dev5.tar.gz","has_sig":false,"md5_digest":"931b8cbb920370c0cbf192fb337bdf31","packagetype":"sdist","python_version":"source","requires_python":null,"size":8254,"upload_time":"2021-09-10T01:44:52","upload_time_iso_8601":"2021-09-10T01:44:52.006886Z","url":"https://files.pythonhosted.org/packages/c2/73/47d233317cd410a67836581f6f8e99c12abea5149baeae91d2f6a710988e/triton-model-analyzer-0.0.1.dev5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.0.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":"","project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.0.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)"],"requires_python":"","summary":"The Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.0.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"429e31579cad76e85b0d5dfd46969fcc1598b1aa178116add47ab21796f20b46","md5":"a8f96e9f0071c875f74112f821287ce9","sha256":"1e7742e8743c999234ffa247a597468bafebaffc9a4365797183465e9ac9c97a"},"downloads":-1,"filename":"triton_model_analyzer-1.0.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"a8f96e9f0071c875f74112f821287ce9","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":2934438,"upload_time":"2021-09-13T20:11:31","upload_time_iso_8601":"2021-09-13T20:11:31.151802Z","url":"https://files.pythonhosted.org/packages/42/9e/31579cad76e85b0d5dfd46969fcc1598b1aa178116add47ab21796f20b46/triton_model_analyzer-1.0.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.1.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":"","project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.1.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)"],"requires_python":"","summary":"The Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.1.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"f2cb5f8b2fb47f76dcc4a09d04debd179d401020ea9b1b36e4653cc5d4813467","md5":"d831a0765427da5184d2d63bdbeb4183","sha256":"9cc809d511bc78b63450048587c7ad9bedf5fd7270ce9220d3f14a4ad92b626d"},"downloads":-1,"filename":"triton_model_analyzer-1.1.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"d831a0765427da5184d2d63bdbeb4183","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":2970122,"upload_time":"2021-09-13T20:54:13","upload_time_iso_8601":"2021-09-13T20:54:13.170835Z","url":"https://files.pythonhosted.org/packages/f2/cb/5f8b2fb47f76dcc4a09d04debd179d401020ea9b1b36e4653cc5d4813467/triton_model_analyzer-1.1.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.10.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":"","project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.10.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.10.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"b25ec7bd0f10c168fcc1e49cd6ff7c80afa72640640cdd1e0c4df90268d54f1c","md5":"0346be68445a199cf950cc784f927dd9","sha256":"643584f28ba15f143daca325eede4f356f2b2bebae26722d59fd86762719c38d"},"downloads":-1,"filename":"triton_model_analyzer-1.10.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"0346be68445a199cf950cc784f927dd9","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":4067327,"upload_time":"2021-11-19T23:47:38","upload_time_iso_8601":"2021-11-19T23:47:38.004891Z","url":"https://files.pythonhosted.org/packages/b2/5e/c7bd0f10c168fcc1e49cd6ff7c80afa72640640cdd1e0c4df90268d54f1c/triton_model_analyzer-1.10.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.11.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":"","project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.11.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.11.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"de9a7e9f059c7e4d3eb1923fec5bec83313160a39fa17ee457b801b8143a7985","md5":"a4d4dc47c5ccdebcc09c050b9e8dc3cd","sha256":"11ddd381fb82eaf9ea59ccb571db4f7a5516c2a927192b4775b01db6fcb802d2"},"downloads":-1,"filename":"triton_model_analyzer-1.11.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"a4d4dc47c5ccdebcc09c050b9e8dc3cd","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":4080345,"upload_time":"2021-12-24T11:08:08","upload_time_iso_8601":"2021-12-24T11:08:08.551639Z","url":"https://files.pythonhosted.org/packages/de/9a/7e9f059c7e4d3eb1923fec5bec83313160a39fa17ee457b801b8143a7985/triton_model_analyzer-1.11.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.12.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":"","project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.12.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.12.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"9b837032d76542ac973e53f5a4d1537a6e666b7f4936e526af8f959c2051d9a5","md5":"7c0af4c64ee885eaa322d0181142f95a","sha256":"6169b4a64f902c659e97ead5e1b5ef66d1b1e685d1a4f4ccbb442210b87b3a69"},"downloads":-1,"filename":"triton_model_analyzer-1.12.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"7c0af4c64ee885eaa322d0181142f95a","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":4088344,"upload_time":"2022-01-31T21:11:07","upload_time_iso_8601":"2022-01-31T21:11:07.955014Z","url":"https://files.pythonhosted.org/packages/9b/83/7032d76542ac973e53f5a4d1537a6e666b7f4936e526af8f959c2051d9a5/triton_model_analyzer-1.12.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.13.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":"","project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.13.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=21.12.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.13.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"8ef1769c7fcaa95e1480d969e2c56d39842abd6f5002386abac26f642f804903","md5":"9252a3732093e650798790c469b56ba6","sha256":"e380e6ce9179c135f718c53401f277b45456fefbd2b799b3ac95730c9236a247"},"downloads":-1,"filename":"triton_model_analyzer-1.13.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"9252a3732093e650798790c469b56ba6","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":4145096,"upload_time":"2022-02-25T18:03:13","upload_time_iso_8601":"2022-02-25T18:03:13.885080Z","url":"https://files.pythonhosted.org/packages/8e/f1/769c7fcaa95e1480d969e2c56d39842abd6f5002386abac26f642f804903/triton_model_analyzer-1.13.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.14.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.14.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=21.12.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.14.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"bc0fd3a5a97c60e7078a5c66888e36a9d1b0c06502956ea845f043e0ac589b03","md5":"d7e58430569dac22df770992fa8c0f4f","sha256":"82ff9470ac5dddd57ee2cc4d3c8480205da2b2581ea7008e14489438bd36cb45"},"downloads":-1,"filename":"triton_model_analyzer-1.14.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"d7e58430569dac22df770992fa8c0f4f","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":4166302,"upload_time":"2022-03-29T22:02:30","upload_time_iso_8601":"2022-03-29T22:02:30.059281Z","url":"https://files.pythonhosted.org/packages/bc/0f/d3a5a97c60e7078a5c66888e36a9d1b0c06502956ea845f043e0ac589b03/triton_model_analyzer-1.14.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.15.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.15.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=21.12.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.15.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"4f935e20a47b39b908c5204ba7157c34c03aef49a992e9b4114842722f08bbf5","md5":"1eb126b300ac48fcd37cc1a78a05458f","sha256":"0c3e47a9e17f0f016742c89b526433a02aaa7af292257d56805c8c0cadb67e5b"},"downloads":-1,"filename":"triton_model_analyzer-1.15.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"1eb126b300ac48fcd37cc1a78a05458f","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":4193379,"upload_time":"2022-04-29T01:31:42","upload_time_iso_8601":"2022-04-29T01:31:42.668448Z","url":"https://files.pythonhosted.org/packages/4f/93/5e20a47b39b908c5204ba7157c34c03aef49a992e9b4114842722f08bbf5/triton_model_analyzer-1.15.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.15.1":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.15.1/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=21.12.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.15.1","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"51345869c0e2d1e903d106f2efd334d453e5d5249bfe98d84766928abeb18372","md5":"a8814a490db10af7998880b46e2ae4aa","sha256":"dbce84047ba5e841741dbad1eafc9fcdd720c876eefee64425d9eb39269ab630"},"downloads":-1,"filename":"triton_model_analyzer-1.15.1-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"a8814a490db10af7998880b46e2ae4aa","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":4199596,"upload_time":"2022-05-06T17:28:40","upload_time_iso_8601":"2022-05-06T17:28:40.419760Z","url":"https://files.pythonhosted.org/packages/51/34/5869c0e2d1e903d106f2efd334d453e5d5249bfe98d84766928abeb18372/triton_model_analyzer-1.15.1-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.16.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.16.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=21.12.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.16.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"0fceac6ca6844237bac0a8cf46367bc50c36d2fd1b2a7ceda59799a7aaf94a6f","md5":"27e8e7561b1b8be7d98e4c0f0c11536c","sha256":"89fc20d6e797cb95201529b0d8356c67dc046496c1671b2d359aa761a74ccd46"},"downloads":-1,"filename":"triton_model_analyzer-1.16.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"27e8e7561b1b8be7d98e4c0f0c11536c","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":4206653,"upload_time":"2022-05-26T22:49:03","upload_time_iso_8601":"2022-05-26T22:49:03.776129Z","url":"https://files.pythonhosted.org/packages/0f/ce/ac6ca6844237bac0a8cf46367bc50c36d2fd1b2a7ceda59799a7aaf94a6f/triton_model_analyzer-1.16.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.17.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.17.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=21.12.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.17.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"30177f4d8fd473e93e85adabb7c4c9e46cb0885dab736d77c374c7abdbd1aed8","md5":"6201c2b10807cdae765b2dd343c0c5d9","sha256":"94c8e345a1021ac78de6c9cfef4047fc11b5d5caeea7610bab0ab5a59a534c80"},"downloads":-1,"filename":"triton_model_analyzer-1.17.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"6201c2b10807cdae765b2dd343c0c5d9","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":4222705,"upload_time":"2022-06-30T01:29:00","upload_time_iso_8601":"2022-06-30T01:29:00.283882Z","url":"https://files.pythonhosted.org/packages/30/17/7f4d8fd473e93e85adabb7c4c9e46cb0885dab736d77c374c7abdbd1aed8/triton_model_analyzer-1.17.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.18.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.18.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=21.12.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.18.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"d7cc1250973b351735137bfae56f1b0708826b55d7cfbd41e5d23762e1961651","md5":"3766c81edb5cf511bf0b68f3badf5134","sha256":"a6484f49e72004e09e502ab63ebeb6cbf8586f3ae6fe0c026becda766ea6454a"},"downloads":-1,"filename":"triton_model_analyzer-1.18.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"3766c81edb5cf511bf0b68f3badf5134","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":4238265,"upload_time":"2022-07-30T00:32:22","upload_time_iso_8601":"2022-07-30T00:32:22.557026Z","url":"https://files.pythonhosted.org/packages/d7/cc/1250973b351735137bfae56f1b0708826b55d7cfbd41e5d23762e1961651/triton_model_analyzer-1.18.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.19.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.19.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=21.12.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.19.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"49d87272036f0d608d67a4c2daeb6f9e2f410bed02393578448a885b48eb7605","md5":"8b1c1ef3500da18675aba4755d2d8652","sha256":"e1345698ab688ce6d6ad695c0dee4fa17173bb45eed4f498980352f3054322e6"},"downloads":-1,"filename":"triton_model_analyzer-1.19.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"8b1c1ef3500da18675aba4755d2d8652","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":5973965,"upload_time":"2022-08-26T17:37:45","upload_time_iso_8601":"2022-08-26T17:37:45.191762Z","url":"https://files.pythonhosted.org/packages/49/d8/7272036f0d608d67a4c2daeb6f9e2f410bed02393578448a885b48eb7605/triton_model_analyzer-1.19.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.2.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":"","project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.2.0/","requires_dist":["distro (>=1.5.0)","docker (>=4.3.1)","matplotlib (>=3.3.4)","numba (>=0.51.2)","pdfkit (>=0.6.1)","prometheus-client (>=0.9.0)","psutil (>=5.8.0)","pyyaml (>=5.3.1)","requests (>=2.24.0)"],"requires_python":"","summary":"The Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.2.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"6abc6bc0a7b76ad90810c64b17fed63aa9dc0dde71f42378654030caf46f1ddb","md5":"b7a861cac5eb20226554b3e2b51e53f9","sha256":"56220e022b8dda20cd19fdb4cf1790000548ff4f1881363c7fb747f86c10403b"},"downloads":-1,"filename":"triton_model_analyzer-1.2.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"b7a861cac5eb20226554b3e2b51e53f9","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":3023393,"upload_time":"2021-09-13T20:54:15","upload_time_iso_8601":"2021-09-13T20:54:15.502825Z","url":"https://files.pythonhosted.org/packages/6a/bc/6bc0a7b76ad90810c64b17fed63aa9dc0dde71f42378654030caf46f1ddb/triton_model_analyzer-1.2.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.20.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.20.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=21.12.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.20.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"6c2917b8a3bff95ec625c200cc81c90db171864dcbf686f642a2533c022c493b","md5":"824afbb27fb5f1c097ca52d1ae37779d","sha256":"f6b8d52710aac6860e98a33f2ef49091532526b8af2f6eb452e01bde219b20ca"},"downloads":-1,"filename":"triton_model_analyzer-1.20.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"824afbb27fb5f1c097ca52d1ae37779d","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6088367,"upload_time":"2022-10-04T00:53:23","upload_time_iso_8601":"2022-10-04T00:53:23.741883Z","url":"https://files.pythonhosted.org/packages/6c/29/17b8a3bff95ec625c200cc81c90db171864dcbf686f642a2533c022c493b/triton_model_analyzer-1.20.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.21.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.21.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=21.12.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.21.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"e99af3b6cab49caf921dff0e9aa456d30f2efb67ac4523017d9df460b6639255","md5":"fc1ce2435bd2c44e577091217db74570","sha256":"d794bd347323b807ad4becbdf27009fd582c0b04a096e4fa3c664f5eb86088d5"},"downloads":-1,"filename":"triton_model_analyzer-1.21.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"fc1ce2435bd2c44e577091217db74570","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6091354,"upload_time":"2022-11-02T22:32:15","upload_time_iso_8601":"2022-11-02T22:32:15.429269Z","url":"https://files.pythonhosted.org/packages/e9/9a/f3b6cab49caf921dff0e9aa456d30f2efb67ac4523017d9df460b6639255/triton_model_analyzer-1.21.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.22.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.22.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=22.08.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.22.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"7eb05d5c9d25c27e53c7cf8ec1ee60ed6742a1fecb511ab060afd84e326aa39f","md5":"ed5dcb7bdcaf40330ee86f46aace406c","sha256":"a441bf20bbabca67064301482622bfdefdb90b204a1715d4c41c9606a9f7b75b"},"downloads":-1,"filename":"triton_model_analyzer-1.22.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"ed5dcb7bdcaf40330ee86f46aace406c","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6103322,"upload_time":"2022-11-22T21:24:28","upload_time_iso_8601":"2022-11-22T21:24:28.407298Z","url":"https://files.pythonhosted.org/packages/7e/b0/5d5c9d25c27e53c7cf8ec1ee60ed6742a1fecb511ab060afd84e326aa39f/triton_model_analyzer-1.22.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.23.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.23.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=22.08.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.23.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"40c382634fea81a6d50bd46d3d2802959c6c48a7f49d04d476a137387b52d4f6","md5":"d4aad4e0de0ae97f330ba139077cba50","sha256":"a2c76f4624d62c18da72d8b701873125536c2ee30b90a25ad824bda7afb90cd8"},"downloads":-1,"filename":"triton_model_analyzer-1.23.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"d4aad4e0de0ae97f330ba139077cba50","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6126658,"upload_time":"2022-12-20T20:00:13","upload_time_iso_8601":"2022-12-20T20:00:13.761114Z","url":"https://files.pythonhosted.org/packages/40/c3/82634fea81a6d50bd46d3d2802959c6c48a7f49d04d476a137387b52d4f6/triton_model_analyzer-1.23.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.24.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.24.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=22.08.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.24.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"c8f1cfa95655c98579800602ad27323394be5fa822beca3c16fd7e2f790e3b45","md5":"acce871f20f11cbc6bab965045b84c4e","sha256":"f67906602f91a255a4f0d8e0727ec7479207dae78cc7a922290a1631ca04cf80"},"downloads":-1,"filename":"triton_model_analyzer-1.24.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"acce871f20f11cbc6bab965045b84c4e","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6128585,"upload_time":"2023-02-01T04:23:50","upload_time_iso_8601":"2023-02-01T04:23:50.983724Z","url":"https://files.pythonhosted.org/packages/c8/f1/cfa95655c98579800602ad27323394be5fa822beca3c16fd7e2f790e3b45/triton_model_analyzer-1.24.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.25.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.25.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=22.08.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.25.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"f73cfaa0c869c2196287eb7b4810af07bbcf5695649f84c7d3e2e6ae7781a7c4","md5":"d2e5a80245e0bede91badc0dc1277093","sha256":"5fc1cdc2487dae24e88d1042598ab9ddcf64c37bbe5ce713e26428465d3829c4"},"downloads":-1,"filename":"triton_model_analyzer-1.25.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"d2e5a80245e0bede91badc0dc1277093","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6133840,"upload_time":"2023-03-01T05:34:04","upload_time_iso_8601":"2023-03-01T05:34:04.625332Z","url":"https://files.pythonhosted.org/packages/f7/3c/faa0c869c2196287eb7b4810af07bbcf5695649f84c7d3e2e6ae7781a7c4/triton_model_analyzer-1.25.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.26.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.26.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=22.08.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.26.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"f813d3589ab1284fcfd18155b0b08eda42581bf6e1cc49edd41a723f6be2bab6","md5":"efb4d61af366b6fad9bd39b50750c663","sha256":"d8dde2c2ad170a64bec5a8f2b2f915f37b6864d6f1c9b0176e4ad49befcb1272"},"downloads":-1,"filename":"triton_model_analyzer-1.26.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"efb4d61af366b6fad9bd39b50750c663","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6149534,"upload_time":"2023-03-28T22:16:30","upload_time_iso_8601":"2023-03-28T22:16:30.746289Z","url":"https://files.pythonhosted.org/packages/f8/13/d3589ab1284fcfd18155b0b08eda42581bf6e1cc49edd41a723f6be2bab6/triton_model_analyzer-1.26.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.27.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.27.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=22.08.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.27.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"5d5bccda94ec4b98cbe6f4ce9b4a7dc37f10ef7822197e3363c73d1cefd7456e","md5":"ff0481bba28bbd09b395888702fcd4a3","sha256":"65a7df46966cfc8088f068738a5d7118b076ec35dd2d9427a3d2458cd6d33e9b"},"downloads":-1,"filename":"triton_model_analyzer-1.27.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"ff0481bba28bbd09b395888702fcd4a3","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6161579,"upload_time":"2023-04-26T01:07:17","upload_time_iso_8601":"2023-04-26T01:07:17.131746Z","url":"https://files.pythonhosted.org/packages/5d/5b/ccda94ec4b98cbe6f4ce9b4a7dc37f10ef7822197e3363c73d1cefd7456e/triton_model_analyzer-1.27.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.28.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.28.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=22.08.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.28.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"24e8602b5bac18d94dca0eb34ad7915383c36c4b179bb136ee4164e24c061045","md5":"2ff83189b6c79700e7cedc7988696f37","sha256":"38992291a79a1f3a7891e8d8197eeb19950798996369b08c7861c80b5843d9c1"},"downloads":-1,"filename":"triton_model_analyzer-1.28.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"2ff83189b6c79700e7cedc7988696f37","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6388489,"upload_time":"2023-05-30T23:57:31","upload_time_iso_8601":"2023-05-30T23:57:31.277031Z","url":"https://files.pythonhosted.org/packages/24/e8/602b5bac18d94dca0eb34ad7915383c36c4b179bb136ee4164e24c061045/triton_model_analyzer-1.28.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.29.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.29.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=22.08.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.29.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"cfdcfdd77e6eaf7c2168bba63ce0f0b0ba8053d201c018163d7a0ee42aba0ba2","md5":"6cb42374557d1f1646e169e301d2eb77","sha256":"88850b6a77d06f589493ac9cddeb6d75e434ffba53b05c356d134696cbd41f44"},"downloads":-1,"filename":"triton_model_analyzer-1.29.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"6cb42374557d1f1646e169e301d2eb77","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6395500,"upload_time":"2023-06-30T01:41:15","upload_time_iso_8601":"2023-06-30T01:41:15.467252Z","url":"https://files.pythonhosted.org/packages/cf/dc/fdd77e6eaf7c2168bba63ce0f0b0ba8053d201c018163d7a0ee42aba0ba2/triton_model_analyzer-1.29.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.3.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":"","project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.3.0/","requires_dist":["cryptography (>=3.3.2)","distro (>=1.5.0)","docker (>=4.3.1)","httplib2 (>=0.19.0)","matplotlib (>=3.3.4)","numba (>=0.51.2)","pdfkit (>=0.6.1)","prometheus-client (>=0.9.0)","psutil (>=5.8.0)","pyyaml (>=5.3.1)","requests (>=2.24.0)","tritonclient[all] (>=2.4.0)"],"requires_python":"","summary":"The Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.3.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"150e6c7c5af2d67f2c1160a7358be1f34852de39aac454445b8a75ec9a1a787d","md5":"18141547dcaa81b3f626bf46e2ff4041","sha256":"6b43162db6bb1cafa7f705669748c61af491e3b2b333d0e4a28832a3a5322b41"},"downloads":-1,"filename":"triton_model_analyzer-1.3.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"18141547dcaa81b3f626bf46e2ff4041","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":3029353,"upload_time":"2021-09-13T20:54:18","upload_time_iso_8601":"2021-09-13T20:54:18.390779Z","url":"https://files.pythonhosted.org/packages/15/0e/6c7c5af2d67f2c1160a7358be1f34852de39aac454445b8a75ec9a1a787d/triton_model_analyzer-1.3.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.30.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.30.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)","gevent (>=22.08.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.30.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"094bd8585222465bff13fe834076d7814777993bacc5d6e20e2455f405d62698","md5":"7e6bc0ccb06f566bc29d78f6ccc92b86","sha256":"a6a9cd59802b43e8be49d691d8e3d56227032f1264c686c5d522774bd7ad7c46"},"downloads":-1,"filename":"triton_model_analyzer-1.30.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"7e6bc0ccb06f566bc29d78f6ccc92b86","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6409466,"upload_time":"2023-07-27T23:24:05","upload_time_iso_8601":"2023-07-27T23:24:05.298295Z","url":"https://files.pythonhosted.org/packages/09/4b/d8585222465bff13fe834076d7814777993bacc5d6e20e2455f405d62698/triton_model_analyzer-1.30.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.31.0.9384447":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.31.0.9384447/","requires_dist":["cryptography >=3.3.2","distro >=1.5.0","docker >=4.3.1","gevent >=22.08.0","httplib2 >=0.19.0","matplotlib >=3.3.4","numba >=0.51.2","pdfkit >=0.6.1","prometheus-client >=0.9.0","psutil >=5.8.0","pyyaml >=5.3.1","requests >=2.24.0","tritonclient[all] >=2.4.0"],"requires_python":"","summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.31.0.9384447","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"7c13c328deff744f025ccd11fe01ec42db2e41f5160f4f0d08e83249ea9bcfc3","md5":"6b1ef78378b86f03fddb636049236c7c","sha256":"d157576614ff91bc860904a2f778d9bb93da1b228750011a758a44b4e2f0e8c6"},"downloads":-1,"filename":"triton_model_analyzer-1.31.0.9384447-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"6b1ef78378b86f03fddb636049236c7c","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6414466,"upload_time":"2023-08-29T00:44:11","upload_time_iso_8601":"2023-08-29T00:44:11.986106Z","url":"https://files.pythonhosted.org/packages/7c/13/c328deff744f025ccd11fe01ec42db2e41f5160f4f0d08e83249ea9bcfc3/triton_model_analyzer-1.31.0.9384447-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.32.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.32.0/","requires_dist":["cryptography >=3.3.2","distro >=1.5.0","docker >=4.3.1","gevent >=22.08.0","httplib2 >=0.19.0","matplotlib >=3.3.4","numba >=0.51.2","pdfkit >=0.6.1","prometheus-client >=0.9.0","psutil >=5.8.0","pyyaml >=5.3.1","requests >=2.24.0","tritonclient[all] >=2.4.0"],"requires_python":"","summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.32.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"b941c476a66972b1e4afb5b36871a2b88152f42b6074edb1bbad4587efdc8685","md5":"5a5722e3a934990e12fd1e25148bd577","sha256":"6c1ae428b705cc9afd9d3d85dc1e62c76957e475d16c4cafe50a510a603ee043"},"downloads":-1,"filename":"triton_model_analyzer-1.32.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"5a5722e3a934990e12fd1e25148bd577","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6454160,"upload_time":"2023-10-03T10:23:01","upload_time_iso_8601":"2023-10-03T10:23:01.645381Z","url":"https://files.pythonhosted.org/packages/b9/41/c476a66972b1e4afb5b36871a2b88152f42b6074edb1bbad4587efdc8685/triton_model_analyzer-1.32.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.33.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.33.0/","requires_dist":["cryptography >=3.3.2","distro >=1.5.0","docker >=4.3.1","gevent >=22.08.0","httplib2 >=0.19.0","matplotlib >=3.3.4","numba >=0.51.2","pdfkit >=0.6.1","prometheus-client >=0.9.0","psutil >=5.8.0","pyyaml >=5.3.1","requests >=2.24.0","tritonclient[all] >=2.4.0"],"requires_python":"","summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.33.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"9f29880ee60d8f2cfc4a27df7a3b7ab2f49eee2f3e527e3a9cfb4216bf81553d","md5":"68c3efcae55e4fb3d30e27a395a93084","sha256":"ee707deda315fde48dcaa77fa4c005a26a0e5a134d281cff7eb525742db05868"},"downloads":-1,"filename":"triton_model_analyzer-1.33.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"68c3efcae55e4fb3d30e27a395a93084","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6480456,"upload_time":"2023-10-30T16:25:46","upload_time_iso_8601":"2023-10-30T16:25:46.191457Z","url":"https://files.pythonhosted.org/packages/9f/29/880ee60d8f2cfc4a27df7a3b7ab2f49eee2f3e527e3a9cfb4216bf81553d/triton_model_analyzer-1.33.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.34.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.34.0/","requires_dist":["cryptography >=3.3.2","distro >=1.5.0","docker >=4.3.1","gevent >=22.08.0","httplib2 >=0.19.0","matplotlib >=3.3.4","numba >=0.51.2","pdfkit >=0.6.1","prometheus-client >=0.9.0","psutil >=5.8.0","pyyaml >=5.3.1","requests >=2.24.0","tritonclient[all] >=2.4.0"],"requires_python":"","summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.34.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"1ae51885571fbca55742eb753d31c06add7b37959f891678d29d23558620d60c","md5":"e8bc1649519738d1bd12bef8d0ffd062","sha256":"5956f5c6032f5b586ee9e4357302d35558d2f4a666bc47cc4f5a354503319e2e"},"downloads":-1,"filename":"triton_model_analyzer-1.34.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"e8bc1649519738d1bd12bef8d0ffd062","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6553108,"upload_time":"2023-12-01T23:44:37","upload_time_iso_8601":"2023-12-01T23:44:37.805908Z","url":"https://files.pythonhosted.org/packages/1a/e5/1885571fbca55742eb753d31c06add7b37959f891678d29d23558620d60c/triton_model_analyzer-1.34.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.35.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.35.0/","requires_dist":["cryptography >=3.3.2","distro >=1.5.0","docker >=4.3.1","gevent >=22.08.0","httplib2 >=0.19.0","matplotlib >=3.3.4","numba >=0.51.2","pdfkit >=0.6.1","prometheus-client >=0.9.0","protobuf","psutil >=5.8.0","pyyaml >=5.3.1","requests >=2.24.0","tritonclient[all] >=2.4.0"],"requires_python":"","summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.35.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"48b9fe892ee5791be7078a1eebb78b6181a49c40e94a8d21edc60d341025f33d","md5":"4bdd31a49bdb2b30378eefd8b64a8bd3","sha256":"abeeb7be8f9abd3c4c29cb1f23d7345ea7a60998fcbaf4e576c2c7a4586c09a5"},"downloads":-1,"filename":"triton_model_analyzer-1.35.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"4bdd31a49bdb2b30378eefd8b64a8bd3","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6553018,"upload_time":"2023-12-20T01:04:35","upload_time_iso_8601":"2023-12-20T01:04:35.867460Z","url":"https://files.pythonhosted.org/packages/48/b9/fe892ee5791be7078a1eebb78b6181a49c40e94a8d21edc60d341025f33d/triton_model_analyzer-1.35.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.36.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.36.0/","requires_dist":["cryptography >=3.3.2","distro >=1.5.0","docker >=4.3.1","gevent >=22.08.0","grpcio <=1.59.3","httplib2 >=0.19.0","matplotlib >=3.3.4","numba >=0.51.2","pdfkit >=0.6.1","prometheus-client >=0.9.0","protobuf","psutil >=5.8.0","pyyaml >=5.3.1","requests >=2.24.0","tritonclient[all] >=2.4.0","urllib3 >=2.0.7"],"requires_python":"","summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.36.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"d03564ded7609ffb02411e0b84bcaff762a7048e7254cf952e775b8a4d562f29","md5":"941acdfef0753f38a32dff1b3fd51b1d","sha256":"798dba41a8361d76646051682a6c8c1c9131ef03043609d9f1dec43e52b5423b"},"downloads":-1,"filename":"triton_model_analyzer-1.36.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"941acdfef0753f38a32dff1b3fd51b1d","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6553899,"upload_time":"2024-01-30T01:09:54","upload_time_iso_8601":"2024-01-30T01:09:54.851210Z","url":"https://files.pythonhosted.org/packages/d0/35/64ded7609ffb02411e0b84bcaff762a7048e7254cf952e775b8a4d562f29/triton_model_analyzer-1.36.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.37.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.37.0/","requires_dist":["cryptography >=3.3.2","distro >=1.5.0","docker >=4.3.1","gevent >=22.08.0","grpcio <=1.59.3","httplib2 >=0.19.0","matplotlib >=3.3.4","numba >=0.51.2","pdfkit >=0.6.1","prometheus-client >=0.9.0","protobuf","psutil >=5.8.0","pyyaml >=5.3.1","requests >=2.24.0","tritonclient[all] >=2.4.0","urllib3 >=2.0.7"],"requires_python":"","summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.37.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"e30674b9a85b1465470df99070739c8d1cb90b9993447f0af616b3097ba5090e","md5":"81d45d21f07e98c12b99ea1934fae2be","sha256":"56889bf43b7d9f2719373d45c85b3ef76620b7d01dd2f51ab2a72673cecc8f15"},"downloads":-1,"filename":"triton_model_analyzer-1.37.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"81d45d21f07e98c12b99ea1934fae2be","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6547129,"upload_time":"2024-03-01T01:36:38","upload_time_iso_8601":"2024-03-01T01:36:38.358961Z","url":"https://files.pythonhosted.org/packages/e3/06/74b9a85b1465470df99070739c8d1cb90b9993447f0af616b3097ba5090e/triton_model_analyzer-1.37.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.38.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton, tensorrt, inference, server, service, analyzer, nvidia","license":"BSD","maintainer":null,"maintainer_email":null,"name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.38.0/","requires_dist":["cryptography>=3.3.2","distro>=1.5.0","docker>=4.3.1","gevent>=22.08.0","grpcio<=1.59.3","httplib2>=0.19.0","matplotlib>=3.3.4","numba>=0.51.2","pdfkit>=0.6.1","prometheus-client>=0.9.0","protobuf","psutil>=5.8.0","pyyaml>=5.3.1","requests>=2.24.0","tritonclient[all]>=2.4.0","urllib3>=2.0.7"],"requires_python":null,"summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.38.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"af4a5e205f8c3f6448ceaddd1d4e4b40d2c0dbb3a96bd58673e326dd14b98fc9","md5":"6bc0612d12ca2c00eb8b6517986eec67","sha256":"83f3b803a73e3f1ddca5aa6f61ff54a3d53a1d6242dfba79aafdaaecaf51b94d"},"downloads":-1,"filename":"triton_model_analyzer-1.38.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"6bc0612d12ca2c00eb8b6517986eec67","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6605271,"upload_time":"2024-03-27T01:47:41","upload_time_iso_8601":"2024-03-27T01:47:41.932576Z","url":"https://files.pythonhosted.org/packages/af/4a/5e205f8c3f6448ceaddd1d4e4b40d2c0dbb3a96bd58673e326dd14b98fc9/triton_model_analyzer-1.38.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.39.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton, tensorrt, inference, server, service, analyzer, nvidia","license":"BSD","maintainer":null,"maintainer_email":null,"name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.39.0/","requires_dist":["cryptography>=3.3.2","distro>=1.5.0","docker>=4.3.1","gevent>=22.08.0","grpcio<=1.59.3","httplib2>=0.19.0","matplotlib>=3.3.4","numba>=0.51.2","pdfkit>=0.6.1","prometheus-client>=0.9.0","protobuf","psutil>=5.8.0","pyyaml>=5.3.1","requests>=2.24.0","tritonclient[all]>=2.4.0","urllib3>=2.0.7"],"requires_python":null,"summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.39.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"9549966d03aa21af3d95a55a387a3bd5cf3a767533709b36e2093711968f9bb1","md5":"ce1e387c961f44c5f22f0dc24da03520","sha256":"85300ca90cd50c56024de80d611cf0d530f3b0a6c810501b20f812705f432035"},"downloads":-1,"filename":"triton_model_analyzer-1.39.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"ce1e387c961f44c5f22f0dc24da03520","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6642246,"upload_time":"2024-04-30T21:25:39","upload_time_iso_8601":"2024-04-30T21:25:39.561457Z","url":"https://files.pythonhosted.org/packages/95/49/966d03aa21af3d95a55a387a3bd5cf3a767533709b36e2093711968f9bb1/triton_model_analyzer-1.39.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.40.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton, tensorrt, inference, server, service, analyzer, nvidia","license":"BSD","maintainer":null,"maintainer_email":null,"name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.40.0/","requires_dist":["cryptography>=3.3.2","distro>=1.5.0","docker>=4.3.1","gevent>=22.08.0","grpcio>=1.41.0","httplib2>=0.19.0","matplotlib>=3.3.4","numba>=0.51.2","pdfkit>=0.6.1","prometheus-client>=0.9.0","protobuf","psutil>=5.8.0","pyyaml>=5.3.1","requests>=2.24.0","tritonclient[all]>=2.4.0","urllib3>=2.0.7"],"requires_python":null,"summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.40.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"b102c6281b5c785e5ed1e2d17b59fb256a03dfd57f8b4059fa5568fa5a8155cb","md5":"7cf9c94d851e1b83a6a0a2ffc1ab5854","sha256":"108c34ee22cf1335bcc259a6f488346c3416aa6fce9833ce088fc1b4d008295d"},"downloads":-1,"filename":"triton_model_analyzer-1.40.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"7cf9c94d851e1b83a6a0a2ffc1ab5854","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6644623,"upload_time":"2024-05-25T02:04:41","upload_time_iso_8601":"2024-05-25T02:04:41.024886Z","url":"https://files.pythonhosted.org/packages/b1/02/c6281b5c785e5ed1e2d17b59fb256a03dfd57f8b4059fa5568fa5a8155cb/triton_model_analyzer-1.40.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.41.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton, tensorrt, inference, server, service, analyzer, nvidia","license":"BSD","maintainer":null,"maintainer_email":null,"name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.41.0/","requires_dist":["cryptography>=3.3.2","distro>=1.5.0","docker>=4.3.1","gevent>=22.08.0","grpcio>=1.41.0","httplib2>=0.19.0","importlib-metadata>=7.1.0","matplotlib>=3.3.4","numba>=0.51.2","optuna==3.6.1","pdfkit>=0.6.1","prometheus-client>=0.9.0","protobuf","psutil>=5.8.0","pyyaml>=5.3.1","requests>=2.24.0","tritonclient[all]>=2.4.0","urllib3>=2.0.7"],"requires_python":null,"summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.41.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"74fd476144e2dddc308b8da7975af395f178286468814c54fb8a40216dcafbf0","md5":"dbb1168836a944734b6f4e79b5c66d90","sha256":"34b55f85394ac309143062383f8b8d2142b1a26efbe4931a2d200b903bae0faf"},"downloads":-1,"filename":"triton_model_analyzer-1.41.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"dbb1168836a944734b6f4e79b5c66d90","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6656356,"upload_time":"2024-06-28T00:23:55","upload_time_iso_8601":"2024-06-28T00:23:55.091086Z","url":"https://files.pythonhosted.org/packages/74/fd/476144e2dddc308b8da7975af395f178286468814c54fb8a40216dcafbf0/triton_model_analyzer-1.41.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.42.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton, tensorrt, inference, server, service, analyzer, nvidia","license":"BSD","maintainer":null,"maintainer_email":null,"name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.42.0/","requires_dist":["cryptography>=3.3.2","distro>=1.5.0","docker>=4.3.1","gevent>=22.08.0","grpcio>=1.41.0","httplib2>=0.19.0","importlib-metadata>=7.1.0","matplotlib>=3.3.4","numba>=0.51.2","optuna==3.6.1","pdfkit>=0.6.1","prometheus-client>=0.9.0","protobuf","psutil>=5.8.0","pyyaml>=5.3.1","requests>=2.24.0","tritonclient[all]>=2.4.0","urllib3>=2.0.7"],"requires_python":null,"summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.42.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"e4d3f3e177e117ea73e176eb86300313bd906917507d891745859ffcf99c5966","md5":"ea7dfd1aae1d24f6d2bab8fcfda79c3e","sha256":"75ae949d40fa69d7333c546a4b69a003f1a7d92340709a4083b12d5e7d0e5c98"},"downloads":-1,"filename":"triton_model_analyzer-1.42.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"ea7dfd1aae1d24f6d2bab8fcfda79c3e","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":7338667,"upload_time":"2024-07-24T19:23:45","upload_time_iso_8601":"2024-07-24T19:23:45.388634Z","url":"https://files.pythonhosted.org/packages/e4/d3/f3e177e117ea73e176eb86300313bd906917507d891745859ffcf99c5966/triton_model_analyzer-1.42.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.42.0.dev0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton, tensorrt, inference, server, service, analyzer, nvidia","license":"BSD","maintainer":null,"maintainer_email":null,"name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.42.0.dev0/","requires_dist":["cryptography>=3.3.2","distro>=1.5.0","docker>=4.3.1","gevent>=22.08.0","grpcio>=1.41.0","httplib2>=0.19.0","importlib-metadata>=7.1.0","matplotlib>=3.3.4","numba>=0.51.2","optuna==3.6.1","pdfkit>=0.6.1","prometheus-client>=0.9.0","protobuf","psutil>=5.8.0","pyyaml>=5.3.1","requests>=2.24.0","tritonclient[all]>=2.4.0","urllib3>=2.0.7"],"requires_python":null,"summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.42.0.dev0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"f8a186262598d59c7803188964d6839f5d6562eb65a91cc181d5eb03280343d0","md5":"13e17d8bd8d3ca442cb51d5896a39bcd","sha256":"e6a60c907db2863c18dd109a637da6b6fc3f16b73484047edd89bf94c8f69db9"},"downloads":-1,"filename":"triton_model_analyzer-1.42.0.dev0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"13e17d8bd8d3ca442cb51d5896a39bcd","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":7338766,"upload_time":"2024-07-24T16:43:42","upload_time_iso_8601":"2024-07-24T16:43:42.666729Z","url":"https://files.pythonhosted.org/packages/f8/a1/86262598d59c7803188964d6839f5d6562eb65a91cc181d5eb03280343d0/triton_model_analyzer-1.42.0.dev0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.43.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton, tensorrt, inference, server, service, analyzer, nvidia","license":"BSD","maintainer":null,"maintainer_email":null,"name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.43.0/","requires_dist":["cryptography>=3.3.2","distro>=1.5.0","docker>=4.3.1","gevent>=22.08.0","grpcio>=1.41.0","httplib2>=0.19.0","importlib-metadata>=7.1.0","matplotlib>=3.3.4","numba>=0.51.2","optuna==3.6.1","pdfkit>=0.6.1","prometheus-client>=0.9.0","protobuf","psutil>=5.8.0","pyyaml>=5.3.1","requests>=2.24.0","tritonclient[all]>=2.4.0","urllib3>=2.0.7"],"requires_python":null,"summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.43.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"240fb2c0b3e80c12e3c7c07a82e6ec7d1eff6c591f35f1eb8bef051260c203be","md5":"215d14b76fe9eca86203faf4a3d5b7a0","sha256":"7f503a03da57ec9556de9a6bcd92c787ed1b197fdea2418b3e1583475bc10d47"},"downloads":-1,"filename":"triton_model_analyzer-1.43.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"215d14b76fe9eca86203faf4a3d5b7a0","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":7355871,"upload_time":"2024-08-26T17:03:31","upload_time_iso_8601":"2024-08-26T17:03:31.240528Z","url":"https://files.pythonhosted.org/packages/24/0f/b2c0b3e80c12e3c7c07a82e6ec7d1eff6c591f35f1eb8bef051260c203be/triton_model_analyzer-1.43.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.44.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.10","Programming Language :: Python :: 3.11","Programming Language :: Python :: 3.8","Programming Language :: Python :: 3.9","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton, tensorrt, inference, server, service, analyzer, nvidia","license":"BSD","maintainer":null,"maintainer_email":null,"name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":null,"project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.44.0/","requires_dist":["cryptography>=3.3.2","distro>=1.5.0","docker>=4.3.1","gevent>=22.08.0","grpcio>=1.41.0","httplib2>=0.19.0","importlib-metadata>=7.1.0","matplotlib>=3.3.4","numba>=0.51.2","optuna==3.6.1","pdfkit>=0.6.1","prometheus-client>=0.9.0","protobuf","psutil>=5.8.0","pyyaml>=5.3.1","requests>=2.24.0","tritonclient[all]>=2.4.0","urllib3>=2.0.7"],"requires_python":null,"summary":"Triton Model Analyzer is a tool to profile and analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.44.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"42b081c68ee76792b843740c4a11dc0389be4076628b124e5cd1495b7ae8d304","md5":"9c0de32314657a9b07abcc4f2b34de9b","sha256":"d3d5b95cf18493090b853ab7aeab74b3f6343bab66346a9f2822c6fcbe5e81d1"},"downloads":-1,"filename":"triton_model_analyzer-1.44.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"9c0de32314657a9b07abcc4f2b34de9b","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":7357137,"upload_time":"2024-09-27T17:03:49","upload_time_iso_8601":"2024-09-27T17:03:49.532725Z","url":"https://files.pythonhosted.org/packages/42/b0/81c68ee76792b843740c4a11dc0389be4076628b124e5cd1495b7ae8d304/triton_model_analyzer-1.44.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.5.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":"","project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.5.0/","requires_dist":["cryptography (>=3.3.2)","distro (>=1.5.0)","docker (>=4.3.1)","httplib2 (>=0.19.0)","matplotlib (>=3.3.4)","numba (>=0.51.2)","pdfkit (>=0.6.1)","prometheus-client (>=0.9.0)","psutil (>=5.8.0)","pyyaml (>=5.3.1)","requests (>=2.24.0)","tritonclient[all] (>=2.4.0)"],"requires_python":"","summary":"The Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.5.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"8f3d7ea95144102787864467d52db471cd5ef9a0865ed8458c63eb95d9b4c8af","md5":"91e62c4028c96f745043c9ba00848613","sha256":"3d69d556ac4fbdc727559ad3969538c340e8f0ee3f456f188c20e54c4c558eb4"},"downloads":-1,"filename":"triton_model_analyzer-1.5.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"91e62c4028c96f745043c9ba00848613","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":3987243,"upload_time":"2021-09-13T20:54:21","upload_time_iso_8601":"2021-09-13T20:54:21.282784Z","url":"https://files.pythonhosted.org/packages/8f/3d/7ea95144102787864467d52db471cd5ef9a0865ed8458c63eb95d9b4c8af/triton_model_analyzer-1.5.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.6.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":"","project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.6.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)"],"requires_python":"","summary":"The Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.6.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"acd9aebc7a99ff3f866032445d4a7472ba3cf3111d8b8c40ce1b4d0700958fc3","md5":"a48d7744779024818c60c047426a974f","sha256":"2e24b56ec6620046cb1839ddf4537d315e4ac72f1bb2cf099a73b2cf92009103"},"downloads":-1,"filename":"triton_model_analyzer-1.6.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"a48d7744779024818c60c047426a974f","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":4042255,"upload_time":"2021-09-13T20:54:24","upload_time_iso_8601":"2021-09-13T20:54:24.386767Z","url":"https://files.pythonhosted.org/packages/ac/d9/aebc7a99ff3f866032445d4a7472ba3cf3111d8b8c40ce1b4d0700958fc3/triton_model_analyzer-1.6.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.7.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":"","project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.7.0/","requires_dist":["pyyaml (>=5.3.1)","requests (>=2.24.0)","cryptography (>=3.3.2)","distro (>=1.5.0)","docker (>=4.3.1)","httplib2 (>=0.19.0)","matplotlib (>=3.3.4)","numba (>=0.51.2)","pdfkit (>=0.6.1)","prometheus-client (>=0.9.0)","psutil (>=5.8.0)","tritonclient[all] (>=2.4.0)"],"requires_python":"","summary":"The Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.7.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"b04ea6ca34afc4122d34fe5c4cee72560624cceac4fa51c776ae6f206b41c0e0","md5":"3c6980abc9d4b402a9454abc5f47c427","sha256":"af3ca8b70c680d8cc1dd88eeedec8fb752df24f4ee15db2b446b10b800e00102"},"downloads":-1,"filename":"triton_model_analyzer-1.7.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"3c6980abc9d4b402a9454abc5f47c427","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":3991105,"upload_time":"2021-09-13T20:54:27","upload_time_iso_8601":"2021-09-13T20:54:27.250124Z","url":"https://files.pythonhosted.org/packages/b0/4e/a6ca34afc4122d34fe5c4cee72560624cceac4fa51c776ae6f206b41c0e0/triton_model_analyzer-1.7.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.8.2":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":"","project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.8.2/","requires_dist":["cryptography (>=3.3.2)","distro (>=1.5.0)","docker (>=4.3.1)","httplib2 (>=0.19.0)","matplotlib (>=3.3.4)","numba (>=0.51.2)","pdfkit (>=0.6.1)","prometheus-client (>=0.9.0)","psutil (>=5.8.0)","pyyaml (>=5.3.1)","requests (>=2.24.0)","tritonclient[all] (>=2.4.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.8.2","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"e495c1a2235fbea9614bd44d50d85c82baec45d9df35a6940561683723df51c6","md5":"85890d530fe65da3512bc1cc5769bcae","sha256":"cb86e39a2b86d412b32d8f8531eb4b1b4eb47a7077318502d0c25b38fc9ac911"},"downloads":-1,"filename":"triton_model_analyzer-1.8.2-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"85890d530fe65da3512bc1cc5769bcae","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":4053590,"upload_time":"2021-09-29T21:51:06","upload_time_iso_8601":"2021-09-29T21:51:06.100706Z","url":"https://files.pythonhosted.org/packages/e4/95/c1a2235fbea9614bd44d50d85c82baec45d9df35a6940561683723df51c6/triton_model_analyzer-1.8.2-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.9.0":{"info":{"author":"NVIDIA Inc.","author_email":"sw-dl-triton@nvidia.com","bugtrack_url":null,"classifiers":["Environment :: Console","Intended Audience :: Developers","Intended Audience :: Information Technology","Intended Audience :: Science/Research","License :: OSI Approved :: BSD License","Natural Language :: English","Operating System :: POSIX :: Linux","Programming Language :: Python :: 3","Programming Language :: Python :: 3.6","Programming Language :: Python :: 3.7","Programming Language :: Python :: 3.8","Topic :: Scientific/Engineering","Topic :: Scientific/Engineering :: Artificial Intelligence","Topic :: Scientific/Engineering :: Image Recognition","Topic :: Software Development :: Libraries","Topic :: Utilities"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://developer.nvidia.com/nvidia-triton-inference-server","keywords":"triton,tensorrt,inference,server,service,analyzer,nvidia","license":"BSD","maintainer":"","maintainer_email":"","name":"triton-model-analyzer","package_url":"https://pypi.org/project/triton-model-analyzer/","platform":"","project_url":"https://pypi.org/project/triton-model-analyzer/","project_urls":{"Homepage":"https://developer.nvidia.com/nvidia-triton-inference-server"},"provides_extra":null,"release_url":"https://pypi.org/project/triton-model-analyzer/1.9.0/","requires_dist":["docker (>=4.3.1)","distro (>=1.5.0)","numba (>=0.51.2)","prometheus-client (>=0.9.0)","requests (>=2.24.0)","pyyaml (>=5.3.1)","psutil (>=5.8.0)","matplotlib (>=3.3.4)","pdfkit (>=0.6.1)","cryptography (>=3.3.2)","httplib2 (>=0.19.0)","tritonclient[all] (>=2.4.0)"],"requires_python":"","summary":"Triton Model Analyzer is a tool to analyze the runtime performance of one or more models on the Triton Inference Server","version":"1.9.0","yanked":false,"yanked_reason":null},"last_serial":25223848,"urls":[{"comment_text":"","digests":{"blake2b_256":"824175e5ffa380231754a15d5198d358e5dd821ffdf154976cf8ff9a2980408c","md5":"9ca21c1d63bdb9beb215d9abd9f8a580","sha256":"027129f1a33e2135b04dc13c5c6483a95f778cb3809193562cf97fe6975da8c7"},"downloads":-1,"filename":"triton_model_analyzer-1.9.0-py3-none-manylinux1_x86_64.whl","has_sig":false,"md5_digest":"9ca21c1d63bdb9beb215d9abd9f8a580","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":4061089,"upload_time":"2021-10-28T00:24:31","upload_time_iso_8601":"2021-10-28T00:24:31.216634Z","url":"https://files.pythonhosted.org/packages/82/41/75e5ffa380231754a15d5198d358e5dd821ffdf154976cf8ff9a2980408c/triton_model_analyzer-1.9.0-py3-none-manylinux1_x86_64.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}