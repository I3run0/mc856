{"0.1.0":{"info":{"author":"Charles Condevaux","author_email":"charles.condevaux@gmail.com","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/ccdv-ai/tokenizer-adapter","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"tokenizer-adapter","package_url":"https://pypi.org/project/tokenizer-adapter/","platform":null,"project_url":"https://pypi.org/project/tokenizer-adapter/","project_urls":{"Homepage":"https://github.com/ccdv-ai/tokenizer-adapter"},"provides_extra":null,"release_url":"https://pypi.org/project/tokenizer-adapter/0.1.0/","requires_dist":["torch >=1.8","tokenizers >=0.15.0","tqdm"],"requires_python":">=3.8","summary":"Tools to adapt a pretrained model to a new vocabulary","version":"0.1.0","yanked":false,"yanked_reason":null},"last_serial":21464436,"urls":[{"comment_text":"","digests":{"blake2b_256":"c808b1136d77d00fc3cb8b29d4fc6bff39b39ba242a222c50ee65f6136737d24","md5":"445944a317ce0bbacfa93e49512b6f6b","sha256":"e4eb8756f313015bb5c412297683e79545058b015c33e545b18561c7558f318d"},"downloads":-1,"filename":"tokenizer_adapter-0.1.0-py3-none-any.whl","has_sig":false,"md5_digest":"445944a317ce0bbacfa93e49512b6f6b","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":8458,"upload_time":"2024-01-15T23:03:50","upload_time_iso_8601":"2024-01-15T23:03:50.181376Z","url":"https://files.pythonhosted.org/packages/c8/08/b1136d77d00fc3cb8b29d4fc6bff39b39ba242a222c50ee65f6136737d24/tokenizer_adapter-0.1.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b61ff0f72e7d90e5e0332854a62d28abfed6630f65af3149ada1b4c2352d6b5e","md5":"8141e64a5299ff46a80d762fedde78e9","sha256":"b0fc0884e490d136b9bd587686ae8570498d5047a1edb61ac5915c7a2edd1546"},"downloads":-1,"filename":"tokenizer-adapter-0.1.0.tar.gz","has_sig":false,"md5_digest":"8141e64a5299ff46a80d762fedde78e9","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":7930,"upload_time":"2024-01-15T23:03:51","upload_time_iso_8601":"2024-01-15T23:03:51.685750Z","url":"https://files.pythonhosted.org/packages/b6/1f/f0f72e7d90e5e0332854a62d28abfed6630f65af3149ada1b4c2352d6b5e/tokenizer-adapter-0.1.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.1":{"info":{"author":"Charles Condevaux","author_email":"charles.condevaux@gmail.com","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/ccdv-ai/tokenizer-adapter","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"tokenizer-adapter","package_url":"https://pypi.org/project/tokenizer-adapter/","platform":null,"project_url":"https://pypi.org/project/tokenizer-adapter/","project_urls":{"Homepage":"https://github.com/ccdv-ai/tokenizer-adapter"},"provides_extra":null,"release_url":"https://pypi.org/project/tokenizer-adapter/0.1.1/","requires_dist":["torch >=1.8","tokenizers >=0.15.0","tqdm"],"requires_python":">=3.8","summary":"A simple to adapt a pretrained language model to a new vocabulary","version":"0.1.1","yanked":false,"yanked_reason":null},"last_serial":21464436,"urls":[{"comment_text":"","digests":{"blake2b_256":"9832e235680b3ff62a3c56db2f383e63f1c511a0916f970145a3c118d6cfe8e7","md5":"87ed4655a10e53feed123bf9df0f5f0b","sha256":"a73f81d769116dbf1901196016dae1aa17f68d4ae26dcffd7f4ced85b796d074"},"downloads":-1,"filename":"tokenizer_adapter-0.1.1-py3-none-any.whl","has_sig":false,"md5_digest":"87ed4655a10e53feed123bf9df0f5f0b","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":8462,"upload_time":"2024-01-15T23:12:03","upload_time_iso_8601":"2024-01-15T23:12:03.880969Z","url":"https://files.pythonhosted.org/packages/98/32/e235680b3ff62a3c56db2f383e63f1c511a0916f970145a3c118d6cfe8e7/tokenizer_adapter-0.1.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"4cbe2c58feeb8e5582316af6d260e48e70fe2d7917c7ad3b54168f75447276c8","md5":"c4de36678a1d0969dbcfe1f9ab445d6e","sha256":"ce472ca7d9f4a37a9bd8818c34fc9779a443bbc02b9b14b6390d407c5c639530"},"downloads":-1,"filename":"tokenizer-adapter-0.1.1.tar.gz","has_sig":false,"md5_digest":"c4de36678a1d0969dbcfe1f9ab445d6e","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":7957,"upload_time":"2024-01-15T23:12:05","upload_time_iso_8601":"2024-01-15T23:12:05.411047Z","url":"https://files.pythonhosted.org/packages/4c/be/2c58feeb8e5582316af6d260e48e70fe2d7917c7ad3b54168f75447276c8/tokenizer-adapter-0.1.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.2":{"info":{"author":"Charles Condevaux","author_email":"charles.condevaux@gmail.com","bugtrack_url":null,"classifiers":["License :: OSI Approved :: MIT License","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/ccdv-ai/tokenizer-adapter","keywords":"","license":"","maintainer":"","maintainer_email":"","name":"tokenizer-adapter","package_url":"https://pypi.org/project/tokenizer-adapter/","platform":null,"project_url":"https://pypi.org/project/tokenizer-adapter/","project_urls":{"Homepage":"https://github.com/ccdv-ai/tokenizer-adapter"},"provides_extra":null,"release_url":"https://pypi.org/project/tokenizer-adapter/0.1.2/","requires_dist":["torch >=1.8","tokenizers >=0.15.0","tqdm"],"requires_python":">=3.8","summary":"A simple to adapt a pretrained language model to a new vocabulary","version":"0.1.2","yanked":false,"yanked_reason":null},"last_serial":21464436,"urls":[{"comment_text":"","digests":{"blake2b_256":"15f72ac73bcf4aa9424170df21cc56bf007c1df4a42deb6e28f2c265ad567642","md5":"d63edd727fd72633760e036d0109127d","sha256":"a378326ebe710255705be5689d6d4664dfc710bd210cd4e5a8df504fcfd73f16"},"downloads":-1,"filename":"tokenizer_adapter-0.1.2-py3-none-any.whl","has_sig":false,"md5_digest":"d63edd727fd72633760e036d0109127d","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.8","size":9258,"upload_time":"2024-01-17T13:59:51","upload_time_iso_8601":"2024-01-17T13:59:51.026904Z","url":"https://files.pythonhosted.org/packages/15/f7/2ac73bcf4aa9424170df21cc56bf007c1df4a42deb6e28f2c265ad567642/tokenizer_adapter-0.1.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e8c2a92888effcc9bf63a38c6d8912647616519209a35a2ee4d9eabb50aa1035","md5":"3578d6cafa4c71c6038cb8a8876606a4","sha256":"bf0c3b859f78f941398b68b22d2c24346cbeecc421a37fa3dc3b932eb608dcbd"},"downloads":-1,"filename":"tokenizer-adapter-0.1.2.tar.gz","has_sig":false,"md5_digest":"3578d6cafa4c71c6038cb8a8876606a4","packagetype":"sdist","python_version":"source","requires_python":">=3.8","size":8862,"upload_time":"2024-01-17T13:59:52","upload_time_iso_8601":"2024-01-17T13:59:52.999778Z","url":"https://files.pythonhosted.org/packages/e8/c2/a92888effcc9bf63a38c6d8912647616519209a35a2ee4d9eabb50aa1035/tokenizer-adapter-0.1.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}