{"0.2.18":{"info":{"author":"Urdu NLTK","author_email":"urdu-nltk@uts.rf.gd","bugtrack_url":null,"classifiers":["Development Status :: 3 - Alpha","Intended Audience :: Developers","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"tokenization, text-processing, nlp, transformers","license":null,"maintainer":null,"maintainer_email":null,"name":"tokenize-text","package_url":"https://pypi.org/project/tokenize-text/","platform":null,"project_url":"https://pypi.org/project/tokenize-text/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/tokenize-text/0.2.18/","requires_dist":["transformers","textblob","requests","json5"],"requires_python":">=3.6","summary":"Tokenizing and processing text inputs with transformer models","version":"0.2.18","yanked":true,"yanked_reason":null},"last_serial":24526984,"urls":[{"comment_text":"","digests":{"blake2b_256":"3cc19b7eb2423ac7a0032627c830f66e3cc4b03b020bbeced8c658c8ccd07692","md5":"5b27ea476f0ccfc48f7c994073316dc5","sha256":"ba6e7f388116ab991f8e1808badf10a6cc7f0e4744ee7e15c180fd586976bcc3"},"downloads":-1,"filename":"tokenize_text-0.2.18-py3-none-any.whl","has_sig":false,"md5_digest":"5b27ea476f0ccfc48f7c994073316dc5","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":3428,"upload_time":"2024-08-02T10:49:22","upload_time_iso_8601":"2024-08-02T10:49:22.115748Z","url":"https://files.pythonhosted.org/packages/3c/c1/9b7eb2423ac7a0032627c830f66e3cc4b03b020bbeced8c658c8ccd07692/tokenize_text-0.2.18-py3-none-any.whl","yanked":true,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"67db42dd20bef8ef098834bfec6f4efb664a28d8771be06cc6130ad5ebb4206e","md5":"a51bc0e784b32990fb647f9e44f853ed","sha256":"74fa7cb66c54840815b830ec1750df6846822b2c8ac38e2fbd47759a01bde180"},"downloads":-1,"filename":"tokenize_text-0.2.18.tar.gz","has_sig":false,"md5_digest":"a51bc0e784b32990fb647f9e44f853ed","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":4070,"upload_time":"2024-08-02T10:49:23","upload_time_iso_8601":"2024-08-02T10:49:23.385452Z","url":"https://files.pythonhosted.org/packages/67/db/42dd20bef8ef098834bfec6f4efb664a28d8771be06cc6130ad5ebb4206e/tokenize_text-0.2.18.tar.gz","yanked":true,"yanked_reason":null}],"vulnerabilities":[]},"0.2.29":{"info":{"author":"Urdu NLTK","author_email":"urdu-nltk@uts.rf.gd","bugtrack_url":null,"classifiers":["Development Status :: 3 - Alpha","Intended Audience :: Developers","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"tokenization, text-processing, nlp, transformers","license":null,"maintainer":null,"maintainer_email":null,"name":"tokenize-text","package_url":"https://pypi.org/project/tokenize-text/","platform":null,"project_url":"https://pypi.org/project/tokenize-text/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/tokenize-text/0.2.29/","requires_dist":["transformers","textblob","requests","json5"],"requires_python":">=3.6","summary":"Tokenizing and processing text inputs with transformer models","version":"0.2.29","yanked":false,"yanked_reason":null},"last_serial":24526984,"urls":[{"comment_text":"","digests":{"blake2b_256":"557a28ede5d96082aa9e7c7aaff4ad80dcc2e4702993342250a2ed0ef6ed6b8a","md5":"be99a409cd7f4f35731ec3fbf870397c","sha256":"89a014793df53480577c4ce60b4fff221231f0efc47b156476873e9ffe2a334f"},"downloads":-1,"filename":"tokenize_text-0.2.29-py3-none-any.whl","has_sig":false,"md5_digest":"be99a409cd7f4f35731ec3fbf870397c","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":94906,"upload_time":"2024-08-11T20:39:01","upload_time_iso_8601":"2024-08-11T20:39:01.481661Z","url":"https://files.pythonhosted.org/packages/55/7a/28ede5d96082aa9e7c7aaff4ad80dcc2e4702993342250a2ed0ef6ed6b8a/tokenize_text-0.2.29-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"1d69d59201e5c9eca7691cd60a3a87f61581b0e1c93bf60c7caec7c9b1869456","md5":"0b23bf6cae03c0b19dc2ade2d40e559e","sha256":"be3b8e2901845a842b4e61a9c53effd56daa4aa984935675ec5b7b4c4b19333b"},"downloads":-1,"filename":"tokenize_text-0.2.29.tar.gz","has_sig":false,"md5_digest":"0b23bf6cae03c0b19dc2ade2d40e559e","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":95952,"upload_time":"2024-08-11T20:39:02","upload_time_iso_8601":"2024-08-11T20:39:02.630873Z","url":"https://files.pythonhosted.org/packages/1d/69/d59201e5c9eca7691cd60a3a87f61581b0e1c93bf60c7caec7c9b1869456/tokenize_text-0.2.29.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.30":{"info":{"author":"Urdu NLTK","author_email":"urdu-nltk@uts.rf.gd","bugtrack_url":null,"classifiers":["Development Status :: 3 - Alpha","Intended Audience :: Developers","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"tokenization, text-processing, nlp, transformers","license":null,"maintainer":null,"maintainer_email":null,"name":"tokenize-text","package_url":"https://pypi.org/project/tokenize-text/","platform":null,"project_url":"https://pypi.org/project/tokenize-text/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/tokenize-text/0.2.30/","requires_dist":["transformers","textblob","requests","json5"],"requires_python":">=3.6","summary":"Tokenizing and processing text inputs with transformer models","version":"0.2.30","yanked":true,"yanked_reason":null},"last_serial":24526984,"urls":[{"comment_text":"","digests":{"blake2b_256":"046d77b78447f517066439972729d91de5331e9ba131ba0d6b21497b807cb5b8","md5":"5daa3e7a057afad10197f14d08a3c4fa","sha256":"a914e48690aafc36bf159dee72818e8351bbbcdb9b1a2809013eb67358be5a42"},"downloads":-1,"filename":"tokenize_text-0.2.30-py3-none-any.whl","has_sig":false,"md5_digest":"5daa3e7a057afad10197f14d08a3c4fa","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":267617,"upload_time":"2024-08-11T20:51:41","upload_time_iso_8601":"2024-08-11T20:51:41.493068Z","url":"https://files.pythonhosted.org/packages/04/6d/77b78447f517066439972729d91de5331e9ba131ba0d6b21497b807cb5b8/tokenize_text-0.2.30-py3-none-any.whl","yanked":true,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"5c36558a3e03dd0ce7628290ab2db174adcbe95b8eccb1b1409b6fdb070cb53b","md5":"df6aa6d1b63ac2a90d7255e0a98d2d81","sha256":"09c7241957c910fd2b0a0ae1b8a837e8db6f1d7103b5bfb2f859ae7f79c07ff7"},"downloads":-1,"filename":"tokenize_text-0.2.30.tar.gz","has_sig":false,"md5_digest":"df6aa6d1b63ac2a90d7255e0a98d2d81","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":268633,"upload_time":"2024-08-11T20:51:43","upload_time_iso_8601":"2024-08-11T20:51:43.520986Z","url":"https://files.pythonhosted.org/packages/5c/36/558a3e03dd0ce7628290ab2db174adcbe95b8eccb1b1409b6fdb070cb53b/tokenize_text-0.2.30.tar.gz","yanked":true,"yanked_reason":null}],"vulnerabilities":[]},"0.2.32":{"info":{"author":"Urdu NLTK","author_email":"urdu-nltk@uts.rf.gd","bugtrack_url":null,"classifiers":["Development Status :: 3 - Alpha","Intended Audience :: Developers","Operating System :: OS Independent","Programming Language :: Python :: 3"],"description_content_type":"text/markdown","docs_url":null,"download_url":null,"downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":null,"keywords":"tokenization, text-processing, nlp, transformers","license":null,"maintainer":null,"maintainer_email":null,"name":"tokenize-text","package_url":"https://pypi.org/project/tokenize-text/","platform":null,"project_url":"https://pypi.org/project/tokenize-text/","project_urls":null,"provides_extra":null,"release_url":"https://pypi.org/project/tokenize-text/0.2.32/","requires_dist":["transformers","textblob","requests","json5"],"requires_python":">=3.6","summary":"Tokenizing and processing text inputs with transformer models","version":"0.2.32","yanked":false,"yanked_reason":null},"last_serial":24526984,"urls":[{"comment_text":"","digests":{"blake2b_256":"80d93adae72518280a3420ac191af5aa04d118c0f0cd3faf66237cc479eba8f3","md5":"008c8101944f1d8ab6baf2440ca3a180","sha256":"a17a8e3a50d82830053026215c054ce1a1706796ebfb91a8d88644300ede0d9f"},"downloads":-1,"filename":"tokenize_text-0.2.32-py3-none-any.whl","has_sig":false,"md5_digest":"008c8101944f1d8ab6baf2440ca3a180","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.6","size":59431,"upload_time":"2024-08-11T21:53:23","upload_time_iso_8601":"2024-08-11T21:53:23.345006Z","url":"https://files.pythonhosted.org/packages/80/d9/3adae72518280a3420ac191af5aa04d118c0f0cd3faf66237cc479eba8f3/tokenize_text-0.2.32-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e5fbd5027fe22c54580709eb25f3b80df1978a14477b90b5f5c5b4595c841dba","md5":"fce8b788882829dc2b8978ff1aa7c6e1","sha256":"82f9e433ad76246cbcb915d9eb33c32ab201b8fe3f616b857a1aea5e71a31604"},"downloads":-1,"filename":"tokenize_text-0.2.32.tar.gz","has_sig":false,"md5_digest":"fce8b788882829dc2b8978ff1aa7c6e1","packagetype":"sdist","python_version":"source","requires_python":">=3.6","size":60445,"upload_time":"2024-08-11T21:53:24","upload_time_iso_8601":"2024-08-11T21:53:24.998551Z","url":"https://files.pythonhosted.org/packages/e5/fb/d5027fe22c54580709eb25f3b80df1978a14477b90b5f5c5b4595c841dba/tokenize_text-0.2.32.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}