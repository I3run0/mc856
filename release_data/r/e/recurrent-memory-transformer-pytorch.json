{"0.0.1":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.0.1/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.0.1","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"7b779ab897da2eed5e00b06ccd9d0c67a95186c80a5a2f03b42deb32af2009ce","md5":"d2b9078d8ba343255ea3506e822cc8d0","sha256":"c80f635baf2fa8b4f4b80ebe6893e71b5231f469e9452360d1767c39f1ddca08"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.0.1-py3-none-any.whl","has_sig":false,"md5_digest":"d2b9078d8ba343255ea3506e822cc8d0","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":5922,"upload_time":"2023-04-24T16:40:43","upload_time_iso_8601":"2023-04-24T16:40:43.464527Z","url":"https://files.pythonhosted.org/packages/7b/77/9ab897da2eed5e00b06ccd9d0c67a95186c80a5a2f03b42deb32af2009ce/recurrent_memory_transformer_pytorch-0.0.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"bfc7ad8f84300dcb0ce266fd86d7841edc4b97d53cd51300c594ee8d10dcb893","md5":"8bb932f86517875d4488829004f0dd8d","sha256":"eea7049aed2161c307410bed9175452bc84d059e2414605bad6a80cf17a36bc2"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.0.1.tar.gz","has_sig":false,"md5_digest":"8bb932f86517875d4488829004f0dd8d","packagetype":"sdist","python_version":"source","requires_python":null,"size":6031,"upload_time":"2023-04-24T16:40:45","upload_time_iso_8601":"2023-04-24T16:40:45.291294Z","url":"https://files.pythonhosted.org/packages/bf/c7/ad8f84300dcb0ce266fd86d7841edc4b97d53cd51300c594ee8d10dcb893/recurrent-memory-transformer-pytorch-0.0.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.10":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.0.10/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.0.10","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"d6a1f14b193b04e002fbbf54dc4406c3f06c36343f2079e762bbd20bf9c55116","md5":"a8b2763963768f846d478a9313f82496","sha256":"e303076b63d15802fe761b65394a6fcbb20db03b7cfaddfc7ff701f47b1899bf"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.0.10-py3-none-any.whl","has_sig":false,"md5_digest":"a8b2763963768f846d478a9313f82496","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":7379,"upload_time":"2023-04-25T01:31:13","upload_time_iso_8601":"2023-04-25T01:31:13.235967Z","url":"https://files.pythonhosted.org/packages/d6/a1/f14b193b04e002fbbf54dc4406c3f06c36343f2079e762bbd20bf9c55116/recurrent_memory_transformer_pytorch-0.0.10-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"bf23455954f8054751ebd55fa7b5abdbc44be77315678261be80a75b4fd30e7c","md5":"e1777d893fe6b18f859d1efe8f6e164d","sha256":"c66030cb6e1167dc4cad9a2a4ad815e6d2d9fac8b0734ce0f42773a76e79afbe"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.0.10.tar.gz","has_sig":false,"md5_digest":"e1777d893fe6b18f859d1efe8f6e164d","packagetype":"sdist","python_version":"source","requires_python":null,"size":7726,"upload_time":"2023-04-25T01:31:15","upload_time_iso_8601":"2023-04-25T01:31:15.805325Z","url":"https://files.pythonhosted.org/packages/bf/23/455954f8054751ebd55fa7b5abdbc44be77315678261be80a75b4fd30e7c/recurrent-memory-transformer-pytorch-0.0.10.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.11":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.0.11/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.0.11","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"b771f1221d2936bb9fc5e29adc5fa7f9bf361fe8fc69f94a99275428d61ea781","md5":"484ea3a445e8a104a251a6f07d1b1031","sha256":"406f458a9329c9cc7862bf177fa459c56e8db81d8dbbd9dd15554d5e32045802"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.0.11-py3-none-any.whl","has_sig":false,"md5_digest":"484ea3a445e8a104a251a6f07d1b1031","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":7391,"upload_time":"2023-04-25T03:58:36","upload_time_iso_8601":"2023-04-25T03:58:36.182349Z","url":"https://files.pythonhosted.org/packages/b7/71/f1221d2936bb9fc5e29adc5fa7f9bf361fe8fc69f94a99275428d61ea781/recurrent_memory_transformer_pytorch-0.0.11-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e94408a1d09884a11a8c0e4fccafcf2cfce586b8b7f853c94a4b01d90483f572","md5":"07f6b7bb93b50c0ad9c5ba9ecbf4203a","sha256":"7c75e427c8b7274f20ea0ac9153a08760b941a4957c47ff7e15b2d6bae2ff5cf"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.0.11.tar.gz","has_sig":false,"md5_digest":"07f6b7bb93b50c0ad9c5ba9ecbf4203a","packagetype":"sdist","python_version":"source","requires_python":null,"size":7750,"upload_time":"2023-04-25T03:58:38","upload_time_iso_8601":"2023-04-25T03:58:38.261515Z","url":"https://files.pythonhosted.org/packages/e9/44/08a1d09884a11a8c0e4fccafcf2cfce586b8b7f853c94a4b01d90483f572/recurrent-memory-transformer-pytorch-0.0.11.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.14":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.0.14/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.0.14","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"5d1def41f1a494829e6ed8e9289bdcf3b99d410f6b30101e840d3d48e029e4fb","md5":"90d24e2582259a30c4a1dfc9101c8851","sha256":"fbaf9fba737d076637843c9a8e5067786fafaaffdb765ec983ee8563ef0121ce"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.0.14-py3-none-any.whl","has_sig":false,"md5_digest":"90d24e2582259a30c4a1dfc9101c8851","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":7611,"upload_time":"2023-04-25T17:12:38","upload_time_iso_8601":"2023-04-25T17:12:38.482664Z","url":"https://files.pythonhosted.org/packages/5d/1d/ef41f1a494829e6ed8e9289bdcf3b99d410f6b30101e840d3d48e029e4fb/recurrent_memory_transformer_pytorch-0.0.14-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b5150b026cc5e6f5c5d50f1620cfd4736796593314f52c1ebc9a680a158852b9","md5":"a8c900c1a0925dfa25e6eaac78f65ded","sha256":"1da2b024c15b72b9dd6e67d97eea6d9316a04963d3c40bf942c131abdee84e73"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.0.14.tar.gz","has_sig":false,"md5_digest":"a8c900c1a0925dfa25e6eaac78f65ded","packagetype":"sdist","python_version":"source","requires_python":null,"size":8062,"upload_time":"2023-04-25T17:12:39","upload_time_iso_8601":"2023-04-25T17:12:39.568935Z","url":"https://files.pythonhosted.org/packages/b5/15/0b026cc5e6f5c5d50f1620cfd4736796593314f52c1ebc9a680a158852b9/recurrent-memory-transformer-pytorch-0.0.14.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.2":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.0.2/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.0.2","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"2de652bd40539980180f10f6e66c9d212ddc7f293ea12f69a85c9412afa79f2d","md5":"bfb3ec43208e5abf747e9ba22396b5f0","sha256":"a924eb37c63d774726112ca23f985459c036a2903264a3a3d8dd2e45f45e2e3c"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.0.2-py3-none-any.whl","has_sig":false,"md5_digest":"bfb3ec43208e5abf747e9ba22396b5f0","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":5998,"upload_time":"2023-04-24T17:06:20","upload_time_iso_8601":"2023-04-24T17:06:20.403855Z","url":"https://files.pythonhosted.org/packages/2d/e6/52bd40539980180f10f6e66c9d212ddc7f293ea12f69a85c9412afa79f2d/recurrent_memory_transformer_pytorch-0.0.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d7c9de0681bf84f328c267b14595ce0adef70fe2592f7ad2f113c84690ecfa61","md5":"21dc5f3dc62ad6f3f347e2109a4d1b41","sha256":"5bbfe2c47dba228894f297ec574d5dd4fb544a4b9180467c29e59243a59222fd"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.0.2.tar.gz","has_sig":false,"md5_digest":"21dc5f3dc62ad6f3f347e2109a4d1b41","packagetype":"sdist","python_version":"source","requires_python":null,"size":6135,"upload_time":"2023-04-24T17:06:22","upload_time_iso_8601":"2023-04-24T17:06:22.994368Z","url":"https://files.pythonhosted.org/packages/d7/c9/de0681bf84f328c267b14595ce0adef70fe2592f7ad2f113c84690ecfa61/recurrent-memory-transformer-pytorch-0.0.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.3":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.0.3/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.0.3","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"2973f1037afa54eb5625200c4f1c808496682124c415473763a8940d55ca31f4","md5":"3f66a538687908fded2741e686e58ab0","sha256":"d2e030f7397b2fb29ef460019593d47dbb8914793fc9d4145cf15a00909e8f3c"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.0.3-py3-none-any.whl","has_sig":false,"md5_digest":"3f66a538687908fded2741e686e58ab0","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6009,"upload_time":"2023-04-24T17:08:27","upload_time_iso_8601":"2023-04-24T17:08:27.462885Z","url":"https://files.pythonhosted.org/packages/29/73/f1037afa54eb5625200c4f1c808496682124c415473763a8940d55ca31f4/recurrent_memory_transformer_pytorch-0.0.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"bc982baae7b0374d0d624b08a462df7e64cb2f15a93929d26c2c2dd23e6dc68e","md5":"2119ef5f243eaae38701d68425f47f12","sha256":"beb17e89fe4955b9938bec2f55754a75b78236bce52a8d93307a8acc3ab9aeba"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.0.3.tar.gz","has_sig":false,"md5_digest":"2119ef5f243eaae38701d68425f47f12","packagetype":"sdist","python_version":"source","requires_python":null,"size":6165,"upload_time":"2023-04-24T17:08:29","upload_time_iso_8601":"2023-04-24T17:08:29.191473Z","url":"https://files.pythonhosted.org/packages/bc/98/2baae7b0374d0d624b08a462df7e64cb2f15a93929d26c2c2dd23e6dc68e/recurrent-memory-transformer-pytorch-0.0.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.4":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.0.4/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.0.4","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"3d3fb8b18ab7e696bdd5c008de5dc3c3347862f1cd330a76200fa6228c81d40b","md5":"812fcbc32af9194fdb6760ce1c1303ac","sha256":"2d34a08ae915050defd4bb55d485da9bd4296f4616ac0e059bf782b142a95f3c"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.0.4-py3-none-any.whl","has_sig":false,"md5_digest":"812fcbc32af9194fdb6760ce1c1303ac","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6033,"upload_time":"2023-04-24T17:15:00","upload_time_iso_8601":"2023-04-24T17:15:00.713381Z","url":"https://files.pythonhosted.org/packages/3d/3f/b8b18ab7e696bdd5c008de5dc3c3347862f1cd330a76200fa6228c81d40b/recurrent_memory_transformer_pytorch-0.0.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"832b5d2663556177012a035678ed0f714b9a0ff746b9622078d46d97dd609265","md5":"ab38ecf5890a5faa0b2379085392d827","sha256":"f94232beb7658e37e150f18381b3399e622d72ee3316aca70a91a35dc11eb7f9"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.0.4.tar.gz","has_sig":false,"md5_digest":"ab38ecf5890a5faa0b2379085392d827","packagetype":"sdist","python_version":"source","requires_python":null,"size":6177,"upload_time":"2023-04-24T17:15:02","upload_time_iso_8601":"2023-04-24T17:15:02.512383Z","url":"https://files.pythonhosted.org/packages/83/2b/5d2663556177012a035678ed0f714b9a0ff746b9622078d46d97dd609265/recurrent-memory-transformer-pytorch-0.0.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.5":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.0.5/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.0.5","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"58ec727bf366f07d1c910befadb63658a9e763e979281dcda662c8189bdeb2a3","md5":"dba605a8d593a2fefe5eae4a270072cb","sha256":"0de34341cfb84c3ee210e393a5602e7172c9ec8780b8c6d16cb51af1d6127570"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.0.5-py3-none-any.whl","has_sig":false,"md5_digest":"dba605a8d593a2fefe5eae4a270072cb","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6480,"upload_time":"2023-04-24T19:42:49","upload_time_iso_8601":"2023-04-24T19:42:49.688919Z","url":"https://files.pythonhosted.org/packages/58/ec/727bf366f07d1c910befadb63658a9e763e979281dcda662c8189bdeb2a3/recurrent_memory_transformer_pytorch-0.0.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"6f27c733daff4ca052a7b62dca895ab2c545f8ad1af019e3ab7f7f6517f1547c","md5":"f501ed199789cfa8aea5fc6786f204b6","sha256":"555a7db8dfd0f8cd76ab57a47d7a3237e273b54237a5ba44de721e31b955abb6"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.0.5.tar.gz","has_sig":false,"md5_digest":"f501ed199789cfa8aea5fc6786f204b6","packagetype":"sdist","python_version":"source","requires_python":null,"size":6833,"upload_time":"2023-04-24T19:42:51","upload_time_iso_8601":"2023-04-24T19:42:51.466459Z","url":"https://files.pythonhosted.org/packages/6f/27/c733daff4ca052a7b62dca895ab2c545f8ad1af019e3ab7f7f6517f1547c/recurrent-memory-transformer-pytorch-0.0.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.6":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.0.6/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.0.6","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"5c77c4467fe0c48f90637eb02f69c9eb5a7d57eb0986eaaefae9674ca4f5e480","md5":"0dc0c816358fa7e7e70622f5e51f1bcd","sha256":"f5d47e7861dd6c2d7eb73be33fbde918031f6655634874064f8432c53d31ed0e"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.0.6-py3-none-any.whl","has_sig":false,"md5_digest":"0dc0c816358fa7e7e70622f5e51f1bcd","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6549,"upload_time":"2023-04-24T19:56:20","upload_time_iso_8601":"2023-04-24T19:56:20.518029Z","url":"https://files.pythonhosted.org/packages/5c/77/c4467fe0c48f90637eb02f69c9eb5a7d57eb0986eaaefae9674ca4f5e480/recurrent_memory_transformer_pytorch-0.0.6-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"2a370974c6a3c49d58d6613f91f2f612b6fffda2eec057d51cedb62a477a177a","md5":"3519ce3e221d794dce4a5bda8d8f62ed","sha256":"c90b9b7c7c30bca8f95f7636c5c3a7b49d3cba81afcbaa0c73b87ca7cfd01c10"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.0.6.tar.gz","has_sig":false,"md5_digest":"3519ce3e221d794dce4a5bda8d8f62ed","packagetype":"sdist","python_version":"source","requires_python":null,"size":6918,"upload_time":"2023-04-24T19:56:22","upload_time_iso_8601":"2023-04-24T19:56:22.225952Z","url":"https://files.pythonhosted.org/packages/2a/37/0974c6a3c49d58d6613f91f2f612b6fffda2eec057d51cedb62a477a177a/recurrent-memory-transformer-pytorch-0.0.6.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.7":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.0.7/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.0.7","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"7046af5d085b732478babef43b06c353c7417f209dadf062e905c5d47986b68d","md5":"e9c21098180a9b8a8ac589ccb0b32fef","sha256":"fa9d462a0dfad96445defe11093aa6143329d06c414e5010195544536aca73bb"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.0.7-py3-none-any.whl","has_sig":false,"md5_digest":"e9c21098180a9b8a8ac589ccb0b32fef","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":6685,"upload_time":"2023-04-24T20:02:54","upload_time_iso_8601":"2023-04-24T20:02:54.231743Z","url":"https://files.pythonhosted.org/packages/70/46/af5d085b732478babef43b06c353c7417f209dadf062e905c5d47986b68d/recurrent_memory_transformer_pytorch-0.0.7-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"151f95af4cc4a5570c44c177acb2f90ac1ea01002443badb446ea0807922c221","md5":"46fe2072c159a2b598988956b80d8202","sha256":"8ed4a34800fd96d33df53c9dd94fa4ade631e774959dcd464dd497bba054a969"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.0.7.tar.gz","has_sig":false,"md5_digest":"46fe2072c159a2b598988956b80d8202","packagetype":"sdist","python_version":"source","requires_python":null,"size":7023,"upload_time":"2023-04-24T20:02:56","upload_time_iso_8601":"2023-04-24T20:02:56.326932Z","url":"https://files.pythonhosted.org/packages/15/1f/95af4cc4a5570c44c177acb2f90ac1ea01002443badb446ea0807922c221/recurrent-memory-transformer-pytorch-0.0.7.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.8":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.0.8/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.0.8","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"f8cf1a4b070e724ffdff2a958d19ce3523d3a3056bd1409ff9909307e4f3b800","md5":"a6f4261e34b6457b3764949a39091ce8","sha256":"8cbd234dec8a67ccef4579904e364a69836c2a184b3b5246775a760e0a592127"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.0.8-py3-none-any.whl","has_sig":false,"md5_digest":"a6f4261e34b6457b3764949a39091ce8","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":7130,"upload_time":"2023-04-24T20:57:25","upload_time_iso_8601":"2023-04-24T20:57:25.963987Z","url":"https://files.pythonhosted.org/packages/f8/cf/1a4b070e724ffdff2a958d19ce3523d3a3056bd1409ff9909307e4f3b800/recurrent_memory_transformer_pytorch-0.0.8-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d49668191a17f3680ddea44baca997ec80d0539f43a90031b9937426b4db0384","md5":"4d9fd839efd2893e00e7cc1a0675de04","sha256":"b2fd0885c2c1c0ff1f716829d9c4d8c55ad9efb6bc8cc1bf7806af8055041555"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.0.8.tar.gz","has_sig":false,"md5_digest":"4d9fd839efd2893e00e7cc1a0675de04","packagetype":"sdist","python_version":"source","requires_python":null,"size":7479,"upload_time":"2023-04-24T20:57:27","upload_time_iso_8601":"2023-04-24T20:57:27.234847Z","url":"https://files.pythonhosted.org/packages/d4/96/68191a17f3680ddea44baca997ec80d0539f43a90031b9937426b4db0384/recurrent-memory-transformer-pytorch-0.0.8.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.9":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.0.9/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.0.9","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"c1ef692f74c68ac5074bef81df9be9a7d281bda0d2d0fba37d8328255c8ab3ab","md5":"c389619501432ef615b40061f7e82354","sha256":"9fd1fdceef475343f191f3e40c1ff06b2619d77b9bd4902497872fb6fd7a7ee8"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.0.9-py3-none-any.whl","has_sig":false,"md5_digest":"c389619501432ef615b40061f7e82354","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":7267,"upload_time":"2023-04-24T21:25:49","upload_time_iso_8601":"2023-04-24T21:25:49.004821Z","url":"https://files.pythonhosted.org/packages/c1/ef/692f74c68ac5074bef81df9be9a7d281bda0d2d0fba37d8328255c8ab3ab/recurrent_memory_transformer_pytorch-0.0.9-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"86a60d6b264f7248d83e9b78689ae69f0baa9eea12533e53a96f557c98b9c8ae","md5":"7af54c3cab2595d64065cd61900b16fa","sha256":"96f4c64ca173ffa5f6a5f4a345ed8feb31f277690a7fb8044982a0f9d76a9610"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.0.9.tar.gz","has_sig":false,"md5_digest":"7af54c3cab2595d64065cd61900b16fa","packagetype":"sdist","python_version":"source","requires_python":null,"size":7616,"upload_time":"2023-04-24T21:25:50","upload_time_iso_8601":"2023-04-24T21:25:50.734330Z","url":"https://files.pythonhosted.org/packages/86/a6/0d6b264f7248d83e9b78689ae69f0baa9eea12533e53a96f557c98b9c8ae/recurrent-memory-transformer-pytorch-0.0.9.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.0":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.1.0/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.1.0","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"0c3781117e7059514e09819d26f57987ce451c5a0d0cab725c09429fe5ff98a1","md5":"9815ca58c3736beb6b3dd917b113808b","sha256":"73a73faf3cf6edaa669b1d40447199676d133207cd3709b4ac9a54a3a4443058"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.1.0-py3-none-any.whl","has_sig":false,"md5_digest":"9815ca58c3736beb6b3dd917b113808b","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":8196,"upload_time":"2023-04-25T19:11:18","upload_time_iso_8601":"2023-04-25T19:11:18.167792Z","url":"https://files.pythonhosted.org/packages/0c/37/81117e7059514e09819d26f57987ce451c5a0d0cab725c09429fe5ff98a1/recurrent_memory_transformer_pytorch-0.1.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"83d818ad197814132404aea1dfce41bbeed300efad3617f565fc2278d70caeff","md5":"2996bb4db8afadca55d0dedd51b7b2c6","sha256":"11792ccaedd231acc5004a88bf60e3500aabf4a94412477d5432aec3ee56fd68"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.1.0.tar.gz","has_sig":false,"md5_digest":"2996bb4db8afadca55d0dedd51b7b2c6","packagetype":"sdist","python_version":"source","requires_python":null,"size":8896,"upload_time":"2023-04-25T19:11:19","upload_time_iso_8601":"2023-04-25T19:11:19.855205Z","url":"https://files.pythonhosted.org/packages/83/d8/18ad197814132404aea1dfce41bbeed300efad3617f565fc2278d70caeff/recurrent-memory-transformer-pytorch-0.1.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.2":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.1.2/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.1.2","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"0363c2d6595b7c62a9eb19ff983b725cf88775bb0a67ab7073071fe54ec5657c","md5":"ad1f4bd5a5a78b58f92c4e32bc5d8b60","sha256":"b386cb832601017b034390c5cedb181f36c96c62c623a5ce07fca69144c91d82"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.1.2-py3-none-any.whl","has_sig":false,"md5_digest":"ad1f4bd5a5a78b58f92c4e32bc5d8b60","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":8220,"upload_time":"2023-04-25T21:15:44","upload_time_iso_8601":"2023-04-25T21:15:44.372875Z","url":"https://files.pythonhosted.org/packages/03/63/c2d6595b7c62a9eb19ff983b725cf88775bb0a67ab7073071fe54ec5657c/recurrent_memory_transformer_pytorch-0.1.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"fa3363a06ce962039ce259d3a0c448500dcb206393003cae956c3e24de2048de","md5":"ad9e1fde913f6a67b2cb9256732d4768","sha256":"18b762f772bfa57d8e8d8da4d9e038af89a5c6a8b57a21d83bc3e18bc76268e6"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.1.2.tar.gz","has_sig":false,"md5_digest":"ad9e1fde913f6a67b2cb9256732d4768","packagetype":"sdist","python_version":"source","requires_python":null,"size":9141,"upload_time":"2023-04-25T21:15:45","upload_time_iso_8601":"2023-04-25T21:15:45.444275Z","url":"https://files.pythonhosted.org/packages/fa/33/63a06ce962039ce259d3a0c448500dcb206393003cae956c3e24de2048de/recurrent-memory-transformer-pytorch-0.1.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.4":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.1.4/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.1.4","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"29c88cc88ed8c866b5d00b24c476ad246be33c089f3416e80ec82f6e5c925e99","md5":"d5f6161096521881d11cf7b87ff7b2bb","sha256":"1f42343a11428e5531fa444304e25ac6d8e6d88cf383035f12841daca9970ee8"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.1.4-py3-none-any.whl","has_sig":false,"md5_digest":"d5f6161096521881d11cf7b87ff7b2bb","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":8225,"upload_time":"2023-04-25T21:36:42","upload_time_iso_8601":"2023-04-25T21:36:42.450836Z","url":"https://files.pythonhosted.org/packages/29/c8/8cc88ed8c866b5d00b24c476ad246be33c089f3416e80ec82f6e5c925e99/recurrent_memory_transformer_pytorch-0.1.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"3564f29788bcd99deba7aa133aec8a3c6ac7991ae2ecbbb76585b4d9aaba3b18","md5":"621e1583eb58763b0217a7106526c8a5","sha256":"7641495f0666cc2be961dc47fa846852b5d41fda8daf742f2a12a6e5c812e9ab"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.1.4.tar.gz","has_sig":false,"md5_digest":"621e1583eb58763b0217a7106526c8a5","packagetype":"sdist","python_version":"source","requires_python":null,"size":9144,"upload_time":"2023-04-25T21:36:44","upload_time_iso_8601":"2023-04-25T21:36:44.139892Z","url":"https://files.pythonhosted.org/packages/35/64/f29788bcd99deba7aa133aec8a3c6ac7991ae2ecbbb76585b4d9aaba3b18/recurrent-memory-transformer-pytorch-0.1.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.5":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.1.5/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.1.5","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"3ca97922cae46d2cb42a543ed06b870419d0b6b1896e3635562d1b162b62ec1d","md5":"7fd7ea7fe287f4e36260290b78765a01","sha256":"c87481b546219b784fdc262335bf18c4f0b1fb9fe1bc0f50d100b004c03b1926"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.1.5-py3-none-any.whl","has_sig":false,"md5_digest":"7fd7ea7fe287f4e36260290b78765a01","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":8502,"upload_time":"2023-04-25T22:58:36","upload_time_iso_8601":"2023-04-25T22:58:36.264313Z","url":"https://files.pythonhosted.org/packages/3c/a9/7922cae46d2cb42a543ed06b870419d0b6b1896e3635562d1b162b62ec1d/recurrent_memory_transformer_pytorch-0.1.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"cace491c704faca774198efe8a490046562d3a06726a12110a595be04f9daedc","md5":"6b6b4fb088d949227aa07101bf056c35","sha256":"f4aae6bff24459eb8b0d9d6f2f235d3dfaffc72576fdb46b84fdee13b71dcf07"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.1.5.tar.gz","has_sig":false,"md5_digest":"6b6b4fb088d949227aa07101bf056c35","packagetype":"sdist","python_version":"source","requires_python":null,"size":9381,"upload_time":"2023-04-25T22:58:38","upload_time_iso_8601":"2023-04-25T22:58:38.786890Z","url":"https://files.pythonhosted.org/packages/ca/ce/491c704faca774198efe8a490046562d3a06726a12110a595be04f9daedc/recurrent-memory-transformer-pytorch-0.1.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.6":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.1.6/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.1.6","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"ee952cc4080c0c286868641f763c89684dadd99bb82457a7256a790529517500","md5":"a28e0f6764fd5619c022c1e7af0ed7dd","sha256":"604742666583a7bad107086c03e331996ee221fec08361145579303d505f0e25"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.1.6-py3-none-any.whl","has_sig":false,"md5_digest":"a28e0f6764fd5619c022c1e7af0ed7dd","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":8720,"upload_time":"2023-04-26T02:03:26","upload_time_iso_8601":"2023-04-26T02:03:26.606200Z","url":"https://files.pythonhosted.org/packages/ee/95/2cc4080c0c286868641f763c89684dadd99bb82457a7256a790529517500/recurrent_memory_transformer_pytorch-0.1.6-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"037f331d9b858673d5446dd1c0b38820e61f3c61e92101d25ed14e576a48a0c1","md5":"225f20efb239d4ccb8d9a6e3d4beda21","sha256":"9824480d2e6fe7c051b3453ede70e99310a9f6301e27aced1bef2641527803a4"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.1.6.tar.gz","has_sig":false,"md5_digest":"225f20efb239d4ccb8d9a6e3d4beda21","packagetype":"sdist","python_version":"source","requires_python":null,"size":9630,"upload_time":"2023-04-26T02:03:28","upload_time_iso_8601":"2023-04-26T02:03:28.038573Z","url":"https://files.pythonhosted.org/packages/03/7f/331d9b858673d5446dd1c0b38820e61f3c61e92101d25ed14e576a48a0c1/recurrent-memory-transformer-pytorch-0.1.6.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.7":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.1.7/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.1.7","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"9f2987eb131abb7ff8936774275945a021c40fb3cbcbfacfa36d8b16e215edbc","md5":"43c54fb313e284af795a455fba2701b8","sha256":"148ff7456d6770bd2b5bed287ad6809235758a2bdb308fafa250850908ca113a"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.1.7-py3-none-any.whl","has_sig":false,"md5_digest":"43c54fb313e284af795a455fba2701b8","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":8761,"upload_time":"2023-04-26T02:43:57","upload_time_iso_8601":"2023-04-26T02:43:57.514419Z","url":"https://files.pythonhosted.org/packages/9f/29/87eb131abb7ff8936774275945a021c40fb3cbcbfacfa36d8b16e215edbc/recurrent_memory_transformer_pytorch-0.1.7-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"3d9ab2e16cdb7b21ddbf61a2d997eb07d833b9cbdd4005dda2c46f27393e41fe","md5":"341473ec610b036eae011addfacd548a","sha256":"dbd065258834bcaead901e7a0f18c8b8059b2a552b59d4beb8ddfb004c9da5db"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.1.7.tar.gz","has_sig":false,"md5_digest":"341473ec610b036eae011addfacd548a","packagetype":"sdist","python_version":"source","requires_python":null,"size":9743,"upload_time":"2023-04-26T02:43:59","upload_time_iso_8601":"2023-04-26T02:43:59.193509Z","url":"https://files.pythonhosted.org/packages/3d/9a/b2e16cdb7b21ddbf61a2d997eb07d833b9cbdd4005dda2c46f27393e41fe/recurrent-memory-transformer-pytorch-0.1.7.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.8":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.1.8/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.1.8","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"7b65e11638e139246cf4bf97f0f4cde7cb9450fe01626e869f6ae8ccc3325835","md5":"cafb05f3e71e8a867088aab8aad0f2a9","sha256":"751ec48b29868480d6fb9a2c2189d3de79a1c25f752869b1e2422baa6d35ffc5"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.1.8-py3-none-any.whl","has_sig":false,"md5_digest":"cafb05f3e71e8a867088aab8aad0f2a9","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":8780,"upload_time":"2023-04-26T03:30:05","upload_time_iso_8601":"2023-04-26T03:30:05.594627Z","url":"https://files.pythonhosted.org/packages/7b/65/e11638e139246cf4bf97f0f4cde7cb9450fe01626e869f6ae8ccc3325835/recurrent_memory_transformer_pytorch-0.1.8-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"0ace429a674aa766b70089ef298a5baebd47c7d7a9b6de92b22a9ac7d1c2cd2e","md5":"0c74171f5cc09a9cb65c6eb1ef280cb9","sha256":"bd554c06c3a5aca4b13912cef448c962bb5ea0fd4c97c7c35342b6f4e8cb577e"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.1.8.tar.gz","has_sig":false,"md5_digest":"0c74171f5cc09a9cb65c6eb1ef280cb9","packagetype":"sdist","python_version":"source","requires_python":null,"size":9760,"upload_time":"2023-04-26T03:30:08","upload_time_iso_8601":"2023-04-26T03:30:08.008365Z","url":"https://files.pythonhosted.org/packages/0a/ce/429a674aa766b70089ef298a5baebd47c7d7a9b6de92b22a9ac7d1c2cd2e/recurrent-memory-transformer-pytorch-0.1.8.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.9":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.1.9/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.1.9","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"e6f9d906693f89e3a0dc4686adf21e1aa66970cf5772dd2586496ddb55a3a7fd","md5":"d784c6aacbeff1f01239757c1d43414d","sha256":"b7247812abaa4412d7a1af25fac4ad94e709ba96da3155afe26b42b5c502d15f"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.1.9-py3-none-any.whl","has_sig":false,"md5_digest":"d784c6aacbeff1f01239757c1d43414d","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":8912,"upload_time":"2023-04-26T13:37:26","upload_time_iso_8601":"2023-04-26T13:37:26.706167Z","url":"https://files.pythonhosted.org/packages/e6/f9/d906693f89e3a0dc4686adf21e1aa66970cf5772dd2586496ddb55a3a7fd/recurrent_memory_transformer_pytorch-0.1.9-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"90dc100ce5ae2d7e9a033940b722783fa67387cf504f972b7a69ca893ed7c22d","md5":"c7f244a67e1c3eaabb0eca23a43d32af","sha256":"c5a581189ebe99b03c5ef01a61311766bedd84d7b69a937444abb683c03456b7"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.1.9.tar.gz","has_sig":false,"md5_digest":"c7f244a67e1c3eaabb0eca23a43d32af","packagetype":"sdist","python_version":"source","requires_python":null,"size":10014,"upload_time":"2023-04-26T13:37:28","upload_time_iso_8601":"2023-04-26T13:37:28.439983Z","url":"https://files.pythonhosted.org/packages/90/dc/100ce5ae2d7e9a033940b722783fa67387cf504f972b7a69ca893ed7c22d/recurrent-memory-transformer-pytorch-0.1.9.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.0":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.2.0/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.2.0","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"87233e97a0bfd83734f3183d6d4136cc7ab302923eabe443aa5bb71cfaf203d2","md5":"33f4ae75d2da4e8e4c4e7e178d3c9384","sha256":"4ccd6a8c09600563a9edaf4d6cbbb12fa1942f08a0750408cf2bf35f9adf32bb"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.2.0-py3-none-any.whl","has_sig":false,"md5_digest":"33f4ae75d2da4e8e4c4e7e178d3c9384","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":9273,"upload_time":"2023-04-26T14:26:13","upload_time_iso_8601":"2023-04-26T14:26:13.052995Z","url":"https://files.pythonhosted.org/packages/87/23/3e97a0bfd83734f3183d6d4136cc7ab302923eabe443aa5bb71cfaf203d2/recurrent_memory_transformer_pytorch-0.2.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7e6e0345cfa66ad77f95a55ad449f606c87de2e14772392df611fce659200d43","md5":"a7674dd22a79bca9b3b77d51eef7a6ea","sha256":"a7e69dbc425c4e856a0b59a9a347c29d433531c0b604925e89c3b639de04a1f5"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.2.0.tar.gz","has_sig":false,"md5_digest":"a7674dd22a79bca9b3b77d51eef7a6ea","packagetype":"sdist","python_version":"source","requires_python":null,"size":10687,"upload_time":"2023-04-26T14:26:15","upload_time_iso_8601":"2023-04-26T14:26:15.677919Z","url":"https://files.pythonhosted.org/packages/7e/6e/0345cfa66ad77f95a55ad449f606c87de2e14772392df611fce659200d43/recurrent-memory-transformer-pytorch-0.2.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.1":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.2.1/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.2.1","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"2c2060d51ab92d9812f3662859158397c87a21b149d715a98120231e8c974a87","md5":"f710216ff352767a05f315c1299e33b8","sha256":"c20b3b44840d6cd5ed810467325c730a546fc05ea8add368b77559a6ed5f449a"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.2.1-py3-none-any.whl","has_sig":false,"md5_digest":"f710216ff352767a05f315c1299e33b8","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":9438,"upload_time":"2023-04-26T14:32:46","upload_time_iso_8601":"2023-04-26T14:32:46.419758Z","url":"https://files.pythonhosted.org/packages/2c/20/60d51ab92d9812f3662859158397c87a21b149d715a98120231e8c974a87/recurrent_memory_transformer_pytorch-0.2.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"0e7949f945853e3a5e977af4f9088cf48368c4dfc2579285f8c910f60f1b2e43","md5":"d63ec134da09703be8ca07cbe8a8cb7a","sha256":"833cfc2b1cede20bafbec6cec264378b09c3de71598fb5de1f769265e8639f33"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.2.1.tar.gz","has_sig":false,"md5_digest":"d63ec134da09703be8ca07cbe8a8cb7a","packagetype":"sdist","python_version":"source","requires_python":null,"size":11027,"upload_time":"2023-04-26T14:32:48","upload_time_iso_8601":"2023-04-26T14:32:48.676933Z","url":"https://files.pythonhosted.org/packages/0e/79/49f945853e3a5e977af4f9088cf48368c4dfc2579285f8c910f60f1b2e43/recurrent-memory-transformer-pytorch-0.2.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.2":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.2.2/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.2.2","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"7469220e821a498cd4764ba8f3b432ffbc81482bca6f8be9302e40d0722bccf7","md5":"4e5b765a833d13a5af1fe48bf540dd94","sha256":"8af8e2e0e59b6899c02edca25bef8beb0f18abfc419b933198d2aba8654ca700"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.2.2-py3-none-any.whl","has_sig":false,"md5_digest":"4e5b765a833d13a5af1fe48bf540dd94","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":9443,"upload_time":"2023-04-26T14:46:05","upload_time_iso_8601":"2023-04-26T14:46:05.016743Z","url":"https://files.pythonhosted.org/packages/74/69/220e821a498cd4764ba8f3b432ffbc81482bca6f8be9302e40d0722bccf7/recurrent_memory_transformer_pytorch-0.2.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"79d12bd8f82d92734839dfe049219ff9c308729c5d72e0bacb1b8c3c06243cec","md5":"5389acabb9228b7b5394f61213423dae","sha256":"eae38242f664bc2241187b1fb4eff972cca950b88d2200e35f8aa7e2c987621b"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.2.2.tar.gz","has_sig":false,"md5_digest":"5389acabb9228b7b5394f61213423dae","packagetype":"sdist","python_version":"source","requires_python":null,"size":11076,"upload_time":"2023-04-26T14:46:06","upload_time_iso_8601":"2023-04-26T14:46:06.383458Z","url":"https://files.pythonhosted.org/packages/79/d1/2bd8f82d92734839dfe049219ff9c308729c5d72e0bacb1b8c3c06243cec/recurrent-memory-transformer-pytorch-0.2.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.3":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.2.3/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.2.3","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"1ae771951ab81ef91633681176e7df753813c706d950c72848b8f713f2e602bc","md5":"1f675150fcb0851b957aaf7a56998f73","sha256":"167133f8e2354e8ebcd5db40700bf9c09a5a8cca80832aba3c187c30c60019b3"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.2.3-py3-none-any.whl","has_sig":false,"md5_digest":"1f675150fcb0851b957aaf7a56998f73","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":9665,"upload_time":"2023-05-03T14:42:44","upload_time_iso_8601":"2023-05-03T14:42:44.421068Z","url":"https://files.pythonhosted.org/packages/1a/e7/71951ab81ef91633681176e7df753813c706d950c72848b8f713f2e602bc/recurrent_memory_transformer_pytorch-0.2.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"edca9af48e36fc99422d44ab76975e2300ffe72469987867f8b72484986aa9fc","md5":"60a6285afe2fde6f12709020c1bd375f","sha256":"241eab14d8b2fc997aa54c8cfd98274591b4d18745970d55b9df09499acad788"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.2.3.tar.gz","has_sig":false,"md5_digest":"60a6285afe2fde6f12709020c1bd375f","packagetype":"sdist","python_version":"source","requires_python":null,"size":11611,"upload_time":"2023-05-03T14:42:46","upload_time_iso_8601":"2023-05-03T14:42:46.131947Z","url":"https://files.pythonhosted.org/packages/ed/ca/9af48e36fc99422d44ab76975e2300ffe72469987867f8b72484986aa9fc/recurrent-memory-transformer-pytorch-0.2.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.4":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.2.4/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.2.4","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"d2bc428c8a223b7c8f0050d6be88ac6df07f622fef58903a5d541cdaa0f3c173","md5":"0ddedfacfc6909f8c5eab4f712048cb5","sha256":"13f1e5450a81d3ca47fda1af793d25d754cf5a507b01cc48b88793a21b4477d5"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.2.4-py3-none-any.whl","has_sig":false,"md5_digest":"0ddedfacfc6909f8c5eab4f712048cb5","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":9665,"upload_time":"2023-05-03T15:57:13","upload_time_iso_8601":"2023-05-03T15:57:13.205780Z","url":"https://files.pythonhosted.org/packages/d2/bc/428c8a223b7c8f0050d6be88ac6df07f622fef58903a5d541cdaa0f3c173/recurrent_memory_transformer_pytorch-0.2.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"4e08e3b769636275e02e88a07e0ed9e134e18dd60aa6d7221ef993173a1811a9","md5":"f4af775fae5f0733f400419678a938fe","sha256":"a4af71e70082b9a4ed8d89c498487c4b798d636ca8b39a8894539e409472411b"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.2.4.tar.gz","has_sig":false,"md5_digest":"f4af775fae5f0733f400419678a938fe","packagetype":"sdist","python_version":"source","requires_python":null,"size":11636,"upload_time":"2023-05-03T15:57:14","upload_time_iso_8601":"2023-05-03T15:57:14.769031Z","url":"https://files.pythonhosted.org/packages/4e/08/e3b769636275e02e88a07e0ed9e134e18dd60aa6d7221ef993173a1811a9/recurrent-memory-transformer-pytorch-0.2.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.5":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.2.5/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.2.5","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"e4c990c59000f622b4eb0f6226bfb830c539b1e674e97ddf2c02de4b20c660b0","md5":"e58ea2363f51365209dd10996a43c4e8","sha256":"ddcfca6be0d9a85b8876506bd00801a52926ac5fe265161811d6b2ef7bd55ffa"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.2.5-py3-none-any.whl","has_sig":false,"md5_digest":"e58ea2363f51365209dd10996a43c4e8","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":9711,"upload_time":"2023-05-03T17:15:58","upload_time_iso_8601":"2023-05-03T17:15:58.155548Z","url":"https://files.pythonhosted.org/packages/e4/c9/90c59000f622b4eb0f6226bfb830c539b1e674e97ddf2c02de4b20c660b0/recurrent_memory_transformer_pytorch-0.2.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"9ab5f2b5be9d7b85891352392387699296fb798c5d6f3b142b122bf6907ff2a4","md5":"c6836ef9519b26a9c9cc6879c070fc18","sha256":"ade6925e0ea6c2b4559a6b9a9520ac25dea6cfb2e782560e54ba0d88511732c7"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.2.5.tar.gz","has_sig":false,"md5_digest":"c6836ef9519b26a9c9cc6879c070fc18","packagetype":"sdist","python_version":"source","requires_python":null,"size":11664,"upload_time":"2023-05-03T17:15:59","upload_time_iso_8601":"2023-05-03T17:15:59.501338Z","url":"https://files.pythonhosted.org/packages/9a/b5/f2b5be9d7b85891352392387699296fb798c5d6f3b142b122bf6907ff2a4/recurrent-memory-transformer-pytorch-0.2.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.0":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.3.0/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.3.0","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"1266d5370444c7557c5611dbb36673b05971ea4973c4e52cfd33f48556899ff7","md5":"95027e59aac0f9455c0df10fe388f6d1","sha256":"70339cf3078fefdef7910fc344473d04fcabdec462a5196c9a32a6fb070c98e0"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.3.0-py3-none-any.whl","has_sig":false,"md5_digest":"95027e59aac0f9455c0df10fe388f6d1","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":9946,"upload_time":"2023-05-03T18:17:20","upload_time_iso_8601":"2023-05-03T18:17:20.413570Z","url":"https://files.pythonhosted.org/packages/12/66/d5370444c7557c5611dbb36673b05971ea4973c4e52cfd33f48556899ff7/recurrent_memory_transformer_pytorch-0.3.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"2e4ee1d2e7f7f7eba1b774dfb1d306250b5ed5ef139bce6cf43053f34c05daef","md5":"f505b242278c44e696ed921a10464762","sha256":"63859f487d3b743bed5a2a6c6254a0dfba62ccc4f8fea745b1131e2e3e818e87"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.3.0.tar.gz","has_sig":false,"md5_digest":"f505b242278c44e696ed921a10464762","packagetype":"sdist","python_version":"source","requires_python":null,"size":11912,"upload_time":"2023-05-03T18:17:21","upload_time_iso_8601":"2023-05-03T18:17:21.920696Z","url":"https://files.pythonhosted.org/packages/2e/4e/e1d2e7f7f7eba1b774dfb1d306250b5ed5ef139bce6cf43053f34c05daef/recurrent-memory-transformer-pytorch-0.3.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.1":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.3.1/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.3.1","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"3b54c54d3eeffbf894c6a48c6be0359c27f99dff39f870dd8f12e91b98a493a8","md5":"48dde12952312e9dba55071cb3e1b0b6","sha256":"f4e3b484d808b080e2ca7c442aab44af5fc7c35ef94e3b28fe2d1b14ff477679"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.3.1-py3-none-any.whl","has_sig":false,"md5_digest":"48dde12952312e9dba55071cb3e1b0b6","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":9952,"upload_time":"2023-05-03T20:06:11","upload_time_iso_8601":"2023-05-03T20:06:11.011579Z","url":"https://files.pythonhosted.org/packages/3b/54/c54d3eeffbf894c6a48c6be0359c27f99dff39f870dd8f12e91b98a493a8/recurrent_memory_transformer_pytorch-0.3.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b0e28e40a5b2642a49f4632942f13f794393176cb4b02894613e46fc2fdd3e8b","md5":"f77fa05b2506cd795e38184c88e2bcc4","sha256":"9709694d0b78bedab5f9a959cb38b09aa071fe9d0cffb48d6154edbbd69e5517"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.3.1.tar.gz","has_sig":false,"md5_digest":"f77fa05b2506cd795e38184c88e2bcc4","packagetype":"sdist","python_version":"source","requires_python":null,"size":11920,"upload_time":"2023-05-03T20:06:12","upload_time_iso_8601":"2023-05-03T20:06:12.634458Z","url":"https://files.pythonhosted.org/packages/b0/e2/8e40a5b2642a49f4632942f13f794393176cb4b02894613e46fc2fdd3e8b/recurrent-memory-transformer-pytorch-0.3.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.3.2":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.3.2/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.3.2","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"045addc93bb7f9d1e0632702b29c205f802c82541dac7111fdf85682f453b91d","md5":"98e96a497e5a3637069d16a3c36bf555","sha256":"6aaa097521f56a02a0979916139fb2442497700b6ba1311c941ad132079149fb"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.3.2-py3-none-any.whl","has_sig":false,"md5_digest":"98e96a497e5a3637069d16a3c36bf555","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":9953,"upload_time":"2023-05-03T20:09:20","upload_time_iso_8601":"2023-05-03T20:09:20.978993Z","url":"https://files.pythonhosted.org/packages/04/5a/ddc93bb7f9d1e0632702b29c205f802c82541dac7111fdf85682f453b91d/recurrent_memory_transformer_pytorch-0.3.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"0d8ab15081b6a89a3563892f434b6ebd78c95d641ae246651483d863fc4c7c25","md5":"ee5ab46ec890808f9db8ac854e8666e4","sha256":"94bdb85e90003b9e9eb629d4595a623b0b60aa7f520c4b1eddf7b305d74edf4c"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.3.2.tar.gz","has_sig":false,"md5_digest":"ee5ab46ec890808f9db8ac854e8666e4","packagetype":"sdist","python_version":"source","requires_python":null,"size":11936,"upload_time":"2023-05-03T20:09:22","upload_time_iso_8601":"2023-05-03T20:09:22.724078Z","url":"https://files.pythonhosted.org/packages/0d/8a/b15081b6a89a3563892f434b6ebd78c95d641ae246651483d863fc4c7c25/recurrent-memory-transformer-pytorch-0.3.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.0":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.4.0/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.4.0","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"332c784e7182459d40391bd3df90876de75455e8193529661f86e5bb85434dcd","md5":"c2d65d442b51e47d889a84109a0edccd","sha256":"932bbb6fbc114b8c92e40ad27784f2772040c9417e74ffac07f471621a73242a"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.4.0-py3-none-any.whl","has_sig":false,"md5_digest":"c2d65d442b51e47d889a84109a0edccd","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":9971,"upload_time":"2023-05-25T22:35:45","upload_time_iso_8601":"2023-05-25T22:35:45.259167Z","url":"https://files.pythonhosted.org/packages/33/2c/784e7182459d40391bd3df90876de75455e8193529661f86e5bb85434dcd/recurrent_memory_transformer_pytorch-0.4.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"ed2f76e17c0499ff4f4cedc735ff4918220694f000e25bcb3e3cacad1d86f252","md5":"2a5e0d675253942b620219eaea295019","sha256":"791c61eb7581b6e30e4cbb14dfd7d4d6f65832c5ebdde4263d74e5dd674f84ec"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.4.0.tar.gz","has_sig":false,"md5_digest":"2a5e0d675253942b620219eaea295019","packagetype":"sdist","python_version":"source","requires_python":null,"size":12048,"upload_time":"2023-05-25T22:35:53","upload_time_iso_8601":"2023-05-25T22:35:53.139215Z","url":"https://files.pythonhosted.org/packages/ed/2f/76e17c0499ff4f4cedc735ff4918220694f000e25bcb3e3cacad1d86f252/recurrent-memory-transformer-pytorch-0.4.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.1":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.4.1/","requires_dist":["einops (>=0.6.1)","torch (>=1.6)"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.4.1","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"2baa3774b7490a65e3c8e8b2097876eafbe1078d6aa3a63e42cdbfe4e4fe6fe3","md5":"5fca9b90545f1c81876fbf211a32230b","sha256":"31f6b8dd3688d38df1bc2dfc9f99e5f595d948310c0842be1904bf49f5c5dd39"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.4.1-py3-none-any.whl","has_sig":false,"md5_digest":"5fca9b90545f1c81876fbf211a32230b","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":10081,"upload_time":"2023-05-27T01:18:40","upload_time_iso_8601":"2023-05-27T01:18:40.627274Z","url":"https://files.pythonhosted.org/packages/2b/aa/3774b7490a65e3c8e8b2097876eafbe1078d6aa3a63e42cdbfe4e4fe6fe3/recurrent_memory_transformer_pytorch-0.4.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"9eceb89049b97029ca5634a61ed0c5ca27f32611c8216f2bdeed98cc067c3706","md5":"1b7c1af5c112dae0989cfbdd2c1a2fa8","sha256":"3014efaf3b907fc27b248b1cb9db9ded22e83f8aaf79fd10498a2b7a3c26eda0"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.4.1.tar.gz","has_sig":false,"md5_digest":"1b7c1af5c112dae0989cfbdd2c1a2fa8","packagetype":"sdist","python_version":"source","requires_python":null,"size":12166,"upload_time":"2023-05-27T01:18:43","upload_time_iso_8601":"2023-05-27T01:18:43.062882Z","url":"https://files.pythonhosted.org/packages/9e/ce/b89049b97029ca5634a61ed0c5ca27f32611c8216f2bdeed98cc067c3706/recurrent-memory-transformer-pytorch-0.4.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.2":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.4.2/","requires_dist":["einops >=0.6.1","torch >=1.6"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.4.2","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"52b16134fadf9af59197f3dcc816e3e74f7fcc148a101ee1571b4f80c6eed9bc","md5":"2e605f52c77dca1e516ca3252d5da7b7","sha256":"924ce9ab75a94ac2e8a2e502a6d9c867f54ee5f6a420421798ee3987d44e7371"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.4.2-py3-none-any.whl","has_sig":false,"md5_digest":"2e605f52c77dca1e516ca3252d5da7b7","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":10080,"upload_time":"2023-08-08T15:56:20","upload_time_iso_8601":"2023-08-08T15:56:20.978650Z","url":"https://files.pythonhosted.org/packages/52/b1/6134fadf9af59197f3dcc816e3e74f7fcc148a101ee1571b4f80c6eed9bc/recurrent_memory_transformer_pytorch-0.4.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"ebab850b1aa3559403009f8011ca5676aa8f515f616ddfa3a76ff7d025c637cf","md5":"1e293998e553067ed2c02fff6553bcff","sha256":"1aa84779c99963156e2f66bf071d4d159ff4420b5344dda3c02d380753dad10c"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.4.2.tar.gz","has_sig":false,"md5_digest":"1e293998e553067ed2c02fff6553bcff","packagetype":"sdist","python_version":"source","requires_python":null,"size":12181,"upload_time":"2023-08-08T15:56:21","upload_time_iso_8601":"2023-08-08T15:56:21.905326Z","url":"https://files.pythonhosted.org/packages/eb/ab/850b1aa3559403009f8011ca5676aa8f515f616ddfa3a76ff7d025c637cf/recurrent-memory-transformer-pytorch-0.4.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.4.3":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.4.3/","requires_dist":["einops >=0.6.1","torch >=1.6"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.4.3","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"3b448cb5aee03cb9e6a168c255948ccbd3d453972190cd47ae0013f081e9ca84","md5":"d61543ce2d72205e5cd9a9e7e14245c7","sha256":"982674df910100ad931ce75920ad58f8c64cfad44d2e387871ce8c918c5b634e"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.4.3-py3-none-any.whl","has_sig":false,"md5_digest":"d61543ce2d72205e5cd9a9e7e14245c7","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":10101,"upload_time":"2023-08-08T21:05:38","upload_time_iso_8601":"2023-08-08T21:05:38.189468Z","url":"https://files.pythonhosted.org/packages/3b/44/8cb5aee03cb9e6a168c255948ccbd3d453972190cd47ae0013f081e9ca84/recurrent_memory_transformer_pytorch-0.4.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"f23a96e89848969c0c99ca0c685c02ba47c542a2932a3c19fa917d8e0f753b6d","md5":"8d3d9096bda1a279a914a6d1310828ed","sha256":"1460720bb1ca366e8e48b4cdb5fca2620ad777c1ced5a7410698d168502f79b0"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.4.3.tar.gz","has_sig":false,"md5_digest":"8d3d9096bda1a279a914a6d1310828ed","packagetype":"sdist","python_version":"source","requires_python":null,"size":12208,"upload_time":"2023-08-08T21:05:39","upload_time_iso_8601":"2023-08-08T21:05:39.214290Z","url":"https://files.pythonhosted.org/packages/f2/3a/96e89848969c0c99ca0c685c02ba47c542a2932a3c19fa917d8e0f753b6d/recurrent-memory-transformer-pytorch-0.4.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.0":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.5.0/","requires_dist":["einops >=0.6.1","torch >=1.6"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.5.0","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"cb8a67cb561dc2988c535cab640c5715a4d4d5397306feb4d2d5fa5df80499f5","md5":"01906faf3d6fe48b75c0d86cc5d697a0","sha256":"f56757d47be69258f93caec893b373afcdf4135ed3ebe1deef870bf20cb4c0d0"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.5.0-py3-none-any.whl","has_sig":false,"md5_digest":"01906faf3d6fe48b75c0d86cc5d697a0","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":10293,"upload_time":"2023-08-09T14:19:56","upload_time_iso_8601":"2023-08-09T14:19:56.243745Z","url":"https://files.pythonhosted.org/packages/cb/8a/67cb561dc2988c535cab640c5715a4d4d5397306feb4d2d5fa5df80499f5/recurrent_memory_transformer_pytorch-0.5.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"ebd4a6e68a10902d72f616e20035a23b55a9724ec164eff5cdee07c8a56249d2","md5":"3f83b8e15cf8becb387ee3afb0692b38","sha256":"9027062c3a097d4de53b2d1a4c22045fd64780de8ed75f5858622e2d0e4bb6a8"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.5.0.tar.gz","has_sig":false,"md5_digest":"3f83b8e15cf8becb387ee3afb0692b38","packagetype":"sdist","python_version":"source","requires_python":null,"size":12423,"upload_time":"2023-08-09T14:19:57","upload_time_iso_8601":"2023-08-09T14:19:57.198197Z","url":"https://files.pythonhosted.org/packages/eb/d4/a6e68a10902d72f616e20035a23b55a9724ec164eff5cdee07c8a56249d2/recurrent-memory-transformer-pytorch-0.5.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.1":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.5.1/","requires_dist":["einops >=0.6.1","torch >=1.6"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.5.1","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"297757346aab1e53a366db8a75c317e9aee702ccaa461f7f7607cfe734e27325","md5":"9fbb0088ee018b4e3338351ae8380a85","sha256":"1dc96c60f8ec1385de439fa9159d2cfec26b1061e5fdaa73ac11a4883da615e0"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.5.1-py3-none-any.whl","has_sig":false,"md5_digest":"9fbb0088ee018b4e3338351ae8380a85","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":10423,"upload_time":"2023-08-29T16:27:34","upload_time_iso_8601":"2023-08-29T16:27:34.148823Z","url":"https://files.pythonhosted.org/packages/29/77/57346aab1e53a366db8a75c317e9aee702ccaa461f7f7607cfe734e27325/recurrent_memory_transformer_pytorch-0.5.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"25bc815d03759b1f9a3df94321f4d6a15b9640ee2591ee336314e220a2faeb94","md5":"49333d1463f3ee19c47f8efba5038f1a","sha256":"d8d963e68807684e2d18d2be9b1abb1336c3caa353028ddd0032f99bd041971f"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.5.1.tar.gz","has_sig":false,"md5_digest":"49333d1463f3ee19c47f8efba5038f1a","packagetype":"sdist","python_version":"source","requires_python":null,"size":12597,"upload_time":"2023-08-29T16:27:35","upload_time_iso_8601":"2023-08-29T16:27:35.513586Z","url":"https://files.pythonhosted.org/packages/25/bc/815d03759b1f9a3df94321f4d6a15b9640ee2591ee336314e220a2faeb94/recurrent-memory-transformer-pytorch-0.5.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.2":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.5.2/","requires_dist":["einops >=0.6.1","torch >=1.6"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.5.2","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"a24aa19e5855d650122ff16c94dec0ea75e56a0333a2c2c4e22c5f6988198602","md5":"c16f037652eb0e7d847e7dbef993812f","sha256":"b8e26e963f5bc46d255cddfc2f4f5e8d92a619b1c3203b98652f52746f41290c"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.5.2-py3-none-any.whl","has_sig":false,"md5_digest":"c16f037652eb0e7d847e7dbef993812f","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":10427,"upload_time":"2023-08-29T16:31:12","upload_time_iso_8601":"2023-08-29T16:31:12.694369Z","url":"https://files.pythonhosted.org/packages/a2/4a/a19e5855d650122ff16c94dec0ea75e56a0333a2c2c4e22c5f6988198602/recurrent_memory_transformer_pytorch-0.5.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"1d6e68d81ad7027dc2f6eaf7a9a436faa3f36de4a98ee2cc759c6072ba3d86e8","md5":"e245419c3836afa6410a754804f2e3d0","sha256":"2b5afe1092b73bd399baee91d6399f790f912cb7e39dd0223da2fd568f450b44"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.5.2.tar.gz","has_sig":false,"md5_digest":"e245419c3836afa6410a754804f2e3d0","packagetype":"sdist","python_version":"source","requires_python":null,"size":12552,"upload_time":"2023-08-29T16:31:14","upload_time_iso_8601":"2023-08-29T16:31:14.025059Z","url":"https://files.pythonhosted.org/packages/1d/6e/68d81ad7027dc2f6eaf7a9a436faa3f36de4a98ee2cc759c6072ba3d86e8/recurrent-memory-transformer-pytorch-0.5.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.3":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.5.3/","requires_dist":["einops >=0.6.1","torch >=1.6"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.5.3","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"c67d25d334271a4ccf604106b5a7a0328ff7c70b7b191b21415c8d5fbaaf4ffa","md5":"a07e713dc1cc024ff4954bd70e1e4134","sha256":"ef86eeaf1c5ac0164ab9b5cb1d7688d35bdff1b871a84c21580d8e3be1686a31"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.5.3-py3-none-any.whl","has_sig":false,"md5_digest":"a07e713dc1cc024ff4954bd70e1e4134","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":10487,"upload_time":"2023-08-29T16:51:10","upload_time_iso_8601":"2023-08-29T16:51:10.505422Z","url":"https://files.pythonhosted.org/packages/c6/7d/25d334271a4ccf604106b5a7a0328ff7c70b7b191b21415c8d5fbaaf4ffa/recurrent_memory_transformer_pytorch-0.5.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b62769ccb09443dd8641b5fd08149613642f928062e0e9a0ab1b14089a5f301e","md5":"4435558e54e6dce23b5a545a84487657","sha256":"09aaf05dcbcdf9c6bf8ad7b633a6e97dcdb7e2a5a14c48b595dcda5f9d6b60a1"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.5.3.tar.gz","has_sig":false,"md5_digest":"4435558e54e6dce23b5a545a84487657","packagetype":"sdist","python_version":"source","requires_python":null,"size":12657,"upload_time":"2023-08-29T16:51:11","upload_time_iso_8601":"2023-08-29T16:51:11.757971Z","url":"https://files.pythonhosted.org/packages/b6/27/69ccb09443dd8641b5fd08149613642f928062e0e9a0ab1b14089a5f301e/recurrent-memory-transformer-pytorch-0.5.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.4":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.5.4/","requires_dist":["einops >=0.6.1","torch >=1.6"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.5.4","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"5009feaa70bb9181e75dc2d438e30dab1852e69b7058a4dacb3625f8b021b254","md5":"adf3d808c7e89415f46b59934194098c","sha256":"10fe8fac5e783e77009b6e468d70e7b22e6c9807958e7e8f5b8ecee3e9b5e30f"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.5.4-py3-none-any.whl","has_sig":false,"md5_digest":"adf3d808c7e89415f46b59934194098c","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":10608,"upload_time":"2023-08-31T19:40:28","upload_time_iso_8601":"2023-08-31T19:40:28.670909Z","url":"https://files.pythonhosted.org/packages/50/09/feaa70bb9181e75dc2d438e30dab1852e69b7058a4dacb3625f8b021b254/recurrent_memory_transformer_pytorch-0.5.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b0af3464b930cea7ee7e2130ca883251776fe9fc6d50b5cf112a83e516d4da5d","md5":"cf78c55480f40c34e57321abb341cfd4","sha256":"ace392f9c94439f895692e43d9b97ab46205ea54d7d648d2602c50c6903aed9b"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.5.4.tar.gz","has_sig":false,"md5_digest":"cf78c55480f40c34e57321abb341cfd4","packagetype":"sdist","python_version":"source","requires_python":null,"size":12771,"upload_time":"2023-08-31T19:40:29","upload_time_iso_8601":"2023-08-31T19:40:29.711630Z","url":"https://files.pythonhosted.org/packages/b0/af/3464b930cea7ee7e2130ca883251776fe9fc6d50b5cf112a83e516d4da5d/recurrent-memory-transformer-pytorch-0.5.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.5":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.5.5/","requires_dist":["einops >=0.6.1","torch >=1.6"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.5.5","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"74ff62e34e6458c22e06c2c0efc51674d6a4cd60152960d20d92c04b15c0a8e8","md5":"f9a8d0cb8928bed27469b2adb7509b52","sha256":"9444c6ad23c633d3f56d687108dfc6141aff478908595a713d1ae2a20a4bbdf8"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.5.5-py3-none-any.whl","has_sig":false,"md5_digest":"f9a8d0cb8928bed27469b2adb7509b52","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":10765,"upload_time":"2023-08-31T21:15:34","upload_time_iso_8601":"2023-08-31T21:15:34.344398Z","url":"https://files.pythonhosted.org/packages/74/ff/62e34e6458c22e06c2c0efc51674d6a4cd60152960d20d92c04b15c0a8e8/recurrent_memory_transformer_pytorch-0.5.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"5bed2cf7b8260a6328b98f8f6cd4833f50e31978fc5d494f1b82036c0ff697ad","md5":"800d61261ec2ba6ad12551431e12e872","sha256":"dd8960e53aac13d2d6bf2e15d8447a4a2efa782a7a38a9cbca35a7d9e7344411"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.5.5.tar.gz","has_sig":false,"md5_digest":"800d61261ec2ba6ad12551431e12e872","packagetype":"sdist","python_version":"source","requires_python":null,"size":12927,"upload_time":"2023-08-31T21:15:35","upload_time_iso_8601":"2023-08-31T21:15:35.819940Z","url":"https://files.pythonhosted.org/packages/5b/ed/2cf7b8260a6328b98f8f6cd4833f50e31978fc5d494f1b82036c0ff697ad/recurrent-memory-transformer-pytorch-0.5.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.5.6":{"info":{"author":"Phil Wang","author_email":"lucidrains@gmail.com","bugtrack_url":null,"classifiers":["Development Status :: 4 - Beta","Intended Audience :: Developers","License :: OSI Approved :: MIT License","Programming Language :: Python :: 3.6","Topic :: Scientific/Engineering :: Artificial Intelligence"],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch","keywords":"artificial intelligence,deep learning,transformers,attention mechanism,recurrence,memory,long-context","license":"MIT","maintainer":"","maintainer_email":"","name":"recurrent-memory-transformer-pytorch","package_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","platform":null,"project_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/","project_urls":{"Homepage":"https://github.com/lucidrains/recurrent-memory-transformer-pytorch"},"provides_extra":null,"release_url":"https://pypi.org/project/recurrent-memory-transformer-pytorch/0.5.6/","requires_dist":["einops >=0.6.1","torch >=1.6"],"requires_python":"","summary":"Recurrent Memory Transformer - Pytorch","version":"0.5.6","yanked":false,"yanked_reason":null},"last_serial":21826628,"urls":[{"comment_text":"","digests":{"blake2b_256":"787ebd64a1bdf6c5927f968ec50ccf4808049eb760909c894d4089bd68415a7c","md5":"9e6d6f4fc290a62cd3a15afe89dace5d","sha256":"6d22d37c94bbdd37a30ace5967d02d4353952e64d5b2434101b831b77f45ebed"},"downloads":-1,"filename":"recurrent_memory_transformer_pytorch-0.5.6-py3-none-any.whl","has_sig":false,"md5_digest":"9e6d6f4fc290a62cd3a15afe89dace5d","packagetype":"bdist_wheel","python_version":"py3","requires_python":null,"size":10802,"upload_time":"2024-02-11T18:29:33","upload_time_iso_8601":"2024-02-11T18:29:33.449113Z","url":"https://files.pythonhosted.org/packages/78/7e/bd64a1bdf6c5927f968ec50ccf4808049eb760909c894d4089bd68415a7c/recurrent_memory_transformer_pytorch-0.5.6-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"631308778eeb56ead8f291e38481c159fdc5ff808fc1e74d64f56a2d1ba26de5","md5":"41f3eecd04f011899e28c1687cd4e3f3","sha256":"baebe9586d68746bb358f65ca20fd294ff8551b7269fbba37e6e4f72d0c558d7"},"downloads":-1,"filename":"recurrent-memory-transformer-pytorch-0.5.6.tar.gz","has_sig":false,"md5_digest":"41f3eecd04f011899e28c1687cd4e3f3","packagetype":"sdist","python_version":"source","requires_python":null,"size":13005,"upload_time":"2024-02-11T18:29:35","upload_time_iso_8601":"2024-02-11T18:29:35.161198Z","url":"https://files.pythonhosted.org/packages/63/13/08778eeb56ead8f291e38481c159fdc5ff808fc1e74d64f56a2d1ba26de5/recurrent-memory-transformer-pytorch-0.5.6.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}