{"1.0.0":{"info":{"author":"Siva Avis","author_email":"forhacku@gmail.com","bugtrack_url":null,"classifiers":["Intended Audience :: Developers","License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)","Programming Language :: Python :: 3","Topic :: Communications","Topic :: Software Development :: Libraries"],"description_content_type":null,"docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/username/","keywords":"gskrawler scraping website emails data webcrawler","license":"","maintainer":"","maintainer_email":"","name":"gskrawler","package_url":"https://pypi.org/project/gskrawler/","platform":"","project_url":"https://pypi.org/project/gskrawler/","project_urls":{"Homepage":"https://github.com/username/"},"provides_extra":null,"release_url":"https://pypi.org/project/gskrawler/1.0.0/","requires_dist":null,"requires_python":"","summary":"gskrawler will enter your domain and scan every page of your website, extracting page titles, descriptions, keywords, and links etc..","version":"1.0.0","yanked":false,"yanked_reason":null},"last_serial":3419552,"urls":[{"comment_text":"","digests":{"blake2b_256":"02c924fe4def0001451535a2390627b5d7e96f7a102d096aa130bd92da1ad713","md5":"346f65562428ab34096fd54cc65daa1d","sha256":"0686faaf69bd5d18b8a643f528e434658c91840204a473878f05d7692da8d8dc"},"downloads":-1,"filename":"gskrawler-1.0.0.tar.gz","has_sig":false,"md5_digest":"346f65562428ab34096fd54cc65daa1d","packagetype":"sdist","python_version":"source","requires_python":null,"size":16248,"upload_time":"2017-12-15T10:35:36","upload_time_iso_8601":"2017-12-15T10:35:36.196118Z","url":"https://files.pythonhosted.org/packages/02/c9/24fe4def0001451535a2390627b5d7e96f7a102d096aa130bd92da1ad713/gskrawler-1.0.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}