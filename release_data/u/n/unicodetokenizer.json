{"0.0.0":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.0.0/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.0.0","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"05f7320fe71db95a096c6a6aea800053db81f686e6402ee5e2710ce75020a53f","md5":"76a084e3ca3d987a892eed0f7ba16e7f","sha256":"9af978b00e80079b336b25531119fbb2ad05beb0cabb87b796ba0b0ac412fbc3"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.0-py3-none-any.whl","has_sig":false,"md5_digest":"76a084e3ca3d987a892eed0f7ba16e7f","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":5453,"upload_time":"2022-06-25T12:26:44","upload_time_iso_8601":"2022-06-25T12:26:44.146089Z","url":"https://files.pythonhosted.org/packages/05/f7/320fe71db95a096c6a6aea800053db81f686e6402ee5e2710ce75020a53f/UnicodeTokenizer-0.0.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"99c02f0c9e1644c2626e863848c527624bb74d637834dd8fcfe9ffb34d5667e5","md5":"ccd9d0f850bf3c0bc7cca1161af622cf","sha256":"285afd28905e9273d44bf4af77146e0be5c934bf45a6b785e2f3f8fdf71e4eb1"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.0.tar.gz","has_sig":false,"md5_digest":"ccd9d0f850bf3c0bc7cca1161af622cf","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":5663,"upload_time":"2022-06-25T12:26:46","upload_time_iso_8601":"2022-06-25T12:26:46.239584Z","url":"https://files.pythonhosted.org/packages/99/c0/2f0c9e1644c2626e863848c527624bb74d637834dd8fcfe9ffb34d5667e5/UnicodeTokenizer-0.0.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.1":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.0.1/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.0.1","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"edffc580a30f96537b9103008479f77e68c3dc4dae05fb6649d7982e3195f9b4","md5":"338cb4673244f8b9f6ee4ad1723195fc","sha256":"d319469ee74add7311bcd5bff441b5130879f53d37b126db51b9264da370e7e4"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.1-py2.py3-none-any.whl","has_sig":false,"md5_digest":"338cb4673244f8b9f6ee4ad1723195fc","packagetype":"bdist_wheel","python_version":"py2.py3","requires_python":">=3.0","size":30503,"upload_time":"2022-06-26T14:14:54","upload_time_iso_8601":"2022-06-26T14:14:54.659198Z","url":"https://files.pythonhosted.org/packages/ed/ff/c580a30f96537b9103008479f77e68c3dc4dae05fb6649d7982e3195f9b4/UnicodeTokenizer-0.0.1-py2.py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"04031f6bd90979767d2e28786554df5d1db406b63c82a278b5acf49b674de026","md5":"122b366104bc4e54088c697ef610e9ee","sha256":"8b6a22222143c81149b8e6276d93df9df9c149312c1e1df1d0742289e3837768"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.1-py3.9.egg","has_sig":false,"md5_digest":"122b366104bc4e54088c697ef610e9ee","packagetype":"bdist_egg","python_version":"0.0.1","requires_python":">=3.0","size":60527,"upload_time":"2022-06-26T14:14:58","upload_time_iso_8601":"2022-06-26T14:14:58.632123Z","url":"https://files.pythonhosted.org/packages/04/03/1f6bd90979767d2e28786554df5d1db406b63c82a278b5acf49b674de026/UnicodeTokenizer-0.0.1-py3.9.egg","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e345863b9144a41c1ac2d2de61473be2c9940c676cb8c91fe9efc938550d2075","md5":"927fda1507fae7752a281ae544c8a26c","sha256":"549f1469c4e056f0a107144069b5fe556496d8ecb5d7aa4c7b80d70a7918f7b1"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.1-py3-none-any.whl","has_sig":false,"md5_digest":"927fda1507fae7752a281ae544c8a26c","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":5467,"upload_time":"2022-06-25T12:32:38","upload_time_iso_8601":"2022-06-25T12:32:38.201542Z","url":"https://files.pythonhosted.org/packages/e3/45/863b9144a41c1ac2d2de61473be2c9940c676cb8c91fe9efc938550d2075/UnicodeTokenizer-0.0.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d8fbfc09c4a8fb5b638ec7cff884b5e3e62d004d3890f9c8a16a2ccf106ad792","md5":"5199742cf48a8f84c872c75a3980cff8","sha256":"85ad3d53ce1370da494e69d6cbebaea13847418f399c120bcef206794e31ca37"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.1.tar.gz","has_sig":false,"md5_digest":"5199742cf48a8f84c872c75a3980cff8","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":5684,"upload_time":"2022-06-25T12:32:41","upload_time_iso_8601":"2022-06-25T12:32:41.448794Z","url":"https://files.pythonhosted.org/packages/d8/fb/fc09c4a8fb5b638ec7cff884b5e3e62d004d3890f9c8a16a2ccf106ad792/UnicodeTokenizer-0.0.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.2":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.0.2/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.0.2","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"a88236c5b0834c35c1bb773ac763fc945c0aaeb37bc5a6f8a669037298a6ad54","md5":"52e810248f20b7ea5c272276b0632270","sha256":"f0b921dddcf36e180e17d98523c876d9c38ec9fad23939941f4968e15991a026"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.2-py3-none-any.whl","has_sig":false,"md5_digest":"52e810248f20b7ea5c272276b0632270","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":30543,"upload_time":"2022-06-26T14:14:56","upload_time_iso_8601":"2022-06-26T14:14:56.719528Z","url":"https://files.pythonhosted.org/packages/a8/82/36c5b0834c35c1bb773ac763fc945c0aaeb37bc5a6f8a669037298a6ad54/UnicodeTokenizer-0.0.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"318b3520d5208c9fcb960d2689e5d59062bfe7391fadcbad0dd425e8af81369e","md5":"d4bd5caadf865192d33b3909ba21d854","sha256":"949a7f8884a851aba68e35253d310e13716be60d2d9a0a89a43be9dd24779f91"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.2.tar.gz","has_sig":false,"md5_digest":"d4bd5caadf865192d33b3909ba21d854","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":17661,"upload_time":"2022-06-26T14:15:00","upload_time_iso_8601":"2022-06-26T14:15:00.644884Z","url":"https://files.pythonhosted.org/packages/31/8b/3520d5208c9fcb960d2689e5d59062bfe7391fadcbad0dd425e8af81369e/UnicodeTokenizer-0.0.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.3":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.0.3/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.0.3","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"30d349ae7e2e1249d45666bdcbf9a8408f5794cc5b42ea2575360e1d89c05308","md5":"39c9d195dd7d4bed68784f8b432624cd","sha256":"3211279872e7c7bd1318d414ce5ada99383cb3b94a6598014f0ff6d8be89c9db"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.3-py3-none-any.whl","has_sig":false,"md5_digest":"39c9d195dd7d4bed68784f8b432624cd","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":13986,"upload_time":"2022-06-30T16:33:40","upload_time_iso_8601":"2022-06-30T16:33:40.218800Z","url":"https://files.pythonhosted.org/packages/30/d3/49ae7e2e1249d45666bdcbf9a8408f5794cc5b42ea2575360e1d89c05308/UnicodeTokenizer-0.0.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"be47ff960f3d6c2308b1724e262606a8e9375551d9cd27190ab22a566dcc50bc","md5":"be6e0409e1cdb7ae85dac1f4a39265ff","sha256":"ebb620bd3480f4fb47f8d4b3b021dd04b4b8198f111141c0237758740723d853"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.3.tar.gz","has_sig":false,"md5_digest":"be6e0409e1cdb7ae85dac1f4a39265ff","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":17672,"upload_time":"2022-06-30T16:33:42","upload_time_iso_8601":"2022-06-30T16:33:42.507995Z","url":"https://files.pythonhosted.org/packages/be/47/ff960f3d6c2308b1724e262606a8e9375551d9cd27190ab22a566dcc50bc/UnicodeTokenizer-0.0.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.4":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.0.4/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.0.4","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"897ed3533fd9cf31474bcaf612269363595e52023735cc4892717fcb2752c3bb","md5":"ec2eee017631ea7b8a1d5d085ef2c906","sha256":"c63b6d86a3440e3e8036851e89f8df6bbb32a363418f2cade04fdbbca4eeca77"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.4-py3-none-any.whl","has_sig":false,"md5_digest":"ec2eee017631ea7b8a1d5d085ef2c906","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":13982,"upload_time":"2022-07-05T14:06:42","upload_time_iso_8601":"2022-07-05T14:06:42.066998Z","url":"https://files.pythonhosted.org/packages/89/7e/d3533fd9cf31474bcaf612269363595e52023735cc4892717fcb2752c3bb/UnicodeTokenizer-0.0.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"88de463058fd51486082fca99ee4d23f0b8d8b59bed41cbfdb83d12730f93b22","md5":"2d28b169af38dd591ac51da69e25522c","sha256":"fc8142ea4ae92a89275cd62d29aae0f1e036eeed8a22525b418e13a998b0c194"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.4.tar.gz","has_sig":false,"md5_digest":"2d28b169af38dd591ac51da69e25522c","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":17666,"upload_time":"2022-07-05T14:06:44","upload_time_iso_8601":"2022-07-05T14:06:44.450949Z","url":"https://files.pythonhosted.org/packages/88/de/463058fd51486082fca99ee4d23f0b8d8b59bed41cbfdb83d12730f93b22/UnicodeTokenizer-0.0.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.5":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.0.5/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.0.5","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"f5324cd36c68195ce700b9c48cff0d6dc4700c12b1c7741c5bbff296e2003113","md5":"1ee6859a2b198b4659299a3441a7ffe9","sha256":"75bcde58eb6e1b32f24945dc2d636ab6f70936e4e14dc5f67cfc44151e2623b7"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.5-py3-none-any.whl","has_sig":false,"md5_digest":"1ee6859a2b198b4659299a3441a7ffe9","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":13938,"upload_time":"2022-07-11T12:55:38","upload_time_iso_8601":"2022-07-11T12:55:38.638940Z","url":"https://files.pythonhosted.org/packages/f5/32/4cd36c68195ce700b9c48cff0d6dc4700c12b1c7741c5bbff296e2003113/UnicodeTokenizer-0.0.5-py3-none-any.whl","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.6":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.0.6/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.0.6","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"8c0c8c71f77311db187003f2741587c817f23dcbe82169ad5648501d01224bdc","md5":"bd2341dc41ff93d6c0b4febacf419961","sha256":"03ab83ffbe210f76d4f7b8c2d73c3064ff633d7cf75d3958779a963bcb946ae5"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.6-py3-none-any.whl","has_sig":false,"md5_digest":"bd2341dc41ff93d6c0b4febacf419961","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":13896,"upload_time":"2022-07-18T13:53:03","upload_time_iso_8601":"2022-07-18T13:53:03.772267Z","url":"https://files.pythonhosted.org/packages/8c/0c/8c71f77311db187003f2741587c817f23dcbe82169ad5648501d01224bdc/UnicodeTokenizer-0.0.6-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a1faa73908deb93262d5a66c3b8646690fd6fa2cd0ae0ce9fcc706d02552416d","md5":"7975ce63f3295c01d6019072676b1df4","sha256":"093a358bf6334e49f4d1502bfa62fe6aa04d9d78f30d098e60284bdfd0b5a2f9"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.6.tar.gz","has_sig":false,"md5_digest":"7975ce63f3295c01d6019072676b1df4","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":17633,"upload_time":"2022-07-18T13:53:06","upload_time_iso_8601":"2022-07-18T13:53:06.901564Z","url":"https://files.pythonhosted.org/packages/a1/fa/a73908deb93262d5a66c3b8646690fd6fa2cd0ae0ce9fcc706d02552416d/UnicodeTokenizer-0.0.6.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.7":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.0.7/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.0.7","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"ffcda776d240041b7bb1ff28cccbdddbe35606caeb8553cbcdeea8c0151ae8d1","md5":"a7caea91e4b160ea3b4628661e89f59a","sha256":"482a893a7bc7a4b58596a812a4fd6ec5199552a9ac7fa250f48d5051cae21099"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.7-py3-none-any.whl","has_sig":false,"md5_digest":"a7caea91e4b160ea3b4628661e89f59a","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":14109,"upload_time":"2022-07-31T15:40:05","upload_time_iso_8601":"2022-07-31T15:40:05.033226Z","url":"https://files.pythonhosted.org/packages/ff/cd/a776d240041b7bb1ff28cccbdddbe35606caeb8553cbcdeea8c0151ae8d1/UnicodeTokenizer-0.0.7-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"42ec147f8409a69e8688b06c7b8b4aaba8fdc3518f6aa351b96ce40e1ded8896","md5":"242bfb5274c8acff7b9b2968eea87d14","sha256":"4d1865e6e45a57097e3f05c0c7ceacd87757cd957169534116ea82eb8461a6d7"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.7.tar.gz","has_sig":false,"md5_digest":"242bfb5274c8acff7b9b2968eea87d14","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":17840,"upload_time":"2022-07-31T15:40:07","upload_time_iso_8601":"2022-07-31T15:40:07.156063Z","url":"https://files.pythonhosted.org/packages/42/ec/147f8409a69e8688b06c7b8b4aaba8fdc3518f6aa351b96ce40e1ded8896/UnicodeTokenizer-0.0.7.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.8":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.0.8/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.0.8","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"d3ee7c7417cd619200b89c1a80c15296927215e6320796a03a5e6f9df8760dd0","md5":"4a1b259e02b00d66af9bd639492afc81","sha256":"22e24c6f3b9371123d861e4a0d3a72feefc583bbfe6727227524338397df81ec"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.8-py3-none-any.whl","has_sig":false,"md5_digest":"4a1b259e02b00d66af9bd639492afc81","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":13845,"upload_time":"2022-08-15T12:52:49","upload_time_iso_8601":"2022-08-15T12:52:49.606555Z","url":"https://files.pythonhosted.org/packages/d3/ee/7c7417cd619200b89c1a80c15296927215e6320796a03a5e6f9df8760dd0/UnicodeTokenizer-0.0.8-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"4d90ab67e33c16f7757156f24d2dd8c7341b9952daf3da71cfb8402bbea2304c","md5":"0496f7b82ef3280f218f962229ab09bf","sha256":"c4392e8a47a017f3bb9e8ee07c5da8fb3a83785af6497bc93a24a7d01bc90e3e"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.8.tar.gz","has_sig":false,"md5_digest":"0496f7b82ef3280f218f962229ab09bf","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":13694,"upload_time":"2022-08-15T12:52:51","upload_time_iso_8601":"2022-08-15T12:52:51.574935Z","url":"https://files.pythonhosted.org/packages/4d/90/ab67e33c16f7757156f24d2dd8c7341b9952daf3da71cfb8402bbea2304c/UnicodeTokenizer-0.0.8.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.0.9":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.0.9/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.0.9","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"6beaf0aede76e6205a1ded9b9bc09898a9e55c0196bb50139be525675ec1cf32","md5":"fd5a111d1505aa2cdeb49b94b08c2cbe","sha256":"639d1d47697c37e3640cdfb68dcfcaf230ef3ec0fa26c1cfe799b639713a5609"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.9-py3-none-any.whl","has_sig":false,"md5_digest":"fd5a111d1505aa2cdeb49b94b08c2cbe","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":6823,"upload_time":"2022-12-22T15:24:37","upload_time_iso_8601":"2022-12-22T15:24:37.387239Z","url":"https://files.pythonhosted.org/packages/6b/ea/f0aede76e6205a1ded9b9bc09898a9e55c0196bb50139be525675ec1cf32/UnicodeTokenizer-0.0.9-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d77ff55c3baf4c4b616b1dd773e212536a9ae34b70dbd94252e67bbfe809c397","md5":"f20457d396be2b64f7a41a98391d799c","sha256":"dbfddfee2345919111464c6e2da462d6790433662a6465f53d698d96a94d747c"},"downloads":-1,"filename":"UnicodeTokenizer-0.0.9.tar.gz","has_sig":false,"md5_digest":"f20457d396be2b64f7a41a98391d799c","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":6772,"upload_time":"2022-12-22T15:24:39","upload_time_iso_8601":"2022-12-22T15:24:39.006172Z","url":"https://files.pythonhosted.org/packages/d7/7f/f55c3baf4c4b616b1dd773e212536a9ae34b70dbd94252e67bbfe809c397/UnicodeTokenizer-0.0.9.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.0":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.1.0/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.1.0","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"a36cb2e7d0c2925061a3bc53fdb632a6b10dce30a1b220af942d2d502449204f","md5":"4dced36859a8fcf9a9d072db0a9d9234","sha256":"23f333c8f5837bc415717069823e10bd982035171138d232f59a5b84d8e4e9a1"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.0-py3-none-any.whl","has_sig":false,"md5_digest":"4dced36859a8fcf9a9d072db0a9d9234","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":5950,"upload_time":"2023-01-01T02:26:50","upload_time_iso_8601":"2023-01-01T02:26:50.439418Z","url":"https://files.pythonhosted.org/packages/a3/6c/b2e7d0c2925061a3bc53fdb632a6b10dce30a1b220af942d2d502449204f/UnicodeTokenizer-0.1.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"b83a6275eb13cbc58ce7e610406da706f1697a8f9bcb127ede8c2b3dc6b40252","md5":"8a41a3af17b4dbc6d81578ed8239d4ef","sha256":"734b7a0f82f017b725686d880542bb5fbe86cc234d2e52982d4edda7871528ef"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.0.tar.gz","has_sig":false,"md5_digest":"8a41a3af17b4dbc6d81578ed8239d4ef","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":5908,"upload_time":"2023-01-01T02:26:52","upload_time_iso_8601":"2023-01-01T02:26:52.467733Z","url":"https://files.pythonhosted.org/packages/b8/3a/6275eb13cbc58ce7e610406da706f1697a8f9bcb127ede8c2b3dc6b40252/UnicodeTokenizer-0.1.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.1":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.1.1/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.1.1","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"a2d31582c8936571165be575bd6573226e0c87d84d10b908884affed24072a02","md5":"9f03eb493f6cf0410321d224b1dd690d","sha256":"062f59acd298d7160e876f4ec2ad2bba2f163e07be38d11f2e94457949869cf0"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.1-py3-none-any.whl","has_sig":false,"md5_digest":"9f03eb493f6cf0410321d224b1dd690d","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":5956,"upload_time":"2023-01-09T14:30:01","upload_time_iso_8601":"2023-01-09T14:30:01.190483Z","url":"https://files.pythonhosted.org/packages/a2/d3/1582c8936571165be575bd6573226e0c87d84d10b908884affed24072a02/UnicodeTokenizer-0.1.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"e41db835a46861aeb664f380633a9cd51de853a1a8ac5db174400a4487e1eb19","md5":"f83180da1ad2262262ae4ffc3c2dc715","sha256":"453db76d0d168afeaf5b1eb9490eb34afee4b7f24b2c6aaa0a47f69b247b506a"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.1.tar.gz","has_sig":false,"md5_digest":"f83180da1ad2262262ae4ffc3c2dc715","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":5923,"upload_time":"2023-01-09T14:30:03","upload_time_iso_8601":"2023-01-09T14:30:03.225600Z","url":"https://files.pythonhosted.org/packages/e4/1d/b835a46861aeb664f380633a9cd51de853a1a8ac5db174400a4487e1eb19/UnicodeTokenizer-0.1.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.10":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.1.10/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.1.10","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"33983897bcbd7057dc8c98e73fb16adc8700d04210b2288b4c18c8c485f392e0","md5":"b4282a5a66b108eb278e5bfc212d3c3f","sha256":"88808a533ed335ca79d13e7791f11987c49bbe6869a6eddbed37baeedede1d58"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.10-py3-none-any.whl","has_sig":false,"md5_digest":"b4282a5a66b108eb278e5bfc212d3c3f","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":5987,"upload_time":"2023-03-12T10:50:08","upload_time_iso_8601":"2023-03-12T10:50:08.319606Z","url":"https://files.pythonhosted.org/packages/33/98/3897bcbd7057dc8c98e73fb16adc8700d04210b2288b4c18c8c485f392e0/UnicodeTokenizer-0.1.10-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"0c35b295f3ae8ab6c21424a83fec10f5d20ad87055ed4874c1c10b1fd3f58234","md5":"95bbb93fffab9b9a68fdaef1b5164563","sha256":"9cc0fcfaeda0e0c44f15566b8ff5bc46e919187e6d894200f28fa713d4f15baa"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.10.tar.gz","has_sig":false,"md5_digest":"95bbb93fffab9b9a68fdaef1b5164563","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":5886,"upload_time":"2023-03-12T10:50:10","upload_time_iso_8601":"2023-03-12T10:50:10.267955Z","url":"https://files.pythonhosted.org/packages/0c/35/b295f3ae8ab6c21424a83fec10f5d20ad87055ed4874c1c10b1fd3f58234/UnicodeTokenizer-0.1.10.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.11":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.1.11/","requires_dist":["PyICU","tokenizers"],"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.1.11","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"52f0499f7e050d8c54e12f1d7d6df89fe2790086d1a2a68d0bd6fe086629d8cc","md5":"4fc02c2f2c42b7f66cf5fa8c3551a31f","sha256":"56412ce01563fd447fee8de66c8844114d74e4819f2c5aaa03306716d505785e"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.11-py3-none-any.whl","has_sig":false,"md5_digest":"4fc02c2f2c42b7f66cf5fa8c3551a31f","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":4193,"upload_time":"2023-09-19T18:14:02","upload_time_iso_8601":"2023-09-19T18:14:02.607464Z","url":"https://files.pythonhosted.org/packages/52/f0/499f7e050d8c54e12f1d7d6df89fe2790086d1a2a68d0bd6fe086629d8cc/UnicodeTokenizer-0.1.11-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"4ed4886886999ee9bb78c790b459133e379e06ca2b7d9603590365050d4f4a89","md5":"08bd8cac93fec839e7477dc3882d2caf","sha256":"7853fbd820ccd9d4628fcd6bea388b7c506663df935cffc303584ab2568fde0a"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.11.tar.gz","has_sig":false,"md5_digest":"08bd8cac93fec839e7477dc3882d2caf","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":3584,"upload_time":"2023-09-19T18:14:04","upload_time_iso_8601":"2023-09-19T18:14:04.523992Z","url":"https://files.pythonhosted.org/packages/4e/d4/886886999ee9bb78c790b459133e379e06ca2b7d9603590365050d4f4a89/UnicodeTokenizer-0.1.11.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.2":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.1.2/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.1.2","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"06c0f11d3b773348bd1940cd69bb1d231f688efc452ba8fc34748fbe798a9ae3","md5":"c719ff5577600b8284ce545626ccde29","sha256":"7f56fb3ea2b4597cccf269c4b6a3efc1359636168239f809285a645f56e60ef9"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.2-py3-none-any.whl","has_sig":false,"md5_digest":"c719ff5577600b8284ce545626ccde29","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":5959,"upload_time":"2023-01-09T15:07:18","upload_time_iso_8601":"2023-01-09T15:07:18.826397Z","url":"https://files.pythonhosted.org/packages/06/c0/f11d3b773348bd1940cd69bb1d231f688efc452ba8fc34748fbe798a9ae3/UnicodeTokenizer-0.1.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"4c176fb47f0c639bafc49626d0b785e71d48c0e014b7e253c86ef935e3574ab7","md5":"b34654c67aa5c54e856dad7b82da824c","sha256":"fffb5c45c6fc8c365c443d651db203df3ddb298e3a62cda7107f6802ec28ec0a"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.2.tar.gz","has_sig":false,"md5_digest":"b34654c67aa5c54e856dad7b82da824c","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":5937,"upload_time":"2023-01-09T15:07:20","upload_time_iso_8601":"2023-01-09T15:07:20.535258Z","url":"https://files.pythonhosted.org/packages/4c/17/6fb47f0c639bafc49626d0b785e71d48c0e014b7e253c86ef935e3574ab7/UnicodeTokenizer-0.1.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.3":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.1.3/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.1.3","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"9b6369108eea9465bc57ff638b5474c75031e1714c28d67fd6500de4fdd5af33","md5":"d31a27fe35cc2fdc6edc7c387ed32cb6","sha256":"3e04919e38a61f86a648bb66b04926ae7f83e893b191590b1d8e7522bc5840b4"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.3-py3-none-any.whl","has_sig":false,"md5_digest":"d31a27fe35cc2fdc6edc7c387ed32cb6","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":5961,"upload_time":"2023-01-09T15:09:22","upload_time_iso_8601":"2023-01-09T15:09:22.214925Z","url":"https://files.pythonhosted.org/packages/9b/63/69108eea9465bc57ff638b5474c75031e1714c28d67fd6500de4fdd5af33/UnicodeTokenizer-0.1.3-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"f2d01c0c27b6b02a176736bf369ec32f14cb5841cd448c84e2db5beefb9df0a4","md5":"861e2fffe12ab1e8516c6ff2fed91ed2","sha256":"afb4c2a18650f98118d621e4dad74df82bd64f7af0df8cf75705a9cc05bd5bbc"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.3.tar.gz","has_sig":false,"md5_digest":"861e2fffe12ab1e8516c6ff2fed91ed2","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":5920,"upload_time":"2023-01-09T15:09:24","upload_time_iso_8601":"2023-01-09T15:09:24.070150Z","url":"https://files.pythonhosted.org/packages/f2/d0/1c0c27b6b02a176736bf369ec32f14cb5841cd448c84e2db5beefb9df0a4/UnicodeTokenizer-0.1.3.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.4":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.1.4/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.1.4","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"d8269dd2a5685d179f596156bf06365eeba4efe35b5a910098643116ff3bfb9d","md5":"24ac36090e94d3fcf13b73d2967b3dd0","sha256":"d4423ac738fcb20045fe52258a8df0b03c67cc141dc87150497690645a24b4f6"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.4-py3-none-any.whl","has_sig":false,"md5_digest":"24ac36090e94d3fcf13b73d2967b3dd0","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":5872,"upload_time":"2023-01-09T15:24:33","upload_time_iso_8601":"2023-01-09T15:24:33.676768Z","url":"https://files.pythonhosted.org/packages/d8/26/9dd2a5685d179f596156bf06365eeba4efe35b5a910098643116ff3bfb9d/UnicodeTokenizer-0.1.4-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"c2f4f97333b9278adcf21eda3242554ba02508855849a8a23ff1332d54cb6116","md5":"f34fca1ce3d3db33d01b5805d97ac9a5","sha256":"0b289f53ac1cb282e6bbb5f7b70c61f9d20f976ce7767a584a46f2adabe5974b"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.4.tar.gz","has_sig":false,"md5_digest":"f34fca1ce3d3db33d01b5805d97ac9a5","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":5829,"upload_time":"2023-01-09T15:24:35","upload_time_iso_8601":"2023-01-09T15:24:35.224683Z","url":"https://files.pythonhosted.org/packages/c2/f4/f97333b9278adcf21eda3242554ba02508855849a8a23ff1332d54cb6116/UnicodeTokenizer-0.1.4.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.5":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.1.5/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.1.5","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"44620f4013016141ea5a31c4e8508de9ae42de18b55b03b9c923f372c03dece4","md5":"0c2a3df8730e0c09819cb9033944536b","sha256":"6ab7a1286902eb1c6980d4f9465c12d04b540d6a368ea31f8ae86c1ccb168fc8"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.5-py3-none-any.whl","has_sig":false,"md5_digest":"0c2a3df8730e0c09819cb9033944536b","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":5892,"upload_time":"2023-01-09T15:33:01","upload_time_iso_8601":"2023-01-09T15:33:01.721846Z","url":"https://files.pythonhosted.org/packages/44/62/0f4013016141ea5a31c4e8508de9ae42de18b55b03b9c923f372c03dece4/UnicodeTokenizer-0.1.5-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"cbdd6cdaab97583c4935912d257160bce17529f2500a21f5228b33a7c526a7ba","md5":"3ace4732bd1baeaa86219503ece83534","sha256":"a32ba88ca8f2b643f39f43af51e4d9ca79c9fce3d1c9503163907115aa7b07cb"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.5.tar.gz","has_sig":false,"md5_digest":"3ace4732bd1baeaa86219503ece83534","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":5844,"upload_time":"2023-01-09T15:33:03","upload_time_iso_8601":"2023-01-09T15:33:03.410363Z","url":"https://files.pythonhosted.org/packages/cb/dd/6cdaab97583c4935912d257160bce17529f2500a21f5228b33a7c526a7ba/UnicodeTokenizer-0.1.5.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.6":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.1.6/","requires_dist":null,"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.1.6","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"f680b39c891a9086b2b35a6361ca5138d2cf773b2f4a03ec9adcf0df35197594","md5":"56f19aa1baa508f3682e4a94e2f4acc6","sha256":"54d0451e0472fecd4b30a564e288263e4eae86554190d0d5a895a25da9ed933b"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.6-py3-none-any.whl","has_sig":false,"md5_digest":"56f19aa1baa508f3682e4a94e2f4acc6","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":6031,"upload_time":"2023-02-09T14:16:02","upload_time_iso_8601":"2023-02-09T14:16:02.753725Z","url":"https://files.pythonhosted.org/packages/f6/80/b39c891a9086b2b35a6361ca5138d2cf773b2f4a03ec9adcf0df35197594/UnicodeTokenizer-0.1.6-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"a94b1c5a45784c93dfcbeb54a01c190e87019308b7645537d48b469d46f013f8","md5":"7e6a74a591fa8a5276310991c19a27ce","sha256":"0981abddddc37c870a370cc88101c79f49679985619f6f5aec46a76f0a0c430c"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.6.tar.gz","has_sig":false,"md5_digest":"7e6a74a591fa8a5276310991c19a27ce","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":5989,"upload_time":"2023-02-09T14:16:04","upload_time_iso_8601":"2023-02-09T14:16:04.337669Z","url":"https://files.pythonhosted.org/packages/a9/4b/1c5a45784c93dfcbeb54a01c190e87019308b7645537d48b469d46f013f8/UnicodeTokenizer-0.1.6.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.7":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.1.7/","requires_dist":["regex"],"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.1.7","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"aecb462521924a24b91ecdc4997b1c7aa90cb6b36e0c5ee4e1de8ea2c747e9c4","md5":"d20214234a776d31a9913297c8da9fbd","sha256":"0a7b4cf2f68abc15dbad19a0b3ca50d5c20036bf22bf626a5720013ee4c2fec7"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.7-py3-none-any.whl","has_sig":false,"md5_digest":"d20214234a776d31a9913297c8da9fbd","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":5779,"upload_time":"2023-02-13T18:04:32","upload_time_iso_8601":"2023-02-13T18:04:32.534119Z","url":"https://files.pythonhosted.org/packages/ae/cb/462521924a24b91ecdc4997b1c7aa90cb6b36e0c5ee4e1de8ea2c747e9c4/UnicodeTokenizer-0.1.7-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"7c2fd6d42108db67556b41363febc22ffede44969f9e234fbc1ffb112b6c9fbf","md5":"3659cdb548db651b2d670b8033ee2e17","sha256":"6f87b8df83ed970b6f5747157cd51d1d1b125f26d6135635afb3dd7711cf0002"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.7.tar.gz","has_sig":false,"md5_digest":"3659cdb548db651b2d670b8033ee2e17","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":5771,"upload_time":"2023-02-13T18:04:34","upload_time_iso_8601":"2023-02-13T18:04:34.141724Z","url":"https://files.pythonhosted.org/packages/7c/2f/d6d42108db67556b41363febc22ffede44969f9e234fbc1ffb112b6c9fbf/UnicodeTokenizer-0.1.7.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.8":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.1.8/","requires_dist":["regex"],"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.1.8","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"c0935293daba30c553e413cd4d291019bf49c633d274f9daac0e83c705e68fe6","md5":"dfcd7f866f243b160921c697551e33b4","sha256":"983637c207efccf06efba5bb412efee415d241dcbdc0c29f468822ea2eab0d3a"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.8-py3-none-any.whl","has_sig":false,"md5_digest":"dfcd7f866f243b160921c697551e33b4","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":5841,"upload_time":"2023-02-24T11:56:05","upload_time_iso_8601":"2023-02-24T11:56:05.071999Z","url":"https://files.pythonhosted.org/packages/c0/93/5293daba30c553e413cd4d291019bf49c633d274f9daac0e83c705e68fe6/UnicodeTokenizer-0.1.8-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"d76cfcab519d77d1e02552c6b7e73e3cfdccfef1a94e3048018b6551209a7454","md5":"4db95d10c43faaf3030963b1b062cba6","sha256":"96f0506f0da6f8ef96cf8514ed9f1fb392b20047a131e093d384157b74a92811"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.8.tar.gz","has_sig":false,"md5_digest":"4db95d10c43faaf3030963b1b062cba6","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":5848,"upload_time":"2023-02-24T11:56:06","upload_time_iso_8601":"2023-02-24T11:56:06.553614Z","url":"https://files.pythonhosted.org/packages/d7/6c/fcab519d77d1e02552c6b7e73e3cfdccfef1a94e3048018b6551209a7454/UnicodeTokenizer-0.1.8.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.1.9":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.1.9/","requires_dist":["regex"],"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.1.9","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"2ca18d347da1a886535e0480fe662a1093a9d02bde7ab74a4b1751bf88aa32a2","md5":"743bf4855eb47757e885c6e1aeda9487","sha256":"7df8dbdd20022d14f44dd2af856810a6252af879c1a19a080fa545e8b53e0d89"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.9-py3-none-any.whl","has_sig":false,"md5_digest":"743bf4855eb47757e885c6e1aeda9487","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":5956,"upload_time":"2023-02-24T12:23:31","upload_time_iso_8601":"2023-02-24T12:23:31.984954Z","url":"https://files.pythonhosted.org/packages/2c/a1/8d347da1a886535e0480fe662a1093a9d02bde7ab74a4b1751bf88aa32a2/UnicodeTokenizer-0.1.9-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"60174b6a8b5e0364dbec57e32cc0b70090629ed336c02a10c28e5407395dd555","md5":"a628b52cbb8457794cf322f78f2221f5","sha256":"709c1a036b3e237751ae108074509113ab0c68fcbf4236697c93d1f9d3592c6c"},"downloads":-1,"filename":"UnicodeTokenizer-0.1.9.tar.gz","has_sig":false,"md5_digest":"a628b52cbb8457794cf322f78f2221f5","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":5953,"upload_time":"2023-02-24T12:23:34","upload_time_iso_8601":"2023-02-24T12:23:34.675507Z","url":"https://files.pythonhosted.org/packages/60/17/4b6a8b5e0364dbec57e32cc0b70090629ed336c02a10c28e5407395dd555/UnicodeTokenizer-0.1.9.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.0":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.2.0/","requires_dist":["PyICU","tokenizers"],"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.2.0","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"7f69f037baa0b5aa7ee92c145fa7a4adc1bebc0459ce28f3171f4b2042cd6a26","md5":"97667568ef62c7b879b4382791622c80","sha256":"93c14b906f5095bb0675838314c82240e2cf9682cab02ab7ab5d547e1218de59"},"downloads":-1,"filename":"UnicodeTokenizer-0.2.0-py3-none-any.whl","has_sig":false,"md5_digest":"97667568ef62c7b879b4382791622c80","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":4186,"upload_time":"2023-09-19T18:14:38","upload_time_iso_8601":"2023-09-19T18:14:38.272228Z","url":"https://files.pythonhosted.org/packages/7f/69/f037baa0b5aa7ee92c145fa7a4adc1bebc0459ce28f3171f4b2042cd6a26/UnicodeTokenizer-0.2.0-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"5715835fd598f4b1dbf308af368fa5a9c19f4e1fa61ab21dd9f16ae53636958f","md5":"5e97a7faae5d6185c62349236b767af3","sha256":"9efd0826dec68b1acfaaa264986e29c3dbdebd57ee7e4ad8eadf9f5442d88ed2"},"downloads":-1,"filename":"UnicodeTokenizer-0.2.0.tar.gz","has_sig":false,"md5_digest":"5e97a7faae5d6185c62349236b767af3","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":3598,"upload_time":"2023-09-19T18:14:40","upload_time_iso_8601":"2023-09-19T18:14:40.577116Z","url":"https://files.pythonhosted.org/packages/57/15/835fd598f4b1dbf308af368fa5a9c19f4e1fa61ab21dd9f16ae53636958f/UnicodeTokenizer-0.2.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.1":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.2.1/","requires_dist":["PyICU","tokenizers"],"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.2.1","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"25a2d98f1afc8ad08e088c11f9f03c9447c515881638f43a62092d58a425fbe6","md5":"522970a1d2893e861578c1e49b884e31","sha256":"cce580cd591193fe6048507a7653607b71d510ad248a93224163fd6002d1ca0e"},"downloads":-1,"filename":"UnicodeTokenizer-0.2.1-py3-none-any.whl","has_sig":false,"md5_digest":"522970a1d2893e861578c1e49b884e31","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":3378,"upload_time":"2023-09-20T21:46:36","upload_time_iso_8601":"2023-09-20T21:46:36.204039Z","url":"https://files.pythonhosted.org/packages/25/a2/d98f1afc8ad08e088c11f9f03c9447c515881638f43a62092d58a425fbe6/UnicodeTokenizer-0.2.1-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"f6a568de89c174308d4d267291aef1d884fc49d886b76d531fe99212d3ea5f32","md5":"45381b7ffa502de618c1d5a3b61a5292","sha256":"8cec0a3d4cac829ad77270bf9feef3975307b56e339ba8ee21d0fd00234595d4"},"downloads":-1,"filename":"UnicodeTokenizer-0.2.1.tar.gz","has_sig":false,"md5_digest":"45381b7ffa502de618c1d5a3b61a5292","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":2729,"upload_time":"2023-09-20T21:46:37","upload_time_iso_8601":"2023-09-20T21:46:37.997597Z","url":"https://files.pythonhosted.org/packages/f6/a5/68de89c174308d4d267291aef1d884fc49d886b76d531fe99212d3ea5f32/UnicodeTokenizer-0.2.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"0.2.2":{"info":{"author":"laohur","author_email":"laohur@gmail.com","bugtrack_url":null,"classifiers":[],"description_content_type":"text/markdown","docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/laohur/UnicodeTokenizer","keywords":"UnicodeTokenizer,Tokenizer,Unicode,ZiTokenizer,ZiCutter,laohur","license":"[Anti-996 License](https: // github.com/996icu/996.ICU/blob/master/LICENSE)","maintainer":"","maintainer_email":"","name":"UnicodeTokenizer","package_url":"https://pypi.org/project/UnicodeTokenizer/","platform":null,"project_url":"https://pypi.org/project/UnicodeTokenizer/","project_urls":{"Homepage":"https://github.com/laohur/UnicodeTokenizer"},"provides_extra":null,"release_url":"https://pypi.org/project/UnicodeTokenizer/0.2.2/","requires_dist":["PyICU","tokenizers"],"requires_python":">=3.0","summary":"UnicodeTokenizer: tokenize all Unicode text","version":"0.2.2","yanked":false,"yanked_reason":null},"last_serial":20625539,"urls":[{"comment_text":"","digests":{"blake2b_256":"e5234c8a7ed50a7bb75c655f1c62765a0d1c0146937a0fb33f359cf70cc25d40","md5":"df4001275e17c125ed61570630bc8851","sha256":"e7116273a9c35d812146c10f9c521c71c47b6b8f3095a558ba7fa1d349e0595b"},"downloads":-1,"filename":"UnicodeTokenizer-0.2.2-py3-none-any.whl","has_sig":false,"md5_digest":"df4001275e17c125ed61570630bc8851","packagetype":"bdist_wheel","python_version":"py3","requires_python":">=3.0","size":3480,"upload_time":"2023-11-14T13:53:03","upload_time_iso_8601":"2023-11-14T13:53:03.968172Z","url":"https://files.pythonhosted.org/packages/e5/23/4c8a7ed50a7bb75c655f1c62765a0d1c0146937a0fb33f359cf70cc25d40/UnicodeTokenizer-0.2.2-py3-none-any.whl","yanked":false,"yanked_reason":null},{"comment_text":"","digests":{"blake2b_256":"56c07ec0c8cda52fb720b3579c9e881bf4ce27eb602052bb95cc7c0602f3372b","md5":"5b63f3cc4622ab47a188a6f2744c7b4a","sha256":"579e817b08b2b01c3d4c4139689d1a9844714de41403ecb936a7a638f7cfb042"},"downloads":-1,"filename":"UnicodeTokenizer-0.2.2.tar.gz","has_sig":false,"md5_digest":"5b63f3cc4622ab47a188a6f2744c7b4a","packagetype":"sdist","python_version":"source","requires_python":">=3.0","size":2832,"upload_time":"2023-11-14T13:53:05","upload_time_iso_8601":"2023-11-14T13:53:05.961542Z","url":"https://files.pythonhosted.org/packages/56/c0/7ec0c8cda52fb720b3579c9e881bf4ce27eb602052bb95cc7c0602f3372b/UnicodeTokenizer-0.2.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}