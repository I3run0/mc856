{"1.0":{"info":{"author":"Simon Descarpentries","author_email":"contact@acoeuro.com","bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","Intended Audience :: End Users/Desktop","License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)","Operating System :: OS Independent","Programming Language :: Python :: 3","Topic :: Internet :: WWW/HTTP"],"description_content_type":null,"docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/Siltaar/doc_crawler.py","keywords":"crawler downloader recursive pdf-extractor web-crawler web-crawler-python file-download","license":"","maintainer":"","maintainer_email":"","name":"doc_crawler","package_url":"https://pypi.org/project/doc_crawler/","platform":"","project_url":"https://pypi.org/project/doc_crawler/","project_urls":{"Homepage":"https://github.com/Siltaar/doc_crawler.py"},"provides_extra":null,"release_url":"https://pypi.org/project/doc_crawler/1.0/","requires_dist":null,"requires_python":"","summary":"Explore a website recursively and download all the wanted documents (PDF, ODT…)","version":"1.0","yanked":false,"yanked_reason":null},"last_serial":3648620,"urls":[{"comment_text":"","digests":{"blake2b_256":"b48752d7f95d1cd72db0b1877dc4363f1f8f3227e4272d8f3edd89055fce27d4","md5":"3de98da7d87403126c1095f60120a450","sha256":"2ffe66eadb16480fc72ef28186b54157ed7144a11ccbbc8a0f90c58f050c3afe"},"downloads":-1,"filename":"doc_crawler-1.0.tar.gz","has_sig":false,"md5_digest":"3de98da7d87403126c1095f60120a450","packagetype":"sdist","python_version":"source","requires_python":null,"size":5347,"upload_time":"2017-08-29T16:36:54","upload_time_iso_8601":"2017-08-29T16:36:54.145057Z","url":"https://files.pythonhosted.org/packages/b4/87/52d7f95d1cd72db0b1877dc4363f1f8f3227e4272d8f3edd89055fce27d4/doc_crawler-1.0.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.1":{"info":{"author":"Simon Descarpentries","author_email":"contact@acoeuro.com","bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","Intended Audience :: End Users/Desktop","License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)","Operating System :: OS Independent","Programming Language :: Python :: 3","Topic :: Internet :: WWW/HTTP"],"description_content_type":null,"docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/Siltaar/doc_crawler.py","keywords":"crawler downloader recursive pdf-extractor web-crawler web-crawler-python file-download","license":"","maintainer":"","maintainer_email":"","name":"doc_crawler","package_url":"https://pypi.org/project/doc_crawler/","platform":"","project_url":"https://pypi.org/project/doc_crawler/","project_urls":{"Homepage":"https://github.com/Siltaar/doc_crawler.py"},"provides_extra":null,"release_url":"https://pypi.org/project/doc_crawler/1.1/","requires_dist":null,"requires_python":"","summary":"Explore a website recursively and download all the wanted documents (PDF, ODT…)","version":"1.1","yanked":false,"yanked_reason":null},"last_serial":3648620,"urls":[{"comment_text":"","digests":{"blake2b_256":"7965b3b70c3b39baa1f314a61065fdfd6ca871add9388f78efd98da0d9857349","md5":"a5df0389fa1ae623eb5354383641097c","sha256":"5953248e21b3d9a6239ff946e935223918421776d85ff37847b693f585f29164"},"downloads":-1,"filename":"doc_crawler-1.1.tar.gz","has_sig":false,"md5_digest":"a5df0389fa1ae623eb5354383641097c","packagetype":"sdist","python_version":"source","requires_python":null,"size":5714,"upload_time":"2017-08-30T10:21:53","upload_time_iso_8601":"2017-08-30T10:21:53.744328Z","url":"https://files.pythonhosted.org/packages/79/65/b3b70c3b39baa1f314a61065fdfd6ca871add9388f78efd98da0d9857349/doc_crawler-1.1.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]},"1.2":{"info":{"author":"Simon Descarpentries","author_email":"contact@acoeuro.com","bugtrack_url":null,"classifiers":["Development Status :: 5 - Production/Stable","Intended Audience :: Developers","Intended Audience :: End Users/Desktop","License :: OSI Approved :: GNU General Public License v3 or later (GPLv3+)","Operating System :: OS Independent","Programming Language :: Python :: 3","Topic :: Internet :: WWW/HTTP"],"description_content_type":null,"docs_url":null,"download_url":"","downloads":{"last_day":-1,"last_month":-1,"last_week":-1},"dynamic":null,"home_page":"https://github.com/Siltaar/doc_crawler.py","keywords":"crawler downloader recursive pdf-extractor web-crawler web-crawler-python file-download pdf zip doc odt","license":"","maintainer":"","maintainer_email":"","name":"doc_crawler","package_url":"https://pypi.org/project/doc_crawler/","platform":"","project_url":"https://pypi.org/project/doc_crawler/","project_urls":{"Homepage":"https://github.com/Siltaar/doc_crawler.py"},"provides_extra":null,"release_url":"https://pypi.org/project/doc_crawler/1.2/","requires_dist":null,"requires_python":"","summary":"Explore a website recursively and download all the wanted documents (PDF, ODT…)","version":"1.2","yanked":false,"yanked_reason":null},"last_serial":3648620,"urls":[{"comment_text":"","digests":{"blake2b_256":"c61599098901d30e2d055c138be7d594ab14794bc3475bd0713bcc8c0df305b3","md5":"4a9ad71302fffd7a30901eefe1caa3a8","sha256":"148a2f660520a6334ebc6c19721776642dd458288fb091cd4e42554cb0d8453c"},"downloads":-1,"filename":"doc_crawler-1.2.tar.gz","has_sig":false,"md5_digest":"4a9ad71302fffd7a30901eefe1caa3a8","packagetype":"sdist","python_version":"source","requires_python":null,"size":6190,"upload_time":"2018-03-07T18:18:59","upload_time_iso_8601":"2018-03-07T18:18:59.301123Z","url":"https://files.pythonhosted.org/packages/c6/15/99098901d30e2d055c138be7d594ab14794bc3475bd0713bcc8c0df305b3/doc_crawler-1.2.tar.gz","yanked":false,"yanked_reason":null}],"vulnerabilities":[]}}